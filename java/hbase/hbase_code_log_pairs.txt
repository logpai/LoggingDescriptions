peerConn.close();	}	}	Connection conn = ConnectionFactory.createConnection(job.getConfiguration());	try {	TokenUtil.addTokenForJob(conn, user, job);	} finally {	conn.close();	}	} catch (InterruptedException ie) {	
interrupted obtaining user authentication token 

UserProvider userProvider = UserProvider.instantiate(job.getConfiguration());	if (userProvider.isHBaseSecurityEnabled()) {	try {	Connection peerConn = ConnectionFactory.createConnection(conf);	try {	TokenUtil.addTokenForJob(peerConn, userProvider.getCurrent(), job);	} finally {	peerConn.close();	}	} catch (InterruptedException e) {	
interrupted obtaining user authentication token 

public static void addDependencyJars(Configuration conf, Class<?>... classes) throws IOException {	
the adddependencyjars configuration class method has been deprecated since it is easy to use incorrectly most users should rely on adddependencyjars job instead see hbase for more details 

public static void addDependencyJarsForClasses(Configuration conf, Class<?>... classes) throws IOException {	FileSystem localFs = FileSystem.getLocal(conf);	Set<String> jars = new HashSet<>();	jars.addAll(conf.getStringCollection("tmpjars"));	Map<String, String> packagedClasses = new HashMap<>();	for (Class<?> clazz : classes) {	if (clazz == null) continue;	Path path = findOrCreateJar(clazz, localFs, packagedClasses);	if (path == null) {	
could not find jar for class in order to ship it to the cluster 

Set<String> jars = new HashSet<>();	jars.addAll(conf.getStringCollection("tmpjars"));	Map<String, String> packagedClasses = new HashMap<>();	for (Class<?> clazz : classes) {	if (clazz == null) continue;	Path path = findOrCreateJar(clazz, localFs, packagedClasses);	if (path == null) {	continue;	}	if (!localFs.exists(path)) {	
could not validate jar file for class 

private static Path findOrCreateJar(Class<?> my_class, FileSystem fs, Map<String, String> packagedClasses) throws IOException {	String jar = findContainingJar(my_class, packagedClasses);	if (null == jar || jar.isEmpty()) {	jar = getJar(my_class);	updateMap(jar, packagedClasses);	}	if (null == jar || jar.isEmpty()) {	return null;	}	
for class s using jar s 

========================= hbase sample_3470 =========================

public synchronized void notifyServer(ServerName sn) {	
started processing 

========================= hbase sample_2774 =========================

public int getDataNodePort() {	HdfsConfiguration.init();	Configuration dnConf = new HdfsConfiguration(masterServices.getConfiguration());	int dnPort = NetUtils.createSocketAddr( dnConf.get(DFSConfigKeys.DFS_DATANODE_ADDRESS_KEY, DFSConfigKeys.DFS_DATANODE_ADDRESS_DEFAULT)).getPort();	
loaded default datanode port for fn 

========================= hbase sample_2324 =========================

public static void setUpBeforeClass() throws Exception {	
hbase regionserver logroll errors tolerated 

public void testRSAbortWithUnflushedEdits() throws Exception {	
starting testrsabortwithunflushededits 

HRegionServer server = TEST_UTIL.getRSForFirstRegionInTable(tableName);	WAL log = server.getWAL(null);	Put p = new Put(Bytes.toBytes("row2001"));	p.addColumn(HConstants.CATALOG_FAMILY, Bytes.toBytes("col"), Bytes.toBytes(2001));	table.put(p);	log.sync();	p = new Put(Bytes.toBytes("row2002"));	p.addColumn(HConstants.CATALOG_FAMILY, Bytes.toBytes("col"), Bytes.toBytes(2002));	table.put(p);	dfsCluster.restartDataNodes();	
restarted datanodes 

table.put(p);	log.sync();	p = new Put(Bytes.toBytes("row2002"));	p.addColumn(HConstants.CATALOG_FAMILY, Bytes.toBytes("col"), Bytes.toBytes(2002));	table.put(p);	dfsCluster.restartDataNodes();	try {	log.rollWriter(true);	} catch (FailedLogCloseException flce) {	} catch (Throwable t) {	
failed test got wrong exception 

========================= hbase sample_1621 =========================

public boolean isNormalizerOn() {	byte [] upData = super.getData(false);	try {	return upData == null || parseFrom(upData).getNormalizerOn();	} catch (DeserializationException dex) {	
zk state for regionnormalizer could not be parsed 

========================= hbase sample_746 =========================

public static void registerFilter(String name, String filterClass) {	
registering new filter 

========================= hbase sample_316 =========================

List<Thread> threads = new ArrayList<>();	final int nbThread = 100;	for (int i = 0; i < nbThread; i++) {	Thread t = new Thread() {	public void run() {	try {	Table ht = util.getConnection().getTable(tableName);	Result r = ht.get(new Get(row1));	noEx.incrementAndGet();	} catch (IOException e) {	
exception 

try {	Table ht = util.getConnection().getTable(tableName);	Result r = ht.get(new Get(row1));	noEx.incrementAndGet();	} catch (IOException e) {	if (!(e instanceof InterruptedIOException) || (e instanceof SocketTimeoutException)) {	badEx.incrementAndGet();	} else {	if (Thread.currentThread().isInterrupted()) {	noInt.incrementAndGet();	
the thread should not be with the interrupt status 

========================= hbase sample_2148 =========================

protected void assertConnectedPeerStatus(boolean status, String peerId) throws Exception {	if (status != rp.getPeerStorage().isPeerEnabled(peerId)) {	fail("ConnectedPeerStatus was " + !status + " but expected " + status + " in ZK");	}	while (true) {	if (status == rp.getPeer(peerId).isPeerEnabled()) {	return;	}	if (zkTimeoutCount < ZK_MAX_COUNT) {	
connectedpeerstatus was but expected sleeping and trying again 

========================= hbase sample_603 =========================

public void forceSelect(CompactionRequestImpl request) {	super.forceSelect(request);	if (this.stripeRequest != null) {	this.stripeRequest.setRequest(this.request);	} else {	
stripe store is forced to take an arbitrary file list and compact it 

========================= hbase sample_2518 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	boolean preserveSplits = random.nextBoolean();	
performing action truncate table preserve splits 

========================= hbase sample_3309 =========================

protected void prepareForLoadTest() throws IOException {	LOG.info("Starting load test: dataBlockEncoding=" + dataBlockEncoding + ", isMultiPut=" + isMultiPut);	numKeys = numKeys();	Admin admin = TEST_UTIL.getAdmin();	while (admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().size() < NUM_RS) {	
sleeping until rss are online 

========================= hbase sample_1334 =========================

private static int write(final JsonGenerator jg, final MBeanServer mBeanServer, ObjectName qry, String attribute, final boolean description) throws IOException {	
listing beans for 

prs = "modelerType";	code = (String) mBeanServer.getAttribute(oname, prs);	}	if (attribute != null) {	prs = attribute;	attributeinfo = mBeanServer.getAttribute(oname, prs);	}	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	
getting attribute of threw 

}	if (attribute != null) {	prs = attribute;	attributeinfo = mBeanServer.getAttribute(oname, prs);	}	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	
getting attribute of threw an exception 

attributeinfo = mBeanServer.getAttribute(oname, prs);	}	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	}	return 0;	} catch (AttributeNotFoundException e) {	
getting attribute of threw an exception 

}	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	}	return 0;	} catch (AttributeNotFoundException e) {	} catch (MBeanException e) {	
getting attribute of threw an exception 

} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	}	return 0;	} catch (AttributeNotFoundException e) {	} catch (MBeanException e) {	} catch (RuntimeException e) {	
getting attribute of threw an exception 

if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	}	return 0;	} catch (AttributeNotFoundException e) {	} catch (MBeanException e) {	} catch (RuntimeException e) {	} catch (ReflectionException e) {	
getting attribute of threw an exception 

}	return 0;	} catch (AttributeNotFoundException e) {	} catch (MBeanException e) {	} catch (RuntimeException e) {	} catch (ReflectionException e) {	}	} catch (InstanceNotFoundException e) {	continue;	} catch (IntrospectionException e) {	
problem while trying to process jmx query with mbean 

} catch (AttributeNotFoundException e) {	} catch (MBeanException e) {	} catch (RuntimeException e) {	} catch (ReflectionException e) {	}	} catch (InstanceNotFoundException e) {	continue;	} catch (IntrospectionException e) {	continue;	} catch (ReflectionException e) {	
problem while trying to process jmx query with mbean 

if (attName.indexOf("=") >= 0 || attName.indexOf(":") >= 0 || attName.indexOf(" ") >= 0) {	return;	}	String descriptionStr = description? attr.getDescription(): null;	Object value = null;	try {	value = mBeanServer.getAttribute(oname, attName);	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	
getting attribute of threw 

}	String descriptionStr = description? attr.getDescription(): null;	Object value = null;	try {	value = mBeanServer.getAttribute(oname, attName);	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	
getting attribute of threw an exception 

try {	value = mBeanServer.getAttribute(oname, attName);	} catch (RuntimeMBeanException e) {	if (e.getCause() instanceof UnsupportedOperationException) {	if (LOG.isTraceEnabled()) {	}	} else {	}	return;	} catch (RuntimeErrorException e) {	
getting attribute of threw an exception 

if (LOG.isTraceEnabled()) {	}	} else {	}	return;	} catch (RuntimeErrorException e) {	return;	} catch (AttributeNotFoundException e) {	return;	} catch (MBeanException e) {	
getting attribute of threw an exception 

} else {	}	return;	} catch (RuntimeErrorException e) {	return;	} catch (AttributeNotFoundException e) {	return;	} catch (MBeanException e) {	return;	} catch (RuntimeException e) {	
getting attribute of threw an exception 

return;	} catch (RuntimeErrorException e) {	return;	} catch (AttributeNotFoundException e) {	return;	} catch (MBeanException e) {	return;	} catch (RuntimeException e) {	return;	} catch (ReflectionException e) {	
getting attribute of threw an exception 

========================= hbase sample_984 =========================

private static void parseCommandLine(String[] args, RESTServlet servlet) {	Options options = new Options();	options.addOption("p", "port", true, "Port to bind to [default: " + DEFAULT_LISTEN_PORT + "]");	options.addOption("ro", "readonly", false, "Respond only to GET HTTP " + "method requests [default: false]");	options.addOption(null, "infoport", true, "Port for web UI");	CommandLine commandLine = null;	try {	commandLine = new PosixParser().parse(options, args);	} catch (ParseException e) {	
could not parse 

CommandLine commandLine = null;	try {	commandLine = new PosixParser().parse(options, args);	} catch (ParseException e) {	printUsageAndExit(options, -1);	}	if (commandLine != null && commandLine.hasOption("port")) {	String val = commandLine.getOptionValue("port");	servlet.getConfiguration().setInt("hbase.rest.port", Integer.parseInt(val));	if (LOG.isDebugEnabled()) {	
port set to 

}	if (commandLine != null && commandLine.hasOption("port")) {	String val = commandLine.getOptionValue("port");	servlet.getConfiguration().setInt("hbase.rest.port", Integer.parseInt(val));	if (LOG.isDebugEnabled()) {	}	}	if (commandLine != null && commandLine.hasOption("readonly")) {	servlet.getConfiguration().setBoolean("hbase.rest.readonly", true);	if (LOG.isDebugEnabled()) {	
readonly set to true 

}	if (commandLine != null && commandLine.hasOption("readonly")) {	servlet.getConfiguration().setBoolean("hbase.rest.readonly", true);	if (LOG.isDebugEnabled()) {	}	}	if (commandLine != null && commandLine.hasOption("infoport")) {	String val = commandLine.getOptionValue("infoport");	servlet.getConfiguration().setInt("hbase.rest.info.port", Integer.parseInt(val));	if (LOG.isDebugEnabled()) {	
web ui port set to 

public static void main(String[] args) throws Exception {	
starting service 

conf.setLong("startcode", System.currentTimeMillis());	String a = conf.get("hbase.rest.info.bindAddress", "0.0.0.0");	InfoServer infoServer = new InfoServer("rest", a, port, false, conf);	infoServer.setAttribute("hbase.conf", conf);	infoServer.start();	}	try {	server.start();	server.join();	} catch (Exception e) {	
failed to start server 

InfoServer infoServer = new InfoServer("rest", a, port, false, conf);	infoServer.setAttribute("hbase.conf", conf);	infoServer.start();	}	try {	server.start();	server.join();	} catch (Exception e) {	System.exit(1);	}	
stopping service 

========================= hbase sample_3077 =========================

public void onHeapMemoryTune(long newMemstoreSize, long newBlockCacheSize) {	if (isOffheap()) {	
not tuning the chunk pool as it is offheap 

public void onHeapMemoryTune(long newMemstoreSize, long newBlockCacheSize) {	if (isOffheap()) {	return;	}	int newMaxCount = (int) (newMemstoreSize * poolSizePercentage / getChunkSize());	if (newMaxCount != this.maxCount) {	if (newMaxCount > this.maxCount) {	
max count for chunks increased from to 

public void onHeapMemoryTune(long newMemstoreSize, long newBlockCacheSize) {	if (isOffheap()) {	return;	}	int newMaxCount = (int) (newMemstoreSize * poolSizePercentage / getChunkSize());	if (newMaxCount != this.maxCount) {	if (newMaxCount > this.maxCount) {	this.maxCount = newMaxCount;	} else {	
max count for chunks decreased from to 

private MemStoreChunkPool initializePool(long globalMemStoreSize, float poolSizePercentage, float initialCountPercentage) {	if (poolSizePercentage <= 0) {	
poolsizepercentage is less than so not using pool 

return null;	}	if (poolSizePercentage > 1.0) {	throw new IllegalArgumentException( MemStoreLAB.CHUNK_POOL_MAXSIZE_KEY + " must be between 0.0 and 1.0");	}	int maxCount = (int) (globalMemStoreSize * poolSizePercentage / getChunkSize());	if (initialCountPercentage > 1.0 || initialCountPercentage < 0) {	throw new IllegalArgumentException( MemStoreLAB.CHUNK_POOL_INITIALSIZE_KEY + " must be between 0.0 and 1.0");	}	int initialCount = (int) (initialCountPercentage * maxCount);	
allocating memstorechunkpool with chunk size max count initial count 

========================= hbase sample_2666 =========================

public static void checkForClusterFreeHeapMemoryLimit(Configuration conf) {	if (conf.get(MEMSTORE_SIZE_OLD_KEY) != null) {	
is deprecated by 

public static float getGlobalMemStoreHeapPercent(final Configuration c, final boolean logInvalid) {	float limit = c.getFloat(MEMSTORE_SIZE_KEY, c.getFloat(MEMSTORE_SIZE_OLD_KEY, DEFAULT_MEMSTORE_SIZE));	if (limit > 0.8f || limit <= 0.0f) {	if (logInvalid) {	
setting global memstore limit to default of because supplied value outside allowed range of 

public static float getGlobalMemStoreHeapLowerMark(final Configuration conf, boolean honorOldConfig) {	String lowMarkPercentStr = conf.get(MEMSTORE_SIZE_LOWER_LIMIT_KEY);	if (lowMarkPercentStr != null) {	float lowMarkPercent = Float.parseFloat(lowMarkPercentStr);	if (lowMarkPercent > 1.0f) {	
bad configuration value for using instead 

if (lowMarkPercentStr != null) {	float lowMarkPercent = Float.parseFloat(lowMarkPercentStr);	if (lowMarkPercent > 1.0f) {	lowMarkPercent = 1.0f;	}	return lowMarkPercent;	}	if (!honorOldConfig) return DEFAULT_MEMSTORE_SIZE_LOWER_LIMIT;	String lowerWaterMarkOldValStr = conf.get(MEMSTORE_SIZE_LOWER_LIMIT_OLD_KEY);	if (lowerWaterMarkOldValStr != null) {	
is deprecated instead use 

}	return lowMarkPercent;	}	if (!honorOldConfig) return DEFAULT_MEMSTORE_SIZE_LOWER_LIMIT;	String lowerWaterMarkOldValStr = conf.get(MEMSTORE_SIZE_LOWER_LIMIT_OLD_KEY);	if (lowerWaterMarkOldValStr != null) {	float lowerWaterMarkOldVal = Float.parseFloat(lowerWaterMarkOldValStr);	float upperMarkPercent = getGlobalMemStoreHeapPercent(conf, false);	if (lowerWaterMarkOldVal > upperMarkPercent) {	lowerWaterMarkOldVal = upperMarkPercent;	
value of is greater than global memstore limit set by setting memstore lower limit to 

public static Pair<Long, MemoryType> getGlobalMemStoreSize(Configuration conf) {	long offheapMSGlobal = conf.getLong(OFFHEAP_MEMSTORE_SIZE_KEY, 0);	if (offheapMSGlobal > 0) {	if (MemStoreLAB.isEnabled(conf)) {	long globalMemStoreLimit = (long) (offheapMSGlobal * 1024 * 1024);	return new Pair<>(globalMemStoreLimit, MemoryType.NON_HEAP);	} else {	
there is no relevance of configuring when is turned off going with on heap global memstore size 

========================= hbase sample_2373 =========================

protected void abortWriter(StoreFileWriter writer) throws IOException {	Path leftoverFile = writer.getPath();	try {	writer.close();	} catch (IOException e) {	
failed to close the writer after an unfinished compaction 

protected void abortWriter(StoreFileWriter writer) throws IOException {	Path leftoverFile = writer.getPath();	try {	writer.close();	} catch (IOException e) {	}	try {	store.getFileSystem().delete(leftoverFile, false);	} catch (IOException e) {	
failed to delete the leftover file after an unfinished compaction 

========================= hbase sample_2689 =========================

public void postBulkLoadHFile(ObserverContext<RegionCoprocessorEnvironment> ctx, List<Pair<byte[], String>> stagingFamilyPaths, Map<byte[], List<Path>> finalPaths) throws IOException {	Configuration cfg = ctx.getEnvironment().getConfiguration();	if (finalPaths == null) {	return;	}	if (!BackupManager.isBackupEnabled(cfg)) {	
skipping recording bulk load in postbulkloadhfile since backup is disabled 

if (!BackupManager.isBackupEnabled(cfg)) {	return;	}	try (Connection connection = ConnectionFactory.createConnection(cfg);	BackupSystemTable tbl = new BackupSystemTable(connection)) {	List<TableName> fullyBackedUpTables = tbl.getTablesForBackupType(BackupType.FULL);	RegionInfo info = ctx.getEnvironment().getRegionInfo();	TableName tableName = info.getTable();	if (!fullyBackedUpTables.contains(tableName)) {	if (LOG.isTraceEnabled()) {	
has not gone thru full backup 

List<TableName> fullyBackedUpTables = tbl.getTablesForBackupType(BackupType.FULL);	RegionInfo info = ctx.getEnvironment().getRegionInfo();	TableName tableName = info.getTable();	if (!fullyBackedUpTables.contains(tableName)) {	if (LOG.isTraceEnabled()) {	}	return;	}	tbl.writePathsPostBulkLoad(tableName, info.getEncodedNameAsBytes(), finalPaths);	} catch (IOException ioe) {	
failed to get tables which have been fully backed up 

public void preCommitStoreFile(final ObserverContext<RegionCoprocessorEnvironment> ctx, final byte[] family, final List<Pair<Path, Path>> pairs) throws IOException {	Configuration cfg = ctx.getEnvironment().getConfiguration();	if (pairs == null || pairs.isEmpty() || !BackupManager.isBackupEnabled(cfg)) {	
skipping recording bulk load in precommitstorefile since backup is disabled 

if (pairs == null || pairs.isEmpty() || !BackupManager.isBackupEnabled(cfg)) {	return;	}	try (Connection connection = ConnectionFactory.createConnection(cfg);	BackupSystemTable tbl = new BackupSystemTable(connection)) {	List<TableName> fullyBackedUpTables = tbl.getTablesForBackupType(BackupType.FULL);	RegionInfo info = ctx.getEnvironment().getRegionInfo();	TableName tableName = info.getTable();	if (!fullyBackedUpTables.contains(tableName)) {	if (LOG.isTraceEnabled()) {	
has not gone thru full backup 

========================= hbase sample_592 =========================

}	if (cleanupPoolOnClose) {	this.pool.shutdown();	try {	boolean terminated = false;	do {	terminated = this.pool.awaitTermination(60, TimeUnit.SECONDS);	} while (!terminated);	} catch (InterruptedException e) {	this.pool.shutdownNow();	
waitfortermination interrupted 

}	return result;	}	});	futures.put(r, future);	}	for (Map.Entry<byte[],Future<R>> e : futures.entrySet()) {	try {	e.getValue().get();	} catch (ExecutionException ee) {	
error calling coprocessor service for row 

AsyncProcess asyncProcess = new AsyncProcess(connection, configuration, RpcRetryingCallerFactory.instantiate(configuration, connection.getStatisticsTracker()), true, RpcControllerFactory.instantiate(configuration));	Callback<ClientProtos.CoprocessorServiceResult> resultsCallback = (byte[] region, byte[] row, ClientProtos.CoprocessorServiceResult serviceResult) -> {	if (LOG.isTraceEnabled()) {	LOG.trace("Received result for endpoint " + methodDescriptor.getFullName() + ": region=" + Bytes.toStringBinary(region) + ", row=" + Bytes.toStringBinary(row) + ", value=" + serviceResult.getValue().getValue());	}	try {	Message.Builder builder = responsePrototype.newBuilderForType();	org.apache.hadoop.hbase.protobuf.ProtobufUtil.mergeFrom(builder, serviceResult.getValue().getValue().toByteArray());	callback.update(region, row, (R) builder.build());	} catch (IOException e) {	
unexpected response type from endpoint 

========================= hbase sample_341 =========================

public Void replicate() throws IOException {	Map<String, Path> tableStagingDirsMap = copyHFilesToStagingDir();	int maxRetries = conf.getInt(HConstants.BULKLOAD_MAX_RETRIES_NUMBER, 10);	for (Entry<String, Path> tableStagingDir : tableStagingDirsMap.entrySet()) {	String tableNameString = tableStagingDir.getKey();	Path stagingDir = tableStagingDir.getValue();	LoadIncrementalHFiles loadHFiles = null;	try {	loadHFiles = new LoadIncrementalHFiles(conf);	} catch (Exception e) {	
failed to initialize loadincrementalhfiles for replicating bulk loaded data 

throw new IOException(e);	}	Configuration newConf = HBaseConfiguration.create(conf);	newConf.set(LoadIncrementalHFiles.CREATE_TABLE_CONF_KEY, "no");	loadHFiles.setConf(newConf);	TableName tableName = TableName.valueOf(tableNameString);	Table table = this.connection.getTable(tableName);	Deque<LoadQueueItem> queue = new LinkedList<>();	loadHFiles.prepareHFileQueue(stagingDir, table, queue, false);	if (queue.isEmpty()) {	
replication process did not find any files to replicate in directory 

private void doBulkLoad(LoadIncrementalHFiles loadHFiles, Table table, Deque<LoadQueueItem> queue, RegionLocator locator, int maxRetries) throws IOException {	int count = 0;	Pair<byte[][], byte[][]> startEndKeys;	while (!queue.isEmpty()) {	startEndKeys = locator.getStartEndKeys();	if (count != 0) {	
error occurred while replicating hfiles retry attempt with files still remaining to replicate 

private void cleanup(String stagingDir, Table table) {	fsDelegationToken.releaseDelegationToken();	if (stagingDir != null) {	try {	sinkFs.delete(new Path(stagingDir), true);	} catch (IOException e) {	
failed to delete the staging directory 

if (stagingDir != null) {	try {	sinkFs.delete(new Path(stagingDir), true);	} catch (IOException e) {	}	}	if (table != null) {	try {	table.close();	} catch (IOException e) {	
failed to close the table 

public Void call() throws IOException {	Path sourceHFilePath;	Path localHFilePath;	int totalHFiles = hfiles.size();	for (int i = 0; i < totalHFiles; i++) {	sourceHFilePath = new Path(sourceBaseNamespaceDirPath, hfiles.get(i));	localHFilePath = new Path(stagingDir, sourceHFilePath.getName());	try {	FileUtil.copy(sourceFs, sourceHFilePath, sinkFs, localHFilePath, false, conf);	} catch (FileNotFoundException e) {	
failed to copy hfile from to trying to copy from hfile archive directory 

for (int i = 0; i < totalHFiles; i++) {	sourceHFilePath = new Path(sourceBaseNamespaceDirPath, hfiles.get(i));	localHFilePath = new Path(stagingDir, sourceHFilePath.getName());	try {	FileUtil.copy(sourceFs, sourceHFilePath, sinkFs, localHFilePath, false, conf);	} catch (FileNotFoundException e) {	sourceHFilePath = new Path(sourceHFileArchiveDirPath, hfiles.get(i));	try {	FileUtil.copy(sourceFs, sourceHFilePath, sinkFs, localHFilePath, false, conf);	} catch (FileNotFoundException e1) {	
failed to copy hfile from to hence ignoring this hfile from replication 

========================= hbase sample_2959 =========================

private void scanColSet(int[] colSet, int[] expectedResultCols) throws IOException {	
scanning column set 

t2 = fs.getFileStatus(p2).getModificationTime();	} catch (IOException ex) {	throw new RuntimeException(ex);	}	return t1 < t2 ? -1 : t1 == t2 ? 1 : 0;	}	});	StoreFileReader lastStoreFileReader = null;	for (StoreFileScanner sfScanner : scanners) lastStoreFileReader = sfScanner.getReader();	new HFilePrettyPrinter(conf).run(new String[]{ "-m", "-p", "-f", lastStoreFileReader.getHFileReader().getPath().toString()});	
disabling bloom filter for 

}	}	List<Integer> actualIds = new ArrayList<>();	for (Cell kv : allResults) {	String qual = Bytes.toString(CellUtil.cloneQualifier(kv));	assertTrue(qual.startsWith(QUALIFIER_PREFIX));	actualIds.add(Integer.valueOf(qual.substring( QUALIFIER_PREFIX.length())));	}	List<Integer> expectedIds = new ArrayList<>();	for (int expectedId : expectedResultCols) expectedIds.add(expectedId);	
column ids returned expected 

========================= hbase sample_1676 =========================

public void testFlushSizeSizing() throws Exception {	
setting up a faulty file system that cannot write in 

User user = User.createUserForTesting(conf, this.name.getMethodName(), new String[]{"foo"});	conf.setClass("fs.file.impl", FaultyFileSystem.class, FileSystem.class);	user.runAs(new PrivilegedExceptionAction<Object>() {	public Object run() throws Exception {	FileSystem fs = FileSystem.get(conf);	assertEquals(FaultyFileSystem.class, fs.getClass());	FaultyFileSystem ffs = (FaultyFileSystem)fs;	init(name.getMethodName(), conf);	MemStoreSize size = store.memstore.getFlushableSize();	assertEquals(0, size.getDataSize());	
adding some data 

FaultyFileSystem ffs = (FaultyFileSystem)fs;	init(name.getMethodName(), conf);	MemStoreSize size = store.memstore.getFlushableSize();	assertEquals(0, size.getDataSize());	MemStoreSizing kvSize = new MemStoreSizing();	store.add(new KeyValue(row, family, qf1, 1, (byte[]) null), kvSize);	kvSize.incMemStoreSize(0, MutableSegment.DEEP_OVERHEAD);	size = store.memstore.getFlushableSize();	assertEquals(kvSize, size);	try {	
Flushing 

IncrementingEnvironmentEdge edge = new IncrementingEnvironmentEdge();	EnvironmentEdgeManagerTestHelper.injectEdge(edge);	Configuration conf = HBaseConfiguration.create();	conf.setBoolean("hbase.store.delete.expired.storefile", true);	conf.setInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MIN_KEY, 5);	init(name.getMethodName() + "-" + minVersions, conf, ColumnFamilyDescriptorBuilder .newBuilder(family).setMinVersions(minVersions).setTimeToLive(ttl).build());	long storeTtl = this.store.getScanInfo().getTtl();	long sleepTime = storeTtl / storeFileNum;	long timeStamp;	for (int i = 1; i <= storeFileNum; i++) {	
adding some data for the store file 

public void testLowestModificationTime() throws Exception {	Configuration conf = HBaseConfiguration.create();	FileSystem fs = FileSystem.get(conf);	init(name.getMethodName(), conf);	int storeFileNum = 4;	for (int i = 1; i <= storeFileNum; i++) {	
adding some data for the store file 

public void testHandleErrorsInFlush() throws Exception {	
setting up a faulty file system that cannot write 

public void testHandleErrorsInFlush() throws Exception {	final Configuration conf = HBaseConfiguration.create();	User user = User.createUserForTesting(conf, "testhandleerrorsinflush", new String[]{"foo"});	conf.setClass("fs.file.impl", FaultyFileSystem.class, FileSystem.class);	user.runAs(new PrivilegedExceptionAction<Object>() {	public Object run() throws Exception {	FileSystem fs = FileSystem.get(conf);	assertEquals(FaultyFileSystem.class, fs.getClass());	init(name.getMethodName(), conf);	
adding some data 

User user = User.createUserForTesting(conf, "testhandleerrorsinflush", new String[]{"foo"});	conf.setClass("fs.file.impl", FaultyFileSystem.class, FileSystem.class);	user.runAs(new PrivilegedExceptionAction<Object>() {	public Object run() throws Exception {	FileSystem fs = FileSystem.get(conf);	assertEquals(FaultyFileSystem.class, fs.getClass());	init(name.getMethodName(), conf);	store.add(new KeyValue(row, family, qf1, 1, (byte[])null), null);	store.add(new KeyValue(row, family, qf2, 1, (byte[])null), null);	store.add(new KeyValue(row, family, qf3, 1, (byte[])null), null);	
before flush we should have no files 

public Object run() throws Exception {	FileSystem fs = FileSystem.get(conf);	assertEquals(FaultyFileSystem.class, fs.getClass());	init(name.getMethodName(), conf);	store.add(new KeyValue(row, family, qf1, 1, (byte[])null), null);	store.add(new KeyValue(row, family, qf2, 1, (byte[])null), null);	store.add(new KeyValue(row, family, qf3, 1, (byte[])null), null);	Collection<StoreFileInfo> files = store.getRegionFileSystem().getStoreFiles(store.getColumnFamilyName());	assertEquals(0, files != null ? files.size() : 0);	try {	
Flushing 

store.add(new KeyValue(row, family, qf2, 1, (byte[])null), null);	store.add(new KeyValue(row, family, qf3, 1, (byte[])null), null);	Collection<StoreFileInfo> files = store.getRegionFileSystem().getStoreFiles(store.getColumnFamilyName());	assertEquals(0, files != null ? files.size() : 0);	try {	flush(1);	fail("Didn't bubble up IOE!");	} catch (IOException ioe) {	assertTrue(ioe.getMessage().contains("Fault injected"));	}	
after failed flush we should still have no files 

private void addStoreFile() throws IOException {	HStoreFile f = this.store.getStorefiles().iterator().next();	Path storedir = f.getPath().getParent();	long seqid = this.store.getMaxSequenceId().orElse(0L);	Configuration c = TEST_UTIL.getConfiguration();	FileSystem fs = FileSystem.get(c);	HFileContext fileContext = new HFileContextBuilder().withBlockSize(BLOCKSIZE_SMALL).build();	StoreFileWriter w = new StoreFileWriter.Builder(c, new CacheConfig(c), fs) .withOutputDir(storedir) .withFileContext(fileContext) .build();	w.appendMetadata(seqid + 1, false);	w.close();	
added store file 

protected boolean shouldFlushInMemory() {	boolean rval = super.shouldFlushInMemory();	if (rval) {	RUNNER_COUNT.incrementAndGet();	if (LOG.isDebugEnabled()) {	
runner count 

========================= hbase sample_1733 =========================

}	if (bloomFilter == null) {	return true;	}	try {	if (!bloomFilter.supportsAutoLoading()) {	return true;	}	return bloomFilter.contains(row, rowOffset, rowLen, null);	} catch (IllegalArgumentException e) {	
bad delete family bloom filter data proceeding without 

exists = false;	} else {	exists = bloomFilter.contains(kvKey, bloom, BloomType.ROWCOL) || bloomFilter.contains(rowBloomKey, bloom, BloomType.ROWCOL);	}	} else {	exists = !keyIsAfterLast && bloomFilter.contains(key, 0, key.length, bloom);	}	return exists;	}	} catch (IOException e) {	
error reading bloom filter data proceeding without 

exists = bloomFilter.contains(kvKey, bloom, BloomType.ROWCOL) || bloomFilter.contains(rowBloomKey, bloom, BloomType.ROWCOL);	}	} else {	exists = !keyIsAfterLast && bloomFilter.contains(key, 0, key.length, bloom);	}	return exists;	}	} catch (IOException e) {	setGeneralBloomFilterFaulty();	} catch (IllegalArgumentException e) {	
bad bloom filter data proceeding without 

try {	if (blockType == BlockType.GENERAL_BLOOM_META) {	if (this.generalBloomFilter != null) return;	DataInput bloomMeta = reader.getGeneralBloomFilterMetadata();	if (bloomMeta != null) {	if (bloomFilterType == BloomType.NONE) {	throw new IOException( "valid bloom filter type not found in FileInfo");	} else {	generalBloomFilter = BloomFilterFactory.createFromMeta(bloomMeta, reader);	if (LOG.isTraceEnabled()) {	
loaded metadata for 

generalBloomFilter = BloomFilterFactory.createFromMeta(bloomMeta, reader);	if (LOG.isTraceEnabled()) {	}	}	}	} else if (blockType == BlockType.DELETE_FAMILY_BLOOM_META) {	if (this.deleteFamilyBloomFilter != null) return;	DataInput bloomMeta = reader.getDeleteBloomFilterMetadata();	if (bloomMeta != null) {	deleteFamilyBloomFilter = BloomFilterFactory.createFromMeta( bloomMeta, reader);	
loaded delete family bloom metadata for 

} else if (blockType == BlockType.DELETE_FAMILY_BLOOM_META) {	if (this.deleteFamilyBloomFilter != null) return;	DataInput bloomMeta = reader.getDeleteBloomFilterMetadata();	if (bloomMeta != null) {	deleteFamilyBloomFilter = BloomFilterFactory.createFromMeta( bloomMeta, reader);	}	} else {	throw new RuntimeException("Block Type: " + blockType.toString() + "is not supported for Bloom filter");	}	} catch (IOException e) {	
error reading bloom filter meta for proceeding without 

DataInput bloomMeta = reader.getDeleteBloomFilterMetadata();	if (bloomMeta != null) {	deleteFamilyBloomFilter = BloomFilterFactory.createFromMeta( bloomMeta, reader);	}	} else {	throw new RuntimeException("Block Type: " + blockType.toString() + "is not supported for Bloom filter");	}	} catch (IOException e) {	setBloomFilterFaulty(blockType);	} catch (IllegalArgumentException e) {	
bad bloom filter meta proceeding without 

========================= hbase sample_2670 =========================

public void recoverFileLease(final FileSystem fs, final Path p, Configuration conf, CancelableProgressable reporter) throws IOException {	
recovering file by changing permission to readonly 

========================= hbase sample_2220 =========================

public Void call() throws Exception {	if (LOG.isDebugEnabled()) {	
drpc started 

AbstractFSWAL<?> fsWAL = (AbstractFSWAL<?>) rss.getWAL(null);	long filenum = fsWAL.getFilenum();	List<WAL> wals = rss.getWALs();	long highest = -1;	for (WAL wal : wals) {	if (wal == null) continue;	if (((AbstractFSWAL<?>) wal).getFilenum() > highest) {	highest = ((AbstractFSWAL<?>) wal).getFilenum();	}	}	
trying to roll log in backup subprocedure current log number highest on 

if (wal == null) continue;	if (((AbstractFSWAL<?>) wal).getFilenum() > highest) {	highest = ((AbstractFSWAL<?>) wal).getFilenum();	}	}	((HRegionServer) rss).getWalRoller().requestRollAll();	long start = EnvironmentEdgeManager.currentTime();	while (!((HRegionServer) rss).getWalRoller().walRollFinished()) {	Thread.sleep(20);	}	
log roll took 

if (wal == null) continue;	if (((AbstractFSWAL<?>) wal).getFilenum() > highest) {	highest = ((AbstractFSWAL<?>) wal).getFilenum();	}	}	((HRegionServer) rss).getWalRoller().requestRollAll();	long start = EnvironmentEdgeManager.currentTime();	while (!((HRegionServer) rss).getWalRoller().walRollFinished()) {	Thread.sleep(20);	}	
after roll log in backup subprocedure current log number on 

========================= hbase sample_584 =========================

}	if (compressionContext != null) {	e.setCompressionContext(compressionContext);	}	boolean hasEntry = false;	try {	hasEntry = readNext(e);	} catch (IllegalArgumentException iae) {	TableName tableName = e.getKey().getTablename();	if (tableName != null && tableName.equals(TableName.OLD_ROOT_TABLE_NAME)) {	
got an old root edit ignoring 

========================= hbase sample_2559 =========================

public void tearDown() throws IOException {	IOException ex = null;	try {	region.close();	} catch (IOException e) {	
caught exception 

public void tearDown() throws IOException {	IOException ex = null;	try {	region.close();	} catch (IOException e) {	ex = e;	}	try {	hlog.close();	} catch (IOException e) {	
caught exception 

========================= hbase sample_1725 =========================

public TableSplit(TableName tableName, Scan scan, byte [] startRow, byte [] endRow, final String location, final String encodedRegionName, long length) {	this.tableName = tableName;	try {	this.scan = (null == scan) ? "" : TableMapReduceUtil.convertScanToString(scan);	} catch (IOException e) {	
failed to convert scan to string 

========================= hbase sample_3466 =========================

public void testGetStargateVersionXML() throws IOException, JAXBException {	Response response = client.get("/version", Constants.MIMETYPE_XML);	assertEquals(200, response.getCode());	assertEquals(Constants.MIMETYPE_XML, response.getHeader("content-type"));	VersionModel model = (VersionModel) context.createUnmarshaller().unmarshal( new ByteArrayInputStream(response.getBody()));	validate(model);	
success retrieving stargate version as xml 

public void testGetStargateVersionJSON() throws IOException {	Response response = client.get("/version", Constants.MIMETYPE_JSON);	assertEquals(200, response.getCode());	assertEquals(Constants.MIMETYPE_JSON, response.getHeader("content-type"));	ObjectMapper mapper = new JacksonJaxbJsonProvider() .locateMapper(VersionModel.class, MediaType.APPLICATION_JSON_TYPE);	VersionModel model = mapper.readValue(response.getBody(), VersionModel.class);	validate(model);	
success retrieving stargate version as json 

public void testGetStorageClusterVersionXML() throws IOException, JAXBException {	Response response = client.get("/version/cluster",Constants.MIMETYPE_XML);	assertEquals(200, response.getCode());	assertEquals(Constants.MIMETYPE_XML, response.getHeader("content-type"));	StorageClusterVersionModel clusterVersionModel = (StorageClusterVersionModel) context.createUnmarshaller().unmarshal( new ByteArrayInputStream(response.getBody()));	assertNotNull(clusterVersionModel);	assertNotNull(clusterVersionModel.getVersion());	
success retrieving storage cluster version as xml 

public void testGetStorageClusterVersionJSON() throws IOException {	Response response = client.get("/version/cluster", Constants.MIMETYPE_JSON);	assertEquals(200, response.getCode());	assertEquals(Constants.MIMETYPE_JSON, response.getHeader("content-type"));	ObjectMapper mapper = new JacksonJaxbJsonProvider() .locateMapper(StorageClusterVersionModel.class, MediaType.APPLICATION_JSON_TYPE);	StorageClusterVersionModel clusterVersionModel = mapper.readValue(response.getBody(), StorageClusterVersionModel.class);	assertNotNull(clusterVersionModel);	assertNotNull(clusterVersionModel.getVersion());	
success retrieving storage cluster version as json 

========================= hbase sample_3036 =========================

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	
computing sizes of snapshots for quota management 

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	}	long start = System.nanoTime();	_chore();	if (null != metrics) {	metrics.incrementSnapshotObserverTime((System.nanoTime() - start) / 1_000_000);	}	} catch (IOException e) {	
failed to compute the size of snapshots will retry 

========================= hbase sample_2332 =========================

if (snapshotDir == null) snapshotDir = SnapshotDescriptionUtils.getSnapshotsDir(rootDir);	if (!fs.exists(snapshotDir)) {	return snapshotDescs;	}	FileStatus[] snapshots = fs.listStatus(snapshotDir, new SnapshotDescriptionUtils.CompletedSnaphotDirectoriesFilter(fs));	MasterCoprocessorHost cpHost = master.getMasterCoprocessorHost();	withCpCall = withCpCall && cpHost != null;	for (FileStatus snapshot : snapshots) {	Path info = new Path(snapshot.getPath(), SnapshotDescriptionUtils.SNAPSHOTINFO_FILE);	if (!fs.exists(info)) {	
snapshot information for doesn t exist 

}	FSDataInputStream in = null;	try {	in = fs.open(info);	SnapshotDescription desc = SnapshotDescription.parseFrom(in);	org.apache.hadoop.hbase.client.SnapshotDescription descPOJO = (withCpCall) ? ProtobufUtil.createSnapshotDesc(desc) : null;	if (withCpCall) {	try {	cpHost.preListSnapshot(descPOJO);	} catch (AccessDeniedException e) {	
current user does not have access to snapshot either you should be owner of this snapshot or admin user 

cpHost.preListSnapshot(descPOJO);	} catch (AccessDeniedException e) {	continue;	}	}	snapshotDescs.add(desc);	if (withCpCall) {	cpHost.postListSnapshot(descPOJO);	}	} catch (IOException e) {	
found a corrupted snapshot 

String snapshotName = snapshot.getName();	FileSystem fs = master.getMasterFileSystem().getFileSystem();	Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshotName, rootDir);	snapshot = SnapshotDescriptionUtils.readSnapshotInfo(fs, snapshotDir);	MasterCoprocessorHost cpHost = master.getMasterCoprocessorHost();	org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preDeleteSnapshot(snapshotPOJO);	}	
deleting snapshot 

String status;	Procedure p = coordinator.getProcedure(expected.getName());	if (p != null) {	status = p.getStatus();	} else {	status = expected.getName() + " not found in proclist " + coordinator.getProcedureNames();	}	throw new HBaseSnapshotException("Snapshot " + ssString +  " had an error.  " + status, e, ProtobufUtil.createSnapshotDesc(expected));	}	if (handler.isFinished()) {	
snapshot has completed notifying client 

if (p != null) {	status = p.getStatus();	} else {	status = expected.getName() + " not found in proclist " + coordinator.getProcedureNames();	}	throw new HBaseSnapshotException("Snapshot " + ssString +  " had an error.  " + status, e, ProtobufUtil.createSnapshotDesc(expected));	}	if (handler.isFinished()) {	return true;	} else if (LOG.isDebugEnabled()) {	
snapshoting is still in progress 

private synchronized void snapshotTable(SnapshotDescription snapshot, final TakeSnapshotHandler handler) throws HBaseSnapshotException {	try {	handler.prepare();	this.executorService.submit(handler);	this.snapshotHandlers.put(TableName.valueOf(snapshot.getTable()), handler);	} catch (Exception e) {	Path workingDir = SnapshotDescriptionUtils.getWorkingSnapshotDir(snapshot, rootDir);	try {	if (!this.master.getMasterFileSystem().getFileSystem().delete(workingDir, true)) {	
couldn t delete working directory for snapshot 

try {	handler.prepare();	this.executorService.submit(handler);	this.snapshotHandlers.put(TableName.valueOf(snapshot.getTable()), handler);	} catch (Exception e) {	Path workingDir = SnapshotDescriptionUtils.getWorkingSnapshotDir(snapshot, rootDir);	try {	if (!this.master.getMasterFileSystem().getFileSystem().delete(workingDir, true)) {	}	} catch (IOException e1) {	
couldn t delete working directory for snapshot 

public void takeSnapshot(SnapshotDescription snapshot) throws IOException {	if (isSnapshotCompleted(snapshot)) {	throw new SnapshotExistsException( "Snapshot '" + snapshot.getName() + "' already stored on the filesystem.", ProtobufUtil.createSnapshotDesc(snapshot));	}	
no existing snapshot attempting snapshot 

});	snapshot = builder.build();	MasterCoprocessorHost cpHost = master.getMasterCoprocessorHost();	org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preSnapshot(snapshotPOJO, desc);	}	TableName snapshotTable = TableName.valueOf(snapshot.getTable());	if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.ENABLED)) {	
table enabled starting distributed snapshot 

snapshot = builder.build();	MasterCoprocessorHost cpHost = master.getMasterCoprocessorHost();	org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preSnapshot(snapshotPOJO, desc);	}	TableName snapshotTable = TableName.valueOf(snapshot.getTable());	if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.ENABLED)) {	snapshotEnabledTable(snapshot);	
started snapshot 

org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preSnapshot(snapshotPOJO, desc);	}	TableName snapshotTable = TableName.valueOf(snapshot.getTable());	if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.ENABLED)) {	snapshotEnabledTable(snapshot);	}	else if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.DISABLED)) {	
table is disabled running snapshot entirely on master 

if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preSnapshot(snapshotPOJO, desc);	}	TableName snapshotTable = TableName.valueOf(snapshot.getTable());	if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.ENABLED)) {	snapshotEnabledTable(snapshot);	}	else if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.DISABLED)) {	snapshotDisabledTable(snapshot);	
started snapshot 

snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);	cpHost.preSnapshot(snapshotPOJO, desc);	}	TableName snapshotTable = TableName.valueOf(snapshot.getTable());	if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.ENABLED)) {	snapshotEnabledTable(snapshot);	}	else if (master.getTableStateManager().isTableState(snapshotTable, TableState.State.DISABLED)) {	snapshotDisabledTable(snapshot);	} else {	
can t snapshot table isn t open or closed we don t know what to do 

TableDescriptor htd = TableDescriptorBuilder.copy(tableName, snapshotTableDesc);	org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);	cpHost.preCloneSnapshot(snapshotPOJO, htd);	}	long procId;	try {	procId = cloneSnapshot(snapshot, htd, nonceKey, restoreAcl);	} catch (IOException e) {	
exception occurred while cloning the snapshot as table 

public long restoreOrCloneSnapshot(final SnapshotDescription reqSnapshot, final NonceKey nonceKey, final boolean restoreAcl) throws IOException {	FileSystem fs = master.getMasterFileSystem().getFileSystem();	Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(reqSnapshot, rootDir);	if (!fs.exists(snapshotDir)) {	
a snapshot named does not exist 

}	org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;	if (cpHost != null) {	snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);	cpHost.preRestoreSnapshot(snapshotPOJO, snapshotTableDesc);	}	long procId;	try {	procId = restoreSnapshot(snapshot, snapshotTableDesc, nonceKey, restoreAcl);	} catch (IOException e) {	
exception occurred while restoring the snapshot as table 

if (this.stopped) return;	this.stopped = true;	for (SnapshotSentinel snapshotHandler: this.snapshotHandlers.values()) {	snapshotHandler.cancel(why);	}	try {	if (coordinator != null) {	coordinator.close();	}	} catch (IOException e) {	
stop procedurecoordinator error 

Set<String> hfileCleaners = new HashSet<>();	String[] cleaners = conf.getStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS);	if (cleaners != null) Collections.addAll(hfileCleaners, cleaners);	Set<String> logCleaners = new HashSet<>();	cleaners = conf.getStrings(HConstants.HBASE_MASTER_LOGCLEANER_PLUGINS);	if (cleaners != null) Collections.addAll(logCleaners, cleaners);	Path oldSnapshotDir = new Path(mfs.getRootDir(), HConstants.OLD_SNAPSHOT_DIR_NAME);	FileSystem fs = mfs.getFileSystem();	List<SnapshotDescription> ss = getCompletedSnapshots(new Path(rootDir, oldSnapshotDir), false);	if (ss != null && !ss.isEmpty()) {	
snapshots from an earlier release were found under 

Set<String> hfileCleaners = new HashSet<>();	String[] cleaners = conf.getStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS);	if (cleaners != null) Collections.addAll(hfileCleaners, cleaners);	Set<String> logCleaners = new HashSet<>();	cleaners = conf.getStrings(HConstants.HBASE_MASTER_LOGCLEANER_PLUGINS);	if (cleaners != null) Collections.addAll(logCleaners, cleaners);	Path oldSnapshotDir = new Path(mfs.getRootDir(), HConstants.OLD_SNAPSHOT_DIR_NAME);	FileSystem fs = mfs.getFileSystem();	List<SnapshotDescription> ss = getCompletedSnapshots(new Path(rootDir, oldSnapshotDir), false);	if (ss != null && !ss.isEmpty()) {	
please rename the directory as 

if (ss != null && !ss.isEmpty()) {	}	if (snapshotEnabled) {	hfileCleaners.add(SnapshotHFileCleaner.class.getName());	hfileCleaners.add(HFileLinkCleaner.class.getName());	conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, hfileCleaners.toArray(new String[hfileCleaners.size()]));	conf.setStrings(HConstants.HBASE_MASTER_LOGCLEANER_PLUGINS, logCleaners.toArray(new String[logCleaners.size()]));	} else {	snapshotEnabled = hfileCleaners.contains(SnapshotHFileCleaner.class.getName()) && hfileCleaners.contains(HFileLinkCleaner.class.getName());	if (snapshotEnabled) {	
snapshot log and hfile cleaners are present in the configuration but the property is set to false is not set 

hfileCleaners.add(HFileLinkCleaner.class.getName());	conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, hfileCleaners.toArray(new String[hfileCleaners.size()]));	conf.setStrings(HConstants.HBASE_MASTER_LOGCLEANER_PLUGINS, logCleaners.toArray(new String[logCleaners.size()]));	} else {	snapshotEnabled = hfileCleaners.contains(SnapshotHFileCleaner.class.getName()) && hfileCleaners.contains(HFileLinkCleaner.class.getName());	if (snapshotEnabled) {	}	}	this.isSnapshotSupported = snapshotEnabled && !userDisabled;	if (!snapshotEnabled) {	
snapshot feature is not enabled missing log and hfile cleaners 

snapshotEnabled = hfileCleaners.contains(SnapshotHFileCleaner.class.getName()) && hfileCleaners.contains(HFileLinkCleaner.class.getName());	if (snapshotEnabled) {	}	}	this.isSnapshotSupported = snapshotEnabled && !userDisabled;	if (!snapshotEnabled) {	Path snapshotDir = SnapshotDescriptionUtils.getSnapshotsDir(mfs.getRootDir());	if (fs.exists(snapshotDir)) {	FileStatus[] snapshots = FSUtils.listStatus(fs, snapshotDir, new SnapshotDescriptionUtils.CompletedSnaphotDirectoriesFilter(fs));	if (snapshots != null) {	
snapshots are present but cleaners are not enabled 

========================= hbase sample_2762 =========================

Class<?> hadoopCredProviderClz = null;	hadoopCredProviderClz = Class.forName(HADOOP_CRED_PROVIDER_CLASS_NAME);	getCredentialEntryMethod = loadMethod(hadoopCredProviderClz, HADOOP_CRED_PROVIDER_GET_CREDENTIAL_ENTRY_METHOD_NAME, String.class);	getAliasesMethod = loadMethod(hadoopCredProviderClz, HADOOP_CRED_PROVIDER_GET_ALIASES_METHOD_NAME);	createCredentialEntryMethod = loadMethod(hadoopCredProviderClz, HADOOP_CRED_PROVIDER_CREATE_CREDENTIAL_ENTRY_METHOD_NAME, String.class, char[].class);	flushMethod = loadMethod(hadoopCredProviderClz, HADOOP_CRED_PROVIDER_FLUSH_METHOD_NAME);	Class<?> hadoopCredentialEntryClz = null;	try {	hadoopCredentialEntryClz = Class .forName(HADOOP_CRED_ENTRY_CLASS_NAME);	} catch (ClassNotFoundException e) {	
failed to load class 

try {	hadoopCredentialEntryClz = Class .forName(HADOOP_CRED_ENTRY_CLASS_NAME);	} catch (ClassNotFoundException e) {	return false;	}	getCredentialMethod = loadMethod(hadoopCredentialEntryClz, HADOOP_CRED_ENTRY_GET_CREDENTIAL_METHOD_NAME);	} catch (Exception e1) {	return false;	}	hadoopClassesAvailable = true;	
credential provider classes have been loaded and initialized successfully through reflection 

private Method loadMethod(Class<?> clz, String name, Class<?>... classes) throws Exception {	Method method = null;	try {	method = clz.getMethod(name, classes);	} catch (SecurityException e) {	fail("security exception caught for: " + name + " in " + clz.getCanonicalName());	throw e;	} catch (NoSuchMethodException e) {	
failed to load the 

protected  List<Object> getCredentialProviders(Configuration conf) {	Object providersObj = null;	try {	providersObj = getProvidersMethod.invoke(hadoopCredProviderFactory, conf);	} catch (IllegalArgumentException e) {	
failed to invoke 

protected  List<Object> getCredentialProviders(Configuration conf) {	Object providersObj = null;	try {	providersObj = getProvidersMethod.invoke(hadoopCredProviderFactory, conf);	} catch (IllegalArgumentException e) {	return null;	} catch (IllegalAccessException e) {	
failed to invoke 

protected  List<Object> getCredentialProviders(Configuration conf) {	Object providersObj = null;	try {	providersObj = getProvidersMethod.invoke(hadoopCredProviderFactory, conf);	} catch (IllegalArgumentException e) {	return null;	} catch (IllegalAccessException e) {	return null;	} catch (InvocationTargetException e) {	
failed to invoke 

========================= hbase sample_880 =========================

kvs.add(kv);	}	}	if (cells == null) {	familyMap.put(entry.getKey(), entry.getValue());	}	}	if (cnt % 10 == 0) context.setStatus("Combine " + cnt);	if (curSize > threshold) {	if (LOG.isDebugEnabled()) {	
combined d put s into d 

}	context.write(row, put);	put = null;	curSize = 0;	cnt = 0;	}	}	}	if (put != null) {	if (LOG.isDebugEnabled()) {	
combined d put s into d 

========================= hbase sample_3489 =========================

public void testIsSameHdfs() throws IOException {	String hadoopVersion = org.apache.hadoop.util.VersionInfo.getVersion();	
hadoop version is 

========================= hbase sample_1322 =========================

continue;	}	Call call = callsToWrite.poll();	if (call.isDone()) {	continue;	}	try {	tracedWriteRequest(call);	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
call write error for call 

this.socket.setTcpNoDelay(this.rpcClient.isTcpNoDelay());	this.socket.setKeepAlive(this.rpcClient.tcpKeepAlive);	if (this.rpcClient.localAddr != null) {	this.socket.bind(this.rpcClient.localAddr);	}	NetUtils.connect(this.socket, remoteId.getAddress(), this.rpcClient.connectTO);	this.socket.setSoTimeout(this.rpcClient.readTO);	return;	} catch (SocketTimeoutException toe) {	if (LOG.isDebugEnabled()) {	
received exception in connection setup 

}	NetUtils.connect(this.socket, remoteId.getAddress(), this.rpcClient.connectTO);	this.socket.setSoTimeout(this.rpcClient.readTO);	return;	} catch (SocketTimeoutException toe) {	if (LOG.isDebugEnabled()) {	}	handleConnectionFailure(timeoutFailures++, this.rpcClient.maxRetries, toe);	} catch (IOException ie) {	if (LOG.isDebugEnabled()) {	
received exception in connection setup 

closeSocket();	if (curRetries >= maxRetries || ExceptionUtil.isInterrupt(ioe)) {	throw ioe;	}	try {	Thread.sleep(this.rpcClient.failureSleep);	} catch (InterruptedException ie) {	ExceptionUtil.rethrowIfInterrupt(ie);	}	if (LOG.isInfoEnabled()) {	
retrying connect to server after sleeping ms already tried time s 

public void run() {	if (LOG.isTraceEnabled()) {	
starting connections 

public void run() {	if (LOG.isTraceEnabled()) {	}	while (waitForWork()) {	readResponse();	}	if (LOG.isTraceEnabled()) {	
stopped connections 

private void handleSaslConnectionFailure(final int currRetries, final int maxRetries, final Exception ex, final UserGroupInformation user) throws IOException, InterruptedException {	closeSocket();	user.doAs(new PrivilegedExceptionAction<Object>() {	public Object run() throws IOException, InterruptedException {	if (shouldAuthenticateOverKrb()) {	if (currRetries < maxRetries) {	if (LOG.isDebugEnabled()) {	
exception encountered while connecting to the server 

relogin();	disposeSasl();	Thread.sleep(ThreadLocalRandom.current().nextInt(reloginMaxBackoff) + 1);	return null;	} else {	String msg = "Couldn't setup connection for " + UserGroupInformation.getLoginUser().getUserName() + " to " + serverPrincipal;	LOG.warn(msg, ex);	throw (IOException) new IOException(msg).initCause(ex);	}	} else {	
exception encountered while connecting to the server 

private void setupIOstreams() throws IOException {	if (socket != null) {	return;	}	if (this.rpcClient.failedServers.isFailedServer(remoteId.getAddress())) {	if (LOG.isDebugEnabled()) {	
not trying to connect to this server is in the failed servers list 

if (socket != null) {	return;	}	if (this.rpcClient.failedServers.isFailedServer(remoteId.getAddress())) {	if (LOG.isDebugEnabled()) {	}	throw new FailedServerException( "This server is in the failed servers list: " + remoteId.address);	}	try {	if (LOG.isDebugEnabled()) {	
connecting to 

private void processResponseForConnectionHeader() throws IOException {	if (!waitingConnectionHeaderResponse) return;	try {	int len = this.in.readInt();	byte[] buff = new byte[len];	int readSize = this.in.read(buff);	if (LOG.isDebugEnabled()) {	
length of response for connection header 

byte[] buff = new byte[len];	int readSize = this.in.read(buff);	if (LOG.isDebugEnabled()) {	}	RPCProtos.ConnectionHeaderResponse connectionHeaderResponse = RPCProtos.ConnectionHeaderResponse.parseFrom(buff);	if (connectionHeaderResponse.hasCryptoCipherMeta()) {	negotiateCryptoAes(connectionHeaderResponse.getCryptoCipherMeta());	}	waitingConnectionHeaderResponse = false;	} catch (SocketTimeoutException ste) {	
can t get the connection header response for rpc timeout please check if server has the correct configuration to support the additional function 

RequestHeader requestHeader = buildRequestHeader(call, cellBlockMeta);	setupIOstreams();	if (Thread.interrupted()) {	throw new InterruptedIOException();	}	calls.put(call.id, call);	try {	call.callStats.setRequestSizeBytes(write(this.out, requestHeader, call.param, cellBlock));	} catch (Throwable t) {	if(LOG.isTraceEnabled()) {	
error while writing call call id 

call.setResponse(value, cellBlockScanner);	call.callStats.setResponseSizeBytes(totalSize);	call.callStats .setCallTimeMs(EnvironmentEdgeManager.currentTime() - call.callStats.getStartTime());	}	} catch (IOException e) {	if (expectedCall) {	call.setException(e);	}	if (e instanceof SocketTimeoutException) {	if (LOG.isTraceEnabled()) {	
ignored 

========================= hbase sample_245 =========================

public void stop(String why) {	
stop 

}	Procedure proc = coordinator.startProcedure(monitor, desc.getInstance(), new byte[0], servers);	if (proc == null) {	String msg = "Failed to submit distributed procedure for '" + getProcedureSignature() + "'";	LOG.error(msg);	throw new IOException(msg);	}	HashMap<String, byte[]> returnData = null;	try {	returnData = proc.waitForCompletedWithRet();	
done waiting exec procedure for 

========================= hbase sample_1565 =========================

public void execute() throws IOException {	try {	failStageIf(Stage.stage_0);	beginBackup(backupManager, backupInfo);	failStageIf(Stage.stage_1);	backupInfo.setPhase(BackupPhase.PREPARE_INCREMENTAL);	
for incremental backup current table set is 

beginBackup(backupManager, backupInfo);	failStageIf(Stage.stage_0);	String savedStartCode = null;	boolean firstBackup = false;	savedStartCode = backupManager.readBackupStartCode();	firstBackup = savedStartCode == null || Long.parseLong(savedStartCode) == 0L;	if (firstBackup) {	backupManager.writeBackupStartCode(0L);	}	failStageIf(Stage.stage_1);	
execute roll log procedure for full backup 

List<String> logFiles = BackupUtils.getWALFilesOlderThan(conf, newTimestamps);	backupManager.recordWALFiles(logFiles);	}	backupInfo.setPhase(BackupPhase.SNAPSHOT);	for (TableName tableName : tableList) {	String snapshotName = "snapshot_" + Long.toString(EnvironmentEdgeManager.currentTime()) + "_" + tableName.getNamespaceAsString() + "_" + tableName.getQualifierAsString();	snapshotTable(admin, tableName, snapshotName);	backupInfo.setSnapshotName(tableName, snapshotName);	}	failStageIf(Stage.stage_3);	
snapshot copy for 

if (useSecondCluster) {	conf2 = HBaseConfiguration.create(conf1);	conf2.set(HConstants.ZOOKEEPER_ZNODE_PARENT, "/2");	TEST_UTIL2 = new HBaseTestingUtility(conf2);	TEST_UTIL2.setZkCluster(TEST_UTIL.getZkCluster());	TEST_UTIL2.startMiniCluster();	}	conf1 = TEST_UTIL.getConfiguration();	TEST_UTIL.startMiniMapReduceCluster();	BACKUP_ROOT_DIR = new Path ( new Path(TEST_UTIL.getConfiguration().get("fs.defaultFS")), BACKUP_ROOT_DIR).toString();	
rootdir 

conf2.set(HConstants.ZOOKEEPER_ZNODE_PARENT, "/2");	TEST_UTIL2 = new HBaseTestingUtility(conf2);	TEST_UTIL2.setZkCluster(TEST_UTIL.getZkCluster());	TEST_UTIL2.startMiniCluster();	}	conf1 = TEST_UTIL.getConfiguration();	TEST_UTIL.startMiniMapReduceCluster();	BACKUP_ROOT_DIR = new Path ( new Path(TEST_UTIL.getConfiguration().get("fs.defaultFS")), BACKUP_ROOT_DIR).toString();	if (useSecondCluster) {	BACKUP_REMOTE_ROOT_DIR = new Path ( new Path(TEST_UTIL2.getConfiguration().get("fs.defaultFS")) + BACKUP_REMOTE_ROOT_DIR).toString();	
remote rootdir 

========================= hbase sample_547 =========================

private List<FileStatus> getWALFiles(FileSystem fs, Path dir) throws IOException {	List<FileStatus> result = new ArrayList<FileStatus>();	
scanning for wal files 

========================= hbase sample_1359 =========================

byte[] fam = Bytes.toBytes("testfamily");	byte[] qf = Bytes.toBytes("testqualifier");	MemStoreSizing memstoreSizing = new MemStoreSizing();	for (int i = 0; i < keys.length; i++) {	long timestamp = System.currentTimeMillis();	Threads.sleep(1);	byte[] row = Bytes.toBytes(keys[i]);	byte[] val = Bytes.toBytes(keys[i] + i);	KeyValue kv = new KeyValue(row, fam, qf, timestamp, val);	hmc.add(kv, memstoreSizing);	
added kv timestamp 

========================= hbase sample_1709 =========================

public boolean isSwitchEnabled() {	byte [] upData = super.getData(false);	try {	return upData == null || parseFrom(upData).getEnabled();	} catch (DeserializationException dex) {	
zk state for loadbalancer could not be parsed 

========================= hbase sample_2826 =========================

public Long startCacheFlush(byte[] encodedRegionName, Set<byte[]> families) {	if (!closeBarrier.beginOp()) {	
flush not started for server closing 

public Long startCacheFlush(byte[] encodedRegionName, Map<byte[], Long> familyToSeq) {	if (!closeBarrier.beginOp()) {	
flush not started for server closing 

protected final void blockOnSync(SyncFuture syncFuture) throws IOException {	try {	if (syncFuture != null) {	syncFuture.get(walSyncTimeoutNs);	}	} catch (TimeoutIOException tioe) {	this.syncFuturesByHandler.remove(Thread.currentThread());	throw tioe;	} catch (InterruptedException ie) {	
Interrupted 

public void shutdown() throws IOException {	if (!shutdown.compareAndSet(false, true)) {	return;	}	closed = true;	try {	closeBarrier.stopAndDrainOps();	} catch (InterruptedException e) {	
exception while waiting for cache flushes and log rolls 

}	if (!CommonFSUtils.renameAndSetModifyTime(fs, file.getPath(), p)) {	throw new IOException("Unable to rename " + file.getPath() + " to " + p);	}	if (!this.listeners.isEmpty()) {	for (WALActionsListener i : this.listeners) {	i.postLogArchive(file.getPath(), p);	}	}	}	
moved wal file s to 

if (!CommonFSUtils.renameAndSetModifyTime(fs, file.getPath(), p)) {	throw new IOException("Unable to rename " + file.getPath() + " to " + p);	}	if (!this.listeners.isEmpty()) {	for (WALActionsListener i : this.listeners) {	i.postLogArchive(file.getPath(), p);	}	}	}	}	
closed wal 

public static void main(String[] args) throws IOException {	if (args.length < 2) {	usage();	System.exit(-1);	}	if (args[0].compareTo("--dump") == 0) {	WALPrettyPrinter.run(Arrays.copyOfRange(args, 1, args.length));	} else if (args[0].compareTo("--perf") == 0) {	
please use the walperformanceevaluation tool instead i e 

public static void main(String[] args) throws IOException {	if (args.length < 2) {	usage();	System.exit(-1);	}	if (args[0].compareTo("--dump") == 0) {	WALPrettyPrinter.run(Arrays.copyOfRange(args, 1, args.length));	} else if (args[0].compareTo("--perf") == 0) {	
thbase org apache hadoop hbase wal walperformanceevaluation iterations 

========================= hbase sample_2575 =========================

throw new IllegalArgumentException("#" + id + ", row cannot be null");	}	RegionLocations locs = connection.locateRegion( tableName, r.getRow(), true, true, RegionReplicaUtil.DEFAULT_REPLICA_ID);	if (locs == null || locs.isEmpty() || locs.getDefaultRegionLocation() == null) {	throw new IOException("#" + id + ", no location found, aborting submit for" + " tableName=" + tableName + " rowkey=" + Bytes.toStringBinary(r.getRow()));	}	loc = locs.getDefaultRegionLocation();	} catch (IOException ex) {	locationErrors = new ArrayList<>(1);	locationErrorRows = new ArrayList<>(1);	
failed to get region location 

========================= hbase sample_394 =========================

SleepAndFailFirstTime.ct.set(0);	try (Table table = builder.setOperationTimeout(120 * 1000).build()) {	execute(table);	}	SleepAndFailFirstTime.ct.set(0);	try (Table table = builder.setOperationTimeout(30 * 1000).build()) {	SleepAndFailFirstTime.ct.set(0);	execute(table);	fail("We expect an exception here");	} catch (SocketTimeoutException | RetriesExhaustedWithDetailsException e) {	
we received an exception as expected 

========================= hbase sample_2125 =========================

public void addHFileRefs(TableName tableName, byte[] family, List<Pair<Path, Path>> pairs) throws ReplicationException {	Map<TableName, List<String>> tableCFMap = replicationPeer.getTableCFs();	if (tableCFMap != null) {	List<String> tableCfs = tableCFMap.get(tableName);	if (tableCFMap.containsKey(tableName) && (tableCfs == null || tableCfs.contains(Bytes.toString(family)))) {	this.queueStorage.addHFileRefs(peerId, pairs);	metrics.incrSizeOfHFileRefsQueue(pairs.size());	} else {	
hfiles will not be replicated belonging to the table family to peer id 

protected void tryStartNewShipper(String walGroupId, PriorityBlockingQueue<Path> queue) {	ReplicationSourceShipper worker = new ReplicationSourceShipper(conf, walGroupId, queue, this);	ReplicationSourceShipper extant = workerThreads.putIfAbsent(walGroupId, worker);	if (extant != null) {	
someone has beat us to start a worker thread for wal group 

protected void tryStartNewShipper(String walGroupId, PriorityBlockingQueue<Path> queue) {	ReplicationSourceShipper worker = new ReplicationSourceShipper(conf, walGroupId, queue, this);	ReplicationSourceShipper extant = workerThreads.putIfAbsent(walGroupId, worker);	if (extant != null) {	} else {	
starting up worker for wal group 

public void tryThrottle(int batchSize) throws InterruptedException {	checkBandwidthChangeAndResetThrottler();	if (throttler.isEnabled()) {	long sleepTicks = throttler.getNextSleepInterval(batchSize);	if (sleepTicks > 0) {	if (LOG.isTraceEnabled()) {	
to sleep ms for throttling control 

protected boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	
sleeping times 

protected boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	}	Thread.sleep(this.sleepForRetries * sleepMultiplier);	} catch (InterruptedException e) {	
interrupted while sleeping between retries 

private void initialize() {	int sleepMultiplier = 1;	while (this.isSourceActive()) {	ReplicationEndpoint replicationEndpoint;	try {	replicationEndpoint = createReplicationEndpoint();	} catch (Exception e) {	
error creating replicationendpoint retry 

if (sleepForRetries("Error creating ReplicationEndpoint", sleepMultiplier)) {	sleepMultiplier++;	}	continue;	}	try {	initAndStartReplicationEndpoint(replicationEndpoint);	this.replicationEndpoint = replicationEndpoint;	break;	} catch (Exception e) {	
error starting replicationendpoint retry 

if (sleepForRetries("Cannot contact the peer's zk ensemble", sleepMultiplier)) {	sleepMultiplier++;	}	}	}	if (clusterId.equals(peerClusterId) && !replicationEndpoint.canReplicateToSameCluster()) {	this.terminate("ClusterId " + clusterId + " is replicating to itself: peerClusterId " + peerClusterId + " which is not allowed by ReplicationEndpoint:" + replicationEndpoint.getClass().getName(), null, false);	this.manager.removeSource(this);	return;	}	
replicating 

public void terminate(String reason, Exception cause, boolean join) {	if (cause == null) {	
closing source because 

public void terminate(String reason, Exception cause, boolean join) {	if (cause == null) {	} else {	
closing source because an error occurred 

worker.stopWorker();	worker.entryReader.interrupt();	worker.interrupt();	}	if (this.replicationEndpoint != null) {	this.replicationEndpoint.stop();	}	if (join) {	for (ReplicationSourceShipper worker : workers) {	Threads.shutdown(worker, this.sleepForRetries);	
replicationsourceworker terminated 

this.replicationEndpoint.stop();	}	if (join) {	for (ReplicationSourceShipper worker : workers) {	Threads.shutdown(worker, this.sleepForRetries);	}	if (this.replicationEndpoint != null) {	try {	this.replicationEndpoint.awaitTerminated(sleepForRetries * maxRetriesMultiplier, TimeUnit.MILLISECONDS);	} catch (TimeoutException te) {	
got exception while waiting for endpoint to shutdown for replication source 

========================= hbase sample_2963 =========================

public void testInterfaceAudienceAnnotation() throws ClassNotFoundException, IOException, LinkageError {	ClassFinder classFinder = new ClassFinder( new And(new MainCodeResourcePathFilter(), new TestFileNameFilter()), new Not((FileNameFilter)new TestFileNameFilter()), new And(new PublicClassFilter(), new Not(new TestClassFilter()), new Not(new GeneratedClassFilter()), new Not(new ShadedProtobufClassFilter()), new Not(new IsInterfaceStabilityClassFilter()), new Not(new InterfaceAudienceAnnotatedClassFilter()), new Not(new CloverInstrumentationFilter())) );	Set<Class<?>> classes = classFinder.findClasses(false);	if (!classes.isEmpty()) {	
these are the classes that do not have interfaceaudience annotation 

public void testNoInterfaceStabilityAnnotationForPublicAPI() throws ClassNotFoundException, IOException, LinkageError {	ClassFinder classFinder = new ClassFinder( new And(new MainCodeResourcePathFilter(), new TestFileNameFilter()), new Not((FileNameFilter)new TestFileNameFilter()), new And(new PublicClassFilter(), new Not(new TestClassFilter()), new Not(new GeneratedClassFilter()), new Not(new ShadedProtobufClassFilter()), new InterfaceAudiencePublicAnnotatedClassFilter(), new Not(new IsInterfaceStabilityClassFilter()), new InterfaceStabilityAnnotatedClassFilter()) );	Set<Class<?>> classes = classFinder.findClasses(false);	if (!classes.isEmpty()) {	
these are the interfaceaudience public classes that have interfacestability annotation 

public void testInterfaceStabilityAnnotationForLimitedAPI() throws ClassNotFoundException, IOException, LinkageError {	ClassFinder classFinder = new ClassFinder( new And(new MainCodeResourcePathFilter(), new TestFileNameFilter()), new Not((FileNameFilter)new TestFileNameFilter()), new And(new PublicClassFilter(), new Not(new TestClassFilter()), new Not(new GeneratedClassFilter()), new Not(new ShadedProtobufClassFilter()), new InterfaceAudienceLimitedPrivateAnnotatedNotConfigClassFilter(), new Not(new IsInterfaceStabilityClassFilter()), new Not(new InterfaceStabilityAnnotatedClassFilter())) );	Set<Class<?>> classes = classFinder.findClasses(false);	if (!classes.isEmpty()) {	
these are the interfaceaudience limitedprivate classes that do not have interfacestability annotation 

public void testProtosInReturnTypes() throws ClassNotFoundException, IOException, LinkageError {	Set<Class<?>> classes = findPublicClasses();	List<Pair<Class<?>, Method>> protosReturnType = new ArrayList<>();	for (Class<?> clazz : classes) {	findProtoInReturnType(clazz, protosReturnType);	}	if (protosReturnType.size() != 0) {	
these are the methods that have protos as the return type 

public void testProtosInParamTypes() throws ClassNotFoundException, IOException, LinkageError {	Set<Class<?>> classes = findPublicClasses();	List<Triple<Class<?>, Method, Class<?>>> protosParamType = new ArrayList<>();	for (Class<?> clazz : classes) {	findProtoInParamType(clazz, protosParamType);	}	if (protosParamType.size() != 0) {	
these are the methods that have protos as the param type 

for (Class<?> param : parameterTypes) {	if (param.getName().contains(HBASE_PROTOBUF)) {	classList.add(clazz);	break;	}	}	}	}	}	if (classList.size() != 0) {	
these are the classes that have protos in the constructor 

========================= hbase sample_49 =========================

public void sendGlobalBarrierReached(Procedure proc, List<String> nodeNames) throws IOException {	String procName = proc.getName();	String reachedNode = zkProc.getReachedBarrierNode(procName);	
creating reached barrier zk node 

public void nodeCreated(String path) {	if (!isInProcedurePath(path)) return;	
node created 

String procName = ZKUtil.getNodeName(ZKUtil.getParent(path));	String member = ZKUtil.getNodeName(path);	try {	byte[] dataFromMember = ZKUtil.getData(watcher, path);	if (dataFromMember != null && dataFromMember.length > 0) {	if (!ProtobufUtil.isPBMagicPrefix(dataFromMember)) {	ForeignException ee = new ForeignException(coordName, "Failed to get data from finished node or data is illegally formatted:" + path);	coordinator.abortProcedure(procName, ee);	} else {	dataFromMember = Arrays.copyOfRange(dataFromMember, ProtobufUtil.lengthOfPBMagic(), dataFromMember.length);	
finished data from procedure member 

} catch (KeeperException e) {	ForeignException ee = new ForeignException(coordName, e);	coordinator.abortProcedure(procName, ee);	} catch (InterruptedException e) {	ForeignException ee = new ForeignException(coordName, e);	coordinator.abortProcedure(procName, ee);	}	} else if (isAbortPathNode(path)) {	abort(path);	} else {	
ignoring created notification for node 

protected void abort(String abortNode) {	String procName = ZKUtil.getNodeName(abortNode);	ForeignException ee = null;	try {	byte[] data = ZKUtil.getData(zkProc.getWatcher(), abortNode);	if (data == null || data.length == 0) {	return;	} else if (!ProtobufUtil.isPBMagicPrefix(data)) {	
got an error notification for op but we can t read the information killing the procedure 

byte[] data = ZKUtil.getData(zkProc.getWatcher(), abortNode);	if (data == null || data.length == 0) {	return;	} else if (!ProtobufUtil.isPBMagicPrefix(data)) {	ee = new ForeignException(coordName, "Data in abort node is illegally formatted.  ignoring content.");	} else {	data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	ee = ForeignException.deserialize(data);	}	} catch (IOException e) {	
got an error notification for op but we can t read the information killing the procedure 

========================= hbase sample_2488 =========================

public Collection<StoreFileInfo> getStoreFiles(final String familyName, final boolean validate) throws IOException {	Path familyDir = getStoreDir(familyName);	FileStatus[] files = FSUtils.listStatus(this.fs, familyDir);	if (files == null) {	if (LOG.isTraceEnabled()) {	
no storefiles for 

Path familyDir = getStoreDir(familyName);	FileStatus[] files = FSUtils.listStatus(this.fs, familyDir);	if (files == null) {	if (LOG.isTraceEnabled()) {	}	return null;	}	ArrayList<StoreFileInfo> storeFiles = new ArrayList<>(files.length);	for (FileStatus status: files) {	if (validate && !StoreFileInfo.isValid(status)) {	
invalid storefile 

public static List<LocatedFileStatus> getStoreFilesLocatedStatus( final HRegionFileSystem regionfs, final String familyName, final boolean validate) throws IOException {	Path familyDir = regionfs.getStoreDir(familyName);	List<LocatedFileStatus> locatedFileStatuses = FSUtils.listLocatedStatus( regionfs.getFileSystem(), familyDir);	if (locatedFileStatuses == null) {	if (LOG.isTraceEnabled()) {	
no storefiles for 

Path familyDir = regionfs.getStoreDir(familyName);	List<LocatedFileStatus> locatedFileStatuses = FSUtils.listLocatedStatus( regionfs.getFileSystem(), familyDir);	if (locatedFileStatuses == null) {	if (LOG.isTraceEnabled()) {	}	return null;	}	List<LocatedFileStatus> validStoreFiles = Lists.newArrayList();	for (LocatedFileStatus status : locatedFileStatuses) {	if (validate && !StoreFileInfo.isValid(status)) {	
invalid storefile 

public boolean hasReferences(final String familyName) throws IOException {	Path storeDir = getStoreDir(familyName);	FileStatus[] files = FSUtils.listStatus(fs, storeDir);	if (files != null) {	for(FileStatus stat: files) {	if(stat.isDirectory()) {	continue;	}	if(StoreFileInfo.isReference(stat.getPath())) {	
reference 

if(!fs.exists(storeDir) && !createDir(storeDir)) throw new IOException("Failed creating " + storeDir);	String name = buildPath.getName();	if (generateNewName) {	name = generateUniqueName((seqNum < 0) ? null : "_SeqId_" + seqNum + "_");	}	Path dstPath = new Path(storeDir, name);	if (!fs.exists(buildPath)) {	throw new FileNotFoundException(buildPath.toString());	}	if (LOG.isDebugEnabled()) {	
committing store file as 

public void createSplitsDir() throws IOException {	Path splitdir = getSplitsDir();	if (fs.exists(splitdir)) {	
the directory exists hence deleting it to recreate it 

public void createMergesDir() throws IOException {	Path mergesdir = getMergesDir();	if (fs.exists(mergesdir)) {	
the directory exists hence deleting it to recreate it 

public static HRegionFileSystem createRegionOnFileSystem(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (fs.exists(regionDir)) {	
trying to create a region that already exists on disk 

public static HRegionFileSystem createRegionOnFileSystem(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (fs.exists(regionDir)) {	throw new IOException("The specified region already exists on disk: " + regionDir);	}	if (!createDirOnFileSystem(fs, conf, regionDir)) {	
unable to create the region directory 

Path regionDir = regionFs.getRegionDir();	if (fs.exists(regionDir)) {	throw new IOException("The specified region already exists on disk: " + regionDir);	}	if (!createDirOnFileSystem(fs, conf, regionDir)) {	throw new IOException("Unable to create region directory: " + regionDir);	}	if (regionInfo.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	regionFs.writeRegionInfoOnFilesystem(false);	} else {	
skipping creation of regioninfo file for 

public static HRegionFileSystem openRegionFromFileSystem(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo, boolean readOnly) throws IOException {	HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (!fs.exists(regionDir)) {	
trying to open a region that do not exists on disk 

throw new IOException("The specified region do not exists on disk: " + regionDir);	}	if (!readOnly) {	regionFs.cleanupTempDir();	regionFs.cleanupSplitsDir();	regionFs.cleanupMergesDir();	if (regionInfo.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	regionFs.checkRegionInfoOnFilesystem();	} else {	if (LOG.isDebugEnabled()) {	
skipping creation of regioninfo file for 

public static void deleteRegionFromFileSystem(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (!fs.exists(regionDir)) {	
trying to delete a region that do not exists on disk 

public static void deleteRegionFromFileSystem(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (!fs.exists(regionDir)) {	return;	}	if (LOG.isDebugEnabled()) {	
deleting region 

HRegionFileSystem regionFs = new HRegionFileSystem(conf, fs, tableDir, regionInfo);	Path regionDir = regionFs.getRegionDir();	if (!fs.exists(regionDir)) {	return;	}	if (LOG.isDebugEnabled()) {	}	Path rootDir = FSUtils.getRootDir(conf);	HFileArchiver.archiveRegion(fs, rootDir, tableDir, regionDir);	if (!fs.delete(regionDir, true)) {	
failed delete of 

private static void sleepBeforeRetry(String msg, int sleepMultiplier, int baseSleepBeforeRetries, int hdfsClientRetriesNumber) throws InterruptedException {	if (sleepMultiplier > hdfsClientRetriesNumber) {	if (LOG.isDebugEnabled()) {	
retries exhausted 

private static void sleepBeforeRetry(String msg, int sleepMultiplier, int baseSleepBeforeRetries, int hdfsClientRetriesNumber) throws InterruptedException {	if (sleepMultiplier > hdfsClientRetriesNumber) {	if (LOG.isDebugEnabled()) {	}	return;	}	if (LOG.isDebugEnabled()) {	
sleeping times 

========================= hbase sample_2522 =========================

public void perform() throws Exception {	
performing action dump cluster status 

public void perform() throws Exception {	
cluster status 

========================= hbase sample_3299 =========================

public void perform() throws Exception {	final Random random = new Random();	final BloomType[] bloomArray = BloomType.values();	final int bloomArraySize = bloomArray.length;	
performing action change bloom filter on all columns of table 

public void perform() throws Exception {	final Random random = new Random();	final BloomType[] bloomArray = BloomType.values();	final int bloomArraySize = bloomArray.length;	modifyAllTableColumns(tableName, (columnName, columnBuilder) -> {	BloomType bloomType = bloomArray[random.nextInt(bloomArraySize)];	
performing action about to set bloom filter type to on column of table 

public void perform() throws Exception {	final Random random = new Random();	final BloomType[] bloomArray = BloomType.values();	final int bloomArraySize = bloomArray.length;	modifyAllTableColumns(tableName, (columnName, columnBuilder) -> {	BloomType bloomType = bloomArray[random.nextInt(bloomArraySize)];	columnBuilder.setBloomFilterType(bloomType);	});	
performing action just set bloom filter types on table 

========================= hbase sample_3333 =========================

public synchronized Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	try {	return cache.getUnreferencedFiles(files, master.getSnapshotManager());	} catch (CorruptedSnapshotException cse) {	
corrupted in progress snapshot file exception ignored 

public synchronized Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	try {	return cache.getUnreferencedFiles(files, master.getSnapshotManager());	} catch (CorruptedSnapshotException cse) {	} catch (IOException e) {	
exception while checking if files were valid keeping them just in case 

try {	long cacheRefreshPeriod = conf.getLong(HFILE_CACHE_REFRESH_PERIOD_CONF_KEY, DEFAULT_HFILE_CACHE_REFRESH_PERIOD);	final FileSystem fs = FSUtils.getCurrentFileSystem(conf);	Path rootDir = FSUtils.getRootDir(conf);	cache = new SnapshotFileCache(fs, rootDir, cacheRefreshPeriod, cacheRefreshPeriod, "snapshot-hfile-cleaner-cache-refresher", new SnapshotFileCache.SnapshotFileInspector() {	public Collection<String> filesUnderSnapshot(final Path snapshotDir) throws IOException {	return SnapshotReferenceUtil.getHFileNames(conf, fs, snapshotDir);	}	});	} catch (IOException e) {	
failed to create cleaner util 

========================= hbase sample_2758 =========================

HColumnDescriptor hcd = new HColumnDescriptor(contents);	hcd.setMaxVersions(3);	desc.addFamily(hcd);	this.admin.createTable(desc);	Put put = new Put(row, timestamp1);	put.addColumn(contents, contents, value1);	Table table = UTIL.getConnection().getTable(desc.getTableName());	table.put(put);	table.close();	UTIL.shutdownMiniHBaseCluster();	
hbase cluster shut down restarting 

========================= hbase sample_1524 =========================

public RefreshHFilesProtos.RefreshHFilesResponse call( RefreshHFilesProtos.RefreshHFilesService refreshHFilesService) throws IOException {	ServerRpcController controller = new ServerRpcController();	BlockingRpcCallback<RefreshHFilesProtos.RefreshHFilesResponse> rpcCallback = new BlockingRpcCallback<>();	refreshHFilesService.refreshHFiles(controller, request, rpcCallback);	if (controller.failedOnException()) {	throw controller.getFailedOn();	}	return rpcCallback.get();	}	});	
done refreshing hfiles 

========================= hbase sample_1174 =========================

boolean isPartial = response.getPartialFlagPerResultCount() > i ? response.getPartialFlagPerResult(i) : false;	List<Cell> cells = new ArrayList<>(noOfCells);	for (int j = 0; j < noOfCells; j++) {	try {	if (cellScanner.advance() == false) {	String msg = "Results sent from server=" + noOfResults + ". But only got " + i + " results completely at client. Resetting the scanner to scan again.";	LOG.error(msg);	throw new DoNotRetryIOException(msg);	}	} catch (IOException ioe) {	
exception while reading cells from result resetting the scanner to scan again 

========================= hbase sample_156 =========================

public void testReplicationStatus() throws Exception {	
testReplicationStatus 

========================= hbase sample_1932 =========================

public void perform() throws IOException {	
performing action changing encodings on 

public void perform() throws IOException {	final int[] possibleIds = {0, 2, 3, 4, 6};	modifyAllTableColumns(tableName, (columnName, columnBuilder) -> {	short id = (short) possibleIds[random.nextInt(possibleIds.length)];	DataBlockEncoding encoding = DataBlockEncoding.getEncodingById(id);	columnBuilder.setDataBlockEncoding(encoding);	
set encoding of column family to 

========================= hbase sample_3325 =========================

protected void closeHTable() {	if (table != null) {	try {	table.close();	} catch (Exception e) {	
error in closing the table 

if (e instanceof RetriesExhaustedWithDetailsException) {	RetriesExhaustedWithDetailsException aggEx = (RetriesExhaustedWithDetailsException) e;	exceptionInfo = aggEx.getExhaustiveDescription();	} else {	StringWriter stackWriter = new StringWriter();	PrintWriter pw = new PrintWriter(stackWriter);	e.printStackTrace(pw);	pw.flush();	exceptionInfo = StringUtils.stringifyException(e);	}	
failed to insert after ms region information errors 

========================= hbase sample_1318 =========================

public void execute(Admin admin) {	
executing splitting normalization plan 

public void execute(Admin admin) {	try {	admin.splitRegion(regionInfo.getRegionName());	} catch (IOException ex) {	
error during region split 

========================= hbase sample_2867 =========================

private static long humanReadableIntervalToSec(final String humanReadableInterval) throws HBaseException {	if (humanReadableInterval == null || humanReadableInterval.equalsIgnoreCase("FOREVER")) {	return HConstants.FOREVER;	}	try {	return Long.parseLong(humanReadableInterval);	} catch(NumberFormatException ex) {	
given interval value is not a number parsing for human readable format 

========================= hbase sample_947 =========================

put2.addColumn(CF2, Bytes.toBytes("col_b"), Bytes.toBytes(0));	table.put(put2);	FamilyFilter filterCF1 = new FamilyFilter(CompareFilter.CompareOp.EQUAL, new BinaryComparator(CF1));	FamilyFilter filterCF2 = new FamilyFilter(CompareFilter.CompareOp.EQUAL, new BinaryComparator(CF2));	FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);	filterList.addFilter(filterCF1);	filterList.addFilter(filterCF2);	Scan scan = new Scan();	scan.setFilter(filterList);	ResultScanner scanner = table.getScanner(scan);	
filter list 

========================= hbase sample_1965 =========================

public void testFullBackupSingleEmpty() throws Exception {	
create full backup image on single table 

public void testFullBackupSingleEmpty() throws Exception {	List<TableName> tables = Lists.newArrayList(table3);	
finished backup 

public void testFullBackupMultipleEmpty() throws Exception {	
create full backup image on mulitple empty tables 

public void testFullBackupSingleDNE() throws Exception {	
test full backup fails on a single table that does not exist 

public void testFullBackupMultipleDNE() throws Exception {	
test full backup fails on multiple tables that do not exist 

public void testFullBackupMixExistAndDNE() throws Exception {	
create full backup fails on tableset containing real and fake table 

========================= hbase sample_551 =========================

options.addOption("t", READ_TIMEOUT_OPTION, true, "Amount of time in milliseconds before a server thread will timeout " + "waiting for client to send data on a connected socket. Currently, " + "only applies to TBoundedThreadPoolServer");	options.addOptionGroup(ImplType.createOptionGroup());	CommandLineParser parser = new PosixParser();	CommandLine cmd = parser.parse(options, args);	List<String> commandLine = Arrays.asList(args);	boolean stop = commandLine.contains("stop");	boolean start = commandLine.contains("start");	boolean invalidStartStop = (start && stop) || (!start && !stop);	if (cmd.hasOption("help") || invalidStartStop) {	if (invalidStartStop) {	
exactly one of start and stop has to be specified 

if (invalidStartStop) {	}	printUsageAndExit(options, 1);	}	try {	if (cmd.hasOption(PORT_OPTION)) {	int listenPort = Integer.parseInt(cmd.getOptionValue(PORT_OPTION));	conf.setInt(ThriftServerRunner.PORT_CONF_KEY, listenPort);	}	} catch (NumberFormatException e) {	
could not parse the value provided for the port option 

int listenPort = Integer.parseInt(cmd.getOptionValue(PORT_OPTION));	conf.setInt(ThriftServerRunner.PORT_CONF_KEY, listenPort);	}	} catch (NumberFormatException e) {	printUsageAndExit(options, -1);	}	try {	if (cmd.hasOption("infoport")) {	String val = cmd.getOptionValue("infoport");	conf.setInt("hbase.thrift.info.port", Integer.parseInt(val));	
web ui port set to 

}	} catch (NumberFormatException e) {	printUsageAndExit(options, -1);	}	try {	if (cmd.hasOption("infoport")) {	String val = cmd.getOptionValue("infoport");	conf.setInt("hbase.thrift.info.port", Integer.parseInt(val));	}	} catch (NumberFormatException e) {	
could not parse the value provided for the infoport option 

public void stop() {	if (this.infoServer != null) {	
stopping infoserver 

private static void optionToConf(CommandLine cmd, String option, Configuration conf, String destConfKey) {	if (cmd.hasOption(option)) {	String value = cmd.getOptionValue(option);	
set configuration key value 

public static void main(String [] args) throws Exception {	
starting service 

public static void main(String [] args) throws Exception {	VersionInfo.logVersion();	int exitCode = 0;	try {	new ThriftServer(HBaseConfiguration.create()).doMain(args);	} catch (ExitCodeException ex) {	exitCode = ex.getExitCode();	}	
stopping service 

========================= hbase sample_802 =========================

private void waitForTableToEnterQuotaViolation(TableName tn) throws Exception {	final HRegionServer rs = TEST_UTIL.getHBaseCluster().getRegionServer(0);	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000, 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	Map<TableName,SpaceQuotaSnapshot> snapshots = rs.getRegionServerSpaceQuotaManager().copyQuotaSnapshots();	SpaceQuotaSnapshot snapshot = snapshots.get(tn);	if (snapshot == null) {	
found no snapshot for 

private void waitForTableToEnterQuotaViolation(TableName tn) throws Exception {	final HRegionServer rs = TEST_UTIL.getHBaseCluster().getRegionServer(0);	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000, 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	Map<TableName,SpaceQuotaSnapshot> snapshots = rs.getRegionServerSpaceQuotaManager().copyQuotaSnapshots();	SpaceQuotaSnapshot snapshot = snapshots.get(tn);	if (snapshot == null) {	return false;	}	
found snapshot 

========================= hbase sample_1436 =========================

protected List<ServerName> mapHostNameToServerName(List<String> hosts) {	if (hosts == null || status == null) {	if (hosts == null) {	
regionlocationfinder top hosts is null 

public HDFSBlocksDistribution getBlockDistribution(RegionInfo hri) {	HDFSBlocksDistribution blockDistbn = null;	try {	if (cache.asMap().containsKey(hri)) {	blockDistbn = cache.get(hri);	return blockDistbn;	} else {	
hdfsblocksdistribution not found in cache for region 

try {	if (cache.asMap().containsKey(hri)) {	blockDistbn = cache.get(hri);	return blockDistbn;	} else {	blockDistbn = internalGetTopBlockLocation(hri);	cache.put(hri, blockDistbn);	return blockDistbn;	}	} catch (ExecutionException e) {	
error while fetching cache entry 

========================= hbase sample_2830 =========================

Put put = new Put(row);	put.addColumn(familyname, row, row);	lHtable1.put(put);	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = lHtable2.get(get);	if (res.isEmpty()) {	
row not available 

}	Delete del = new Delete(row);	lHtable1.delete(del);	get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for del replication");	}	Result res = lHtable2.get(get);	if (res.size() >= 1) {	
row not deleted 

scanner1.close();	assertEquals(1, res1.length);	assertEquals(3, res1[0].getColumnCells(famName, qualifierName).size());	for (int i = 0; i < NB_RETRIES; i++) {	scan = new Scan();	scan.readVersions(100);	scanner1 = htable2.getScanner(scan);	res1 = scanner1.next(1);	scanner1.close();	if (res1.length != 1) {	
only got rows 

scan = new Scan();	scan.readVersions(100);	scanner1 = htable2.getScanner(scan);	res1 = scanner1.next(1);	scanner1.close();	if (res1.length != 1) {	Thread.sleep(SLEEP_TIME);	} else {	int cellNumber = res1[0].getColumnCells(famName, Bytes.toBytes("f1")).size();	if (cellNumber != 3) {	
only got cells 

scanner1.close();	assertEquals(1, res1.length);	assertEquals(3, res1[0].getColumnCells(famName, qualifierName).size());	for (int i = 0; i < NB_RETRIES; i++) {	scan = new Scan();	scan.readVersions(100);	scanner1 = htable2.getScanner(scan);	res1 = scanner1.next(1);	scanner1.close();	if (res1.length != 1) {	
only got rows 

scan = new Scan();	scan.readVersions(100);	scanner1 = htable2.getScanner(scan);	res1 = scanner1.next(1);	scanner1.close();	if (res1.length != 1) {	Thread.sleep(SLEEP_TIME);	} else {	int cellNumber = res1[0].getColumnCells(famName, Bytes.toBytes("f1")).size();	if (cellNumber != 3) {	
only got cells 

========================= hbase sample_3372 =========================

public void run(Callable<Boolean> monkeyCallable, String testName) throws Exception {	int maxIters = util.getHBaseClusterInterface().isDistributedCluster() ? 10 : 3;	
starting with iterations 

TimingResult putTime = putFuture.get();	TimingResult scanTime = scanFuture.get();	TimingResult adminTime = adminFuture.get();	resultPuts.add(putTime);	resultScan.add(scanTime);	resultAdmin.add(adminTime);	Thread.sleep(5000l);	}	} catch (Exception e) {	long runtimeMs = TimeUnit.MILLISECONDS.convert(System.nanoTime() - start, TimeUnit.NANOSECONDS);	
failed after ms 

throw e;	} catch (TableExistsException e) {	throw e;	} catch (TableNotFoundException e) {	throw e;	} catch (RetriesExhaustedException e){	throw e;	} catch (Exception e) {	resetCount++;	if (resetCount < maxIterations) {	
non fatal exception while running resetting loop counter 

throw e;	} catch (TableNotFoundException e) {	throw e;	} catch (RetriesExhaustedException e){	throw e;	} catch (Exception e) {	resetCount++;	if (resetCount < maxIterations) {	numAfterDone = 0;	} else {	
too many unexpected exceptions aborting 

========================= hbase sample_3237 =========================

public void testIllegalTableNamesRegex() {	for (String tn : illegalTableNames) {	
testing 

========================= hbase sample_90 =========================

for (int i = 0; i < 100000; i++) {	registerLocalObserver(cm);	cm.notifyAllObservers(conf);	System.gc();	if (cm.getNumObservers() <= i) {	outOfScopeObserversDeregistered = true;	break;	}	}	if (!outOfScopeObserversDeregistered) {	
observers were not gc ed something seems to be wrong 

========================= hbase sample_2001 =========================

public void setup() throws Exception {	TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniZKCluster();	conf = TEST_UTIL.getConfiguration();	zkw = new ZKWatcher(conf, "split-log-manager-tests" + UUID.randomUUID().toString(), null);	master = new DummyMasterServices(zkw, conf);	ZKUtil.deleteChildrenRecursively(zkw, zkw.znodePaths.baseZNode);	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.baseZNode);	assertTrue(ZKUtil.checkExists(zkw, zkw.znodePaths.baseZNode) != -1);	
created 

TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniZKCluster();	conf = TEST_UTIL.getConfiguration();	zkw = new ZKWatcher(conf, "split-log-manager-tests" + UUID.randomUUID().toString(), null);	master = new DummyMasterServices(zkw, conf);	ZKUtil.deleteChildrenRecursively(zkw, zkw.znodePaths.baseZNode);	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.baseZNode);	assertTrue(ZKUtil.checkExists(zkw, zkw.znodePaths.baseZNode) != -1);	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.splitLogZNode);	assertTrue(ZKUtil.checkExists(zkw, zkw.znodePaths.splitLogZNode) != -1);	
created 

private Task findOrCreateOrphanTask(String path) {	return slm.tasks.computeIfAbsent(path, k -> {	
creating orphan task 

private String submitTaskAndWait(TaskBatch batch, String name) throws KeeperException, InterruptedException {	String tasknode = ZKSplitLog.getEncodedNodeName(zkw, name);	NodeCreationListener listener = new NodeCreationListener(zkw, tasknode);	zkw.registerListener(listener);	ZKUtil.watchAndCheckExists(zkw, tasknode);	slm.enqueueSplitTask(name, batch);	assertEquals(1, batch.installed);	assertTrue(findOrCreateOrphanTask(tasknode).batch == batch);	assertEquals(1L, tot_mgr_node_create_queued.sum());	
waiting for task node creation 

private String submitTaskAndWait(TaskBatch batch, String name) throws KeeperException, InterruptedException {	String tasknode = ZKSplitLog.getEncodedNodeName(zkw, name);	NodeCreationListener listener = new NodeCreationListener(zkw, tasknode);	zkw.registerListener(listener);	ZKUtil.watchAndCheckExists(zkw, tasknode);	slm.enqueueSplitTask(name, batch);	assertEquals(1, batch.installed);	assertTrue(findOrCreateOrphanTask(tasknode).batch == batch);	assertEquals(1L, tot_mgr_node_create_queued.sum());	listener.waitForCreation();	
task created 

public void testTaskCreation() throws Exception {	
testtaskcreation test the creation of a task in zk 

public void testTaskCreation() throws Exception {	slm = new SplitLogManager(master, conf);	TaskBatch batch = new TaskBatch();	String tasknode = submitTaskAndWait(batch, "foo/1");	byte[] data = ZKUtil.getData(zkw, tasknode);	SplitLogTask slt = SplitLogTask.parseFrom(data);	
task node created 

public void testOrphanTaskAcquisition() throws Exception {	
TestOrphanTaskAcquisition 

SplitLogTask slt = new SplitLogTask.Owned(master.getServerName());	zkw.getRecoverableZooKeeper().create(tasknode, slt.toByteArray(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);	slm = new SplitLogManager(master, conf);	waitForCounter(tot_mgr_orphan_task_acquired, 0, 1, to/2);	Task task = findOrCreateOrphanTask(tasknode);	assertTrue(task.isOrphan());	waitForCounter(tot_mgr_heartbeat, 0, 1, to/2);	assertFalse(task.isUnassigned());	long curt = System.currentTimeMillis();	assertTrue((task.last_update <= curt) && (task.last_update > (curt - 1000)));	
waiting for manager to resubmit the orphan task 

public void testUnassignedOrphan() throws Exception {	
testunassignedorphan an unassigned task is resubmitted at startup 

public void testMultipleResubmits() throws Exception {	
testmultipleresbmits no indefinite resubmissions 

public void testRescanCleanup() throws Exception {	
testrescancleanup ensure rescan nodes are cleaned up 

public void testTaskDone() throws Exception {	
testtaskdone cleanup task node once in done state 

public void testTaskErr() throws Exception {	
testtaskerr cleanup task node once in err state 

public void testTaskResigned() throws Exception {	
testtaskresigned resubmit task node once in resigned state 

public void testUnassignedTimeout() throws Exception {	
testunassignedtimeout iff all tasks are unassigned then resubmit 

slm = new SplitLogManager(master, conf);	waitForCounter(tot_mgr_orphan_task_acquired, 0, 1, to/2);	TaskBatch batch = new TaskBatch();	submitTaskAndWait(batch, "foo/1");	for (int i = 0; i < (3 * to)/100; i++) {	Thread.sleep(100);	final ServerName worker2 = ServerName.valueOf("worker1,1,1");	slt = new SplitLogTask.Owned(worker2);	ZKUtil.setData(zkw, tasknode1, slt.toByteArray());	}	
waiting for manager to resubmit the orphan task 

public void testDeadWorker() throws Exception {	
testDeadWorker 

========================= hbase sample_1787 =========================

return;	}	LOG.info("Performing action: Compact mob of table " + tableName + ", major=" + major);	try {	if (major) {	admin.majorCompact(tableName, CompactType.MOB);	} else {	admin.compact(tableName, CompactType.MOB);	}	} catch (Exception ex) {	
mob compaction failed might be caused by other chaos 

========================= hbase sample_3305 =========================

public void stop(String why) {	this.stopping = true;	if (running.compareAndSet(true, false)) {	
shutting down due to request 

========================= hbase sample_1292 =========================

boolean oldValue = master.getRegionNormalizerTracker().isNormalizerOn();	boolean newValue = on;	try {	try {	master.getRegionNormalizerTracker().setNormalizerOn(newValue);	} catch (KeeperException ke) {	throw new IOException(ke);	}	LOG.info(master.getClientIdAuditPrefix() + " set normalizerSwitch=" + newValue);	} catch (IOException ioe) {	
error flipping normalizer switch 

public AssignRegionResponse assignRegion(RpcController controller, AssignRegionRequest req) throws ServiceException {	try {	master.checkInitialized();	final RegionSpecifierType type = req.getRegion().getType();	if (type != RegionSpecifierType.REGION_NAME) {	
assignregion specifier type expected actual 

final RegionSpecifierType type = req.getRegion().getType();	if (type != RegionSpecifierType.REGION_NAME) {	}	final byte[] regionName = req.getRegion().getValue().toByteArray();	final RegionInfo regionInfo = master.getAssignmentManager().getRegionInfo(regionName);	if (regionInfo == null) throw new UnknownRegionException(Bytes.toStringBinary(regionName));	final AssignRegionResponse arr = AssignRegionResponse.newBuilder().build();	if (master.cpHost != null) {	master.cpHost.preAssign(regionInfo);	}	
assign 

public DeleteSnapshotResponse deleteSnapshot(RpcController controller, DeleteSnapshotRequest request) throws ServiceException {	try {	master.checkInitialized();	master.snapshotManager.checkSnapshotSupport();	
delete 

public ExecProcedureResponse execProcedure(RpcController controller, ExecProcedureRequest request) throws ServiceException {	try {	master.checkInitialized();	ProcedureDescription desc = request.getProcedure();	MasterProcedureManager mpm = master.getMasterProcedureManagerHost().getProcedureManager( desc.getSignature());	if (mpm == null) {	throw new ServiceException(new DoNotRetryIOException("The procedure is not registered: " + desc.getSignature()));	}	
procedure request for 

public ExecProcedureResponse execProcedureWithRet(RpcController controller, ExecProcedureRequest request) throws ServiceException {	try {	master.checkInitialized();	ProcedureDescription desc = request.getProcedure();	MasterProcedureManager mpm = master.getMasterProcedureManagerHost().getProcedureManager( desc.getSignature());	if (mpm == null) {	throw new ServiceException("The procedure is not registered: " + desc.getSignature());	}	
procedure request for 

public IsProcedureDoneResponse isProcedureDone(RpcController controller, IsProcedureDoneRequest request) throws ServiceException {	try {	master.checkInitialized();	ProcedureDescription desc = request.getProcedure();	MasterProcedureManager mpm = master.getMasterProcedureManagerHost().getProcedureManager( desc.getSignature());	if (mpm == null) {	throw new ServiceException("The procedure is not registered: " + desc.getSignature());	}	
checking to see if procedure from request is done 

public IsSnapshotDoneResponse isSnapshotDone(RpcController controller, IsSnapshotDoneRequest request) throws ServiceException {	
checking to see if snapshot from request is done 

public MoveRegionResponse moveRegion(RpcController controller, MoveRegionRequest req) throws ServiceException {	final byte [] encodedRegionName = req.getRegion().getValue().toByteArray();	RegionSpecifierType type = req.getRegion().getType();	final byte [] destServerName = (req.hasDestServerName())? Bytes.toBytes(ProtobufUtil.toServerName(req.getDestServerName()).getServerName()):null;	MoveRegionResponse mrr = MoveRegionResponse.newBuilder().build();	if (type != RegionSpecifierType.ENCODED_REGION_NAME) {	
moveregion specifier type expected actual 

public OfflineRegionResponse offlineRegion(RpcController controller, OfflineRegionRequest request) throws ServiceException {	try {	master.checkInitialized();	final RegionSpecifierType type = request.getRegion().getType();	if (type != RegionSpecifierType.REGION_NAME) {	
moveregion specifier type expected actual 

master.checkInitialized();	final RegionSpecifierType type = request.getRegion().getType();	if (type != RegionSpecifierType.REGION_NAME) {	}	final byte[] regionName = request.getRegion().getValue().toByteArray();	final RegionInfo hri = master.getAssignmentManager().getRegionInfo(regionName);	if (hri == null) throw new UnknownRegionException(Bytes.toStringBinary(regionName));	if (master.cpHost != null) {	master.cpHost.preRegionOffline(hri);	}	
offline 

public ShutdownResponse shutdown(RpcController controller, ShutdownRequest request) throws ServiceException {	
shutdown 

public ShutdownResponse shutdown(RpcController controller, ShutdownRequest request) throws ServiceException {	try {	master.shutdown();	} catch (IOException e) {	
exception occurred in hmaster shutdown 

public SnapshotResponse snapshot(RpcController controller, SnapshotRequest request) throws ServiceException {	try {	master.checkInitialized();	master.snapshotManager.checkSnapshotSupport();	
snapshot request for 

public StopMasterResponse stopMaster(RpcController controller, StopMasterRequest request) throws ServiceException {	
stop 

public StopMasterResponse stopMaster(RpcController controller, StopMasterRequest request) throws ServiceException {	try {	master.stopMaster();	} catch (IOException e) {	
exception occurred while stopping master 

public UnassignRegionResponse unassignRegion(RpcController controller, UnassignRegionRequest req) throws ServiceException {	try {	final byte [] regionName = req.getRegion().getValue().toByteArray();	RegionSpecifierType type = req.getRegion().getType();	final boolean force = req.getForce();	UnassignRegionResponse urr = UnassignRegionResponse.newBuilder().build();	master.checkInitialized();	if (type != RegionSpecifierType.REGION_NAME) {	
unassignregion specifier type expected actual 

private void checkHFileFormatVersionForMob() throws IOException {	if (HFile.getFormatVersion(master.getConfiguration()) < HFile.MIN_FORMAT_VERSION_WITH_TAGS) {	
a minimum hfile version of is required for mob compaction compaction will not run 

}	boolean allFiles = false;	List<ColumnFamilyDescriptor> compactedColumns = new ArrayList<>();	ColumnFamilyDescriptor[] hcds = master.getTableDescriptors().get(tableName).getColumnFamilies();	byte[] family = null;	if (request.hasFamily()) {	family = request.getFamily().toByteArray();	for (ColumnFamilyDescriptor hcd : hcds) {	if (Bytes.equals(family, hcd.getName())) {	if (!hcd.isMobEnabled()) {	
column family is not a mob column family 

}	}	} else {	for (ColumnFamilyDescriptor hcd : hcds) {	if (hcd.isMobEnabled()) {	compactedColumns.add(hcd);	}	}	}	if (compactedColumns.isEmpty()) {	
no mob column families are assigned in the mob compaction 

}	}	if (compactedColumns.isEmpty()) {	throw new DoNotRetryIOException( "No mob column families are assigned in the mob compaction");	}	if (request.hasMajor() && request.getMajor()) {	allFiles = true;	}	String familyLogMsg = (family != null) ? Bytes.toString(family) : "";	if (LOG.isTraceEnabled()) {	
user triggered mob compaction requested for table for column family 

protected String getDescription() {	return "RequestLock";	}	};	} else {	throw new IllegalArgumentException("one of table/namespace/region should be specified");	}	long procId = MasterProcedureUtil.submitProcedure(npr);	return LockResponse.newBuilder().setProcId(procId).build();	} catch (IllegalArgumentException e) {	
exception when queuing lock 

}	};	} else {	throw new IllegalArgumentException("one of table/namespace/region should be specified");	}	long procId = MasterProcedureUtil.submitProcedure(npr);	return LockResponse.newBuilder().setProcId(procId).build();	} catch (IllegalArgumentException e) {	throw new ServiceException(new DoNotRetryIOException(e));	} catch (IOException e) {	
exception when queuing lock 

public ClearDeadServersResponse clearDeadServers(RpcController controller, ClearDeadServersRequest request) throws ServiceException {	
clear dead region servers 

public ClearDeadServersResponse clearDeadServers(RpcController controller, ClearDeadServersRequest request) throws ServiceException {	ClearDeadServersResponse.Builder response = ClearDeadServersResponse.newBuilder();	try {	master.checkInitialized();	if (master.cpHost != null) {	master.cpHost.preClearDeadServers();	}	if (master.getServerManager().areDeadServersInProgress()) {	
some dead server is still under processing won t clear the dead server list 

========================= hbase sample_2847 =========================

protected Action simpleMergeOrFlatten(VersionedSegmentsList versionedList, String strategy) {	int numOfSegments = versionedList.getNumOfSegments();	if (numOfSegments > pipelineThreshold) {	
in memory compaction of merging segments 

protected Action simpleMergeOrFlatten(VersionedSegmentsList versionedList, String strategy) {	int numOfSegments = versionedList.getNumOfSegments();	if (numOfSegments > pipelineThreshold) {	return getMergingAction();	}	
in memory compaction of flattening a segment 

protected Action compact(VersionedSegmentsList versionedList, String strategyInfo) {	int numOfSegments = versionedList.getNumOfSegments();	
memory compaction for store compacting segments 

========================= hbase sample_2514 =========================

protected Flow executeFromState(final MasterProcedureEnv env, TruncateTableState state) throws InterruptedException {	if (LOG.isTraceEnabled()) {	LOG.trace(this + " execute state=" + state);	}	try {	switch (state) {	case TRUNCATE_TABLE_PRE_OPERATION: if (!prepareTruncate(env)) {	assert isFailed() : "the truncate should have an exception here";	return Flow.NO_MORE_STATE;	}	
waiting for regions in transition 

setNextState(TruncateTableState.TRUNCATE_TABLE_ASSIGN_REGIONS);	break;	case TRUNCATE_TABLE_ASSIGN_REGIONS: CreateTableProcedure.setEnablingState(env, getTableName());	addChildProcedure(env.getAssignmentManager().createRoundRobinAssignProcedures(regions));	setNextState(TruncateTableState.TRUNCATE_TABLE_POST_OPERATION);	tableDescriptor = null;	regions = null;	break;	case TRUNCATE_TABLE_POST_OPERATION: CreateTableProcedure.setEnabledState(env, getTableName());	postTruncate(env);	
truncate completed 

========================= hbase sample_2797 =========================

case GC_MERGED_REGIONS_PREPARE: setNextState(GCMergedRegionsState.GC_MERGED_REGIONS_PURGE);	break;	case GC_MERGED_REGIONS_PURGE: addChildProcedure(createGCRegionProcedures(env));	setNextState(GCMergedRegionsState.GC_REGION_EDIT_METADATA);	break;	case GC_REGION_EDIT_METADATA: MetaTableAccessor.deleteMergeQualifiers(env.getMasterServices().getConnection(), mergedChild);	return Flow.NO_MORE_STATE;	default: throw new UnsupportedOperationException(this + " unhandled state=" + state);	}	} catch (IOException ioe) {	
error trying to gc merged regions retrying 

========================= hbase sample_2778 =========================

protected int doWork() throws Exception {	generateRegionsAndServers();	String methodName = "roundRobinAssignment";	
calling 

protected int doWork() throws Exception {	generateRegionsAndServers();	String methodName = "roundRobinAssignment";	Stopwatch watch = Stopwatch.createStarted();	loadBalancer.roundRobinAssignment(regions, servers);	System.out.print(formatResults(methodName, watch.elapsed(TimeUnit.MILLISECONDS)));	methodName = "retainAssignment";	
calling 

generateRegionsAndServers();	String methodName = "roundRobinAssignment";	Stopwatch watch = Stopwatch.createStarted();	loadBalancer.roundRobinAssignment(regions, servers);	System.out.print(formatResults(methodName, watch.elapsed(TimeUnit.MILLISECONDS)));	methodName = "retainAssignment";	watch.reset().start();	loadBalancer.retainAssignment(regionServerMap, servers);	System.out.print(formatResults(methodName, watch.elapsed(TimeUnit.MILLISECONDS)));	methodName = "balanceCluster";	
calling 

========================= hbase sample_1857 =========================

return true;	}	}	} else {	if (getAuthManager().matchPermission(user, tableName, family.getKey(), perm)) {	return true;	}	}	}	} else if (LOG.isDebugEnabled()) {	
empty family map passed for permission check 

}	long latestTs = Math.max(opTs, latestCellTs);	if (latestTs == 0 || latestTs == HConstants.LATEST_TIMESTAMP) {	latestTs = EnvironmentEdgeManager.currentTime();	}	get.setTimeRange(0, latestTs + 1);	if (!diffCellTsFromOpTs && request == OpType.PUT) {	get.setMaxVersions(1);	}	if (LOG.isTraceEnabled()) {	
scanning for cells with 

long curColCheckTs = opTs;	boolean foundColumn = false;	try {	boolean more = false;	ScannerContext scannerContext = ScannerContext.newBuilder().setBatchLimit(1).build();	do {	cells.clear();	more = scanner.next(cells, scannerContext);	for (Cell cell: cells) {	if (LOG.isTraceEnabled()) {	
found cell 

if (!getAuthManager().authorize(user, getTableName(e), cell, action)) {	return false;	}	}	cellGrants++;	}	} while (more);	} catch (AccessDeniedException ex) {	throw ex;	} catch (IOException ex) {	
exception while getting cells to calculate covering permission 

public void start(CoprocessorEnvironment env) throws IOException {	CompoundConfiguration conf = new CompoundConfiguration();	conf.add(env.getConfiguration());	authorizationEnabled = AccessChecker.isAuthorizationSupported(conf);	if (!authorizationEnabled) {	
the accesscontroller has been loaded with authorization checks disabled 

public void start(CoprocessorEnvironment env) throws IOException {	CompoundConfiguration conf = new CompoundConfiguration();	conf.add(env.getConfiguration());	authorizationEnabled = AccessChecker.isAuthorizationSupported(conf);	if (!authorizationEnabled) {	}	shouldCheckExecPermission = conf.getBoolean(AccessControlConstants.EXEC_PERMISSION_CHECKS_KEY, AccessControlConstants.DEFAULT_EXEC_PERMISSION_CHECKS);	cellFeaturesEnabled = (HFile.getFormatVersion(conf) >= HFile.MIN_FORMAT_VERSION_WITH_TAGS);	if (!cellFeaturesEnabled) {	
a minimum hfile version of is required to persist cell acls consider setting accordingly 

public void postCompletedCreateTableAction( final ObserverContext<MasterCoprocessorEnvironment> c, final TableDescriptor desc, final RegionInfo[] regions) throws IOException {	if (AccessControlLists.isAclTable(desc)) {	this.aclTabAvailable = true;	} else if (!(TableName.NAMESPACE_TABLE_NAME.equals(desc.getTableName()))) {	if (!aclTabAvailable) {	
not adding owner permission for table is not yet created should be configured as the first coprocessor 

final Configuration conf = ctx.getEnvironment().getConfiguration();	User.runAsLoginUser(new PrivilegedExceptionAction<Void>() {	public Void run() throws Exception {	try (Table table = ctx.getEnvironment().getConnection(). getTable(AccessControlLists.ACL_TABLE_NAME)) {	AccessControlLists.removeNamespacePermissions(conf, namespace, table);	}	return null;	}	});	getAuthManager().getZKPermissionWatcher().deleteNamespaceACLNode(namespace);	
entry deleted in table 

public void preOpen(ObserverContext<RegionCoprocessorEnvironment> c) throws IOException {	RegionCoprocessorEnvironment env = c.getEnvironment();	final Region region = env.getRegion();	if (region == null) {	
null region from regioncoprocessorenvironment in preopen 

public void postOpen(ObserverContext<RegionCoprocessorEnvironment> c) {	RegionCoprocessorEnvironment env = c.getEnvironment();	final Region region = env.getRegion();	if (region == null) {	
null region from regioncoprocessorenvironment in postopen 

}	List<Tag> tags = Lists.newArrayList();	List<Tag> aclTags = Lists.newArrayList();	ListMultimap<String,Permission> perms = ArrayListMultimap.create();	if (oldCell != null) {	Iterator<Tag> tagIterator = PrivateCellUtil.tagsIterator(oldCell);	while (tagIterator.hasNext()) {	Tag tag = tagIterator.next();	if (tag.getType() != AccessControlLists.ACL_TAG_TYPE) {	if (LOG.isTraceEnabled()) {	
carrying forward tag from type length 

aclTags.add(tag);	}	}	}	byte[] aclBytes = mutation.getACL();	if (aclBytes != null) {	tags.add(new ArrayBackedTag(AccessControlLists.ACL_TAG_TYPE, aclBytes));	} else {	if (perms != null) {	if (LOG.isTraceEnabled()) {	
carrying forward acls from 

public void revoke(RpcController controller, AccessControlProtos.RevokeRequest request, RpcCallback<AccessControlProtos.RevokeResponse> done) {	final UserPermission perm = AccessControlUtil.toUserPermission(request.getUserPermission());	AccessControlProtos.RevokeResponse response = null;	try {	if (aclRegion) {	if (!initialized) {	throw new CoprocessorException("AccessController not yet initialized");	}	if (LOG.isDebugEnabled()) {	
received request to revoke access permission 

}	User.runAsLoginUser(new PrivilegedExceptionAction<Void>() {	public Void run() throws Exception {	try (Table table = regionEnv.getConnection(). getTable(AccessControlLists.ACL_TABLE_NAME)) {	AccessControlLists.removeUserPermission(regionEnv.getConfiguration(), perm, table);	}	return null;	}	});	if (AUDITLOG.isTraceEnabled()) {	
revoked permission 

========================= hbase sample_2282 =========================

private static void updateACLs(final HBaseTestingUtility util, Callable c) throws Exception {	final Map<AccessController,Long> oldMTimes = getAuthManagerMTimes(util.getHBaseCluster());	c.call();	util.waitFor(WAIT_TIME, 100, new Predicate<IOException>() {	public boolean evaluate() throws IOException {	Map<AccessController,Long> mtimes = getAuthManagerMTimes(util.getHBaseCluster());	for (Map.Entry<AccessController,Long> e: mtimes.entrySet()) {	if (!oldMTimes.containsKey(e.getKey())) {	
snapshot of accesscontroller state does not include instance on region 

public static void grantOnNamespaceUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user, final String namespace, final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.grant(connection, namespace, user, actions);	} catch (Throwable t) {	
grant failed 

public static void revokeFromNamespaceUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user, final String namespace, final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.revoke(connection, namespace, user, actions);	} catch (Throwable t) {	
revoke failed 

public static void grantOnTableUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user, final TableName table, final byte[] family, final byte[] qualifier, final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.grant(connection, table, user, family, qualifier, actions);	} catch (Throwable t) {	
grant failed 

public static void grantGlobalUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user, final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.grant(connection, user, actions);	} catch (Throwable t) {	
grant failed 

public static void revokeFromTableUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user, final TableName table, final byte[] family, final byte[] qualifier, final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.revoke(connection, table, user, family, qualifier, actions);	} catch (Throwable t) {	
revoke failed 

public static void revokeGlobalUsingAccessControlClient(final HBaseTestingUtility util, final Connection connection, final String user,final Permission.Action... actions) throws Exception {	SecureTestUtil.updateACLs(util, new Callable<Void>() {	public Void call() throws Exception {	try {	AccessControlClient.revoke(connection, user, actions);	} catch (Throwable t) {	
revoke failed 

public static void deleteTable(HBaseTestingUtility testUtil, Admin admin, TableName tableName) throws Exception {	MasterSyncObserver observer = testUtil.getHBaseCluster().getMaster() .getMasterCoprocessorHost().findCoprocessor(MasterSyncObserver.class);	observer.tableDeletionLatch = new CountDownLatch(1);	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException e) {	
table already disabled so just deleting it 

========================= hbase sample_1380 =========================

public void preCommitStoreFile(final ObserverContext<RegionCoprocessorEnvironment> ctx, final byte[] family, final List<Pair<Path, Path>> pairs) throws IOException {	RegionCoprocessorEnvironment env = ctx.getEnvironment();	Configuration c = env.getConfiguration();	if (pairs == null || pairs.isEmpty() || !c.getBoolean(HConstants.REPLICATION_BULKLOAD_ENABLE_KEY, HConstants.REPLICATION_BULKLOAD_ENABLE_DEFAULT)) {	
skipping recording bulk load entries in precommitstorefile for bulkloaded data replication 

========================= hbase sample_2955 =========================

public Writer create() throws IOException {	if ((path != null ? 1 : 0) + (ostream != null ? 1 : 0) != 1) {	throw new AssertionError("Please specify exactly one of " + "filesystem/path or path");	}	if (path != null) {	ostream = HFileWriterImpl.createOutputStream(conf, fs, path, favoredNodes);	try {	ostream.setDropBehind(shouldDropBehind && cacheConf.shouldDropBehindCompaction());	} catch (UnsupportedOperationException uoe) {	
unable to set drop behind on 

public Writer create() throws IOException {	if ((path != null ? 1 : 0) + (ostream != null ? 1 : 0) != 1) {	throw new AssertionError("Please specify exactly one of " + "filesystem/path or path");	}	if (path != null) {	ostream = HFileWriterImpl.createOutputStream(conf, fs, path, favoredNodes);	try {	ostream.setDropBehind(shouldDropBehind && cacheConf.shouldDropBehindCompaction());	} catch (UnsupportedOperationException uoe) {	
unable to set drop behind on 

private static Reader openReader(Path path, FSDataInputStreamWrapper fsdis, long size, CacheConfig cacheConf, HFileSystem hfs, boolean primaryReplicaReader, Configuration conf) throws IOException {	FixedFileTrailer trailer = null;	try {	boolean isHBaseChecksum = fsdis.shouldUseHBaseChecksum();	assert !isHBaseChecksum;	trailer = FixedFileTrailer.readFromStream(fsdis.getStream(isHBaseChecksum), size);	switch (trailer.getMajorVersion()) {	
opening hfile with reader 

========================= hbase sample_2406 =========================

private Path getHdfsDestinationDir() {	Path rootDir = TEST_UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getRootDir();	Path path = new Path(new Path(rootDir, "export-test"), "export-" + System.currentTimeMillis());	
hdfs export destination path 

private Path getLocalDestinationDir() {	Path path = TEST_UTIL.getDataTestDir("local-export-" + System.currentTimeMillis());	
local export destination path 

========================= hbase sample_3352 =========================

Path topPath = splitStoreFile(regionFs, topHri, TEST_FAMILY, f, midRow, true);	HRegionInfo bottomHri = new HRegionInfo(regionFs.getRegionInfo().getTable(), midRow, null);	Path bottomPath = splitStoreFile(regionFs, bottomHri, TEST_FAMILY, f, midRow, false);	HStoreFile topF = new HStoreFile(this.fs, topPath, conf, cacheConf, BloomType.NONE, true);	topF.initReader();	StoreFileReader top = topF.getReader();	HStoreFile bottomF = new HStoreFile(this.fs, bottomPath, conf, cacheConf, BloomType.NONE, true);	bottomF.initReader();	StoreFileReader bottom = bottomF.getReader();	ByteBuffer previous = null;	
midkey 

boolean first = true;	ByteBuffer key = null;	HFileScanner topScanner = top.getScanner(false, false);	while ((!topScanner.isSeeked() && topScanner.seekTo()) || (topScanner.isSeeked() && topScanner.next())) {	key = ByteBuffer.wrap(((KeyValue) topScanner.getKey()).getKey());	if ((PrivateCellUtil.compare(topScanner.getReader().getComparator(), midKV, key.array(), key.arrayOffset(), key.limit())) > 0) {	fail("key=" + Bytes.toStringBinary(key) + " < midkey=" + midkey);	}	if (first) {	first = false;	
first in top 

HFileScanner topScanner = top.getScanner(false, false);	while ((!topScanner.isSeeked() && topScanner.seekTo()) || (topScanner.isSeeked() && topScanner.next())) {	key = ByteBuffer.wrap(((KeyValue) topScanner.getKey()).getKey());	if ((PrivateCellUtil.compare(topScanner.getReader().getComparator(), midKV, key.array(), key.arrayOffset(), key.limit())) > 0) {	fail("key=" + Bytes.toStringBinary(key) + " < midkey=" + midkey);	}	if (first) {	first = false;	}	}	
last in top 

first = false;	}	}	first = true;	HFileScanner bottomScanner = bottom.getScanner(false, false);	while ((!bottomScanner.isSeeked() && bottomScanner.seekTo()) || bottomScanner.next()) {	previous = ByteBuffer.wrap(((KeyValue) bottomScanner.getKey()).getKey());	key = ByteBuffer.wrap(((KeyValue) bottomScanner.getKey()).getKey());	if (first) {	first = false;	
first in bottom 

HFileScanner bottomScanner = bottom.getScanner(false, false);	while ((!bottomScanner.isSeeked() && bottomScanner.seekTo()) || bottomScanner.next()) {	previous = ByteBuffer.wrap(((KeyValue) bottomScanner.getKey()).getKey());	key = ByteBuffer.wrap(((KeyValue) bottomScanner.getKey()).getKey());	if (first) {	first = false;	}	assertTrue(key.compareTo(bbMidkeyBytes) < 0);	}	if (previous != null) {	
last in bottom 

first = true;	topScanner = top.getScanner(false, false);	KeyValue.KeyOnlyKeyValue keyOnlyKV = new KeyValue.KeyOnlyKeyValue();	while ((!topScanner.isSeeked() && topScanner.seekTo()) || topScanner.next()) {	key = ByteBuffer.wrap(((KeyValue) topScanner.getKey()).getKey());	keyOnlyKV.setKey(key.array(), 0 + key.arrayOffset(), key.limit());	assertTrue(PrivateCellUtil.compare(topScanner.getReader().getComparator(), keyOnlyKV, badmidkey, 0, badmidkey.length) >= 0);	if (first) {	first = false;	KeyValue keyKV = KeyValueUtil.createKeyValueFromKey(key);	
first top when key bottom 

if (first) {	first = false;	KeyValue keyKV = KeyValueUtil.createKeyValueFromKey(key);	String tmp = Bytes.toString(keyKV.getRowArray(), keyKV.getRowOffset(), keyKV.getRowLength());	for (int i = 0; i < tmp.length(); i++) {	assertTrue(tmp.charAt(i) == 'a');	}	}	}	KeyValue keyKV = KeyValueUtil.createKeyValueFromKey(key);	
last top when key bottom 

bottomF = new HStoreFile(this.fs, bottomPath, conf, cacheConf, BloomType.NONE, true);	bottomF.initReader();	bottom = bottomF.getReader();	first = true;	bottomScanner = bottom.getScanner(false, false);	while ((!bottomScanner.isSeeked() && bottomScanner.seekTo()) || bottomScanner.next()) {	key = ByteBuffer.wrap(((KeyValue) bottomScanner.getKey()).getKey());	if (first) {	first = false;	keyKV = KeyValueUtil.createKeyValueFromKey(key);	
first bottom when key top 

if (first) {	first = false;	keyKV = KeyValueUtil.createKeyValueFromKey(key);	tmp = Bytes.toString(keyKV.getRowArray(), keyKV.getRowOffset(), keyKV.getRowLength());	for (int i = 0; i < tmp.length(); i++) {	assertTrue(tmp.charAt(i) == 'a');	}	}	}	keyKV = KeyValueUtil.createKeyValueFromKey(key);	
last bottom when key top 

private void assertOrdering(Comparator<? super HStoreFile> comparator, HStoreFile ... sfs) {	ArrayList<HStoreFile> sorted = Lists.newArrayList(sfs);	Collections.shuffle(sorted);	Collections.sort(sorted, comparator);	
sfs 

private void assertOrdering(Comparator<? super HStoreFile> comparator, HStoreFile ... sfs) {	ArrayList<HStoreFile> sorted = Lists.newArrayList(sfs);	Collections.shuffle(sorted);	Collections.sort(sorted, comparator);	
sorted 

========================= hbase sample_1695 =========================

while (EnvironmentEdgeManager.currentTime() - start < 180000) {	Scan scan = new Scan();	scan.setCaching(50);	int count = 0;	try (ResultScanner results = t2.getScanner(scan)) {	for (Result result : results) {	count++;	}	}	if (count < 50) {	
waiting all logs pushed to slave expected actual 

========================= hbase sample_1945 =========================

public void setupSaslHandler(ChannelPipeline p) {	String qop = (String) saslClient.getNegotiatedProperty(Sasl.QOP);	if (LOG.isDebugEnabled()) {	
sasl client context established negotiated qop 

========================= hbase sample_121 =========================

long startTime = EnvironmentEdgeManager.currentTime();	while (!admin.tableExists(tableName) || !admin.isTableAvailable(tableName)) {	try {	Thread.sleep(100);	} catch (InterruptedException e) {	}	if (EnvironmentEdgeManager.currentTime() - startTime > TIMEOUT) {	throw new IOException("Failed to create backup system table "+ tableName +" after " + TIMEOUT + "ms");	}	}	
backup table exists and available 

}	List<Path> files;	if (!mapForSrc[srcIdx].containsKey(fam)) {	files = new ArrayList<Path>();	mapForSrc[srcIdx].put(fam, files);	} else {	files = mapForSrc[srcIdx].get(fam);	}	files.add(new Path(path));	if (LOG.isDebugEnabled()) {	
found bulk loaded file 

public void deleteBackupInfo(String backupId) throws IOException {	if (LOG.isTraceEnabled()) {	
delete backup status in backup system table for 

public void writePathsPostBulkLoad(TableName tabName, byte[] region, Map<byte[], List<Path>> finalPaths) throws IOException {	if (LOG.isDebugEnabled()) {	
write bulk load descriptor to backup with entries 

public void writePathsPostBulkLoad(TableName tabName, byte[] region, Map<byte[], List<Path>> finalPaths) throws IOException {	if (LOG.isDebugEnabled()) {	}	try (Table table = connection.getTable(bulkLoadTableName)) {	List<Put> puts = BackupSystemTable.createPutForCommittedBulkload(tabName, region, finalPaths);	table.put(puts);	
written rows for bulk load of 

public void writeFilesForBulkLoadPreCommit(TableName tabName, byte[] region, final byte[] family, final List<Pair<Path, Path>> pairs) throws IOException {	if (LOG.isDebugEnabled()) {	
write bulk load descriptor to backup with entries 

public void writeFilesForBulkLoadPreCommit(TableName tabName, byte[] region, final byte[] family, final List<Pair<Path, Path>> pairs) throws IOException {	if (LOG.isDebugEnabled()) {	}	try (Table table = connection.getTable(bulkLoadTableName)) {	List<Put> puts = BackupSystemTable.createPutForPreparedBulkload(tabName, region, family, pairs);	table.put(puts);	
written rows for bulk load of 

public void deleteBulkLoadedRows(List<byte[]> rows) throws IOException {	try (Table table = connection.getTable(bulkLoadTableName)) {	List<Delete> lstDels = new ArrayList<>();	for (byte[] row : rows) {	Delete del = new Delete(row);	lstDels.add(del);	
orig deleting the row 

public void deleteBulkLoadedRows(List<byte[]> rows) throws IOException {	try (Table table = connection.getTable(bulkLoadTableName)) {	List<Delete> lstDels = new ArrayList<>();	for (byte[] row : rows) {	Delete del = new Delete(row);	lstDels.add(del);	}	table.delete(lstDels);	
deleted original bulkload rows 

public BackupInfo readBackupInfo(String backupId) throws IOException {	if (LOG.isTraceEnabled()) {	
read backup status from backup system table for 

public String readBackupStartCode(String backupRoot) throws IOException {	
read backup start code from backup system table 

public void writeBackupStartCode(Long startCode, String backupRoot) throws IOException {	if (LOG.isTraceEnabled()) {	
write backup start code to backup system table 

public void startBackupExclusiveOperation() throws IOException {	
start new backup exclusive operation 

public void finishBackupExclusiveOperation() throws IOException {	
finish backup exclusive operation 

public ArrayList<BackupInfo> getBackupHistory(boolean onlyCompleted) throws IOException {	
get backup history from backup system table 

public ArrayList<BackupInfo> getBackupInfos(BackupState state) throws IOException {	
get backup infos from backup system table 

public Set<TableName> getIncrementalBackupTableSet(String backupRoot) throws IOException {	
get incremental backup table set from backup system table 

public void addWALFiles(List<String> files, String backupId, String backupRoot) throws IOException {	if (LOG.isTraceEnabled()) {	
add wal files to backup system table files 

public void addWALFiles(List<String> files, String backupId, String backupRoot) throws IOException {	if (LOG.isTraceEnabled()) {	}	if (LOG.isDebugEnabled()) {	
add 

public Iterator<WALItem> getWALFilesIterator(String backupRoot) throws IOException {	
get wal files from backup system table 

final ResultScanner scanner = table.getScanner(scan);	final Iterator<Result> it = scanner.iterator();	return new Iterator<WALItem>() {	public boolean hasNext() {	boolean next = it.hasNext();	if (!next) {	try {	scanner.close();	table.close();	} catch (IOException e) {	
close wal iterator 

public boolean isWALFileDeletable(String file) throws IOException {	if (LOG.isTraceEnabled()) {	
check if wal file has been already backed up in backup system table 

public boolean hasBackupSessions() throws IOException {	
has backup sessions from backup system table 

public List<String> listBackupSets() throws IOException {	
backup set list 

public List<TableName> describeBackupSet(String name) throws IOException {	if (LOG.isTraceEnabled()) {	
backup set describe 

public void addToBackupSet(String name, String[] newTables) throws IOException {	if (LOG.isTraceEnabled()) {	
backup set add tables 

public void removeFromBackupSet(String name, String[] toRemove) throws IOException {	if (LOG.isTraceEnabled()) {	
backup set remove from tables 

public void removeFromBackupSet(String name, String[] toRemove) throws IOException {	if (LOG.isTraceEnabled()) {	}	String[] disjoint = null;	String[] tables = null;	try (Table table = connection.getTable(tableName)) {	Get get = createGetForBackupSet(name);	Result res = table.get(get);	if (res.isEmpty()) {	
backup set not found 

return;	} else {	res.advance();	tables = cellValueToBackupSet(res.current());	disjoint = disjoin(tables, toRemove);	}	if (disjoint.length > 0 && disjoint.length != tables.length) {	Put put = createPutForBackupSet(name, disjoint);	table.put(put);	} else if (disjoint.length == tables.length) {	
backup set does not contain tables 

} else {	res.advance();	tables = cellValueToBackupSet(res.current());	disjoint = disjoin(tables, toRemove);	}	if (disjoint.length > 0 && disjoint.length != tables.length) {	Put put = createPutForBackupSet(name, disjoint);	table.put(put);	} else if (disjoint.length == tables.length) {	} else {	
backup set is empty deleting 

public void deleteBackupSet(String name) throws IOException {	if (LOG.isTraceEnabled()) {	
backup set delete 

for (Path path : entry.getValue()) {	String file = path.toString();	int lastSlash = file.lastIndexOf("/");	String filename = file.substring(lastSlash + 1);	Put put = new Put(rowkey(BULK_LOAD_PREFIX, table.toString(), BLK_LD_DELIM, Bytes.toString(region), BLK_LD_DELIM, filename));	put.addColumn(BackupSystemTable.META_FAMILY, TBL_COL, table.getName());	put.addColumn(BackupSystemTable.META_FAMILY, FAM_COL, entry.getKey());	put.addColumn(BackupSystemTable.META_FAMILY, PATH_COL, file.getBytes());	put.addColumn(BackupSystemTable.META_FAMILY, STATE_COL, BL_COMMIT);	puts.add(put);	
writing done bulk path for 

public static void restoreFromSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	
restoring from snapshot 

public static void restoreFromSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	try (Admin admin = conn.getAdmin()) {	String snapshotName = BackupSystemTable.getSnapshotName(conf);	if (snapshotExists(admin, snapshotName)) {	admin.disableTable(BackupSystemTable.getTableName(conf));	admin.restoreSnapshot(snapshotName);	admin.enableTable(BackupSystemTable.getTableName(conf));	
done restoring backup system table 

public static void restoreFromSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	try (Admin admin = conn.getAdmin()) {	String snapshotName = BackupSystemTable.getSnapshotName(conf);	if (snapshotExists(admin, snapshotName)) {	admin.disableTable(BackupSystemTable.getTableName(conf));	admin.restoreSnapshot(snapshotName);	admin.enableTable(BackupSystemTable.getTableName(conf));	} else {	
could not restore backup system table snapshot does not exists 

public static void deleteSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	
deleting from the system 

public static void deleteSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	try (Admin admin = conn.getAdmin()) {	String snapshotName = BackupSystemTable.getSnapshotName(conf);	if (snapshotExists(admin, snapshotName)) {	admin.deleteSnapshot(snapshotName);	
done deleting backup system table snapshot 

public static void deleteSnapshot(Connection conn) throws IOException {	Configuration conf = conn.getConfiguration();	try (Admin admin = conn.getAdmin()) {	String snapshotName = BackupSystemTable.getSnapshotName(conf);	if (snapshotExists(admin, snapshotName)) {	admin.deleteSnapshot(snapshotName);	} else {	
snapshot does not exists 

Path path = pair.getSecond();	String file = path.toString();	int lastSlash = file.lastIndexOf("/");	String filename = file.substring(lastSlash + 1);	Put put = new Put(rowkey(BULK_LOAD_PREFIX, table.toString(), BLK_LD_DELIM, Bytes.toString(region), BLK_LD_DELIM, filename));	put.addColumn(BackupSystemTable.META_FAMILY, TBL_COL, table.getName());	put.addColumn(BackupSystemTable.META_FAMILY, FAM_COL, family);	put.addColumn(BackupSystemTable.META_FAMILY, PATH_COL, file.getBytes());	put.addColumn(BackupSystemTable.META_FAMILY, STATE_COL, BL_PREPARE);	puts.add(put);	
writing raw bulk path for 

public void startDeleteOperation(String[] backupIdList) throws IOException {	if (LOG.isTraceEnabled()) {	
start delete operation for backups 

public void finishDeleteOperation() throws IOException {	
finsih delete operation for backup ids 

public String[] getListOfBackupIdsFromDeleteOperation() throws IOException {	
get delete operation for backup ids 

public void startMergeOperation(String[] backupIdList) throws IOException {	if (LOG.isTraceEnabled()) {	
start merge operation for backups 

public void updateProcessedTablesForMerge(List<TableName> tables) throws IOException {	if (LOG.isTraceEnabled()) {	
update tables for merge 

public void finishMergeOperation() throws IOException {	
finish merge operation for backup ids 

public String[] getListOfBackupIdsFromMergeOperation() throws IOException {	
get backup ids for merge operation 

static String getRegionNameFromOrigBulkLoadRow(String rowStr) {	String[] parts = rowStr.split(BLK_LD_DELIM);	int idx = 3;	if (parts.length == 4) {	idx = 2;	}	
bulk row string region 

========================= hbase sample_571 =========================

public void run() {	try {	doWaiting();	} catch (InterruptedException e) {	throw new RuntimeException("Failed wait", e);	}	
exiting 

========================= hbase sample_1416 =========================

public void sleep(final long startTime) {	if (this.stopper.isStopped()) {	return;	}	long now = System.currentTimeMillis();	long waitTime = this.period - (now - startTime);	if (waitTime > this.period) {	
calculated wait time setting to this period 

while (waitTime > 0) {	long woke = -1;	try {	synchronized (sleepLock) {	if (triggerWake) break;	sleepLock.wait(waitTime);	}	woke = System.currentTimeMillis();	long slept = woke - now;	if (slept - this.period > MINIMAL_DELTA_FOR_LOGGING) {	
we slept ms instead of ms this is likely due to a long garbage collecting pause and it s usually bad see http 

========================= hbase sample_967 =========================

public void run() {	updateTimeTrackingBeforeRun();	if (missedStartTime() && isScheduled()) {	onChoreMissedStartTime();	
chore missed its start time 

public void run() {	updateTimeTrackingBeforeRun();	if (missedStartTime() && isScheduled()) {	onChoreMissedStartTime();	} else if (stopper.isStopped() || !isScheduled()) {	cancel(false);	cleanup();	
chore was stopped 

cancel(false);	cleanup();	} else {	try {	if (!initialChoreComplete) {	initialChoreComplete = initialChore();	} else {	chore();	}	} catch (Throwable t) {	
caught error 

========================= hbase sample_1103 =========================

if (this.storeConfigInfo != null) {	cfTTL = this.storeConfigInfo.getStoreFileTtl();	}	if (filesToCompact.size() == 1) {	HStoreFile sf = filesToCompact.iterator().next();	OptionalLong minTimestamp = sf.getMinimumTimestamp();	long oldest = minTimestamp.isPresent() ? now - minTimestamp.getAsLong() : Long.MIN_VALUE;	if (sf.isMajorCompactionResult() && (cfTTL == Long.MAX_VALUE || oldest < cfTTL)) {	float blockLocalityIndex = sf.getHDFSBlockDistribution().getBlockLocalityIndex( RSRpcServices.getHostname(comConf.conf, false));	if (blockLocalityIndex < comConf.getMinLocalityToForceCompact()) {	
major compaction triggered on only store to make hdfs blocks local current blocklocalityindex is min 

OptionalLong minTimestamp = sf.getMinimumTimestamp();	long oldest = minTimestamp.isPresent() ? now - minTimestamp.getAsLong() : Long.MIN_VALUE;	if (sf.isMajorCompactionResult() && (cfTTL == Long.MAX_VALUE || oldest < cfTTL)) {	float blockLocalityIndex = sf.getHDFSBlockDistribution().getBlockLocalityIndex( RSRpcServices.getHostname(comConf.conf, false));	if (blockLocalityIndex < comConf.getMinLocalityToForceCompact()) {	result = true;	} else {	LOG.debug("Skipping major compaction of " + regionInfo + " because one (major) compacted file only, oldestTime " + oldest + "ms is < TTL=" + cfTTL + " and blockLocalityIndex is " + blockLocalityIndex + " (min " + comConf.getMinLocalityToForceCompact() + ")");	}	} else if (cfTTL != HConstants.FOREVER && oldest > cfTTL) {	
major compaction triggered on store because keyvalues outdated time since last major compaction ms 

float blockLocalityIndex = sf.getHDFSBlockDistribution().getBlockLocalityIndex( RSRpcServices.getHostname(comConf.conf, false));	if (blockLocalityIndex < comConf.getMinLocalityToForceCompact()) {	result = true;	} else {	LOG.debug("Skipping major compaction of " + regionInfo + " because one (major) compacted file only, oldestTime " + oldest + "ms is < TTL=" + cfTTL + " and blockLocalityIndex is " + blockLocalityIndex + " (min " + comConf.getMinLocalityToForceCompact() + ")");	}	} else if (cfTTL != HConstants.FOREVER && oldest > cfTTL) {	result = true;	}	} else {	
major compaction triggered on store time since last major compaction ms 

for (int i = countOfFiles - 1; i >= 0; --i) {	HStoreFile file = candidates.get(i);	fileSizes[i] = file.getReader().length();	int tooFar = i + comConf.getMaxFilesToCompact() - 1;	sumSize[i] = fileSizes[i] + ((i + 1 < countOfFiles) ? sumSize[i + 1] : 0) - ((tooFar < countOfFiles) ? fileSizes[tooFar] : 0);	}	while (countOfFiles - start >= comConf.getMinFilesToCompact() && fileSizes[start] > Math.max(comConf.getMinCompactSize(), (long) (sumSize[start + 1] * ratio))) {	++start;	}	if (start < countOfFiles) {	
default compaction algorithm has selected files from candidates 

========================= hbase sample_2685 =========================

public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {	if (filterConfig == null) return;	uri = ((HttpServletRequest)request).getRequestURI();	
filtering 

static void access(String urlstring) throws IOException {	
access 

========================= hbase sample_3201 =========================

}	}	groupClusterLoad.put(HConstants.ENSEMBLE_TABLE_NAME, groupClusterState);	this.internalBalancer.setClusterLoad(groupClusterLoad);	List<RegionPlan> groupPlans = this.internalBalancer .balanceCluster(groupClusterState);	if (groupPlans != null) {	regionPlans.addAll(groupPlans);	}	}	} catch (IOException exp) {	
exception while balancing cluster 

private void generateGroupMaps( List<RegionInfo> regions, List<ServerName> servers, ListMultimap<String, RegionInfo> regionMap, ListMultimap<String, ServerName> serverMap) throws HBaseIOException {	try {	for (RegionInfo region : regions) {	String groupName = rsGroupInfoManager.getRSGroupOfTable(region.getTable());	if (groupName == null) {	
group for table is null 

private List<ServerName> filterOfflineServers(RSGroupInfo RSGroupInfo, List<ServerName> onlineServers) {	if (RSGroupInfo != null) {	return filterServers(RSGroupInfo.getServers(), onlineServers);	} else {	
rsgroup information found to be null some regions might be unassigned 

public Set<RegionInfo> getMisplacedRegions( Map<RegionInfo, ServerName> regions) throws IOException {	Set<RegionInfo> misplacedRegions = new HashSet<>();	for(Map.Entry<RegionInfo, ServerName> region : regions.entrySet()) {	RegionInfo regionInfo = region.getKey();	ServerName assignedServer = region.getValue();	RSGroupInfo info = rsGroupInfoManager.getRSGroup(rsGroupInfoManager. getRSGroupOfTable(regionInfo.getTable()));	if (assignedServer == null) {	
there is no assigned server for 

Set<RegionInfo> misplacedRegions = new HashSet<>();	for(Map.Entry<RegionInfo, ServerName> region : regions.entrySet()) {	RegionInfo regionInfo = region.getKey();	ServerName assignedServer = region.getValue();	RSGroupInfo info = rsGroupInfoManager.getRSGroup(rsGroupInfoManager. getRSGroupOfTable(regionInfo.getTable()));	if (assignedServer == null) {	continue;	}	RSGroupInfo otherInfo = rsGroupInfoManager.getRSGroupOfServer(assignedServer.getAddress());	if (info == null && otherInfo == null) {	
couldn t obtain rs group information for on 

correctAssignments.put(LoadBalancer.BOGUS_SERVER_NAME, new LinkedList<>());	for (Map.Entry<ServerName, List<RegionInfo>> assignments : existingAssignments.entrySet()){	ServerName sName = assignments.getKey();	correctAssignments.put(sName, new LinkedList<>());	List<RegionInfo> regions = assignments.getValue();	for (RegionInfo region : regions) {	RSGroupInfo info = null;	try {	info = rsGroupInfoManager.getRSGroup( rsGroupInfoManager.getRSGroupOfTable(region.getTable()));	} catch (IOException exp) {	
rsgroup information null for region of table 

========================= hbase sample_3344 =========================

private void syncFailed(long epochWhenSync, Throwable error) {	
sync failed 

nextCursor++) {	if (!waitingConsumePayloads.isPublished(nextCursor)) {	break;	}	RingBufferTruck truck = waitingConsumePayloads.get(nextCursor);	switch (truck.type()) {	case APPEND: toWriteAppends.addLast(truck.unloadAppend());	break;	case SYNC: syncFutures.add(truck.unloadSync());	break;	
ringbuffertruck with unexpected type 

protected void doShutdown() throws IOException {	waitForSafePoint();	executeClose(closeExecutor, writer);	closeExecutor.shutdown();	try {	if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {	
we have waited seconds but the close of async writer doesn t complete please check the status of underlying filesystem or increase the wait time by the config async wal wait on shutdown in seconds 

protected void doShutdown() throws IOException {	waitForSafePoint();	executeClose(closeExecutor, writer);	closeExecutor.shutdown();	try {	if (!closeExecutor.awaitTermination(waitOnShutdownInSeconds, TimeUnit.SECONDS)) {	}	} catch (InterruptedException e) {	
the wait for close of async writer is interrupted 

private static long executeClose(ExecutorService closeExecutor, AsyncWriter writer) {	long fileLength;	if (writer != null) {	fileLength = writer.getLength();	closeExecutor.execute(() -> {	try {	writer.close();	} catch (IOException e) {	
close old writer failed 

========================= hbase sample_2555 =========================

public boolean accept(Path path) {	if (AbstractFSWALProvider.isMetaFile(path)) {	if (LOG.isDebugEnabled()) {	
skip meta log file 

if (AbstractFSWALProvider.isMetaFile(path)) {	if (LOG.isDebugEnabled()) {	}	return false;	}	long timestamp;	try {	timestamp = BackupUtils.getCreationTime(path);	return timestamp > lastBackupTS;	} catch (Exception e) {	
cannot read timestamp of log file 

========================= hbase sample_567 =========================

public void stop(String why) {	
stopping because 

private WALEntry createEntry(TableName table, int row,  KeyValue.Type type, List<Cell> cells) {	byte[] fam = table.equals(TABLE_NAME1) ? FAM_NAME1 : FAM_NAME2;	byte[] rowBytes = Bytes.toBytes(row);	try {	Thread.sleep(1);	} catch (InterruptedException e) {	
was interrupted while sleep meh 

========================= hbase sample_1953 =========================

public StripeCompactionRequest selectCompaction(StripeInformationProvider si, List<HStoreFile> filesCompacting, boolean isOffpeak) throws IOException {	if (!filesCompacting.isEmpty()) {	
not selecting compaction files compacting 

public StripeCompactionRequest selectCompaction(StripeInformationProvider si, List<HStoreFile> filesCompacting, boolean isOffpeak) throws IOException {	if (!filesCompacting.isEmpty()) {	return null;	}	Collection<HStoreFile> allFiles = si.getStorefiles();	if (StoreUtils.hasReferences(allFiles)) {	
there are references in the store compacting all files 

if (stripeCount == 0) {	if (!shouldCompactL0) return null;	return selectNewStripesCompaction(si);	}	boolean canDropDeletesNoL0 = l0Files.isEmpty();	if (shouldCompactL0) {	if (!canDropDeletesNoL0) {	StripeCompactionRequest result = selectSingleStripeCompaction( si, true, canDropDeletesNoL0, isOffpeak);	if (result != null) return result;	}	
selecting compaction with files 

for (HStoreFile sf : selection) {	size += sf.getReader().length();	}	if (bqSelection == null || selection.size() > bqSelection.size() || (selection.size() == bqSelection.size() && size < bqTotalSize)) {	bqSelection = selection;	bqIndex = i;	bqTotalSize = size;	}	}	if (bqSelection == null) {	
no good compaction is possible in any stripe 

String splitString = "";	if (hasAllFiles && bqTotalSize >= config.getSplitSize()) {	if (includeL0) {	return null;	}	Pair<Long, Integer> kvsAndCount = estimateTargetKvs(filesToCompact, config.getSplitCount());	targetKvs = kvsAndCount.getFirst();	targetCount = kvsAndCount.getSecond();	splitString = "; the stripe will be split into at most " + targetCount + " stripes with " + targetKvs + " target KVs";	}	
found compaction in a stripe with end key with files of total size 

}	Pair<Long, Integer> kvsAndCount = estimateTargetKvs(filesToCompact, config.getSplitCount());	targetKvs = kvsAndCount.getFirst();	targetCount = kvsAndCount.getSecond();	splitString = "; the stripe will be split into at most " + targetCount + " stripes with " + targetKvs + " target KVs";	}	StripeCompactionRequest req;	if (includeL0) {	assert hasAllFiles;	List<HStoreFile> l0Files = si.getLevel0Files();	
adding files to compaction to be able to drop deletes 

private StripeCompactionRequest selectNewStripesCompaction(StripeInformationProvider si) {	List<HStoreFile> l0Files = si.getLevel0Files();	Pair<Long, Integer> kvsAndCount = estimateTargetKvs(l0Files, config.getInitialCount());	
creating initial stripes with kvs each via compaction of files 

}	if (length > bestLength) {	bestStart = start;	bestLength = length;	}	if (bestLength == 0) return null;	if (bestLength == 1) {	if (bestStart == (stripes.size() - 1)) return null;	++bestLength;	}	
merging stripes to delete expired store files 

========================= hbase sample_2693 =========================

private int parseAndRun(String[] args) throws IOException {	if (!BackupManager.isBackupEnabled(getConf())) {	System.err.println(BackupRestoreConstants.ENABLE_BACKUP);	return -1;	}	System.out.println(BackupRestoreConstants.VERIFY_BACKUP);	if (cmd.hasOption(OPTION_DEBUG)) {	
org apache hadoop hbase backup 

private int parseAndRun(String[] args) throws IOException {	if (!BackupManager.isBackupEnabled(getConf())) {	System.err.println(BackupRestoreConstants.ENABLE_BACKUP);	return -1;	}	System.out.println(BackupRestoreConstants.VERIFY_BACKUP);	if (cmd.hasOption(OPTION_DEBUG)) {	}	boolean overwrite = cmd.hasOption(OPTION_OVERWRITE);	if (overwrite) {	
found overwrite option in restore command will overwrite to existing table if any in the restore target 

return -1;	}	System.out.println(BackupRestoreConstants.VERIFY_BACKUP);	if (cmd.hasOption(OPTION_DEBUG)) {	}	boolean overwrite = cmd.hasOption(OPTION_OVERWRITE);	if (overwrite) {	}	boolean check = cmd.hasOption(OPTION_CHECK);	if (check) {	
found check option in restore command will check and verify the dependencies 

public int run(String[] args) throws IOException {	if (conf == null) {	
tool configuration is not initialized 

}	if (cmd.hasOption(SHORT_HELP_OPTION) || cmd.hasOption(LONG_HELP_OPTION)) {	printToolUsage();	return EXIT_FAILURE;	}	processOptions(cmd);	int ret = EXIT_FAILURE;	try {	ret = doWork();	} catch (Exception e) {	
error running command line tool 

========================= hbase sample_588 =========================

public void start(CoprocessorEnvironment env) throws IOException {	String where = null;	if (env instanceof MasterCoprocessorEnvironment) {	where = "master";	} else if (env instanceof RegionServerCoprocessorEnvironment) {	where = "regionserver";	} else if (env instanceof RegionCoprocessorEnvironment) {	
on regioncoprocessorenvironment 

public void start(CoprocessorEnvironment env) throws IOException {	String where = null;	if (env instanceof MasterCoprocessorEnvironment) {	where = "master";	} else if (env instanceof RegionServerCoprocessorEnvironment) {	where = "regionserver";	} else if (env instanceof RegionCoprocessorEnvironment) {	}	
start coprocessor on 

public void stop(CoprocessorEnvironment env) throws IOException {	String fileName = null;	if (env instanceof MasterCoprocessorEnvironment) {	fileName = MASTER_FILE;	} else if (env instanceof RegionServerCoprocessorEnvironment) {	fileName = REGIONSERVER_FILE;	} else if (env instanceof RegionCoprocessorEnvironment) {	
on regioncoprocessorenvironment 

if (env instanceof MasterCoprocessorEnvironment) {	fileName = MASTER_FILE;	} else if (env instanceof RegionServerCoprocessorEnvironment) {	fileName = REGIONSERVER_FILE;	} else if (env instanceof RegionCoprocessorEnvironment) {	}	Configuration conf = UTIL.getConfiguration();	Path resultFile = new Path(UTIL.getDataTestDirOnTestFS(), fileName);	FileSystem fs = FileSystem.get(conf);	boolean result = fs.createNewFile(resultFile);	
create file return rc 

public void testStopped() throws Exception {	MiniHBaseCluster cluster = UTIL.getHBaseCluster();	
shutdown hbase cluster 

public void testStopped() throws Exception {	MiniHBaseCluster cluster = UTIL.getHBaseCluster();	cluster.shutdown();	
wait for the hbase cluster shutdown 

========================= hbase sample_1545 =========================

private void setUp() throws Exception {	this.util = new IntegrationTestingUtility();	
initializing checking cluster has servers 

private void setUp() throws Exception {	this.util = new IntegrationTestingUtility();	util.initializeCluster(MIN_NUM_SERVERS);	
done initializing checking cluster 

protected void deleteTable() throws Exception {	if (util.getAdmin().tableExists(TABLE_NAME)) {	
deleting table 

protected void deleteTable() throws Exception {	if (util.getAdmin().tableExists(TABLE_NAME)) {	if (!util.getAdmin().isTableDisabled(TABLE_NAME)) {	util.getAdmin().disableTable(TABLE_NAME);	}	util.getAdmin().deleteTable(TABLE_NAME);	
deleted table 

private void tearDown() throws Exception {	deleteTable();	
restoring the cluster 

private void tearDown() throws Exception {	deleteTable();	util.restoreCluster();	
done restoring the cluster 

MultiThreadedReader reader = new MultiThreadedReader(dataGen, conf, TABLE_NAME, 100);	reader.linkToWriter(writer);	long testStartTime = System.currentTimeMillis();	writer.start(startKey, endKey, writeThreads);	reader.start(startKey, endKey, readThreads);	writer.waitForFinish();	reader.waitForFinish();	status("Readers and writers stopped for test " + description);	boolean success = writer.getNumWriteFailures() == 0;	if (!success) {	
write failed 

writer.start(startKey, endKey, writeThreads);	reader.start(startKey, endKey, readThreads);	writer.waitForFinish();	reader.waitForFinish();	status("Readers and writers stopped for test " + description);	boolean success = writer.getNumWriteFailures() == 0;	if (!success) {	} else {	success = reader.getNumReadErrors() == 0 && reader.getNumReadFailures() == 0;	if (!success) {	
read failed 

for (Pair<Long, Long> pt : reader.getMetrics().getCombinedCdf()) {	perfDump.append(String.format( "csvread,%s,%d,%d%n", description, pt.getFirst(), pt.getSecond()));	}	if (dumpTimePerf) {	Iterator<Triple<Long, Double, Long>> timePerf = reader.getMetrics().getCombinedTimeSeries();	while (timePerf.hasNext()) {	Triple<Long, Double, Long> pt = timePerf.next();	perfDump.append(String.format("csvtime,%s,%d,%d,%.4f%n", description, pt.getFirst(), pt.getThird(), pt.getSecond()));	}	}	
performance data dump for test test took sec 

private static void status(String s) {	
status 

protected void createTable(HTableDescriptor htd) throws Exception {	deleteTable();	if (util.getHBaseClusterInterface() instanceof MiniHBaseCluster) {	
test does not make a lot of sense for minicluster will set flush size low 

========================= hbase sample_3256 =========================

assertFalse(ts1.isPresent());	for (int i = 0; i < 3; i++) {	table.put(p).join();	admin.flush(tableName).join();	}	admin.majorCompact(tableName).join();	long curt = System.currentTimeMillis();	long waitTime = 10000;	long endt = curt + waitTime;	CompactionState state = admin.getCompactionState(tableName).get();	
current compaction state is 

}	admin.majorCompact(tableName).join();	long curt = System.currentTimeMillis();	long waitTime = 10000;	long endt = curt + waitTime;	CompactionState state = admin.getCompactionState(tableName).get();	while (state == CompactionState.NONE && curt < endt) {	Thread.sleep(100);	state = admin.getCompactionState(tableName).get();	curt = System.currentTimeMillis();	
current compaction state is 

long waitTime = 10000;	long endt = curt + waitTime;	CompactionState state = admin.getCompactionState(tableName).get();	while (state == CompactionState.NONE && curt < endt) {	Thread.sleep(100);	state = admin.getCompactionState(tableName).get();	curt = System.currentTimeMillis();	}	if (state == CompactionState.MAJOR) {	state = admin.getCompactionState(tableName).get();	
current compaction state is 

while (state == CompactionState.NONE && curt < endt) {	Thread.sleep(100);	state = admin.getCompactionState(tableName).get();	curt = System.currentTimeMillis();	}	if (state == CompactionState.MAJOR) {	state = admin.getCompactionState(tableName).get();	while (state != CompactionState.NONE && curt < endt) {	Thread.sleep(10);	state = admin.getCompactionState(tableName).get();	
current compaction state is 

========================= hbase sample_2017 =========================

public void shutdown() {	if (state == Coprocessor.State.ACTIVE) {	state = Coprocessor.State.STOPPING;	Thread currentThread = Thread.currentThread();	ClassLoader hostClassLoader = currentThread.getContextClassLoader();	try {	currentThread.setContextClassLoader(this.getClassLoader());	impl.stop(this);	state = Coprocessor.State.STOPPED;	} catch (IOException ioe) {	
error stopping coprocessor 

========================= hbase sample_2447 =========================

public void nodeDeleted(String path) {	if (stopper.isStopped()) {	return;	}	boolean cont = refreshListIfRightPath(path);	if (!cont) {	return;	}	
znode expired triggering replicatorremoved event 

========================= hbase sample_619 =========================

protected void postPeerModification(MasterProcedureEnv env) throws IOException {	
successfully updated peer config of to 

========================= hbase sample_2851 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	
performing action flush table 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	try {	admin.flush(tableName);	} catch (Exception ex) {	
flush failed might be caused by other chaos 

========================= hbase sample_3313 =========================

private void checkSplittable(final MasterProcedureEnv env, final RegionInfo regionToSplit, final byte[] splitRow) throws IOException {	if(regionToSplit.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) {	throw new IllegalArgumentException ("Can't invoke split on non-default regions directly");	}	RegionStateNode node = env.getAssignmentManager().getRegionStates().getRegionStateNode(getParentRegion());	IOException splittableCheckIOE = null;	boolean splittable = false;	if (node != null) {	try {	if (bestSplitRow == null || bestSplitRow.length == 0) {	
splitkey isn t explicitly specified will try to find a best split key from rs 

private static long getDaughterRegionIdTimestamp(final RegionInfo hri) {	long rid = EnvironmentEdgeManager.currentTime();	if (rid < hri.getRegionId()) {	
clock skew parent regions id is but current time here is 

public boolean prepareSplitRegion(final MasterProcedureEnv env) throws IOException {	RegionStateNode node = env.getAssignmentManager().getRegionStates().getRegionStateNode(getParentRegion());	if (node == null) {	throw new UnknownRegionException(getParentRegion().getRegionNameAsString());	}	RegionInfo parentHRI = node.getRegionInfo();	if (node.isInState(State.SPLIT)) {	
split of skipped state is already split 

public boolean prepareSplitRegion(final MasterProcedureEnv env) throws IOException {	RegionStateNode node = env.getAssignmentManager().getRegionStates().getRegionStateNode(getParentRegion());	if (node == null) {	throw new UnknownRegionException(getParentRegion().getRegionNameAsString());	}	RegionInfo parentHRI = node.getRegionInfo();	if (node.isInState(State.SPLIT)) {	return false;	}	if (parentHRI.isSplit() || parentHRI.isOffline()) {	
split of skipped because offline split 

final MasterFileSystem mfs = env.getMasterServices().getMasterFileSystem();	final Configuration conf = env.getMasterConfiguration();	int nbFiles = 0;	final Map<String, Collection<StoreFileInfo>> files = new HashMap<String, Collection<StoreFileInfo>>(regionFs.getFamilies().size());	for (String family: regionFs.getFamilies()) {	Collection<StoreFileInfo> sfis = regionFs.getStoreFiles(family);	if (sfis == null) continue;	Collection<StoreFileInfo> filteredSfis = null;	for (StoreFileInfo sfi: sfis) {	if (sfi.isReference()) {	
skipping split of presuming ready for archiving 

========================= hbase sample_2781 =========================

public byte[] calcIndexKey(byte[] lastKeyOfPreviousBlock, byte[] firstKeyInBlock) {	byte[] fakeKey = getShortMidpointKey(lastKeyOfPreviousBlock, firstKeyInBlock);	if (compareFlatKey(fakeKey, firstKeyInBlock) > 0) {	
unexpected getshortmidpointkey result fakekey firstkeyinblock 

public byte[] calcIndexKey(byte[] lastKeyOfPreviousBlock, byte[] firstKeyInBlock) {	byte[] fakeKey = getShortMidpointKey(lastKeyOfPreviousBlock, firstKeyInBlock);	if (compareFlatKey(fakeKey, firstKeyInBlock) > 0) {	return firstKeyInBlock;	}	if (lastKeyOfPreviousBlock != null && compareFlatKey(lastKeyOfPreviousBlock, fakeKey) >= 0) {	
unexpected getshortmidpointkey result lastkeyofpreviousblock fakekey 

========================= hbase sample_1142 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1841 =========================

public void abort(String why, Throwable e) {	aborted = true;	}	});	l.setBalancerOn(false);	for (int replicaId = 1; replicaId < 3; replicaId ++) {	RegionInfo h = RegionReplicaUtil.getRegionInfoForReplica(RegionInfoBuilder.FIRST_META_REGIONINFO, replicaId);	try {	TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager().waitForAssignment(h);	} catch (NoSuchProcedureException e) {	
presume the procedure has been cleaned up so just proceed 

}	});	l.setBalancerOn(false);	for (int replicaId = 1; replicaId < 3; replicaId ++) {	RegionInfo h = RegionReplicaUtil.getRegionInfoForReplica(RegionInfoBuilder.FIRST_META_REGIONINFO, replicaId);	try {	TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager().waitForAssignment(h);	} catch (NoSuchProcedureException e) {	}	}	
all meta replicas assigned 

public void testShutdownOfReplicaHolder() throws Exception {	try (ClusterConnection conn = (ClusterConnection) ConnectionFactory.createConnection(TEST_UTIL.getConfiguration())) {	RegionLocations rl = conn. locateRegion(TableName.META_TABLE_NAME, Bytes.toBytes(""), false, true);	HRegionLocation hrl = rl.getRegionLocation(1);	ServerName oldServer = hrl.getServerName();	TEST_UTIL.getHBaseClusterInterface().killRegionServer(oldServer);	int i = 0;	do {	
waiting for the replica to come up 

========================= hbase sample_2129 =========================

public void before() throws IOException {	
before 

public void before() throws IOException {	UTIL.ensureSomeRegionServersAvailable(1);	
before done 

========================= hbase sample_3368 =========================

wal.sync();	lastSync = 0;	}	}	latencyHistogram.update(System.nanoTime() - now);	}	}	long totalTime = (System.currentTimeMillis() - startTime);	logBenchmarkResult(Thread.currentThread().getName(), numIterations, totalTime);	} catch (Exception e) {	
thread failed 

if (cipher != null) {	Configuration conf = getConf();	conf.set(HConstants.CRYPTO_KEYPROVIDER_CONF_KEY, KeyProviderForTesting.class.getName());	conf.set(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, "hbase");	conf.setClass("hbase.regionserver.hlog.reader.impl", SecureProtobufLogReader.class, WAL.Reader.class);	conf.setClass("hbase.regionserver.hlog.writer.impl", SecureProtobufLogWriter.class, Writer.class);	conf.setBoolean(HConstants.ENABLE_WAL_ENCRYPTION, true);	conf.set(HConstants.CRYPTO_WAL_ALGORITHM_CONF_KEY, cipher);	}	if (numThreads < numRegions) {	
number of threads is less than the number of regions some regions will sit idle 

conf.setClass("hbase.regionserver.hlog.reader.impl", SecureProtobufLogReader.class, WAL.Reader.class);	conf.setClass("hbase.regionserver.hlog.writer.impl", SecureProtobufLogWriter.class, Writer.class);	conf.setBoolean(HConstants.ENABLE_WAL_ENCRYPTION, true);	conf.set(HConstants.CRYPTO_WAL_ALGORITHM_CONF_KEY, cipher);	}	if (numThreads < numRegions) {	}	getConf().setInt(HConstants.REGION_SERVER_HANDLER_COUNT, numThreads);	FSUtils.setFsDefault(getConf(), FSUtils.getRootDir(getConf()));	FileSystem fs = FileSystem.get(getConf());	
filesystem 

reporter.start(30, TimeUnit.SECONDS);	long putTime = runBenchmark(benchmarks, numThreads);	logBenchmarkResult("Summary: threads=" + numThreads + ", iterations=" + numIterations + ", syncInterval=" + syncInterval, numIterations * numThreads, putTime);	for (int i = 0; i < numRegions; i++) {	if (regions[i] != null) {	closeRegion(regions[i]);	regions[i] = null;	}	}	if (verify) {	
verifying written log entries 

}	}	} finally {	mockServices.stop("test clean up.");	for (int i = 0; i < numRegions; i++) {	if (regions[i] != null) {	closeRegion(regions[i]);	}	}	if (null != roller) {	
shutting down log roller 

private HRegion openRegion(final FileSystem fs, final Path dir, final TableDescriptor htd, final WALFactory wals, final long whenToRoll, final LogRoller roller) throws IOException {	RegionInfo regionInfo = RegionInfoBuilder.newBuilder(htd.getTableName()).build();	final WAL wal = wals.getWAL(regionInfo);	if (walsListenedTo.add(wal)) {	roller.addWAL(wal);	wal.registerWALActionsListener(new WALActionsListener() {	private int appends = 0;	public void visitLogEntryBeforeWrite(WALKey logKey, WALEdit logEdit) {	this.appends++;	if (this.appends % whenToRoll == 0) {	
rolling after edits 

========================= hbase sample_1355 =========================

}	TEST_UTIL.flush();	ColumnRangeFilter filter;	Scan scan = new Scan();	scan.setMaxVersions();	for (StringRange s : rangeMap.keySet()) {	filter = new ColumnRangeFilter(s.getStart() == null ? null : Bytes.toBytes(s.getStart()), s.isStartInclusive(), s.getEnd() == null ? null : Bytes.toBytes(s.getEnd()), s.isEndInclusive());	scan.setFilter(filter);	ResultScanner scanner = ht.getScanner(scan);	List<Cell> results = new ArrayList<>();	
scan column range 

long timeBeforeScan = System.currentTimeMillis();	Result result;	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	results.add(kv);	}	}	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("scan time = " + scanTime + "ms");	
found results 

long timeBeforeScan = System.currentTimeMillis();	Result result;	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	results.add(kv);	}	}	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("scan time = " + scanTime + "ms");	
expecting results 

Result result;	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	results.add(kv);	}	}	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("scan time = " + scanTime + "ms");	for (KeyValue kv : results) {	
found row column 

========================= hbase sample_1990 =========================

boolean writeToWAL = Boolean.parseBoolean(m.group(7));	boolean useTags = Boolean.parseBoolean(m.group(8));	int noOfTags = Integer.parseInt(m.group(9));	LOG.debug("tableName=" + tableName + " split["+ splitList.size() + "] " + " startRow=" + startRow + " rows=" + rows + " totalRows=" + totalRows + " clients=" + clients + " flushCommits=" + flushCommits + " writeToWAL=" + writeToWAL + " useTags=" + useTags + " noOfTags=" + noOfTags);	PeInputSplit newSplit = new PeInputSplit(tableName, startRow, rows, totalRows, clients, flushCommits, writeToWAL, useTags, noOfTags);	splitList.add(newSplit);	}	}	in.close();	}	
total of splits 

private boolean checkTable(RemoteAdmin admin) throws IOException {	HTableDescriptor tableDescriptor = getTableDescriptor();	if (this.presplitRegions > 0) {	if (admin.isTableAvailable(tableDescriptor.getTableName().getName())) {	admin.deleteTable(tableDescriptor.getTableName().getName());	}	byte[][] splits = getSplits();	for (int i=0; i < splits.length; i++) {	
split 

private boolean checkTable(RemoteAdmin admin) throws IOException {	HTableDescriptor tableDescriptor = getTableDescriptor();	if (this.presplitRegions > 0) {	if (admin.isTableAvailable(tableDescriptor.getTableName().getName())) {	admin.deleteTable(tableDescriptor.getTableName().getName());	}	byte[][] splits = getSplits();	for (int i=0; i < splits.length; i++) {	}	admin.createTable(tableDescriptor);	
table created with splits 

admin.deleteTable(tableDescriptor.getTableName().getName());	}	byte[][] splits = getSplits();	for (int i=0; i < splits.length; i++) {	}	admin.createTable(tableDescriptor);	} else {	boolean tableExists = admin.isTableAvailable(tableDescriptor.getTableName().getName());	if (!tableExists) {	admin.createTable(tableDescriptor);	
table created 

pe.compression = compression;	pe.writeToWAL = writeToWal;	pe.presplitRegions = preSplitRegions;	pe.N = N;	pe.connection = connection;	pe.useTags = useTags;	pe.noOfTags = numTags;	try {	long elapsedTime = pe.runOneClient(cmd, index * perClientRows, perClientRows, R, flushCommits, writeToWAL, useTags, noOfTags, connection, new Status() {	public void setStatus(final String msg) throws IOException {	
client 

pe.N = N;	pe.connection = connection;	pe.useTags = useTags;	pe.noOfTags = numTags;	try {	long elapsedTime = pe.runOneClient(cmd, index * perClientRows, perClientRows, R, flushCommits, writeToWAL, useTags, noOfTags, connection, new Status() {	public void setStatus(final String msg) throws IOException {	}	});	timings[index] = elapsedTime;	
finished in ms writing rows 

threads.add(t);	}	for (Thread t: threads) {	t.start();	}	for (Thread t: threads) {	while(t.isAlive()) {	try {	t.join();	} catch (InterruptedException e) {	
interrupted continuing 

}	for (Thread t: threads) {	while(t.isAlive()) {	try {	t.join();	} catch (InterruptedException e) {	}	}	}	final String test = cmd.getSimpleName();	
summary of timings ms 

} catch (InterruptedException e) {	}	}	}	final String test = cmd.getSimpleName();	Arrays.sort(timings);	long total = 0;	for (int i = 0; i < this.N; i++) {	total += timings[i];	}	
tmin ms tmax ms tavg ms 

LOG.info(msg);	}	};	RemoteAdmin admin = null;	try {	Client client = new Client(cluster);	admin = new RemoteAdmin(client, getConf());	checkTable(admin);	runOneClient(cmd, 0, this.R, this.R, this.flushCommits, this.writeToWAL, this.useTags, this.noOfTags, this.connection, status);	} catch (Exception e) {	
Failed 

}	}	runTest(cmdClass);	errCode = 0;	break;	}	printUsage();	break;	}	} catch (Exception e) {	
Failed 

========================= hbase sample_3041 =========================

public static MonkeyFactory getFactory(String factoryName) {	MonkeyFactory fact = FACTORIES.get(factoryName);	if (fact == null && factoryName != null && !factoryName.isEmpty()) {	Class klass = null;	try {	klass = Class.forName(factoryName);	if (klass != null) {	fact = (MonkeyFactory) ReflectionUtils.newInstance(klass);	}	} catch (Exception e) {	
error trying to create could not load it by class name 

========================= hbase sample_3295 =========================

public MasterFlushTableProcedureManager() {}	public void stop(String why) {	
stop 

Procedure proc = coordinator.startProcedure(monitor, desc.getInstance(), new byte[0], Lists.newArrayList(regionServers));	monitor.rethrowException();	if (proc == null) {	String msg = "Failed to submit distributed procedure " + desc.getSignature() + " for '" + desc.getInstance() + "'. " + "Another flush procedure is running?";	LOG.error(msg);	throw new IOException(msg);	}	procMap.put(tableName, proc);	try {	proc.waitForCompleted();	
done waiting exec procedure for 

Procedure proc = coordinator.startProcedure(monitor, desc.getInstance(), new byte[0], Lists.newArrayList(regionServers));	monitor.rethrowException();	if (proc == null) {	String msg = "Failed to submit distributed procedure " + desc.getSignature() + " for '" + desc.getInstance() + "'. " + "Another flush procedure is running?";	LOG.error(msg);	throw new IOException(msg);	}	procMap.put(tableName, proc);	try {	proc.waitForCompleted();	
master flush table procedure is successful 

========================= hbase sample_2484 =========================

private int dumpReplicationQueues(DumpOptions opts) throws Exception {	Configuration conf = getConf();	HBaseAdmin.available(conf);	ClusterConnection connection = (ClusterConnection) ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin();	ZKWatcher zkw = new ZKWatcher(conf, "DumpReplicationQueues" + System.currentTimeMillis(), new WarnOnlyAbortable(), true);	try {	
our quorum 

private int dumpReplicationQueues(DumpOptions opts) throws Exception {	Configuration conf = getConf();	HBaseAdmin.available(conf);	ClusterConnection connection = (ClusterConnection) ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin();	ZKWatcher zkw = new ZKWatcher(conf, "DumpReplicationQueues" + System.currentTimeMillis(), new WarnOnlyAbortable(), true);	try {	List<TableCFs> replicatedTableCFs = admin.listReplicatedTableCFs();	if (replicatedTableCFs.isEmpty()) {	
no tables with a configured replication peer were found 

Configuration conf = getConf();	HBaseAdmin.available(conf);	ClusterConnection connection = (ClusterConnection) ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin();	ZKWatcher zkw = new ZKWatcher(conf, "DumpReplicationQueues" + System.currentTimeMillis(), new WarnOnlyAbortable(), true);	try {	List<TableCFs> replicatedTableCFs = admin.listReplicatedTableCFs();	if (replicatedTableCFs.isEmpty()) {	return(0);	} else {	
replicated tables 

Admin admin = connection.getAdmin();	ZKWatcher zkw = new ZKWatcher(conf, "DumpReplicationQueues" + System.currentTimeMillis(), new WarnOnlyAbortable(), true);	try {	List<TableCFs> replicatedTableCFs = admin.listReplicatedTableCFs();	if (replicatedTableCFs.isEmpty()) {	return(0);	} else {	}	List<ReplicationPeerDescription> peers = admin.listReplicationPeers();	if (peers.isEmpty()) {	
replication is enabled but no peer configuration was found 

if (replicatedTableCFs.isEmpty()) {	return(0);	} else {	}	List<ReplicationPeerDescription> peers = admin.listReplicationPeers();	if (peers.isEmpty()) {	}	System.out.println("Dumping replication peers and configurations:");	System.out.println(dumpPeersState(peers));	if (opts.isDistributed()) {	
found distributed will poll each regionserver 

private long getTotalWALSize(FileSystem fs, List<String> wals, ServerName server) throws IOException {	long size = 0;	FileStatus fileStatus;	for (String wal : wals) {	try {	fileStatus = (new WALLink(getConf(), server.getServerName(), wal)).getFileStatus(fs);	} catch (IOException e) {	if (e instanceof FileNotFoundException) {	numWalsNotFound++;	
wal couldn t be found skipping 

private long getTotalWALSize(FileSystem fs, List<String> wals, ServerName server) throws IOException {	long size = 0;	FileStatus fileStatus;	for (String wal : wals) {	try {	fileStatus = (new WALLink(getConf(), server.getServerName(), wal)).getFileStatus(fs);	} catch (IOException e) {	if (e instanceof FileNotFoundException) {	numWalsNotFound++;	} else {	
can t get file status of wal skipping 

public void abort(String why, Throwable e) {	
dumpreplicationqueue received abort ignoring reason 

public void stop(String why) {	
dumpreplicationqueue received stop ignoring reason 

========================= hbase sample_2938 =========================

return DeleteResult.VERSION_DELETED;	}	if (cell.getTimestamp() <= node.ts && tagMatched(cell, node.tagInfo)) {	return DeleteResult.COLUMN_DELETED;	}	}	if (duplicateMvcc < Long.MAX_VALUE) {	return DeleteResult.VERSION_MASKED;	}	} catch (IOException e) {	
error in isdeleted check will treat cell as not deleted 

========================= hbase sample_2312 =========================

Job job = createSubmittableJob(getConf(), args);	if (job == null) {	return -1;	}	boolean success = job.waitForCompletion(true);	final long expectedCount = getConf().getLong(EXPECTED_COUNT_KEY, -1);	if (success && expectedCount != -1) {	final Counter counter = job.getCounters().findCounter(RowCounterMapper.Counters.ROWS);	success = expectedCount == counter.getValue();	if (!success) {	
failing job because count of does not match expected count of 

========================= hbase sample_3446 =========================

public static Writer createWriter(final Configuration conf, final FileSystem fs, final Path path, final boolean overwritable) throws IOException {	Class<? extends Writer> logWriterClass = conf.getClass("hbase.regionserver.hlog.writer.impl", ProtobufLogWriter.class, Writer.class);	Writer writer = null;	try {	writer = logWriterClass.newInstance();	writer.init(fs, path, conf, overwritable);	return writer;	} catch (Exception e) {	if (e instanceof CommonFSUtils.StreamLacksCapabilityException) {	
the regionserver write ahead log provider for filesystem implementations relies on the ability to call for proper operation during component failures but the current filesystem does not support doing so please check the config value of and ensure it points to a filesystem mount that has suitable capabilities for output streams 

public static Writer createWriter(final Configuration conf, final FileSystem fs, final Path path, final boolean overwritable) throws IOException {	Class<? extends Writer> logWriterClass = conf.getClass("hbase.regionserver.hlog.writer.impl", ProtobufLogWriter.class, Writer.class);	Writer writer = null;	try {	writer = logWriterClass.newInstance();	writer.init(fs, path, conf, overwritable);	return writer;	} catch (Exception e) {	if (e instanceof CommonFSUtils.StreamLacksCapabilityException) {	} else {	
error instantiating log writer 

writer.init(fs, path, conf, overwritable);	return writer;	} catch (Exception e) {	if (e instanceof CommonFSUtils.StreamLacksCapabilityException) {	} else {	}	if (writer != null) {	try{	writer.close();	} catch(IOException ee){	
cannot close log writer 

========================= hbase sample_2257 =========================

public void regionServerRemoved(String regionServer) {	rsRemovedData = regionServer;	rsRemovedCount.getAndIncrement();	
received regionserverremoved event 

public void abort(String why, Throwable e) {	
aborting 

========================= hbase sample_1928 =========================

HTableDescriptor desc = new HTableDescriptor(tableName);	for (byte[] family : new byte[][] { dummy, test }) {	desc.addFamily(new HColumnDescriptor(family));	}	Constraints.add(desc, AllFailConstraint.class);	util.getAdmin().createTable(desc);	Table table = util.getConnection().getTable(tableName);	Put put = new Put(row1);	byte[] qualifier = new byte[0];	put.addColumn(dummy, qualifier, "fail".getBytes());	
doing put in table 

desc.addFamily(new HColumnDescriptor(family));	}	Constraints.add(desc, CheckWasRunConstraint.class);	Constraints.disable(desc);	util.getAdmin().createTable(desc);	Table table = util.getConnection().getTable(tableName);	try {	Put put = new Put(row1);	byte[] qualifier = new byte[0];	put.addColumn(dummy, qualifier, "pass".getBytes());	
doing put in table 

========================= hbase sample_2168 =========================

protected void runOneIteration() {	Action actionOne = PolicyBasedChaosMonkey.selectRandomItem(actionsOne);	Action actionTwo = PolicyBasedChaosMonkey.selectRandomItem(actionsTwo);	Future fOne = executor.submit(new ActionRunner(actionOne));	Future fTwo = executor.submit(new ActionRunner(actionTwo));	try {	fOne.get();	fTwo.get();	} catch (InterruptedException e) {	
exception occurred during performing action 

protected void runOneIteration() {	Action actionOne = PolicyBasedChaosMonkey.selectRandomItem(actionsOne);	Action actionTwo = PolicyBasedChaosMonkey.selectRandomItem(actionsTwo);	Future fOne = executor.submit(new ActionRunner(actionOne));	Future fTwo = executor.submit(new ActionRunner(actionTwo));	try {	fOne.get();	fTwo.get();	} catch (InterruptedException e) {	} catch (ExecutionException ex) {	
exception occurred during performing action 

========================= hbase sample_3283 =========================

public void perform() throws Exception {	
performing action restart region server holding meta 

public void perform() throws Exception {	ServerName server = cluster.getServerHoldingMeta();	if (server == null) {	
no server is holding hbase meta right now 

========================= hbase sample_3329 =========================

HTableDescriptor htd = new HTableDescriptor(tableName);	htd.addFamily(new HColumnDescriptor(FAMILYNAME));	admin.createTable(htd);	HTU.waitUntilNoRegionsInTransition(60000);	HRegionInfo hri = new HRegionInfo(htd.getTableName(),  Bytes.toBytes("A"), Bytes.toBytes("B"), false, System.currentTimeMillis(), 2);	HRegionFileSystem regionFs = HRegionFileSystem.createRegionOnFileSystem(conf, fs, FSUtils.getTableDir(rootDir, hri.getTable()), hri);	Path regionDir = regionFs.getRegionDir();	try {	HRegionFileSystem.loadRegionInfoFileContent(fs, regionDir);	} catch (IOException e) {	
caught expected ioe due missing regioninfo file due skipping region open 

htd.addFamily(new HColumnDescriptor(FAMILYNAME));	admin.createTable(htd);	HTU.waitUntilNoRegionsInTransition(60000);	HRegionInfo hri = new HRegionInfo(htd.getTableName(),  Bytes.toBytes("A"), Bytes.toBytes("B"), false, System.currentTimeMillis(), 2);	HRegionFileSystem regionFs = HRegionFileSystem.createRegionOnFileSystem(conf, fs, FSUtils.getTableDir(rootDir, hri.getTable()), hri);	Path regionDir = regionFs.getRegionDir();	try {	HRegionFileSystem.loadRegionInfoFileContent(fs, regionDir);	} catch (IOException e) {	List<HRegionInfo> regions = admin.getTableRegions(tableName);	
regions 

========================= hbase sample_1601 =========================

hasMore = scanner.next(curVals);	for (Cell kv : curVals) {	if (CellUtil.matchingQualifier(kv, qualifier)) {	sumResult += Bytes.toInt(kv.getValueArray(), kv.getValueOffset());	}	}	} while (hasMore);	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

========================= hbase sample_1251 =========================

public void regionClose(final SnapshotRegionManifest.Builder region) throws IOException {	if (fs.exists(snapshotDir)) {	SnapshotRegionManifest manifest = region.build();	FSDataOutputStream stream = fs.create(getRegionManifestPath(snapshotDir, manifest));	try {	manifest.writeTo(stream);	} finally {	stream.close();	}	} else {	
can t write manifest without parent dir maybe it has been deleted by master 

========================= hbase sample_2187 =========================

private void warmUpConnectionCache(Connection connection, TableName tn) throws IOException {	try (RegionLocator locator = connection.getRegionLocator(tn)) {	
warmed up region location cache for got 

========================= hbase sample_1178 =========================

public boolean start() throws IOException {	if (!compactingMemStore.hasImmutableSegments()) {	return false;	}	versionedList = compactingMemStore.getImmutableSegments();	
starting in memory compaction of 

if (!isInterrupted.get()) {	result = createSubstitution(nextStep);	}	if (!isInterrupted.get()) {	if (resultSwapped = compactingMemStore.swapCompactedSegments( versionedList, result, merge)) {	strategy.updateStats(result);	compactingMemStore.updateLowestUnflushedSequenceIdInWAL(true);	}	}	} catch (IOException e) {	
interrupting the memstore in memory compaction for store 

========================= hbase sample_2611 =========================

public String getStoragePolicyName(Path path) {	try {	Object blockStoragePolicySpi = ReflectionUtils.invokeMethod(this.fs, "getStoragePolicy", path);	return (String) ReflectionUtils.invokeMethod(blockStoragePolicySpi, "getName");	} catch (Exception e) {	if (LOG.isTraceEnabled()) {	
failed to get policy directly 

BlockStoragePolicy[] policies = dfs.getStoragePolicies();	for (BlockStoragePolicy policy : policies) {	if (policy.getId() == storagePolicyId) {	return policy.getName();	}	}	}	}	}	} catch (Throwable e) {	
failed to get block storage policy of 

private FileSystem maybeWrapFileSystem(FileSystem base, Configuration conf) {	try {	Class<?> clazz = conf.getClass("hbase.fs.wrapper", null);	if (clazz != null) {	return (FileSystem) clazz.getConstructor(FileSystem.class, Configuration.class) .newInstance(base, conf);	}	} catch (Exception e) {	
failed to wrap filesystem 

static boolean addLocationsOrderInterceptor(Configuration conf, final ReorderBlocks lrb) {	if (!conf.getBoolean("hbase.filesystem.reorder.blocks", true)) {	
addlocationsorderinterceptor configured to false 

static boolean addLocationsOrderInterceptor(Configuration conf, final ReorderBlocks lrb) {	if (!conf.getBoolean("hbase.filesystem.reorder.blocks", true)) {	return false;	}	FileSystem fs;	try {	fs = FileSystem.get(conf);	} catch (IOException e) {	
can t get the file system from the conf 

if (!conf.getBoolean("hbase.filesystem.reorder.blocks", true)) {	return false;	}	FileSystem fs;	try {	fs = FileSystem.get(conf);	} catch (IOException e) {	return false;	}	if (!(fs instanceof DistributedFileSystem)) {	
the file system is not a distributedfilesystem skipping on block location reordering 

fs = FileSystem.get(conf);	} catch (IOException e) {	return false;	}	if (!(fs instanceof DistributedFileSystem)) {	return false;	}	DistributedFileSystem dfs = (DistributedFileSystem) fs;	DFSClient dfsc = dfs.getClient();	if (dfsc == null) {	
the distributedfilesystem does not contain a dfsclient can t add the location block reordering interceptor continuing but this is unexpected 

return false;	}	try {	Field nf = DFSClient.class.getDeclaredField("namenode");	nf.setAccessible(true);	Field modifiersField = Field.class.getDeclaredField("modifiers");	modifiersField.setAccessible(true);	modifiersField.setInt(nf, nf.getModifiers() & ~Modifier.FINAL);	ClientProtocol namenode = (ClientProtocol) nf.get(dfsc);	if (namenode == null) {	
the dfsclient is not linked to a namenode can t add the location block reordering interceptor continuing but this is unexpected 

nf.setAccessible(true);	Field modifiersField = Field.class.getDeclaredField("modifiers");	modifiersField.setAccessible(true);	modifiersField.setInt(nf, nf.getModifiers() & ~Modifier.FINAL);	ClientProtocol namenode = (ClientProtocol) nf.get(dfsc);	if (namenode == null) {	return false;	}	ClientProtocol cp1 = createReorderingProxy(namenode, lrb, conf);	nf.set(dfsc, cp1);	
added intercepting call to namenode getblocklocations so can do block reordering using class 

Field modifiersField = Field.class.getDeclaredField("modifiers");	modifiersField.setAccessible(true);	modifiersField.setInt(nf, nf.getModifiers() & ~Modifier.FINAL);	ClientProtocol namenode = (ClientProtocol) nf.get(dfsc);	if (namenode == null) {	return false;	}	ClientProtocol cp1 = createReorderingProxy(namenode, lrb, conf);	nf.set(dfsc, cp1);	} catch (NoSuchFieldException e) {	
can t modify the dfsclient namenode field to add the location reorder 

modifiersField.setInt(nf, nf.getModifiers() & ~Modifier.FINAL);	ClientProtocol namenode = (ClientProtocol) nf.get(dfsc);	if (namenode == null) {	return false;	}	ClientProtocol cp1 = createReorderingProxy(namenode, lrb, conf);	nf.set(dfsc, cp1);	} catch (NoSuchFieldException e) {	return false;	} catch (IllegalAccessException e) {	
can t modify the dfsclient namenode field to add the location reorder 

public void reorderBlocks(Configuration conf, LocatedBlocks lbs, String src) throws IOException {	ServerName sn = AbstractFSWALProvider.getServerNameFromWALDirectoryName(conf, src);	if (sn == null) {	return;	}	String hostName = sn.getHostname();	if (LOG.isTraceEnabled()) {	
is an wal file so reordering blocks last hostname will be 

========================= hbase sample_2996 =========================

public void testReportForDutyWithMasterChange() throws Exception {	cluster.getConfiguration().setInt(HConstants.MASTER_PORT, HBaseTestingUtility.randomFreePort());	boolean tablesOnMaster = LoadBalancer.isTablesOnMaster(testUtil.getConfiguration());	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MINTOSTART, tablesOnMaster? 2: 1);	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MAXTOSTART, tablesOnMaster? 2: 1);	master = cluster.addMaster();	rs = cluster.addRegionServer();	
starting master 

boolean tablesOnMaster = LoadBalancer.isTablesOnMaster(testUtil.getConfiguration());	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MINTOSTART, tablesOnMaster? 2: 1);	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MAXTOSTART, tablesOnMaster? 2: 1);	master = cluster.addMaster();	rs = cluster.addRegionServer();	master.start();	rs.start();	waitForClusterOnline(master);	cluster.getConfiguration().set(HConstants.REGION_SERVER_IMPL, MyRegionServer.class.getName());	rs2 = cluster.addRegionServer();	
starting region server 

waitForClusterOnline(master);	cluster.getConfiguration().set(HConstants.REGION_SERVER_IMPL, MyRegionServer.class.getName());	rs2 = cluster.addRegionServer();	rs2.start();	waitForSecondRsStarted();	master.getMaster().stop("Stopping master");	cluster.getConfiguration().setInt(HConstants.MASTER_PORT, HBaseTestingUtility.randomFreePort());	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MINTOSTART, tablesOnMaster? 3: 2);	cluster.getConfiguration().setInt(ServerManager.WAIT_ON_REGIONSERVERS_MAXTOSTART, tablesOnMaster? 3: 2);	backupMaster = cluster.addMaster();	
starting new master 

private void waitForClusterOnline(MasterThread master) throws InterruptedException {	while (true) {	if (master.getMaster().isInitialized()) {	break;	}	Thread.sleep(SLEEP_INTERVAL);	
waiting for master to come online 

private void waitForSecondRsStarted() throws InterruptedException {	while (true) {	if (((MyRegionServer) rs2.getRegionServer()).getRpcStubCreatedFlag() == true) {	break;	}	Thread.sleep(SLEEP_INTERVAL);	
waiting rs to be started 

ServerName newSn = super.getMasterAddressTracker().getMasterAddress(true);	if (newSn != null && !newSn.equals(sn)) {	masterChanged = true;	break;	}	try {	Thread.sleep(SLEEP_INTERVAL);	} catch (InterruptedException e) {	return null;	}	
waiting for master switch over 

========================= hbase sample_1713 =========================

public List<Path> abortWriters() {	List<Path> paths = new ArrayList<>();	for (StoreFileWriter writer : writers()) {	try {	if (writer != null) {	paths.add(writer.getPath());	writer.close();	}	} catch (Exception ex) {	
failed to close the writer after an unfinished compaction 

========================= hbase sample_2580 =========================

public void setClusterDown() throws KeeperException {	try {	ZKUtil.deleteNode(watcher, watcher.znodePaths.clusterStateZNode);	} catch(KeeperException.NoNodeException nne) {	
attempted to set cluster as down but already down cluster state node not found 

========================= hbase sample_731 =========================

long heapOverhead = hmc.getActive().heapSize();	int totalLen = 0;	for (int i = 0; i < keys.length; i++) {	long timestamp = System.currentTimeMillis();	Threads.sleep(1);	byte[] row = Bytes.toBytes(keys[i]);	byte[] val = Bytes.toBytes(keys[i] + i);	KeyValue kv = new KeyValue(row, fam, qf, timestamp, val);	totalLen += kv.getLength();	hmc.add(kv, null);	
added kv timestamp 

long size = hmc.getActive().keySize();	long heapOverhead = hmc.getActive().heapSize();	int totalLen = 0;	for (int i = 0; i < keys.length; i++) {	long timestamp = System.currentTimeMillis();	Threads.sleep(1);	byte[] row = Bytes.toBytes(keys[i]);	KeyValue kv = new KeyValue(row, fam, qf, timestamp, val);	totalLen += kv.getLength();	hmc.add(kv, null);	
added kv timestamp 

========================= hbase sample_1656 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3112 =========================

}	table.put(putb);	HRegion hr1 = (HRegion) util.getRSForFirstRegionInTable(TEST_TABLE) .getRegionByEncodedName(admin.getTableRegions(TEST_TABLE).get(0).getEncodedName());	hr1.refreshStoreFiles(true);	for (HStore store : hr1.getStores()) {	store.closeAndArchiveCompactedFiles();	}	try {	hr1.compact(false);	} catch (IOException e) {	
got an exception during compaction 

========================= hbase sample_1590 =========================

this.conf = new CompoundConfiguration() .add(confParam) .addBytesMap(region.getTableDescriptor().getValues()) .addStringMap(family.getConfiguration()) .addBytesMap(family.getValues());	this.blocksize = family.getBlocksize();	String policyName = family.getStoragePolicy();	if (null == policyName) {	policyName = this.conf.get(BLOCK_STORAGE_POLICY_KEY, DEFAULT_BLOCK_STORAGE_POLICY);	}	this.fs.setStoragePolicy(family.getNameAsString(), policyName.trim());	this.dataBlockEncoder = new HFileDataBlockEncoderImpl(family.getDataBlockEncoding());	this.comparator = region.getCellComparator();	long timeToPurgeDeletes = Math.max(conf.getLong("hbase.hstore.time.to.purge.deletes", 0), 0);	
time to purge deletes set to ms in store 

}	String className;	switch (inMemoryCompaction) {	case NONE: className = DefaultMemStore.class.getName();	this.memstore = ReflectionUtils.newInstance(DefaultMemStore.class, new Object[] { conf, this.comparator });	break;	default: Class<? extends CompactingMemStore> clz = conf.getClass(MEMSTORE_CLASS_NAME, CompactingMemStore.class, CompactingMemStore.class);	className = clz.getName();	this.memstore = ReflectionUtils.newInstance(clz, new Object[] { conf, this.comparator, this, this.getHRegion().getRegionServicesForStores(), inMemoryCompaction });	}	
memstore class name is 

default: Class<? extends CompactingMemStore> clz = conf.getClass(MEMSTORE_CLASS_NAME, CompactingMemStore.class, CompactingMemStore.class);	className = clz.getName();	this.memstore = ReflectionUtils.newInstance(clz, new Object[] { conf, this.comparator, this, this.getHRegion().getRegionServicesForStores(), inMemoryCompaction });	}	this.offPeakHours = OffPeakHours.getInstance(conf);	createCacheConf(family);	this.verifyBulkLoads = conf.getBoolean("hbase.hstore.bulkload.verify", false);	this.blockingFileCount = conf.getInt(BLOCKING_STOREFILES_KEY, DEFAULT_BLOCKING_STOREFILE_COUNT);	this.compactionCheckMultiplier = conf.getInt( COMPACTCHECKER_INTERVAL_MULTIPLIER_KEY, DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER);	if (this.compactionCheckMultiplier <= 0) {	
compaction check period multiplier must be positive setting default 

ArrayList<HStoreFile> results = new ArrayList<>(files.size());	IOException ioe = null;	try {	for (int i = 0; i < totalValidStoreFile; i++) {	try {	HStoreFile storeFile = completionService.take().get();	if (storeFile != null) {	long length = storeFile.getReader().length();	this.storeSize += length;	this.totalUncompressedBytes += storeFile.getReader().getTotalUncompressedBytes();	
loaded 

storeFileOpenerThreadPool.shutdownNow();	}	if (ioe != null) {	boolean evictOnClose = cacheConf != null? cacheConf.shouldEvictOnClose(): true;	for (HStoreFile file : results) {	try {	if (file != null) {	file.closeStoreFile(evictOnClose);	}	} catch (IOException e) {	
could not close store file 

for (HStoreFile sf : compactedFiles) {	compactedFilesSet.put(sf.getFileInfo(), sf);	}	Set<StoreFileInfo> newFilesSet = new HashSet<StoreFileInfo>(newFiles);	newFilesSet = Sets.difference(newFilesSet, compactedFilesSet.keySet());	Set<StoreFileInfo> toBeAddedFiles = Sets.difference(newFilesSet, currentFilesSet.keySet());	Set<StoreFileInfo> toBeRemovedFiles = Sets.difference(currentFilesSet.keySet(), newFilesSet);	if (toBeAddedFiles.isEmpty() && toBeRemovedFiles.isEmpty()) {	return;	}	
refreshing store files for region files to add files to remove 

public void assertBulkLoadHFileOk(Path srcPath) throws IOException {	HFile.Reader reader  = null;	try {	
validating hfile at for inclusion in store region 

Preconditions.checkState(lk.isPresent(), "Last key can not be null");	byte[] lastKey =  CellUtil.cloneRow(lk.get());	if (LOG.isDebugEnabled()) {	LOG.debug("HFile bounds: first=" + Bytes.toStringBinary(firstKey.get()) + " last=" + Bytes.toStringBinary(lastKey));	LOG.debug("Region bounds: first=" + Bytes.toStringBinary(getRegionInfo().getStartKey()) + " last=" + Bytes.toStringBinary(getRegionInfo().getEndKey()));	}	if (!this.getRegionInfo().containsRange(firstKey.get(), lastKey)) {	throw new WrongRegionException( "Bulk load file " + srcPath.toString() + " does not fit inside region " + this.getRegionInfo().getRegionNameAsString());	}	if(reader.length() > conf.getLong(HConstants.HREGION_MAX_FILESIZE, HConstants.DEFAULT_MAX_FILE_SIZE)) {	
trying to bulk load hfile with size bytes can be problematic as it may lead to oversplitting 

LOG.debug("HFile bounds: first=" + Bytes.toStringBinary(firstKey.get()) + " last=" + Bytes.toStringBinary(lastKey));	LOG.debug("Region bounds: first=" + Bytes.toStringBinary(getRegionInfo().getStartKey()) + " last=" + Bytes.toStringBinary(getRegionInfo().getEndKey()));	}	if (!this.getRegionInfo().containsRange(firstKey.get(), lastKey)) {	throw new WrongRegionException( "Bulk load file " + srcPath.toString() + " does not fit inside region " + this.getRegionInfo().getRegionNameAsString());	}	if(reader.length() > conf.getLong(HConstants.HREGION_MAX_FILESIZE, HConstants.DEFAULT_MAX_FILE_SIZE)) {	}	if (verifyBulkLoads) {	long verificationStartTime = EnvironmentEdgeManager.currentTime();	
full verification started for bulk load hfile 

if (prevCell != null) {	if (comparator.compareRows(prevCell, cell) > 0) {	throw new InvalidHFileException("Previous row is greater than" + " current row: path=" + srcPath + " previous=" + CellUtil.getCellKeyAsString(prevCell) + " current=" + CellUtil.getCellKeyAsString(cell));	}	if (CellComparator.getInstance().compareFamilies(prevCell, cell) != 0) {	throw new InvalidHFileException("Previous key had different" + " family compared to current key: path=" + srcPath + " previous=" + Bytes.toStringBinary(prevCell.getFamilyArray(), prevCell.getFamilyOffset(), prevCell.getFamilyLength()) + " current=" + Bytes.toStringBinary(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength()));	}	}	prevCell = cell;	} while (scanner.next());	
full verification complete for bulk load hfile took ms 

public Path bulkLoadHFile(byte[] family, String srcPathStr, Path dstPath) throws IOException {	Path srcPath = new Path(srcPathStr);	try {	fs.commitStoreFile(srcPath, dstPath);	} finally {	if (this.getCoprocessorHost() != null) {	this.getCoprocessorHost().postCommitStoreFile(family, srcPath, dstPath);	}	}	
loaded hfile into store as updating store file list 

Path srcPath = new Path(srcPathStr);	try {	fs.commitStoreFile(srcPath, dstPath);	} finally {	if (this.getCoprocessorHost() != null) {	this.getCoprocessorHost().postCommitStoreFile(family, srcPath, dstPath);	}	}	HStoreFile sf = createStoreFileAndReader(dstPath);	bulkLoadHFile(sf);	
successfully loaded store file into store new location 

private void bulkLoadHFile(HStoreFile sf) throws IOException {	StoreFileReader r = sf.getReader();	this.storeSize += r.length();	this.totalUncompressedBytes += r.getTotalUncompressedBytes();	this.lock.writeLock().lock();	try {	this.storeEngine.getStoreFileManager().insertNewFiles(Lists.newArrayList(sf));	} finally {	this.lock.writeLock().unlock();	}	
loaded hfile into store 

}	} catch (ExecutionException e) {	if (ioe == null) ioe = new IOException(e.getCause());	}	}	} finally {	storeFileCloserThreadPool.shutdownNow();	}	if (ioe != null) throw ioe;	}	
closed 

public void replayCompactionMarker(CompactionDescriptor compaction, boolean pickCompactionFiles, boolean removeFiles) throws IOException {	
completing compaction from the wal marker 

for (HStoreFile sf : this.getStorefiles()) {	compactionOutputs.remove(sf.getPath().getName());	}	for (String compactionOutput : compactionOutputs) {	StoreFileInfo storeFileInfo = fs.getStoreFileInfo(getColumnFamilyName(), compactionOutput);	HStoreFile storeFile = createStoreFileAndReader(storeFileInfo);	outputStoreFiles.add(storeFile);	}	}	if (!inputStoreFiles.isEmpty() || !outputStoreFiles.isEmpty()) {	
replaying compaction marker replacing input files with output files 

public boolean shouldPerformMajorCompaction() throws IOException {	for (HStoreFile sf : this.storeEngine.getStoreFileManager().getStorefiles()) {	if (sf.getReader() == null) {	
storefile has null reader 

addToCompactingFiles(selectedFiles);	this.forceMajor = this.forceMajor && !request.isMajor();	request.setPriority((priority != Store.NO_PRIORITY) ? priority : getCompactPriority());	request.setDescription(getRegionInfo().getRegionNameAsString(), getColumnFamilyName());	request.setTracker(tracker);	}	} finally {	this.lock.readLock().unlock();	}	if (LOG.isDebugEnabled()) {	
initiating major minor compaction all files 

private void removeUnneededFiles() throws IOException {	if (!conf.getBoolean("hbase.store.delete.expired.storefile", true)) return;	if (getColumnFamilyDescriptor().getMinVersions() > 0) {	
skipping expired store file removal due to min version being 

} finally {	this.lock.readLock().unlock();	}	if (CollectionUtils.isEmpty(delSfs)) {	return;	}	Collection<HStoreFile> newFiles = Collections.emptyList();	writeCompactionWalRecord(delSfs, newFiles);	replaceStoreFiles(delSfs, newFiles);	completeCompaction(delSfs);	
completed removal of unnecessary expired file s in of total size for store is 

private void validateStoreFile(Path path) throws IOException {	HStoreFile storeFile = null;	try {	storeFile = createStoreFileAndReader(path);	} catch (IOException e) {	
failed to open store file keeping it in tmp location 

protected void completeCompaction(Collection<HStoreFile> compactedFiles) throws IOException {	this.storeSize = 0L;	this.totalUncompressedBytes = 0L;	for (HStoreFile hsf : this.storeEngine.getStoreFileManager().getStorefiles()) {	StoreFileReader r = hsf.getReader();	if (r == null) {	
storefile has a null reader 

public boolean canSplit() {	this.lock.readLock().lock();	try {	boolean result = !hasReferences();	if (!result) {	
not splittable has references 

public Optional<byte[]> getSplitPoint() {	this.lock.readLock().lock();	try {	assert !this.getRegionInfo().isMetaRegion();	if (hasReferences()) {	
not splittable has references 

public Optional<byte[]> getSplitPoint() {	this.lock.readLock().lock();	try {	assert !this.getRegionInfo().isMetaRegion();	if (hasReferences()) {	return Optional.empty();	}	return this.storeEngine.getStoreFileManager().getSplitPoint();	} catch(IOException e) {	
failed getting store size for 

private LongStream getStoreFileAgeStream() {	return this.storeEngine.getStoreFileManager().getStorefiles().stream().filter(sf -> {	if (sf.getReader() == null) {	
storefile has a null reader 

private long getStorefilesSize(Predicate<HStoreFile> predicate) {	return this.storeEngine.getStoreFileManager().getStorefiles().stream().filter(sf -> {	if (sf.getReader() == null) {	
storefile has a null reader 

private long getStoreFileFieldSize(ToLongFunction<StoreFileReader> f) {	return this.storeEngine.getStoreFileManager().getStorefiles().stream().filter(sf -> {	if (sf.getReader() == null) {	
storefile has a null reader 

public int getCompactPriority() {	int priority = this.storeEngine.getStoreFileManager().getStoreCompactionPriority();	if (priority == PRIORITY_USER) {	
compaction priority is user despite there being no user compaction 

if (CollectionUtils.isEmpty(this.tempFiles)) {	return false;	}	List<HStoreFile> storeFiles = new ArrayList<>(this.tempFiles.size());	for (Path storeFilePath : tempFiles) {	try {	HStoreFile sf = HStore.this.commitFile(storeFilePath, cacheFlushSeqNum, status);	outputFileSize += sf.getReader().length();	storeFiles.add(sf);	} catch (IOException ex) {	
failed to commit store file 

try {	HStoreFile sf = HStore.this.commitFile(storeFilePath, cacheFlushSeqNum, status);	outputFileSize += sf.getReader().length();	storeFiles.add(sf);	} catch (IOException ex) {	for (HStoreFile sf : storeFiles) {	Path pathToDelete = sf.getPath();	try {	sf.deleteStoreFile();	} catch (IOException deleteEx) {	
failed to delete store file we committed halting 

public synchronized void closeAndArchiveCompactedFiles() throws IOException {	archiveLock.lock();	try {	lock.readLock().lock();	Collection<HStoreFile> copyCompactedfiles = null;	try {	Collection<HStoreFile> compactedfiles = this.getStoreEngine().getStoreFileManager().getCompactedfiles();	if (CollectionUtils.isNotEmpty(compactedfiles)) {	copyCompactedfiles = new ArrayList<>(compactedfiles);	} else {	
no compacted files to archive 

private void removeCompactedfiles(Collection<HStoreFile> compactedfiles) throws IOException {	final List<HStoreFile> filesToRemove = new ArrayList<>(compactedfiles.size());	for (final HStoreFile file : compactedfiles) {	synchronized (file) {	try {	StoreFileReader r = file.getReader();	if (r == null) {	
the file was closed but still not archived 

final List<HStoreFile> filesToRemove = new ArrayList<>(compactedfiles.size());	for (final HStoreFile file : compactedfiles) {	synchronized (file) {	try {	StoreFileReader r = file.getReader();	if (r == null) {	filesToRemove.add(file);	continue;	}	if (file.isCompactedAway() && !file.isReferencedInReads()) {	
closing and archiving the file 

StoreFileReader r = file.getReader();	if (r == null) {	filesToRemove.add(file);	continue;	}	if (file.isCompactedAway() && !file.isReferencedInReads()) {	r.close(true);	filesToRemove.add(file);	}	} catch (Exception e) {	
exception while trying to close the compacted store file 

if (file.isCompactedAway() && !file.isReferencedInReads()) {	r.close(true);	filesToRemove.add(file);	}	} catch (Exception e) {	}	}	}	if (this.isPrimaryReplicaStore()) {	if (!filesToRemove.isEmpty()) {	
moving the files to archive 

private void clearCompactedfiles(List<HStoreFile> filesToRemove) throws IOException {	
clearing the compacted file from this store 

========================= hbase sample_2646 =========================

protected void runTestOnTable(Table table) throws IOException {	Job job = null;	try {	
before map reduce startup 

protected void runTestOnTable(Table table) throws IOException {	Job job = null;	try {	job = new Job(table.getConfiguration(), "process column contents");	job.setNumReduceTasks(1);	Scan scan = new Scan();	scan.addFamily(INPUT_FAMILY);	TableMapReduceUtil.initTableMapperJob( table.getName().getNameAsString(), scan, ProcessContentsMapper.class, ImmutableBytesWritable.class, Put.class, job);	TableMapReduceUtil.initTableReducerJob( table.getName().getNameAsString(), IdentityTableReducer.class, job);	FileOutputFormat.setOutputPath(job, new Path("test"));	
started 

Job job = null;	try {	job = new Job(table.getConfiguration(), "process column contents");	job.setNumReduceTasks(1);	Scan scan = new Scan();	scan.addFamily(INPUT_FAMILY);	TableMapReduceUtil.initTableMapperJob( table.getName().getNameAsString(), scan, ProcessContentsMapper.class, ImmutableBytesWritable.class, Put.class, job);	TableMapReduceUtil.initTableReducerJob( table.getName().getNameAsString(), IdentityTableReducer.class, job);	FileOutputFormat.setOutputPath(job, new Path("test"));	assertTrue(job.waitForCompletion(true));	
after map reduce completion 

========================= hbase sample_3406 =========================

static void createPresplitTable(TableName tableName, SplitAlgorithm splitAlgo, String[] columnFamilies, Configuration conf) throws IOException, InterruptedException {	final int splitCount = conf.getInt("split.count", 0);	Preconditions.checkArgument(splitCount > 1, "Split count must be > 1");	Preconditions.checkArgument(columnFamilies.length > 0, "Must specify at least one column family. ");	
creating table with column families presplitting to regions 

builder.addColumnFamily(ColumnFamilyDescriptorBuilder.of(cf));	}	try (Connection connection = ConnectionFactory.createConnection(conf)) {	Admin admin = connection.getAdmin();	try {	Preconditions.checkArgument(!admin.tableExists(tableName), "Table already exists: " + tableName);	admin.createTable(builder.build(), splitAlgo.split(splitCount));	} finally {	admin.close();	}	
table created waiting for regions to show online in meta 

try {	Preconditions.checkArgument(!admin.tableExists(tableName), "Table already exists: " + tableName);	admin.createTable(builder.build(), splitAlgo.split(splitCount));	} finally {	admin.close();	}	if (!conf.getBoolean("split.verify", true)) {	int onlineRegions = 0;	while (onlineRegions < splitCount) {	onlineRegions = MetaTableAccessor.getRegionCount(connection, tableName);	
of regions online 

}	if (!conf.getBoolean("split.verify", true)) {	int onlineRegions = 0;	while (onlineRegions < splitCount) {	onlineRegions = MetaTableAccessor.getRegionCount(connection, tableName);	if (onlineRegions < splitCount) {	Thread.sleep(10 * 1000);	}	}	}	
finished creating table with regions 

Path tableDir = FSUtils.getTableDir(hbDir, tableName);	Path splitFile = new Path(tableDir, "_balancedSplit");	FileSystem fs = FileSystem.get(conf);	LinkedList<Pair<byte[], byte[]>> tmpRegionSet = null;	try (Table table = connection.getTable(tableName)) {	tmpRegionSet = getSplits(connection, tableName, splitAlgo);	}	LinkedList<Pair<byte[], byte[]>> outstanding = Lists.newLinkedList();	int splitCount = 0;	final int origCount = tmpRegionSet.size();	
bucketing regions by regionserver 

TreeMap<ServerName, LinkedList<Pair<byte[], byte[]>>> daughterRegions = Maps.newTreeMap();	try (RegionLocator regionLocator = connection.getRegionLocator(tableName)) {	for (Pair<byte[], byte[]> dr : tmpRegionSet) {	ServerName rsLocation = regionLocator.getRegionLocation(dr.getSecond()).getServerName();	if (!daughterRegions.containsKey(rsLocation)) {	LinkedList<Pair<byte[], byte[]>> entry = Lists.newLinkedList();	daughterRegions.put(rsLocation, entry);	}	daughterRegions.get(rsLocation).add(dr);	}	
done with bucketing split time 

}	daughterRegions.get(rsLocation).add(dr);	}	long startTime = System.currentTimeMillis();	byte[] rawData = readFile(fs, splitFile);	FSDataOutputStream splitOut = fs.create(splitFile);	try {	splitOut.write(rawData);	try {	while (!daughterRegions.isEmpty()) {	
rs have regions to splt 

if (rsSizes.containsKey(sn)) {	rsSizes.put(sn, rsSizes.get(sn) + 1);	} else {	rsSizes.put(sn, 1);	}	}	for (Map.Entry<ServerName, LinkedList<Pair<byte[], byte[]>>> daughterRegion : daughterRegions.entrySet()) {	Pair<byte[], byte[]> dr = null;	ServerName rsLoc = daughterRegion.getKey();	LinkedList<Pair<byte[], byte[]>> regionList = daughterRegion.getValue();	
finding a region on 

for (Map.Entry<ServerName, LinkedList<Pair<byte[], byte[]>>> daughterRegion : daughterRegions.entrySet()) {	Pair<byte[], byte[]> dr = null;	ServerName rsLoc = daughterRegion.getKey();	LinkedList<Pair<byte[], byte[]>> regionList = daughterRegion.getValue();	while (!regionList.isEmpty()) {	dr = regionList.pop();	byte[] split = dr.getSecond();	HRegionLocation regionLoc = regionLocator.getRegionLocation(split);	ServerName newRs = regionLoc.getServerName();	if (newRs.compareTo(rsLoc) != 0) {	
region with moved to relocating 

LinkedList<Pair<byte[], byte[]>> entry = Lists.newLinkedList();	daughterRegions.put(newRs, entry);	}	daughterRegions.get(newRs).add(dr);	dr = null;	continue;	}	byte[] sk = regionLoc.getRegionInfo().getStartKey();	if (sk.length != 0) {	if (Bytes.equals(split, sk)) {	
region already split on skipping this region 

byte[] start = dr.getFirst();	Preconditions.checkArgument(Bytes.equals(start, sk), splitAlgo .rowToStr(start) + " != " + splitAlgo.rowToStr(sk));	}	break;	}	if (regionList.isEmpty()) {	daughterRegions.remove(rsLoc);	}	if (dr == null) continue;	byte[] split = dr.getSecond();	
splitting at 

if (dr == null) continue;	byte[] split = dr.getSecond();	try (Admin admin = connection.getAdmin()) {	admin.split(tableName, split);	}	LinkedList<Pair<byte[], byte[]>> finished = Lists.newLinkedList();	LinkedList<Pair<byte[], byte[]>> local_finished = Lists.newLinkedList();	if (conf.getBoolean("split.verify", true)) {	outstanding.addLast(dr);	while (outstanding.size() >= MAX_OUTSTANDING) {	
wait for outstanding splits 

LinkedList<Pair<byte[], byte[]>> local_finished = Lists.newLinkedList();	if (conf.getBoolean("split.verify", true)) {	outstanding.addLast(dr);	while (outstanding.size() >= MAX_OUTSTANDING) {	local_finished = splitScan(outstanding, connection, tableName, splitAlgo);	if (local_finished.isEmpty()) {	Thread.sleep(30 * 1000);	} else {	finished.addAll(local_finished);	outstanding.removeAll(local_finished);	
outstanding splits finished 

splitOut.writeChars("- " + splitAlgo.rowToStr(region.getFirst()) + " " + splitAlgo.rowToStr(region.getSecond()) + "\n");	splitCount++;	if (splitCount % 10 == 0) {	long tDiff = (System.currentTimeMillis() - startTime) LOG.debug("STATUS UPDATE: " + splitCount + " / " + origCount + ". Avg Time / Split = " + org.apache.hadoop.util.StringUtils.formatTime(tDiff));	}	}	}	}	if (conf.getBoolean("split.verify", true)) {	while (!outstanding.isEmpty()) {	
finally wait for outstanding splits 

while (!outstanding.isEmpty()) {	LinkedList<Pair<byte[], byte[]>> finished = splitScan(outstanding, connection, tableName, splitAlgo);	if (finished.isEmpty()) {	Thread.sleep(30 * 1000);	} else {	outstanding.removeAll(finished);	for (Pair<byte[], byte[]> region : finished) {	splitOut.writeChars("- " + splitAlgo.rowToStr(region.getFirst()) + " " + splitAlgo.rowToStr(region.getSecond()) + "\n");	splitCount++;	}	
finally outstanding splits finished 

Thread.sleep(30 * 1000);	} else {	outstanding.removeAll(finished);	for (Pair<byte[], byte[]> region : finished) {	splitOut.writeChars("- " + splitAlgo.rowToStr(region.getFirst()) + " " + splitAlgo.rowToStr(region.getSecond()) + "\n");	splitCount++;	}	}	}	}	
all regions have been successfully split 

if (!refFound) {	check.remove(hri);	}	}	if (check.isEmpty()) {	finished.add(region);	} else {	physicalSplitting.add(region);	}	} catch (NoServerForRegionException nsfre) {	
no server exception thrown for 

if (check.isEmpty()) {	finished.add(region);	} else {	physicalSplitting.add(region);	}	} catch (NoServerForRegionException nsfre) {	physicalSplitting.add(region);	((ClusterConnection)connection).clearRegionCache();	}	}	
split scan finished split wait reference wait 

static LinkedList<Pair<byte[], byte[]>> getSplits(final Connection connection, TableName tableName, SplitAlgorithm splitAlgo) throws IOException {	Pair<Path, Path> tableDirAndSplitFile = getTableDirAndSplitFile(connection.getConfiguration(), tableName);	Path tableDir = tableDirAndSplitFile.getFirst();	Path splitFile = tableDirAndSplitFile.getSecond();	FileSystem fs = tableDir.getFileSystem(connection.getConfiguration());	Set<Pair<String, String>> daughterRegions = Sets.newHashSet();	if (!fs.exists(splitFile)) {	
no file calculating splits 

try (RegionLocator regionLocator = connection.getRegionLocator(tableName)) {	tmp = regionLocator.getStartEndKeys();	}	Preconditions.checkArgument(tmp.getFirst().length == tmp.getSecond().length, "Start and End rows should be equivalent");	for (int i = 0; i < tmp.getFirst().length; ++i) {	byte[] start = tmp.getFirst()[i], end = tmp.getSecond()[i];	if (start.length == 0) start = splitAlgo.firstRow();	if (end.length == 0) end = splitAlgo.lastRow();	rows.add(Pair.newPair(start, end));	}	
table has regions that will be split 

if (end.length == 0) end = splitAlgo.lastRow();	rows.add(Pair.newPair(start, end));	}	Path tmpFile = new Path(tableDir, "_balancedSplit_prepare");	FSDataOutputStream tmpOut = fs.create(tmpFile);	for (Pair<byte[], byte[]> r : rows) {	byte[] splitPoint = splitAlgo.split(r.getFirst(), r.getSecond());	String startStr = splitAlgo.rowToStr(r.getFirst());	String splitStr = splitAlgo.rowToStr(splitPoint);	daughterRegions.add(Pair.newPair(startStr, splitStr));	
will split at 

for (Pair<byte[], byte[]> r : rows) {	byte[] splitPoint = splitAlgo.split(r.getFirst(), r.getSecond());	String startStr = splitAlgo.rowToStr(r.getFirst());	String splitStr = splitAlgo.rowToStr(splitPoint);	daughterRegions.add(Pair.newPair(startStr, splitStr));	tmpOut.writeChars("+ " + startStr + splitAlgo.separator() + splitStr + "\n");	}	tmpOut.close();	fs.rename(tmpFile, splitFile);	} else {	
balancedsplit file found replay log to restore state 

tmpIn.close();	for (String line : sb.toString().split("\n")) {	String[] cmd = line.split(splitAlgo.separator());	Preconditions.checkArgument(3 == cmd.length);	byte[] start = splitAlgo.strToRow(cmd[1]);	String startStr = splitAlgo.rowToStr(start);	byte[] splitPoint = splitAlgo.strToRow(cmd[2]);	String splitStr = splitAlgo.rowToStr(splitPoint);	Pair<String, String> r = Pair.newPair(startStr, splitStr);	if (cmd[0].equals("+")) {	
adding 

String[] cmd = line.split(splitAlgo.separator());	Preconditions.checkArgument(3 == cmd.length);	byte[] start = splitAlgo.strToRow(cmd[1]);	String startStr = splitAlgo.rowToStr(start);	byte[] splitPoint = splitAlgo.strToRow(cmd[2]);	String splitStr = splitAlgo.rowToStr(splitPoint);	Pair<String, String> r = Pair.newPair(startStr, splitStr);	if (cmd[0].equals("+")) {	daughterRegions.add(r);	} else {	
removing 

String splitStr = splitAlgo.rowToStr(splitPoint);	Pair<String, String> r = Pair.newPair(startStr, splitStr);	if (cmd[0].equals("+")) {	daughterRegions.add(r);	} else {	Preconditions.checkArgument(cmd[0].equals("-"), "Unknown option: " + cmd[0]);	Preconditions.checkState(daughterRegions.contains(r), "Missing row: " + r);	daughterRegions.remove(r);	}	}	
done reading regions left 

========================= hbase sample_2217 =========================

float newMemstoreSize;	float newBlockCacheSize;	if (prevTuneDirection == StepDirection.NEUTRAL && newTuneDirection != StepDirection.NEUTRAL && rollingStatsForTunerSteps.getDeviation() < TUNER_STEP_EPS) {	step = maximumStepSize;	} else if ((newTuneDirection == StepDirection.INCREASE_MEMSTORE_SIZE && decayingTunerStepSizeSum < 0) || (newTuneDirection == StepDirection.INCREASE_BLOCK_CACHE_SIZE && decayingTunerStepSizeSum > 0)) {	if (!offheapMemstore && step != minimumStepSize) {	step = step / 2.00f;	}	}	if (step < minimumStepSize) {	
tuner step size is too low we will not perform any tuning this time 

========================= hbase sample_2647 =========================

boolean authenticate = true;	String passwordFile = null;	String accessFile = null;	System.setProperty("java.rmi.server.randomIDs", "true");	String rmiSSLValue = System.getProperty("com.sun.management.jmxremote.ssl", "false");	rmiSSL = Boolean.parseBoolean(rmiSSLValue);	String authenticateValue = System.getProperty("com.sun.management.jmxremote.authenticate", "false");	authenticate = Boolean.parseBoolean(authenticateValue);	passwordFile = System.getProperty("com.sun.management.jmxremote.password.file");	accessFile = System.getProperty("com.sun.management.jmxremote.access.file");	
rmissl authenticate passwordfile accessfile 

MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();	JMXServiceURL serviceUrl = buildJMXServiceURL(rmiRegistryPort, rmiConnectorPort);	try {	synchronized(JMXListener.class) {	if (JMX_CS != null) {	throw new RuntimeException("Started by another thread?");	}	JMX_CS = JMXConnectorServerFactory.newJMXConnectorServer(serviceUrl, jmxEnv, mbs);	JMX_CS.start();	}	
connectorserver started 

JMXServiceURL serviceUrl = buildJMXServiceURL(rmiRegistryPort, rmiConnectorPort);	try {	synchronized(JMXListener.class) {	if (JMX_CS != null) {	throw new RuntimeException("Started by another thread?");	}	JMX_CS = JMXConnectorServerFactory.newJMXConnectorServer(serviceUrl, jmxEnv, mbs);	JMX_CS.start();	}	} catch (IOException e) {	
fail to start connector server 

public void stopConnectorServer() throws IOException {	synchronized (JMXListener.class) {	if (JMX_CS != null) {	JMX_CS.stop();	
connectorserver stopped 

public void start(CoprocessorEnvironment env) throws IOException {	int rmiRegistryPort = -1;	int rmiConnectorPort = -1;	Configuration conf = env.getConfiguration();	if (env instanceof MasterCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("master" + RMI_REGISTRY_PORT_CONF_KEY, defMasterRMIRegistryPort);	rmiConnectorPort = conf.getInt("master" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	
master rmiregistryport master rmiconnectorport 

public void start(CoprocessorEnvironment env) throws IOException {	int rmiRegistryPort = -1;	int rmiConnectorPort = -1;	Configuration conf = env.getConfiguration();	if (env instanceof MasterCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("master" + RMI_REGISTRY_PORT_CONF_KEY, defMasterRMIRegistryPort);	rmiConnectorPort = conf.getInt("master" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	} else if (env instanceof RegionServerCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("regionserver" + RMI_REGISTRY_PORT_CONF_KEY, defRegionserverRMIRegistryPort);	rmiConnectorPort = conf.getInt("regionserver" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	
regionserver rmiregistryport regionserver rmiconnectorport 

int rmiRegistryPort = -1;	int rmiConnectorPort = -1;	Configuration conf = env.getConfiguration();	if (env instanceof MasterCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("master" + RMI_REGISTRY_PORT_CONF_KEY, defMasterRMIRegistryPort);	rmiConnectorPort = conf.getInt("master" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	} else if (env instanceof RegionServerCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("regionserver" + RMI_REGISTRY_PORT_CONF_KEY, defRegionserverRMIRegistryPort);	rmiConnectorPort = conf.getInt("regionserver" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	} else if (env instanceof RegionCoprocessorEnvironment) {	
jmxlistener should not be loaded in region environment 

rmiRegistryPort = conf.getInt("master" + RMI_REGISTRY_PORT_CONF_KEY, defMasterRMIRegistryPort);	rmiConnectorPort = conf.getInt("master" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	} else if (env instanceof RegionServerCoprocessorEnvironment) {	rmiRegistryPort = conf.getInt("regionserver" + RMI_REGISTRY_PORT_CONF_KEY, defRegionserverRMIRegistryPort);	rmiConnectorPort = conf.getInt("regionserver" + RMI_CONNECTOR_PORT_CONF_KEY, rmiRegistryPort);	} else if (env instanceof RegionCoprocessorEnvironment) {	return;	}	synchronized(JMXListener.class) {	if (JMX_CS != null) {	
jmxlistener has been started at registry port 

========================= hbase sample_2997 =========================

public void close() {	if (connection != null) {	try {	connection.close();	} catch (Exception ex) {	
could not close the connection 

public boolean verifyResultAgainstDataGenerator(Result result, boolean verifyValues, boolean verifyCfAndColumnIntegrity) {	String rowKeyStr = Bytes.toString(result.getRow());	if (result.isEmpty()) {	
error checking data for key no data returned 

String rowKeyStr = Bytes.toString(result.getRow());	if (result.isEmpty()) {	printLocations(result);	return false;	}	if (!verifyValues && !verifyCfAndColumnIntegrity) {	return true;	}	byte[][] expectedCfs = dataGenerator.getColumnFamilies();	if (verifyCfAndColumnIntegrity && (expectedCfs.length != result.getMap().size())) {	
error checking data for key bad family count 

}	byte[][] expectedCfs = dataGenerator.getColumnFamilies();	if (verifyCfAndColumnIntegrity && (expectedCfs.length != result.getMap().size())) {	printLocations(result);	return false;	}	for (byte[] cf : result.getMap().keySet()) {	String cfStr = Bytes.toString(cf);	Map<byte[], byte[]> columnValues = result.getFamilyMap(cf);	if (columnValues == null) {	
error checking data for key no data for family 

for (byte[] cf : result.getMap().keySet()) {	String cfStr = Bytes.toString(cf);	Map<byte[], byte[]> columnValues = result.getFamilyMap(cf);	if (columnValues == null) {	printLocations(result);	return false;	}	Map<String, MutationType> mutateInfo = null;	if (verifyCfAndColumnIntegrity || verifyValues) {	if (!columnValues.containsKey(MUTATE_INFO)) {	
error checking data for key column family column value is not found 

long cfHash = Arrays.hashCode(cf);	byte[] mutateInfoValue = columnValues.remove(MUTATE_INFO);	mutateInfo = parseMutateInfo(mutateInfoValue);	for (Map.Entry<String, MutationType> mutate: mutateInfo.entrySet()) {	if (mutate.getValue() == MutationType.DELETE) {	byte[] column = Bytes.toBytes(mutate.getKey());	long columnHash = Arrays.hashCode(column);	long hashCode = cfHash + columnHash;	if (hashCode % 2 == 0) {	if (columnValues.containsKey(column)) {	
error checking data for key column family column should be deleted 

if (columnValues.containsKey(column)) {	printLocations(result);	return false;	}	byte[] hashCodeBytes = Bytes.toBytes(hashCode);	columnValues.put(column, hashCodeBytes);	}	}	}	if (!columnValues.containsKey(INCREMENT)) {	
error checking data for key column family column value is not found 

if (!columnValues.containsKey(INCREMENT)) {	printLocations(result);	return false;	}	long currentValue = Bytes.toLong(columnValues.remove(INCREMENT));	if (verifyValues) {	long amount = mutateInfo.isEmpty() ? 0 : cfHash;	long originalValue = Arrays.hashCode(result.getRow());	long extra = currentValue - originalValue;	if (extra != 0 && (amount == 0 || extra % amount != 0)) {	
error checking data for key column family column increment extra amount 

long currentValue = Bytes.toLong(columnValues.remove(INCREMENT));	if (verifyValues) {	long amount = mutateInfo.isEmpty() ? 0 : cfHash;	long originalValue = Arrays.hashCode(result.getRow());	long extra = currentValue - originalValue;	if (extra != 0 && (amount == 0 || extra % amount != 0)) {	printLocations(result);	return false;	}	if (amount != 0 && extra != amount) {	
warning checking data for key column family column increment incremented times 

}	}	if (verifyCfAndColumnIntegrity && !dataGenerator.verify(result.getRow(), cf, columnValues.keySet())) {	String colsStr = "";	for (byte[] col : columnValues.keySet()) {	if (colsStr.length() > 0) {	colsStr += ", ";	}	colsStr += "[" + Bytes.toString(col) + "]";	}	
error checking data for key bad columns for family 

int n = 1;	while (true) {	int newOffset = offset - hashCodeBytes.length;	if (newOffset < 0 || !Bytes.equals(hashCodeBytes, 0, hashCodeBytes.length, bytes, newOffset, hashCodeBytes.length)) {	break;	}	offset = newOffset;	n++;	}	if (n > 1) {	
warning checking data for key column family column appended times 

}	byte[] dest = new byte[offset];	System.arraycopy(bytes, 0, dest, 0, offset);	bytes = dest;	}	} else if (hashCode % 2 == 0) {	mutationVerified = Bytes.equals(bytes, hashCodeBytes);	verificationNeeded = false;	}	if (!mutationVerified) {	
error checking data for key mutation checking failed for column family column mutation hashcode verificationneeded 

} else if (hashCode % 2 == 0) {	mutationVerified = Bytes.equals(bytes, hashCodeBytes);	verificationNeeded = false;	}	if (!mutationVerified) {	printLocations(result);	return false;	}	}	if (verificationNeeded && !dataGenerator.verify(result.getRow(), cf, kv.getKey(), bytes)) {	
error checking data for key column family column mutation value of length 

private void printLocations(Result r) {	RegionLocations rl = null;	if (r == null) {	
failed for null result 

private void printLocations(Result r) {	RegionLocations rl = null;	if (r == null) {	return;	}	
failed for stale 

RegionLocations rl = null;	if (r == null) {	return;	}	if (r.getRow() == null) {	return;	}	try {	rl = ((ClusterConnection)connection).locateRegion(tableName, r.getRow(), true, true);	} catch (IOException e) {	
couldn t get locations for row 

}	if (r.getRow() == null) {	return;	}	try {	rl = ((ClusterConnection)connection).locateRegion(tableName, r.getRow(), true, true);	} catch (IOException e) {	}	HRegionLocation locations[] = rl.getRegionLocations();	for (HRegionLocation h : locations) {	
location 

========================= hbase sample_1342 =========================

private void doRun() {	if (stopped.get()) {	executor.stop();	return;	}	if (LOG.isTraceEnabled()) {	
dorun called 

if (LOG.isTraceEnabled()) {	}	Collection<MetricRegistry> registries = MetricRegistries.global().getMetricRegistries();	for (MetricRegistry registry : registries) {	MetricRegistryInfo info = registry.getMetricRegistryInfo();	if (info.isExistingSource()) {	continue;	}	if (!registeredSources.containsKey(info)) {	if (LOG.isDebugEnabled()) {	
registering adapter for the metricregistry 

Collection<MetricRegistry> registries = MetricRegistries.global().getMetricRegistries();	for (MetricRegistry registry : registries) {	MetricRegistryInfo info = registry.getMetricRegistryInfo();	if (info.isExistingSource()) {	continue;	}	if (!registeredSources.containsKey(info)) {	if (LOG.isDebugEnabled()) {	}	MetricsSourceAdapter adapter = new MetricsSourceAdapter(registry);	
registering 

registeredSources.put(info, adapter);	}	}	boolean removed = false;	for (Iterator<Entry<MetricRegistryInfo, MetricsSourceAdapter>> it = registeredSources.entrySet().iterator(); it.hasNext();) {	Entry<MetricRegistryInfo, MetricsSourceAdapter> entry = it.next();	MetricRegistryInfo info = entry.getKey();	Optional<MetricRegistry> found = MetricRegistries.global().get(info);	if (!found.isPresent()) {	if (LOG.isDebugEnabled()) {	
removing adapter for the metricregistry 

========================= hbase sample_675 =========================

static Optional<byte[]> getFileSplitPoint(HStoreFile file, CellComparator comparator) throws IOException {	StoreFileReader reader = file.getReader();	if (reader == null) {	
storefile reader is null cannot get split point 

}	Optional<Cell> optionalMidKey = reader.midKey();	if (!optionalMidKey.isPresent()) {	return Optional.empty();	}	Cell midKey = optionalMidKey.get();	Cell firstKey = reader.getFirstKey().get();	Cell lastKey = reader.getLastKey().get();	if (comparator.compareRows(midKey, firstKey) == 0 || comparator.compareRows(midKey, lastKey) == 0) {	if (LOG.isDebugEnabled()) {	
cannot split because midkey is the same as first or last row 

========================= hbase sample_2581 =========================

public void addFront(Iterator<Procedure> procedureIterator) {	schedLock();	try {	int count = 0;	while (procedureIterator.hasNext()) {	Procedure procedure = procedureIterator.next();	if (LOG.isTraceEnabled()) {	
wake 

public Procedure poll(final long nanos) {	schedLock();	try {	if (!running) {	
the scheduler is not running 

protected void wakeProcedure(final Procedure procedure) {	
wake 

========================= hbase sample_1207 =========================

public void postCreateTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableDescriptor desc, RegionInfo[] regions) throws IOException {	if (this.start > 0) {	long time = System.currentTimeMillis() - start;	
create table took 

public void testMasterObserver() throws IOException {	MetricRegistryInfo info = MetricsCoprocessor.createRegistryInfoForMasterCoprocessor( CustomMasterObserver.class.getName());	Optional<MetricRegistry> registry =  MetricRegistries.global().get(info);	assertTrue(registry.isPresent());	Optional<Metric> metric = registry.get().get("CreateTable");	assertTrue(metric.isPresent());	try (Connection connection = ConnectionFactory.createConnection(UTIL.getConfiguration());	Admin admin = connection.getAdmin()) {	Timer createTableTimer = (Timer)metric.get();	long prevCount = createTableTimer.getHistogram().getCount();	
creating table 

public void testRegionServerObserver() throws IOException {	try (Connection connection = ConnectionFactory.createConnection(UTIL.getConfiguration());	Admin admin = connection.getAdmin()) {	
rolling wals 

========================= hbase sample_1529 =========================

private VisibilityLabelsCache(ZKWatcher watcher, Configuration conf) throws IOException {	zkVisibilityWatcher = new ZKVisibilityLabelWatcher(watcher, this, conf);	try {	zkVisibilityWatcher.start();	} catch (KeeperException ke) {	
zookeeper initialization failed 

========================= hbase sample_2305 =========================

if (numStores <= 1) {	numStores = 1;	}	inmemoryFlushSize = memstoreFlushSize / numStores;	if (indexType == IndexType.ARRAY_MAP) {	factor = conf.getDouble(IN_MEMORY_FLUSH_THRESHOLD_FACTOR_KEY, IN_MEMORY_FLUSH_THRESHOLD_FACTOR_DEFAULT);	} else {	factor = conf.getDouble(IN_MEMORY_FLUSH_THRESHOLD_FACTOR_KEY, IN_MEMORY_FLUSH_THRESHOLD_FACTOR_DEFAULT);	}	inmemoryFlushSize *= factor;	
setting in memory flush size threshold to and immutable segments index to be of type 

public MemStoreSnapshot snapshot() {	if (!this.snapshot.isEmpty()) {	
snapshot called again without clearing previous doing nothing another ongoing flush or did we fail last attempt 

public MemStoreSnapshot snapshot() {	if (!this.snapshot.isEmpty()) {	} else {	if (LOG.isDebugEnabled()) {	
flushing to disk region store 

protected void checkActiveSize() {	if (shouldFlushInMemory()) {	InMemoryFlushRunnable runnable = new InMemoryFlushRunnable();	if (LOG.isTraceEnabled()) {	
dispatching the memstore in memory flush for store 

private void pushPipelineToSnapshot() {	int iterationsCnt = 0;	boolean done = false;	while (!done) {	iterationsCnt++;	VersionedSegmentsList segments = pipeline.getVersionedList();	pushToSnapshot(segments.getStoreSegments());	done = pipeline.swap(segments, null, false, false);	if (iterationsCnt>2) {	
multiple unsuccessful attempts to push the compaction pipeline to snapshot while flushing to disk 

public void run() {	try {	flushInMemory();	} catch (IOException e) {	
unable to run memstore compaction region store 

========================= hbase sample_2610 =========================

for (int i = 0; i < numWriters; i++) {	AtomicityWriter writer = new AtomicityWriter(ctx, rows, FAMILIES, sharedPool);	writers.add(writer);	ctx.addThread(writer);	}	ctx.addThread(new RepeatingTestThread(ctx) {	public void doAnAction() throws Exception {	try {	admin.flush(TABLE_NAME);	} catch (IOException ioe) {	
ignoring exception while flushing 

}	List<AtomicScanReader> scanners = Lists.newArrayList();	for (int i = 0; i < numScanners; i++) {	AtomicScanReader scanner = new AtomicScanReader(ctx, FAMILIES, sharedPool);	scanners.add(scanner);	ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	
finished test writers 

List<AtomicScanReader> scanners = Lists.newArrayList();	for (int i = 0; i < numScanners; i++) {	AtomicScanReader scanner = new AtomicScanReader(ctx, FAMILIES, sharedPool);	scanners.add(scanner);	ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	
wrote 

for (int i = 0; i < numScanners; i++) {	AtomicScanReader scanner = new AtomicScanReader(ctx, FAMILIES, sharedPool);	scanners.add(scanner);	ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	}	
readers 

AtomicScanReader scanner = new AtomicScanReader(ctx, FAMILIES, sharedPool);	scanners.add(scanner);	ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	}	for (AtomicGetReader reader : getters) {	
read 

scanners.add(scanner);	ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	}	for (AtomicGetReader reader : getters) {	}	
scanners 

ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	}	for (AtomicGetReader reader : getters) {	}	for (AtomicScanReader scanner : scanners) {	
scanned 

ctx.addThread(scanner);	}	ctx.startThreads();	ctx.waitFor(millisToRun);	ctx.stop();	for (AtomicityWriter writer : writers) {	}	for (AtomicGetReader reader : getters) {	}	for (AtomicScanReader scanner : scanners) {	
verified rows 

public static void main(String[] args) {	Configuration c = HBaseConfiguration.create();	int status;	try {	AcidGuaranteesTestTool test = new AcidGuaranteesTestTool();	status = ToolRunner.run(c, test, args);	} catch (Exception e) {	
exiting due to error 

========================= hbase sample_1895 =========================

boolean finished = false;	ScannerContext scannerContext = ScannerContext.newBuilder().setBatchLimit(compactionKVMax).build();	throughputController.start(compactionName);	KeyValueScanner kvs = (scanner instanceof KeyValueScanner)? (KeyValueScanner)scanner : null;	long shippedCallSizeLimit = (long) numofFilesToCompact * this.store.getColumnFamilyDescriptor().getBlocksize();	try {	try {	mobFileWriter = mobStore.createWriterInTmp(new Date(fd.latestPutTs), fd.maxKeyCount, compactionCompression, store.getRegionInfo().getStartKey(), true);	fileName = Bytes.toBytes(mobFileWriter.getPath().getName());	} catch (IOException e) {	
failed to create mob writer we will continue the compaction by writing mob cells directly in store files 

try {	try {	mobFileWriter = mobStore.createWriterInTmp(new Date(fd.latestPutTs), fd.maxKeyCount, compactionCompression, store.getRegionInfo().getStartKey(), true);	fileName = Bytes.toBytes(mobFileWriter.getPath().getName());	} catch (IOException e) {	}	if (major) {	try {	delFileWriter = mobStore.createDelFileWriterInTmp(new Date(fd.latestPutTs), fd.maxKeyCount, compactionCompression, store.getRegionInfo().getStartKey());	} catch (IOException e) {	
failed to create del writer we will continue the compaction by writing delete markers directly in store files 

if (mobCell.getValueLength() != 0) {	PrivateCellUtil.setSequenceId(mobCell, c.getSequenceId());	writer.append(mobCell);	cellsCountCompactedFromMob++;	cellsSizeCompactedFromMob += mobCell.getValueLength();	} else {	writer.append(c);	}	}	} else {	
the value format of the keyvalue is wrong its length is less than 

========================= hbase sample_3001 =========================

public void testRestartWithoutData() throws Exception {	for (int i = 0; i < 10; ++i) {	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	}	
active wals 

assertEquals(3, logs.length);	for (int i = 0; i < logs.length; ++i) {	corruptLog(logs[i], 4);	}	htu.getConfiguration().setBoolean(WALProcedureStore.EXEC_WAL_CLEANUP_ON_LOAD_CONF_KEY, false);	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	assertEquals(3, loader.getLoadedCount());	assertEquals(0, loader.getCorruptedCount());	final ArrayList<ProcedureWALFile> walFiles = procStore.getActiveLogs();	
wals 

for (int i = 0; i < logs.length; ++i) {	corruptLog(logs[i], 4);	}	htu.getConfiguration().setBoolean(WALProcedureStore.EXEC_WAL_CLEANUP_ON_LOAD_CONF_KEY, false);	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	assertEquals(3, loader.getLoadedCount());	assertEquals(0, loader.getCorruptedCount());	final ArrayList<ProcedureWALFile> walFiles = procStore.getActiveLogs();	assertEquals(4, walFiles.size());	
checking wal 

corruptLog(logs[i], 4);	}	htu.getConfiguration().setBoolean(WALProcedureStore.EXEC_WAL_CLEANUP_ON_LOAD_CONF_KEY, false);	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	assertEquals(3, loader.getLoadedCount());	assertEquals(0, loader.getCorruptedCount());	final ArrayList<ProcedureWALFile> walFiles = procStore.getActiveLogs();	assertEquals(4, walFiles.size());	assertUpdated(walFiles.get(0).getTracker(), procs, new int[]{0, 1, 2, 3}, new int[] {4, 5});	
checking wal 

}	htu.getConfiguration().setBoolean(WALProcedureStore.EXEC_WAL_CLEANUP_ON_LOAD_CONF_KEY, false);	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	assertEquals(3, loader.getLoadedCount());	assertEquals(0, loader.getCorruptedCount());	final ArrayList<ProcedureWALFile> walFiles = procStore.getActiveLogs();	assertEquals(4, walFiles.size());	assertUpdated(walFiles.get(0).getTracker(), procs, new int[]{0, 1, 2, 3}, new int[] {4, 5});	assertUpdated(walFiles.get(1).getTracker(), procs, new int[]{2, 3, 4}, new int[] {0, 1, 5});	
checking wal 

htu.getConfiguration().setBoolean(WALProcedureStore.EXEC_WAL_CLEANUP_ON_LOAD_CONF_KEY, false);	final LoadCounter loader = new LoadCounter();	storeRestart(loader);	assertEquals(3, loader.getLoadedCount());	assertEquals(0, loader.getCorruptedCount());	final ArrayList<ProcedureWALFile> walFiles = procStore.getActiveLogs();	assertEquals(4, walFiles.size());	assertUpdated(walFiles.get(0).getTracker(), procs, new int[]{0, 1, 2, 3}, new int[] {4, 5});	assertUpdated(walFiles.get(1).getTracker(), procs, new int[]{2, 3, 4}, new int[] {0, 1, 5});	assertUpdated(walFiles.get(2).getTracker(), procs, new int[]{4, 5}, new int[] {0, 1, 2, 3});	
checking global tracker 

private void verifyProcIdsOnRestart(final Set<Long> procIds) throws Exception {	
expected 

========================= hbase sample_1196 =========================

public void healthCheckerTest(String script, HealthCheckerExitStatus expectedStatus) throws Exception {	Configuration config = getConfForNodeHealthScript();	config.addResource(healthScriptFile.getName());	String location = healthScriptFile.getAbsolutePath();	long timeout = config.getLong(HConstants.HEALTH_SCRIPT_TIMEOUT, SCRIPT_TIMEOUT);	HealthChecker checker = new HealthChecker();	checker.init(location, timeout);	createScript(script, true);	HealthReport report = checker.checkHealth();	assertEquals(expectedStatus, report.getStatus());	
health status 

========================= hbase sample_2169 =========================

}	} else {	this.majorCompaction = new AtomicBoolean(false);	}	b = metadataMap.get(EXCLUDE_FROM_MINOR_COMPACTION_KEY);	this.excludeFromMinorCompaction = (b != null && Bytes.toBoolean(b));	BloomType hfileBloomType = reader.getBloomFilterType();	if (cfBloomType != BloomType.NONE) {	reader.loadBloomfilter(BlockType.GENERAL_BLOOM_META);	if (hfileBloomType != cfBloomType) {	
hfile bloom filter type for but specified in column family configuration 

this.majorCompaction = new AtomicBoolean(false);	}	b = metadataMap.get(EXCLUDE_FROM_MINOR_COMPACTION_KEY);	this.excludeFromMinorCompaction = (b != null && Bytes.toBoolean(b));	BloomType hfileBloomType = reader.getBloomFilterType();	if (cfBloomType != BloomType.NONE) {	reader.loadBloomfilter(BlockType.GENERAL_BLOOM_META);	if (hfileBloomType != cfBloomType) {	}	} else if (hfileBloomType != BloomType.NONE) {	
bloom filter turned off by cf config for 

reader.loadBloomfilter(BlockType.GENERAL_BLOOM_META);	if (hfileBloomType != cfBloomType) {	}	} else if (hfileBloomType != BloomType.NONE) {	}	reader.loadBloomfilter(BlockType.DELETE_FAMILY_BLOOM_META);	try {	byte[] data = metadataMap.get(TIMERANGE_KEY);	this.reader.timeRange = data == null ? null : TimeRangeTracker.parseFrom(data).toTimeRange();	} catch (IllegalArgumentException e) {	
error reading timestamp range data from meta proceeding without 

public void initReader() throws IOException {	if (reader == null) {	try {	open();	} catch (Exception e) {	try {	boolean evictOnClose = cacheConf != null ? cacheConf.shouldEvictOnClose() : true;	this.closeStoreFile(evictOnClose);	} catch (IOException ee) {	
failed to close reader 

========================= hbase sample_2539 =========================

protected void runOneIteration() {	if (actions.isEmpty()) {	this.stop("done");	return;	}	Action action = actions.remove(0);	try {	action.perform();	} catch (Exception ex) {	
exception occurred during performing action 

========================= hbase sample_3282 =========================

public void perform() throws Exception {	if (sleepTime > 0) {	Thread.sleep(sleepTime);	}	Admin admin = this.context.getHBaseIntegrationTestingUtility().getAdmin();	Collection<ServerName> serversList = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics().keySet();	ServerName[] servers = serversList.toArray(new ServerName[serversList.size()]);	
performing action move regions of table 

public void perform() throws Exception {	if (sleepTime > 0) {	Thread.sleep(sleepTime);	}	Admin admin = this.context.getHBaseIntegrationTestingUtility().getAdmin();	Collection<ServerName> serversList = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics().keySet();	ServerName[] servers = serversList.toArray(new ServerName[serversList.size()]);	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	
table doesn t have regions to move 

return;	}	Collections.shuffle(regions);	long start = System.currentTimeMillis();	for (HRegionInfo regionInfo:regions) {	if (context.isStopping()) {	return;	}	try {	String destServerName = servers[RandomUtils.nextInt(0, servers.length)].getServerName();	
moving to 

Collections.shuffle(regions);	long start = System.currentTimeMillis();	for (HRegionInfo regionInfo:regions) {	if (context.isStopping()) {	return;	}	try {	String destServerName = servers[RandomUtils.nextInt(0, servers.length)].getServerName();	admin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(destServerName));	} catch (Exception ex) {	
move failed might be caused by other chaos 

========================= hbase sample_3328 =========================

public void testRootPath() {	try {	FSUtils.validateRootPath(new Path("file: } catch (IOException e) {	
unexpected exception checking valid path 

public void testRootPath() {	try {	FSUtils.validateRootPath(new Path("file: } catch (IOException e) {	fail();	}	try {	FSUtils.validateRootPath(new Path("hdfs: } catch (IOException e) {	
unexpected exception checking valid path 

fail();	}	try {	FSUtils.validateRootPath(new Path("hdfs: } catch (IOException e) {	fail();	}	try {	FSUtils.validateRootPath(new Path("/hbase"));	fail();	} catch (IOException e) {	
got expected exception when checking invalid path 

========================= hbase sample_1315 =========================

public void testBlockStoragePolicy() throws Exception {	TEST_UTIL = new HBaseTestingUtility();	Configuration conf = TEST_UTIL.getConfiguration();	TEST_UTIL.startMiniCluster();	HTable table = (HTable) TEST_UTIL.createTable(TABLE_NAME, FAMILIES);	assertEquals("Should start with empty table", 0, TEST_UTIL.countRows(table));	HRegionFileSystem regionFs = getHRegionFS(table, conf);	String spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	String spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

public void testBlockStoragePolicy() throws Exception {	TEST_UTIL = new HBaseTestingUtility();	Configuration conf = TEST_UTIL.getConfiguration();	TEST_UTIL.startMiniCluster();	HTable table = (HTable) TEST_UTIL.createTable(TABLE_NAME, FAMILIES);	assertEquals("Should start with empty table", 0, TEST_UTIL.countRows(table));	HRegionFileSystem regionFs = getHRegionFS(table, conf);	String spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	String spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

assertEquals("HOT", spA);	assertEquals("HOT", spB);	TEST_UTIL.shutdownMiniCluster();	TEST_UTIL.getConfiguration().set(HStore.BLOCK_STORAGE_POLICY_KEY, "WARM");	TEST_UTIL.startMiniCluster();	table = (HTable) TEST_UTIL.createTable(TABLE_NAME, FAMILIES);	regionFs = getHRegionFS(table, conf);	try (Admin admin = TEST_UTIL.getConnection().getAdmin()) {	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

assertEquals("HOT", spA);	assertEquals("HOT", spB);	TEST_UTIL.shutdownMiniCluster();	TEST_UTIL.getConfiguration().set(HStore.BLOCK_STORAGE_POLICY_KEY, "WARM");	TEST_UTIL.startMiniCluster();	table = (HTable) TEST_UTIL.createTable(TABLE_NAME, FAMILIES);	regionFs = getHRegionFS(table, conf);	try (Admin admin = TEST_UTIL.getConnection().getAdmin()) {	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

try (Admin admin = TEST_UTIL.getConnection().getAdmin()) {	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	assertEquals("WARM", spA);	assertEquals("WARM", spB);	HColumnDescriptor hcdA = new HColumnDescriptor(Bytes.toString(FAMILIES[0]));	hcdA.setValue(HStore.BLOCK_STORAGE_POLICY_KEY, "ONE_SSD");	admin.modifyColumnFamily(TABLE_NAME, hcdA);	while (TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager(). getRegionStates().hasRegionsInTransition()) {	Thread.sleep(200);	
waiting on table to finish schema altering 

hcdA.setValue(HStore.BLOCK_STORAGE_POLICY_KEY, "ONE_SSD");	admin.modifyColumnFamily(TABLE_NAME, hcdA);	while (TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager(). getRegionStates().hasRegionsInTransition()) {	Thread.sleep(200);	}	HColumnDescriptor hcdB = new HColumnDescriptor(Bytes.toString(FAMILIES[1]));	hcdB.setStoragePolicy("ALL_SSD");	admin.modifyColumnFamily(TABLE_NAME, hcdB);	while (TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager().getRegionStates() .hasRegionsInTransition()) {	Thread.sleep(200);	
waiting on table to finish schema altering 

Thread.sleep(200);	}	HColumnDescriptor hcdB = new HColumnDescriptor(Bytes.toString(FAMILIES[1]));	hcdB.setStoragePolicy("ALL_SSD");	admin.modifyColumnFamily(TABLE_NAME, hcdB);	while (TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager().getRegionStates() .hasRegionsInTransition()) {	Thread.sleep(200);	}	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

Thread.sleep(200);	}	HColumnDescriptor hcdB = new HColumnDescriptor(Bytes.toString(FAMILIES[1]));	hcdB.setStoragePolicy("ALL_SSD");	admin.modifyColumnFamily(TABLE_NAME, hcdB);	while (TEST_UTIL.getMiniHBaseCluster().getMaster().getAssignmentManager().getRegionStates() .hasRegionsInTransition()) {	Thread.sleep(200);	}	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

FileStatus[] tempFiles = FSUtils.listStatus(fs, storeTempDir);	assertNull(tempFiles);	assertEquals("ONE_SSD", ((HFileSystem) regionFs.getFileSystem()).getStoragePolicyName(storeTempDir));	for (FileStatus status : storeFiles) {	assertEquals("ONE_SSD", ((HFileSystem) regionFs.getFileSystem()).getStoragePolicyName(status.getPath()));	}	regionFs.setStoragePolicy(Bytes.toString(FAMILIES[0]), "ALL_SSD");	regionFs.setStoragePolicy(Bytes.toString(FAMILIES[1]), "ONE_SSD");	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

FileStatus[] tempFiles = FSUtils.listStatus(fs, storeTempDir);	assertNull(tempFiles);	assertEquals("ONE_SSD", ((HFileSystem) regionFs.getFileSystem()).getStoragePolicyName(storeTempDir));	for (FileStatus status : storeFiles) {	assertEquals("ONE_SSD", ((HFileSystem) regionFs.getFileSystem()).getStoragePolicyName(status.getPath()));	}	regionFs.setStoragePolicy(Bytes.toString(FAMILIES[0]), "ALL_SSD");	regionFs.setStoragePolicy(Bytes.toString(FAMILIES[1]), "ONE_SSD");	spA = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[0]));	spB = regionFs.getStoragePolicyName(Bytes.toString(FAMILIES[1]));	
storage policy of cf 

public FSDataOutputStream create(Path arg0, FsPermission arg1, boolean arg2, int arg3, short arg4, long arg5, Progressable arg6) throws IOException {	
create 

public boolean mkdirs(Path arg0, FsPermission arg1) throws IOException {	
mkdirs 

public boolean rename(Path arg0, Path arg1) throws IOException {	
rename 

========================= hbase sample_1600 =========================

public void initialize() throws IOException {	
start to scan the hbase meta for the current region assignment snappshot 

if (hri == null) continue;	addAssignment(hri, hrls[i].getServerName());	addRegion(hri);	}	hri = rl.getRegionLocation(0).getRegionInfo();	byte[] favoredNodes = result.getValue(HConstants.CATALOG_FAMILY, FavoredNodeAssignmentHelper.FAVOREDNODES_QUALIFIER);	if (favoredNodes == null) return true;	ServerName[] favoredServerList = FavoredNodeAssignmentHelper.getFavoredNodesList(favoredNodes);	existingAssignmentPlan.updateFavoredNodesMap(hri, Arrays.asList(favoredServerList));	if (favoredServerList.length != FavoredNodeAssignmentHelper.FAVORED_NODES_NUM) {	
insufficient favored nodes for region fn 

existingAssignmentPlan.updateFavoredNodesMap(hri, Arrays.asList(favoredServerList));	if (favoredServerList.length != FavoredNodeAssignmentHelper.FAVORED_NODES_NUM) {	}	for (int i = 0; i < favoredServerList.length; i++) {	if (i == PRIMARY.ordinal()) addPrimaryAssignment(hri, favoredServerList[i]);	if (i == SECONDARY.ordinal()) addSecondaryAssignment(hri, favoredServerList[i]);	if (i == TERTIARY.ordinal()) addTeritiaryAssignment(hri, favoredServerList[i]);	}	return true;	} catch (RuntimeException e) {	
catche remote exception when processing 

if (i == SECONDARY.ordinal()) addSecondaryAssignment(hri, favoredServerList[i]);	if (i == TERTIARY.ordinal()) addTeritiaryAssignment(hri, favoredServerList[i]);	}	return true;	} catch (RuntimeException e) {	throw e;	}	}	};	MetaTableAccessor.fullScanRegions(connection, v);	
finished to scan the hbase meta for the current region assignment snapshot 

========================= hbase sample_2885 =========================

public void announce() {	
running 

========================= hbase sample_1250 =========================

private RestoreMetaChanges restoreHdfsRegions(final ThreadPoolExecutor exec) throws IOException {	LOG.info("starting restore table regions using snapshot=" + snapshotDesc);	Map<String, SnapshotRegionManifest> regionManifests = snapshotManifest.getRegionManifestsMap();	if (regionManifests == null) {	
nothing to restore snapshot looks empty 

}	RestoreMetaChanges metaChanges = new RestoreMetaChanges(tableDesc, parentsMap);	Set<String> regionNames = new HashSet<>(regionManifests.keySet());	RegionInfo mobRegion = MobUtils.getMobRegionInfo(snapshotManifest.getTableDescriptor() .getTableName());	List<RegionInfo> tableRegions = getTableRegions();	if (tableRegions != null) {	monitor.rethrowException();	for (RegionInfo regionInfo: tableRegions) {	String regionName = regionInfo.getEncodedName();	if (regionNames.contains(regionName)) {	
region to restore 

RegionInfo mobRegion = MobUtils.getMobRegionInfo(snapshotManifest.getTableDescriptor() .getTableName());	List<RegionInfo> tableRegions = getTableRegions();	if (tableRegions != null) {	monitor.rethrowException();	for (RegionInfo regionInfo: tableRegions) {	String regionName = regionInfo.getEncodedName();	if (regionNames.contains(regionName)) {	regionNames.remove(regionName);	metaChanges.addRegionToRestore(regionInfo);	} else {	
region to remove 

status.setStatus("Finished deleting excess regions from table.");	}	if (regionNames.size() > 0) {	List<RegionInfo> regionsToAdd = new ArrayList<>(regionNames.size());	monitor.rethrowException();	if (regionNames.contains(mobRegion.getEncodedName())) {	cloneHdfsMobRegion(regionManifests, mobRegion);	regionNames.remove(mobRegion.getEncodedName());	}	for (String regionName: regionNames) {	
region to add 

for (RegionInfo regionInfo: regionInfos) {	if (regionInfo.isSplitParent()) {	parentRegions.add(regionInfo);	} else {	regionsByName.put(regionInfo.getEncodedName(), regionInfo);	}	}	for (RegionInfo regionInfo: parentRegions) {	Pair<String, String> daughters = parentsMap.get(regionInfo.getEncodedName());	if (daughters == null) {	
skip update of unreferenced offline parent 

}	}	for (RegionInfo regionInfo: parentRegions) {	Pair<String, String> daughters = parentsMap.get(regionInfo.getEncodedName());	if (daughters == null) {	continue;	}	if (daughters.getSecond() == null) {	daughters.setSecond(daughters.getFirst());	}	
update splits parent 

if (linkPath != null) {	in = HFileLink.buildFromHFileLinkPattern(conf, linkPath).open(fs);	} else {	linkPath = new Path(new Path(HRegion.getRegionDir(snapshotManifest.getSnapshotDir(), regionInfo.getEncodedName()), familyDir.getName()), hfileName);	in = fs.open(linkPath);	}	OutputStream out = fs.create(outPath);	IOUtils.copyBytes(in, out, conf);	}	String regionName = Bytes.toString(regionsMap.get(regionInfo.getEncodedNameAsBytes()));	
restore reference to 

private List<RegionInfo> getTableRegions() throws IOException {	
get table regions 

throw new IllegalArgumentException("Restore directory cannot be a sub directory of HBase " + "root directory. RootDir: " + rootDir + ", restoreDir: " + restoreDir);	}	Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshotName, rootDir);	SnapshotDescription snapshotDesc = SnapshotDescriptionUtils.readSnapshotInfo(fs, snapshotDir);	SnapshotManifest manifest = SnapshotManifest.open(conf, fs, snapshotDir, snapshotDesc);	MonitoredTask status = TaskMonitor.get().createStatus( "Restoring  snapshot '" + snapshotName + "' to directory " + restoreDir);	ForeignExceptionDispatcher monitor = new ForeignExceptionDispatcher();	RestoreSnapshotHelper helper = new RestoreSnapshotHelper(conf, fs, manifest, manifest.getTableDescriptor(), restoreDir, monitor, status, false);	RestoreMetaChanges metaChanges = helper.restoreHdfsRegions();	if (LOG.isDebugEnabled()) {	
restored table dir 

public static void restoreSnapshotAcl(SnapshotDescription snapshot, TableName newTableName, Configuration conf) throws IOException {	if (snapshot.hasUsersAndPermissions() && snapshot.getUsersAndPermissions() != null) {	
restore snapshot acl to table snapshot table 

========================= hbase sample_2186 =========================

public static void main(String[] argv) throws IOException {	TestHFileSeek testCase = new TestHFileSeek();	MyOptions options = new MyOptions(argv);	if (options.proceed == false) {	return;	}	testCase.options = options;	for (int i = 0; i < options.trialCount; i++) {	
beginning trial 

========================= hbase sample_1495 =========================

private void cleanup() {	try {	if (fs.exists(this.restoreDir)) {	if (!fs.delete(this.restoreDir, true)) {	
delete restore directory for the snapshot failed restoredir 

private void cleanup() {	try {	if (fs.exists(this.restoreDir)) {	if (!fs.delete(this.restoreDir, true)) {	}	}	} catch (IOException ex) {	
could not delete restore directory for the snapshot restoredir 

========================= hbase sample_3017 =========================

Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();	Path tabledir = FSUtils.getTableDir(rootdir, td.getTableName());	Path parentdir = new Path(tabledir, parent.getEncodedName());	Path storedir = HStore.getStoreHomedir(tabledir, splita, td.getColumnFamilies()[0].getName());	Reference ref = Reference.createTopReference(Bytes.toBytes("ccc"));	long now = System.currentTimeMillis();	Path p = new Path(storedir, Long.toString(now) + "." + parent.getEncodedName());	FileSystem fs = this.masterServices.getMasterFileSystem().getFileSystem();	Path path = ref.write(fs, p);	assertTrue(fs.exists(path));	
created reference 

Thread.sleep(1001);	final Map<HRegionInfo, Result> splitParents = new TreeMap<>(new SplitParentFirstComparator());	splitParents.put(parent, createResult(parent, splita, splitb));	splita.setOffline(true);	splitParents.put(splita, createResult(splita, splitaa, splitab));	final Map<HRegionInfo, Result> mergedRegions = new TreeMap<>();	CatalogJanitor spy = spy(this.janitor);	doReturn(new Triple<>(10, mergedRegions, splitParents)).when(spy). getMergedRegionsAndSplitParents();	LOG.info("parent=" + parent.getShortNameToLog() + ", splita=" + splita.getShortNameToLog());	Path splitaRef = createReferences(this.masterServices, td, parent, splita, Bytes.toBytes("ccc"), false);	
created reference 

HRegionInfo parent = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("eee"));	HRegionInfo splita = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("ccc"));	HRegionInfo splitb = new HRegionInfo(td.getTableName(), Bytes.toBytes("ccc"), Bytes.toBytes("eee"));	Result parentMetaRow = createResult(parent, splita, splitb);	FileSystem fs = FileSystem.get(HTU.getConfiguration());	Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();	FSUtils.setRootDir(fs.getConf(), rootdir);	Path tabledir = FSUtils.getTableDir(rootdir, td.getTableName());	Path storedir = HStore.getStoreHomedir(tabledir, parent, td.getColumnFamilies()[0].getName());	Path storeArchive = HFileArchiveUtil.getStoreArchivePath(this.masterServices.getConfiguration(), parent, tabledir, td.getColumnFamilies()[0].getName());	
table dir 

HRegionInfo parent = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("eee"));	HRegionInfo splita = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("ccc"));	HRegionInfo splitb = new HRegionInfo(td.getTableName(), Bytes.toBytes("ccc"), Bytes.toBytes("eee"));	Result parentMetaRow = createResult(parent, splita, splitb);	FileSystem fs = FileSystem.get(HTU.getConfiguration());	Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();	FSUtils.setRootDir(fs.getConf(), rootdir);	Path tabledir = FSUtils.getTableDir(rootdir, td.getTableName());	Path storedir = HStore.getStoreHomedir(tabledir, parent, td.getColumnFamilies()[0].getName());	Path storeArchive = HFileArchiveUtil.getStoreArchivePath(this.masterServices.getConfiguration(), parent, tabledir, td.getColumnFamilies()[0].getName());	
store dir 

HRegionInfo parent = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("eee"));	HRegionInfo splita = new HRegionInfo(td.getTableName(), Bytes.toBytes("aaa"), Bytes.toBytes("ccc"));	HRegionInfo splitb = new HRegionInfo(td.getTableName(), Bytes.toBytes("ccc"), Bytes.toBytes("eee"));	Result parentMetaRow = createResult(parent, splita, splitb);	FileSystem fs = FileSystem.get(HTU.getConfiguration());	Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();	FSUtils.setRootDir(fs.getConf(), rootdir);	Path tabledir = FSUtils.getTableDir(rootdir, td.getTableName());	Path storedir = HStore.getStoreHomedir(tabledir, parent, td.getColumnFamilies()[0].getName());	Path storeArchive = HFileArchiveUtil.getStoreArchivePath(this.masterServices.getConfiguration(), parent, tabledir, td.getColumnFamilies()[0].getName());	
store archive dir 

FileSystem fs = FileSystem.get(HTU.getConfiguration());	Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();	FSUtils.setRootDir(fs.getConf(), rootdir);	Path tabledir = FSUtils.getTableDir(rootdir, td.getTableName());	Path storedir = HStore.getStoreHomedir(tabledir, parent, td.getColumnFamilies()[0].getName());	Path storeArchive = HFileArchiveUtil.getStoreArchivePath(this.masterServices.getConfiguration(), parent, tabledir, td.getColumnFamilies()[0].getName());	FileStatus[] mockFiles = addMockStoreFiles(2, this.masterServices, storedir);	FileStatus[] storeFiles = fs.listStatus(storedir);	int index = 0;	for (FileStatus file : storeFiles) {	
have store file 

FileStatus[] storeFiles = fs.listStatus(storedir);	int index = 0;	for (FileStatus file : storeFiles) {	assertEquals("Got unexpected store file", mockFiles[index].getPath(), storeFiles[index].getPath());	index++;	}	assertTrue(janitor.cleanParent(parent, parentMetaRow));	Path parentDir = new Path(tabledir, parent.getEncodedName());	ProcedureTestingUtility.waitAllProcedures(masterServices.getMasterProcedureExecutor());	assertTrue(!fs.exists(parentDir));	
finished cleanup of parent region 

private FileStatus[] addMockStoreFiles(int count, MasterServices services, Path storedir) throws IOException {	FileSystem fs = services.getMasterFileSystem().getFileSystem();	fs.mkdirs(storedir);	for (int i = 0; i < count; i++) {	Path storeFile = new Path(storedir, "_store" + i);	FSDataOutputStream dos = fs.create(storeFile, true);	dos.writeBytes("Some data: " + i);	dos.close();	}	
adding store files to the storedir 

========================= hbase sample_1883 =========================

public WALFactory(final Configuration conf, final List<WALActionsListener> listeners, final String factoryId) throws IOException {	timeoutMillis = conf.getInt("hbase.hlog.open.timeout", 300000);	logReaderClass = conf.getClass("hbase.regionserver.hlog.reader.impl", ProtobufLogReader.class, AbstractFSWALProvider.Reader.class);	this.conf = conf;	this.factoryId = factoryId;	if (conf.getBoolean("hbase.regionserver.hlog.enabled", true)) {	provider = getProvider(WAL_PROVIDER, DEFAULT_WAL_PROVIDER, listeners, null);	} else {	
running with wal disabled 

while (true) {	try {	reader = lrClass.newInstance();	reader.init(fs, path, conf, null);	return reader;	} catch (IOException e) {	if (reader != null) {	try {	reader.close();	} catch (IOException exception) {	
could not close fsdatainputstream 

while (true) {	try {	reader = lrClass.newInstance();	reader.init(fs, path, conf, null);	return reader;	} catch (IOException e) {	if (reader != null) {	try {	reader.close();	} catch (IOException exception) {	
exception details 

} catch (IOException e) {	if (reader != null) {	try {	reader.close();	} catch (IOException exception) {	}	}	String msg = e.getMessage();	if (msg != null && (msg.contains("Cannot obtain block length") || msg.contains("Could not obtain the last block") || msg .matches("Blocklist for [^ ]* has changed.*"))) {	if (++nbAttempt == 1) {	
lease should have recovered this is not expected will retry 

}	}	String msg = e.getMessage();	if (msg != null && (msg.contains("Cannot obtain block length") || msg.contains("Could not obtain the last block") || msg .matches("Blocklist for [^ ]* has changed.*"))) {	if (++nbAttempt == 1) {	}	if (reporter != null && !reporter.progress()) {	throw new InterruptedIOException("Operation is cancelled");	}	if (nbAttempt > 2 && openTimeout < EnvironmentEdgeManager.currentTime()) {	
can t open after attempts and ms for 

public static WALFactory getInstance(Configuration configuration) {	WALFactory factory = singleton.get();	if (null == factory) {	WALFactory temp = new WALFactory(configuration);	if (singleton.compareAndSet(null, temp)) {	factory = temp;	} else {	try {	temp.close();	} catch (IOException exception) {	
failed to close temporary singleton ignoring 

========================= hbase sample_2256 =========================

fail("Waited too much time for truncate");	}	ResultScanner scanner = htable2.getScanner(scan);	Result[] res = scanner.next(NB_ROWS_IN_BIG_BATCH);	scanner.close();	if (res.length != 0) {	if (res.length < lastCount) {	i--;	}	lastCount = res.length;	
still got rows 

public void testChangingNumberOfPeerRegionServers() throws IOException, InterruptedException {	
testSimplePutDelete 

htable1 = utility1.getConnection().getTable(tableName);	}	htable1.put(put);	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

========================= hbase sample_1929 =========================

public Mutation beforeMutate(long rowkeyBase, Mutation m) throws IOException {	if (!(m instanceof Delete)) {	if (userNames != null && userNames.length > 0) {	int mod = ((int) rowkeyBase % this.userNames.length);	if (((int) rowkeyBase % specialPermCellInsertionFactor) == 0) {	if (LOG.isTraceEnabled()) {	
adding special perm 

========================= hbase sample_1303 =========================

public void sendGlobalBarrierStart() throws ForeignException {	
starting procedure kicking off acquire phase on members 

public void sendGlobalBarrierComplete() {	
finished coordinator procedure removing self from list of running procedures 

public void barrierAcquiredByMember(String member) {	
member joining acquired barrier for procedure on coordinator 

public void barrierAcquiredByMember(String member) {	if (this.acquiringMembers.contains(member)) {	synchronized (joinBarrierLock) {	if (this.acquiringMembers.remove(member)) {	this.inBarrierMembers.add(member);	acquiredBarrierLatch.countDown();	}	}	
waiting on remaining members to acquire global barrier 

public void barrierAcquiredByMember(String member) {	if (this.acquiringMembers.contains(member)) {	synchronized (joinBarrierLock) {	if (this.acquiringMembers.remove(member)) {	this.inBarrierMembers.add(member);	acquiredBarrierLatch.countDown();	}	}	} else {	
member joined barrier but we weren t waiting on it to join continuing on 

public void barrierReleasedByMember(String member, byte[] dataFromMember) {	boolean removed = false;	synchronized (joinBarrierLock) {	removed = this.inBarrierMembers.remove(member);	if (removed) {	releasedBarrierLatch.countDown();	}	}	if (removed) {	
member released barrier for procedure counting down latch waiting for more 

public void barrierReleasedByMember(String member, byte[] dataFromMember) {	boolean removed = false;	synchronized (joinBarrierLock) {	removed = this.inBarrierMembers.remove(member);	if (removed) {	releasedBarrierLatch.countDown();	}	}	if (removed) {	} else {	
member released barrier for procedure but we weren t waiting on it to release 

========================= hbase sample_2485 =========================

hasMore = scanner.next(curVals);	for (Cell kv : curVals) {	if (CellUtil.matchingQualifier(kv, qualifier)) {	sumResult += Bytes.toInt(kv.getValueArray(), kv.getValueOffset());	}	}	} while (hasMore);	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	}	}	}	
returning result 

========================= hbase sample_1246 =========================

if (addr == null) {	this.hostAddress = "*Unknown*";	} else {	this.hostAddress = addr.getHostAddress();	}	this.remotePort = socket.getPort();	if (rpcServer.socketSendBufferSize != 0) {	try {	socket.setSendBufferSize(rpcServer.socketSendBufferSize);	} catch (IOException e) {	
connection unable to set socket send buffer size to 

public synchronized void close() {	disposeSasl();	data = null;	callCleanup = null;	if (!channel.isOpen()) return;	try {	socket.shutdownOutput();	} catch (Exception ignored) {	if (SimpleRpcServer.LOG.isTraceEnabled()) {	
ignored exception 

if (channel.isOpen()) {	try {	channel.close();	} catch (Exception ignored) {	}	}	try {	socket.close();	} catch (Exception ignored) {	if (SimpleRpcServer.LOG.isTraceEnabled()) {	
ignored exception 

========================= hbase sample_2893 =========================

if (rsServices != null) {	this.rsAccounting = this.rsServices.getRegionServerAccounting();	this.coprocessorHost = new RegionCoprocessorHost(this, rsServices, conf);	this.metricsRegionWrapper = new MetricsRegionWrapperImpl(this);	this.metricsRegion = new MetricsRegion(this.metricsRegionWrapper);	} else {	this.metricsRegionWrapper = null;	this.metricsRegion = null;	}	if (LOG.isDebugEnabled()) {	
instantiated 

private long initializeRegionInternals(final CancelableProgressable reporter, final MonitoredTask status) throws IOException {	if (coprocessorHost != null) {	status.setStatus("Running coprocessor pre-open hook");	coprocessorHost.preOpen();	}	if (this.getRegionInfo().getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	status.setStatus("Writing region info on filesystem");	fs.checkRegionInfoOnFilesystem();	} else {	if (LOG.isDebugEnabled()) {	
skipping creation of regioninfo file for 

} catch (ExecutionException e) {	throw new IOException(e.getCause());	} finally {	storeOpenerThreadPool.shutdownNow();	if (!allStoresOpened) {	LOG.error("Could not initialize all stores for the region=" + this);	for (HStore store : this.stores.values()) {	try {	store.close();	} catch (IOException e) {	
close store failed 

public boolean isMergeable() {	if (!isAvailable()) {	
region is not mergeable because it is closing or closed 

public boolean isMergeable() {	if (!isAvailable()) {	return false;	}	if (hasReferences()) {	
region is not mergeable because it has references 

private Map<byte[], List<HStoreFile>> doClose(boolean abort, MonitoredTask status) throws IOException {	if (isClosed()) {	
region already closed 

}	if (coprocessorHost != null) {	status.setStatus("Running coprocessor pre-close hooks");	this.coprocessorHost.preClose(abort);	}	status.setStatus("Disabling compacts and flushes for region");	boolean canFlush = true;	synchronized (writestate) {	canFlush = !writestate.readOnly;	writestate.writesEnabled = false;	
closing disabling compactions flushes 

}	status.setStatus("Disabling compacts and flushes for region");	boolean canFlush = true;	synchronized (writestate) {	canFlush = !writestate.readOnly;	writestate.writesEnabled = false;	waitForFlushesAndCompactions();	}	if (!abort && worthPreFlushing() && canFlush) {	status.setStatus("Pre-flushing region before close");	
running close preflush of 

throw (InterruptedIOException) new InterruptedIOException().initCause(e);	}	}	this.closing.set(true);	status.setStatus("Disabling writes for close");	try {	if (this.isClosed()) {	status.abort("Already got closed by another process");	return null;	}	
updates disabled for region 

}	if (!abort && canFlush) {	int failedfFlushCount = 0;	int flushCount = 0;	long tmp = 0;	long remainingSize = this.memstoreDataSize.get();	while (remainingSize > 0) {	try {	internalFlushcache(status);	if(flushCount >0) {	
running extra flush carrying snapshot 

}	}	status.setStatus("Writing region close event to WAL");	if (!abort && wal != null && getRegionServerServices() != null && !writestate.readOnly) {	writeRegionCloseMarker(wal);	}	this.closed.set(true);	if (!canFlush) {	this.decrMemStoreSize(new MemStoreSizing(memstoreDataSize.get(), getMemStoreHeapSize()));	} else if (memstoreDataSize.get() != 0) {	
memstore size is 

status.setStatus("Running coprocessor post-close hooks");	this.coprocessorHost.postClose(abort);	}	if (this.metricsRegion != null) {	this.metricsRegion.close();	}	if (this.metricsRegionWrapper != null) {	Closeables.close(this.metricsRegionWrapper, true);	}	status.markComplete("Closed");	
closed 

public void waitForFlushesAndCompactions() {	synchronized (writestate) {	if (this.writestate.readOnly) {	return;	}	boolean interrupted = false;	try {	while (writestate.compacting.get() > 0 || writestate.flushing) {	
waiting for compactions cache flush to complete for region 

synchronized (writestate) {	if (this.writestate.readOnly) {	return;	}	boolean interrupted = false;	try {	while (writestate.compacting.get() > 0 || writestate.flushing) {	try {	writestate.wait();	} catch (InterruptedException iex) {	
interrupted while waiting 

public boolean waitForFlushes(long timeout) {	synchronized (writestate) {	if (this.writestate.readOnly) {	return true;	}	if (!writestate.flushing) return true;	long start = System.currentTimeMillis();	long duration = 0;	boolean interrupted = false;	
waiting for cache flush to complete for region 

long start = System.currentTimeMillis();	long duration = 0;	boolean interrupted = false;	try {	while (writestate.flushing) {	if (timeout > 0 && duration >= timeout) break;	try {	long toWait = timeout == 0 ? 0 : (timeout - duration);	writestate.wait(toWait);	} catch (InterruptedException iex) {	
interrupted while waiting 

break;	} finally {	duration = System.currentTimeMillis() - start;	}	}	} finally {	if (interrupted) {	Thread.currentThread().interrupt();	}	}	
waited ms for flush to complete 

public boolean compact(CompactionContext compaction, HStore store, ThroughputController throughputController, User user) throws IOException {	assert compaction != null && compaction.hasSelection();	assert !compaction.getRequest().getFiles().isEmpty();	if (this.closing.get() || this.closed.get()) {	
skipping compaction on because closing closed 

assert !compaction.getRequest().getFiles().isEmpty();	if (this.closing.get() || this.closed.get()) {	store.cancelRequestedCompaction(compaction);	return false;	}	MonitoredTask status = null;	boolean requestNeedsCancellation = true;	try {	byte[] cf = Bytes.toBytes(store.getColumnFamilyName());	if (stores.get(cf) != store) {	
store on region has been re instantiated cancel this compaction request it may be caused by the roll back of split transaction 

if (writestate.writesEnabled) {	wasStateSet = true;	writestate.compacting.incrementAndGet();	} else {	String msg = "NOT compacting region " + this + ". Writes disabled.";	LOG.info(msg);	status.abort(msg);	return false;	}	}	
starting compaction on in region as an off peak compaction 

private void doAbortFlushToWAL(final WAL wal, final long flushOpSeqId, final Map<byte[], List<Path>> committedFiles) {	if (wal == null) return;	try {	FlushDescriptor desc = ProtobufUtil.toFlushDescriptor(FlushAction.ABORT_FLUSH, getRegionInfo(), flushOpSeqId, committedFiles);	WALUtil.writeFlushMarker(wal, this.getReplicationScope(), getRegionInfo(), desc, false, mvcc);	} catch (Throwable t) {	
received unexpected exception trying to write abort flush marker to wal 

private boolean writeFlushRequestMarkerToWAL(WAL wal, boolean writeFlushWalMarker) {	if (writeFlushWalMarker && wal != null && !writestate.readOnly) {	FlushDescriptor desc = ProtobufUtil.toFlushDescriptor(FlushAction.CANNOT_FLUSH, getRegionInfo(), -1, new TreeMap<>(Bytes.BYTES_COMPARATOR));	try {	WALUtil.writeFlushMarker(wal, this.getReplicationScope(), getRegionInfo(), desc, true, mvcc);	return true;	} catch (IOException e) {	
received exception while trying to write the flush request to wal 

if (wal != null) {	FlushDescriptor desc = ProtobufUtil.toFlushDescriptor(FlushAction.COMMIT_FLUSH, getRegionInfo(), flushOpSeqId, committedFiles);	WALUtil.writeFlushMarker(wal, this.getReplicationScope(), getRegionInfo(), desc, true, mvcc);	}	} catch (Throwable t) {	if (wal != null) {	try {	FlushDescriptor desc = ProtobufUtil.toFlushDescriptor(FlushAction.ABORT_FLUSH, getRegionInfo(), flushOpSeqId, committedFiles);	WALUtil.writeFlushMarker(wal, this.replicationScope, getRegionInfo(), desc, false, mvcc);	} catch (Throwable ex) {	
failed writing abort flush marker to wal 

for (byte[] family : familyCellMap.keySet()) {	if (!region.htableDescriptor.hasColumnFamily(family)) {	if (nonExistentList == null) {	nonExistentList = new ArrayList<>();	}	nonExistentList.add(family);	}	}	if (nonExistentList != null) {	for (byte[] family : nonExistentList) {	
no family for omit from reply 

public OperationStatus[] batchReplay(MutationReplay[] mutations, long replaySeqId) throws IOException {	if (!RegionReplicaUtil.isDefaultReplica(getRegionInfo()) && replaySeqId < lastReplayedOpenRegionSeqId) {	if (LOG.isTraceEnabled()) {	LOG.trace(getRegionInfo().getEncodedName() + " : " + "Skipping " + mutations.length + " mutations with replaySeqId=" + replaySeqId + " which is < than lastReplayedOpenRegionSeqId=" + lastReplayedOpenRegionSeqId);	for (MutationReplay mut : mutations) {	
skipping 

public void setReadsEnabled(boolean readsEnabled) {	if (readsEnabled && !this.writestate.readsEnabled) {	
enabling reads for region 

}	long seqid = minSeqIdForTheRegion;	FileSystem fs = this.fs.getFileSystem();	NavigableSet<Path> files = WALSplitter.getSplitEditFilesSorted(fs, regiondir);	if (LOG.isDebugEnabled()) {	LOG.debug("Found " + (files == null ? 0 : files.size()) + " recovered edits file(s) under " + regiondir);	}	if (files == null || files.isEmpty()) return seqid;	for (Path edits: files) {	if (edits == null || !fs.exists(edits)) {	
null or non existent edits file 

String msg = "Maximum sequenceid for this wal is " + maxSeqId + " and minimum sequenceid for the region is " + minSeqIdForTheRegion + ", skipped the whole file, path=" + edits;	LOG.debug(msg);	}	continue;	}	try {	seqid = Math.max(seqid, replayRecoveredEdits(edits, maxSeqIdInStores, reporter));	} catch (IOException e) {	boolean skipErrors = conf.getBoolean( HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS, conf.getBoolean( "hbase.skip.errors", HConstants.DEFAULT_HREGION_EDITS_REPLAY_SKIP_ERRORS));	if (conf.get("hbase.skip.errors") != null) {	
the property hbase skip errors has been deprecated please use instead 

if (files.size() > 0 && this.conf.getBoolean("hbase.region.archive.recovered.edits", false)) {	String fakeFamilyName = WALSplitter.getRegionDirRecoveredEditsDir(regiondir).getName();	Set<HStoreFile> fakeStoreFiles = new HashSet<>(files.size());	for (Path file: files) {	fakeStoreFiles.add( new HStoreFile(getRegionFileSystem().getFileSystem(), file, this.conf, null, null, true));	}	getRegionFileSystem().removeStoreFiles(fakeFamilyName, fakeStoreFiles);	} else {	for (Path file: files) {	if (!fs.delete(file, false)) {	
failed delete of 

replayWALCompactionMarker(compaction, false, true, Long.MAX_VALUE);	}	}	skippedEdits++;	continue;	}	if (store == null || !CellUtil.matchingFamily(cell, store.getColumnFamilyDescriptor().getName())) {	store = getStore(cell);	}	if (store == null) {	
no family for 

continue;	}	if (store == null || !CellUtil.matchingFamily(cell, store.getColumnFamilyDescriptor().getName())) {	store = getStore(cell);	}	if (store == null) {	skippedEdits++;	continue;	}	if (checkRowWithinBoundary && !rowIsInRange(this.getRegionInfo(), cell.getRowArray(), cell.getRowOffset(), cell.getRowLength())) {	
row of is not within region boundary 

private void replayFlushInStores(FlushDescriptor flush, PrepareFlushResult prepareFlushResult, boolean dropMemstoreSnapshot) throws IOException {	for (StoreFlushDescriptor storeFlush : flush.getStoreFlushesList()) {	byte[] family = storeFlush.getFamilyName().toByteArray();	HStore store = getStore(family);	if (store == null) {	
received a flush commit marker from primary but the family is not found ignoring storeflushdescriptor 

List<String> flushFiles = storeFlush.getFlushOutputList();	StoreFlushContext ctx = null;	long startTime = EnvironmentEdgeManager.currentTime();	if (prepareFlushResult == null || prepareFlushResult.storeFlushCtxs == null) {	ctx = store.createFlushContext(flush.getFlushSequenceNumber(), FlushLifeCycleTracker.DUMMY);	} else {	ctx = prepareFlushResult.storeFlushCtxs.get(family);	startTime = prepareFlushResult.startTime;	}	if (ctx == null) {	
unexpected flush commit marker received from store but no associated flush context ignoring 

private MemStoreSize dropMemStoreContentsForSeqId(long seqId, HStore store) throws IOException {	MemStoreSizing totalFreedSize = new MemStoreSizing();	this.updatesLock.writeLock().lock();	try {	long currentSeqId = mvcc.getReadPoint();	if (seqId >= currentSeqId) {	
dropping memstore contents as well since replayed flush seqid is greater than current seqid 

long currentSeqId = mvcc.getReadPoint();	if (seqId >= currentSeqId) {	if (store == null) {	for (HStore s : stores.values()) {	totalFreedSize.incMemStoreSize(doDropStoreMemStoreContentsForSeqId(s, currentSeqId));	}	} else {	totalFreedSize.incMemStoreSize(doDropStoreMemStoreContentsForSeqId(store, currentSeqId));	}	} else {	
not dropping memstore contents since replayed flush seqid is smaller than current seqid 

private void replayWALFlushCannotFlushMarker(FlushDescriptor flush, long replaySeqId) {	synchronized (writestate) {	if (this.lastReplayedOpenRegionSeqId > replaySeqId) {	
skipping replaying flush event because its sequence id is smaller than this regions lastreplayedopenregionseqid of 

protected boolean refreshStoreFiles(boolean force) throws IOException {	if (!force && ServerRegionReplicaUtil.isDefaultReplica(this.getRegionInfo())) {	return false;	}	if (LOG.isDebugEnabled()) {	
refreshing store files to see whether we can free up memstore 

private static boolean isZeroLengthThenDelete(final FileSystem fs, final Path p) throws IOException {	FileStatus stat = fs.getFileStatus(p);	if (stat.getLen() > 0) {	return false;	}	
file is zero length deleting 

if (reachDeadlineFirst) {	throw new TimeoutIOException(message);	} else {	throw new IOException(message);	}	}	rowLockContext.setThreadName(Thread.currentThread().getName());	success = true;	return result;	} catch (InterruptedException ie) {	
thread interrupted waiting for lock on row 

rowLockContext.setThreadName(Thread.currentThread().getName());	success = true;	return result;	} catch (InterruptedException ie) {	InterruptedIOException iie = new InterruptedIOException();	iie.initCause(ie);	TraceUtil.addTimelineAnnotation("Interrupted exception getting row lock");	Thread.currentThread().interrupt();	throw iie;	} catch (Error error) {	
error to get row lock for cause 

store.assertBulkLoadHFileOk(new Path(path));	} catch (WrongRegionException wre) {	failures.add(p);	} catch (IOException ioe) {	ioes.add(ioe);	}	}	}	if (ioes.size() != 0) {	IOException e = MultipleIOException.createIOException(ioes);	
there were one or more io errors when checking if the bulk load is ok 

}	if (ioes.size() != 0) {	IOException e = MultipleIOException.createIOException(ioes);	throw e;	}	if (failures.size() != 0) {	StringBuilder list = new StringBuilder();	for (Pair<byte[], String> p : failures) {	list.append("\n").append(Bytes.toString(p.getFirst())).append(" : ") .append(p.getSecond());	}	
there was a recoverable bulk load failure likely due to a split these family hfile pairs were not loaded 

}	List<Pair<Path, Path>> lst = familyWithFinalPath.get(familyName);	try {	String finalPath = path;	if (bulkLoadListener != null) {	finalPath = bulkLoadListener.prepareBulkLoad(familyName, path, copyFile);	}	Pair<Path, Path> pair = store.preBulkLoadHFile(finalPath, seqId);	lst.add(pair);	} catch (IOException ioe) {	
there was a partial failure due to io when attempting to load 

if (bulkLoadListener != null) {	finalPath = bulkLoadListener.prepareBulkLoad(familyName, path, copyFile);	}	Pair<Path, Path> pair = store.preBulkLoadHFile(finalPath, seqId);	lst.add(pair);	} catch (IOException ioe) {	if (bulkLoadListener != null) {	try {	bulkLoadListener.failedBulkLoad(familyName, path);	} catch (Exception ex) {	
error while calling failedbulkload for family with path 

for (Pair<Path, Path> p : entry.getValue()) {	String path = p.getFirst().toString();	Path commitedStoreFile = p.getSecond();	HStore store = getStore(familyName);	try {	store.bulkLoadHFile(familyName, path, commitedStoreFile);	try {	FileSystem fs = commitedStoreFile.getFileSystem(baseConf);	storeFilesSizes.put(commitedStoreFile.getName(), fs.getFileStatus(commitedStoreFile) .getLen());	} catch (IOException e) {	
failed to find the size of hfile 

storeFiles.get(familyName).add(commitedStoreFile);	} else {	List<Path> storeFileNames = new ArrayList<>();	storeFileNames.add(commitedStoreFile);	storeFiles.put(familyName, storeFileNames);	}	if (bulkLoadListener != null) {	bulkLoadListener.doneBulkLoad(familyName, path);	}	} catch (IOException ioe) {	
there was a partial failure due to io when attempting to load 

storeFiles.put(familyName, storeFileNames);	}	if (bulkLoadListener != null) {	bulkLoadListener.doneBulkLoad(familyName, path);	}	} catch (IOException ioe) {	if (bulkLoadListener != null) {	try {	bulkLoadListener.failedBulkLoad(familyName, path);	} catch (Exception ex) {	
error while calling failedbulkload for family with path 

long afterTime = rpcCall.get().disconnectSince();	if (afterTime >= 0) {	throw new CallerDisconnectedException( "Aborting on region " + getRegionInfo().getRegionNameAsString() + ", call " + this + " after " + afterTime + " ms, since " + "caller disconnected");	}	}	Cell current = this.storeHeap.peek();	boolean shouldStop = shouldStop(current);	boolean hasFilterRow = this.filter != null && this.filter.hasFilterRow();	if (hasFilterRow) {	if (LOG.isTraceEnabled()) {	
filter hasfilterrow is true which prevents partial results from being formed changing scope of limits that may create partials 

public static HRegion openHRegion(final Configuration conf, final FileSystem fs, final Path rootDir, final Path tableDir, final RegionInfo info, final TableDescriptor htd, final WAL wal, final RegionServerServices rsServices, final CancelableProgressable reporter) throws IOException {	if (info == null) throw new NullPointerException("Passed region info is null");	if (LOG.isDebugEnabled()) {	
opening region 

public static void warmupHRegion(final RegionInfo info, final TableDescriptor htd, final WAL wal, final Configuration conf, final RegionServerServices rsServices, final CancelableProgressable reporter) throws IOException {	if (info == null) throw new NullPointerException("Passed region info is null");	if (LOG.isDebugEnabled()) {	
hregion warming up region 

private void doProcessRowWithTimeout(final RowProcessor<?,?> processor, final long now, final HRegion region, final List<Mutation> mutations, final WALEdit walEdit, final long timeout) throws IOException {	if (timeout < 0) {	try {	processor.process(now, region, mutations, walEdit);	} catch (IOException e) {	String row = processor.getRowsToLock().isEmpty() ? "" : " on row(s):" + Bytes.toStringBinary(processor.getRowsToLock().iterator().next()) + "...";	
rowprocessor throws exception 

}	return;	}	FutureTask<Void> task = new FutureTask<>(new Callable<Void>() {	public Void call() throws IOException {	try {	processor.process(now, region, mutations, walEdit);	return null;	} catch (IOException e) {	String row = processor.getRowsToLock().isEmpty() ? "" : " on row(s):" + Bytes.toStringBinary(processor.getRowsToLock().iterator().next()) + "...";	
rowprocessor throws exception 

String row = processor.getRowsToLock().isEmpty() ? "" : " on row(s):" + Bytes.toStringBinary(processor.getRowsToLock().iterator().next()) + "...";	throw e;	}	}	});	rowProcessorExecutor.execute(task);	try {	task.get(timeout, TimeUnit.MILLISECONDS);	} catch (TimeoutException te) {	String row = processor.getRowsToLock().isEmpty() ? "" : " on row(s):" + Bytes.toStringBinary(processor.getRowsToLock().iterator().next()) + "...";	
rowprocessor timeout ms 

public boolean registerService(com.google.protobuf.Service instance) {	com.google.protobuf.Descriptors.ServiceDescriptor serviceDesc = instance.getDescriptorForType();	String serviceName = CoprocessorRpcUtils.getServiceName(serviceDesc);	if (coprocessorServiceHandlers.containsKey(serviceName)) {	
coprocessor service already registered rejecting request from 

public byte[] checkSplit() {	if (this.getRegionInfo().isMetaRegion() || TableName.NAMESPACE_TABLE_NAME.equals(this.getRegionInfo().getTable())) {	if (shouldForceSplit()) {	
cannot split meta region in hbase and above 

return null;	}	if (!splitPolicy.shouldSplit()) {	return null;	}	byte[] ret = splitPolicy.getSplitPoint();	if (ret != null) {	try {	checkRow(ret, "calculated split");	} catch (IOException e) {	
ignoring invalid split 

private void recordMutationWithoutWal(final Map<byte [], List<Cell>> familyMap) {	numMutationsWithoutWAL.increment();	if (numMutationsWithoutWAL.sum() <= 1) {	
writing data to region with wal disabled data may be lost in the event of a crash 

private void lock(final Lock lock, final int multiplier) throws RegionTooBusyException, InterruptedIOException {	try {	final long waitTime = Math.min(maxBusyWaitDuration, busyWaitDuration * Math.min(multiplier, maxBusyWaitMultiplier));	if (!lock.tryLock(waitTime, TimeUnit.MILLISECONDS)) {	throw new RegionTooBusyException("Failed to obtain lock; regionName=" + (this.getRegionInfo() == null? "unknown": this.getRegionInfo().getRegionNameAsString()) + ", server=" + (this.getRegionServerServices() == null? "unknown": this.getRegionServerServices().getServerName()));	}	} catch (InterruptedException ie) {	
interrupted while waiting for a lock 

boolean shouldFlush = false;	synchronized (writestate) {	if (!this.writestate.isFlushRequested()) {	shouldFlush = true;	writestate.flushRequested = true;	}	}	if (shouldFlush) {	this.rsServices.getFlushRequester().requestFlush(this, false, tracker);	if (LOG.isDebugEnabled()) {	
flush requested on 

========================= hbase sample_2714 =========================

public synchronized void enable() {	boolean ret = disableCompactions.compareAndSet(false, true);	if (!ret && LOG.isTraceEnabled()) {	
compactions were already disabled upon enabling the policy 

public synchronized void disable() {	boolean ret = disableCompactions.compareAndSet(true, false);	if (!ret && LOG.isTraceEnabled()) {	
compactions were already enabled upon disabling the policy 

========================= hbase sample_2344 =========================

public void startServletContainer(Configuration conf) throws Exception {	if (server != null) {	
servletcontainer already running 

public void startServletContainer(Configuration conf) throws Exception {	if (server != null) {	return;	}	RESTServlet.getInstance(conf, UserProvider.instantiate(conf));	ResourceConfig app = new ResourceConfig(). packages("org.apache.hadoop.hbase.rest").register(JacksonJaxbJsonProvider.class);	ServletHolder sh = new ServletHolder(new ServletContainer(app));	server = new Server(0);	
configured 

ServerConnector serverConnector = new ServerConnector(server, new HttpConnectionFactory(httpConfig));	serverConnector.setPort(testServletPort);	server.addConnector(serverConnector);	ServletContextHandler ctxHandler = new ServletContextHandler(server, "/", ServletContextHandler.SESSIONS);	ctxHandler.addServlet(sh, "/*");	String[] filterClasses = conf.getStrings(Constants.FILTER_CLASSES, ArrayUtils.EMPTY_STRING_ARRAY);	for (String filter : filterClasses) {	filter = filter.trim();	ctxHandler.addFilter(filter, "/*", EnumSet.of(DispatcherType.REQUEST));	}	
loaded filter classes 

String[] filterClasses = conf.getStrings(Constants.FILTER_CLASSES, ArrayUtils.EMPTY_STRING_ARRAY);	for (String filter : filterClasses) {	filter = filter.trim();	ctxHandler.addFilter(filter, "/*", EnumSet.of(DispatcherType.REQUEST));	}	conf.set(RESTServer.REST_CSRF_BROWSER_USERAGENTS_REGEX_KEY, ".*");	RESTServer.addCSRFFilter(ctxHandler, conf);	HttpServerUtil.constrainHttpMethods(ctxHandler);	server.start();	testServletPort = ((ServerConnector)server.getConnectors()[0]).getLocalPort();	
started on port 

========================= hbase sample_3040 =========================

public void before() throws IOException {	
before 

public void before() throws IOException {	UTIL.ensureSomeRegionServersAvailable(1);	
before done 

public void testExtensionOfTableInputFormatBase() throws IOException, InterruptedException, ClassNotFoundException {	
testing use of an inputformat taht extends inputformatbase 

public void testJobConfigurableExtensionOfTableInputFormatBase() throws IOException, InterruptedException, ClassNotFoundException {	
testing use of an inputformat taht extends inputformatbase using jobconfigurable 

public void testDeprecatedExtensionOfTableInputFormatBase() throws IOException, InterruptedException, ClassNotFoundException {	
testing use of an inputformat taht extends inputformatbase using the approach documented in 

========================= hbase sample_3410 =========================

private boolean addToCache(TableCache tableCache, HRegionLocation loc) {	if (LOG.isTraceEnabled()) {	
try adding to cache 

private boolean addToCache(TableCache tableCache, HRegionLocation loc) {	if (LOG.isTraceEnabled()) {	}	byte[] startKey = loc.getRegion().getStartKey();	HRegionLocation oldLoc = tableCache.cache.putIfAbsent(startKey, loc);	if (oldLoc == null) {	return true;	}	if (oldLoc.getSeqNum() > loc.getSeqNum() || oldLoc.getServerName().equals(loc.getServerName())) {	if (LOG.isTraceEnabled()) {	
will not add to cache because the old value is newer than us or has the same server name 

if (oldLoc.getSeqNum() > loc.getSeqNum() || oldLoc.getServerName().equals(loc.getServerName())) {	if (LOG.isTraceEnabled()) {	}	return false;	}	return loc == tableCache.cache.compute(startKey, (k, oldValue) -> {	if (oldValue == null || oldValue.getSeqNum() <= loc.getSeqNum()) {	return loc;	}	if (LOG.isTraceEnabled()) {	
will not add to cache because the old value is newer than us or has the same server name maybe it is updated before we replace it 

private void addToCache(HRegionLocation loc) {	addToCache(getTableCache(loc.getRegion().getTable()), loc);	if (LOG.isTraceEnabled()) {	
try adding to cache 

========================= hbase sample_399 =========================

MasterKeepAliveConnection masterAdmin = Mockito.mock(MasterKeepAliveConnection.class);	Mockito.when(masterAdmin.createTable((RpcController)Mockito.any(), (CreateTableRequest)Mockito.any())). thenThrow(new ServiceException("Test fail").initCause(new PleaseHoldException("test")));	Mockito.when(connection.getKeepAliveMasterService()).thenReturn(masterAdmin);	Admin admin = new HBaseAdmin(connection);	try {	HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(name.getMethodName()));	try {	admin.createTable(htd, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);	fail();	} catch (RetriesExhaustedException e) {	
expected fail 

RpcRetryingCallerFactory callerFactory = new RpcRetryingCallerFactory(configuration);	Mockito.when(connection.getRpcRetryingCallerFactory()).thenReturn(callerFactory);	Admin admin = null;	try {	admin = Mockito.spy(new HBaseAdmin(connection));	Mockito.doReturn(null).when(((HBaseAdmin)admin)).getRegion(Matchers.<byte[]>any());	try {	caller.call(admin);	fail();	} catch (RetriesExhaustedException e) {	
expected fail 

========================= hbase sample_2128 =========================

public void test_TIMERANGE() throws Exception {	Configuration conf = new Configuration(this.util.getConfiguration());	RecordWriter<ImmutableBytesWritable, Cell> writer = null;	TaskAttemptContext context = null;	Path dir = util.getDataTestDir("test_TIMERANGE_present");	
timerange dir writing to dir 

public void testMRIncrementalLoad() throws Exception {	
starting test testmrincrementalload 

public void testMRIncrementalLoadWithSplit() throws Exception {	
starting test testmrincrementalloadwithsplit 

public void testMRIncrementalLoadWithLocality() throws Exception {	
starting test testmrincrementalloadwithlocality 

public void testMRIncrementalLoadWithPutSortReducer() throws Exception {	
starting test testmrincrementalloadwithputsortreducer 

public void testMultiMRIncrementalLoadWithPutSortReducer() throws Exception {	
starting test testmultimrincrementalloadwithputsortreducer 

}	assertEquals("Column family not found in FS.", FAMILIES.length, dir);	}	if (writeMultipleTables) {	assertEquals("Dir for all input tables not created", numTableDirs, allTables.size());	}	Admin admin = util.getConnection().getAdmin();	try {	if (shouldChangeRegions) {	Table chosenTable = allTables.values().iterator().next();	
changing regions in table 

try {	if (shouldChangeRegions) {	Table chosenTable = allTables.values().iterator().next();	admin.disableTable(chosenTable.getName());	util.waitUntilNoRegionsInTransition();	util.deleteTable(chosenTable.getName());	byte[][] newSplitKeys = generateRandomSplitKeys(14);	Table table = util.createTable(chosenTable.getName(), FAMILIES, newSplitKeys);	while (util.getConnection().getRegionLocator(chosenTable.getName()) .getAllRegionLocations().size() != 15 || !admin.isTableAvailable(table.getName())) {	Thread.sleep(200);	
waiting for new region assignment to happen 

util.deleteTable(chosenTable.getName());	byte[][] newSplitKeys = generateRandomSplitKeys(14);	Table table = util.createTable(chosenTable.getName(), FAMILIES, newSplitKeys);	while (util.getConnection().getRegionLocator(chosenTable.getName()) .getAllRegionLocations().size() != 15 || !admin.isTableAvailable(table.getName())) {	Thread.sleep(200);	}	}	for (HFileOutputFormat2.TableInfo singleTableInfo : tableInfo) {	Path tableDir = testDir;	String tableNameStr = singleTableInfo.getHTableDescriptor().getNameAsString();	
running loadincrementalhfiles on table 

}	results.close();	}	String tableDigestBefore = util.checksumRows(currentTable);	HDFSBlocksDistribution hbd = new HDFSBlocksDistribution();	for (HRegion region : util.getHBaseCluster().getRegions(currentTableName)) {	hbd.add(region.getHDFSBlocksDistribution());	}	for (String hostname : hostnames) {	float locality = hbd.getBlockLocalityIndex(hostname);	
locality of 

for (HRegion region : util.getHBaseCluster().getRegions(currentTableName)) {	hbd.add(region.getHDFSBlocksDistribution());	}	for (String hostname : hostnames) {	float locality = hbd.getBlockLocalityIndex(hostname);	assertEquals(100, (int) (locality * 100));	}	admin.disableTable(currentTableName);	while (!admin.isTableDisabled(currentTableName)) {	Thread.sleep(200);	
waiting for table to disable 

conf.set(HFileOutputFormat2.STORAGE_POLICY_PROPERTY_CF_PREFIX + Bytes.toString(HFileOutputFormat2.combineTableNameSuffix( TABLE_NAMES[0].getName(), FAMILIES[0])), "ONE_SSD");	Path cf1Dir = new Path(util.getDataTestDir(), Bytes.toString(FAMILIES[0]));	Path cf2Dir = new Path(util.getDataTestDir(), Bytes.toString(FAMILIES[1]));	util.startMiniDFSCluster(3);	FileSystem fs = util.getDFSCluster().getFileSystem();	try {	fs.mkdirs(cf1Dir);	fs.mkdirs(cf2Dir);	String spA = getStoragePolicyName(fs, cf1Dir);	String spB = getStoragePolicyName(fs, cf2Dir);	
storage policy of cf 

conf.set(HFileOutputFormat2.STORAGE_POLICY_PROPERTY_CF_PREFIX + Bytes.toString(HFileOutputFormat2.combineTableNameSuffix( TABLE_NAMES[0].getName(), FAMILIES[0])), "ONE_SSD");	Path cf1Dir = new Path(util.getDataTestDir(), Bytes.toString(FAMILIES[0]));	Path cf2Dir = new Path(util.getDataTestDir(), Bytes.toString(FAMILIES[1]));	util.startMiniDFSCluster(3);	FileSystem fs = util.getDFSCluster().getFileSystem();	try {	fs.mkdirs(cf1Dir);	fs.mkdirs(cf2Dir);	String spA = getStoragePolicyName(fs, cf1Dir);	String spB = getStoragePolicyName(fs, cf2Dir);	
storage policy of cf 

fs.mkdirs(cf1Dir);	fs.mkdirs(cf2Dir);	String spA = getStoragePolicyName(fs, cf1Dir);	String spB = getStoragePolicyName(fs, cf2Dir);	assertEquals("HOT", spA);	assertEquals("HOT", spB);	HFileOutputFormat2.configureStoragePolicy(conf, fs, HFileOutputFormat2.combineTableNameSuffix(TABLE_NAMES[0].getName(), FAMILIES[0]), cf1Dir);	HFileOutputFormat2.configureStoragePolicy(conf, fs, HFileOutputFormat2.combineTableNameSuffix(TABLE_NAMES[0].getName(), FAMILIES[1]), cf2Dir);	spA = getStoragePolicyName(fs, cf1Dir);	spB = getStoragePolicyName(fs, cf2Dir);	
storage policy of cf 

fs.mkdirs(cf1Dir);	fs.mkdirs(cf2Dir);	String spA = getStoragePolicyName(fs, cf1Dir);	String spB = getStoragePolicyName(fs, cf2Dir);	assertEquals("HOT", spA);	assertEquals("HOT", spB);	HFileOutputFormat2.configureStoragePolicy(conf, fs, HFileOutputFormat2.combineTableNameSuffix(TABLE_NAMES[0].getName(), FAMILIES[0]), cf1Dir);	HFileOutputFormat2.configureStoragePolicy(conf, fs, HFileOutputFormat2.combineTableNameSuffix(TABLE_NAMES[0].getName(), FAMILIES[1]), cf2Dir);	spA = getStoragePolicyName(fs, cf1Dir);	spB = getStoragePolicyName(fs, cf2Dir);	
storage policy of cf 

private String getStoragePolicyName(FileSystem fs, Path path) {	try {	Object blockStoragePolicySpi = ReflectionUtils.invokeMethod(fs, "getStoragePolicy", path);	return (String) ReflectionUtils.invokeMethod(blockStoragePolicySpi, "getName");	} catch (Exception e) {	if (LOG.isTraceEnabled()) {	
failed to get policy directly 

BlockStoragePolicy[] policies = dfs.getStoragePolicies();	for (BlockStoragePolicy policy : policies) {	if (policy.getId() == storagePolicyId) {	return policy.getName();	}	}	}	}	}	} catch (Throwable e) {	
failed to get block storage policy of 

========================= hbase sample_3386 =========================

protected boolean updateTransition(final MasterProcedureEnv env, final RegionStateNode regionNode) throws IOException {	if (regionNode.isInState(State.CLOSED, State.OFFLINE)) {	
not unassigned 

protected boolean remoteCallFailed(final MasterProcedureEnv env, final RegionStateNode regionNode, final IOException exception) {	if (exception instanceof ServerCrashException) {	try {	reportTransition(env, regionNode, TransitionCode.CLOSED, HConstants.NO_SEQNUM);	} catch (UnexpectedStateException e) {	throw new RuntimeException(e);	}	} else if (exception instanceof RegionServerAbortedException || exception instanceof RegionServerStoppedException || exception instanceof ServerNotRunningYetException) {	
ignoring waiting on servercrashprocedure 

protected boolean remoteCallFailed(final MasterProcedureEnv env, final RegionStateNode regionNode, final IOException exception) {	if (exception instanceof ServerCrashException) {	try {	reportTransition(env, regionNode, TransitionCode.CLOSED, HConstants.NO_SEQNUM);	} catch (UnexpectedStateException e) {	throw new RuntimeException(e);	}	} else if (exception instanceof RegionServerAbortedException || exception instanceof RegionServerStoppedException || exception instanceof ServerNotRunningYetException) {	} else if (exception instanceof NotServingRegionException) {	
is this ok any logs to replay acting as though all good 

========================= hbase sample_2780 =========================

public void testFullBackupRemote() throws Exception {	
test remote full backup on a single table 

} catch (InterruptedException ie) {	}	try {	HTable t1 = (HTable) conn.getTable(table1);	Put p1;	for (int i = 0; i < NB_ROWS_IN_FAM3; i++) {	p1 = new Put(Bytes.toBytes("row-t1" + i));	p1.addColumn(fam3Name, qualName, Bytes.toBytes("val" + i));	t1.put(p1);	}	
wrote rows into 

hcd.setMobEnabled(true);	hcd.setMobThreshold(0L);	table1Desc.addFamily(hcd);	HBaseTestingUtility.modifyTableSync(TEST_UTIL.getAdmin(), table1Desc);	SnapshotTestingUtils.loadData(TEST_UTIL, table1, 50, fam2Name);	HTable t1 = (HTable) conn.getTable(table1);	int rows0 = MobSnapshotTestingUtils.countMobRows(t1, fam2Name);	latch.countDown();	String backupId = backupTables(BackupType.FULL, Lists.newArrayList(table1), BACKUP_REMOTE_ROOT_DIR);	assertTrue(checkSucceeded(backupId));	
backup complete 

========================= hbase sample_531 =========================

public void testClassFinderFiltersByNameInJar() throws Exception {	final long counter = testCounter.incrementAndGet();	final String classNamePrefix = name.getMethodName();	
created jar 

public void testClassFinderFiltersByClassInJar() throws Exception {	final long counter = testCounter.incrementAndGet();	final String classNamePrefix = name.getMethodName();	
created jar 

public void testClassFinderCanFindClassesInDirs() throws Exception {	final long counter = testCounter.incrementAndGet();	final String classNamePrefix = name.getMethodName();	String pkgNameSuffix = name.getMethodName();	
created jar 

public void testClassFinderFiltersByNameInDirs() throws Exception {	final long counter = testCounter.incrementAndGet();	final String classNamePrefix = name.getMethodName();	String pkgNameSuffix = name.getMethodName();	
created jar 

public void testClassFinderFiltersByClassInDirs() throws Exception {	final long counter = testCounter.incrementAndGet();	final String classNamePrefix = name.getMethodName();	String pkgNameSuffix = name.getMethodName();	
created jar 

========================= hbase sample_862 =========================

public boolean evaluate() throws Exception {	for (HRegion region : cluster.getRegions(tn)) {	for (HStore store : region.getStores()) {	Collection<HStoreFile> files = store.getStoreEngine().getStoreFileManager().getCompactedfiles();	if (null != files && !files.isEmpty()) {	
still has compacted files 

========================= hbase sample_1456 =========================

private void init(RegionLocator regionLocator, Admin admin) throws IOException {	if (!enabled(admin.getConfiguration())) {	
region size calculation disabled 

private void init(RegionLocator regionLocator, Admin admin) throws IOException {	if (!enabled(admin.getConfiguration())) {	return;	}	if (regionLocator.getName().isSystemTable()) {	
region size calculation disabled for system tables 

private void init(RegionLocator regionLocator, Admin admin) throws IOException {	if (!enabled(admin.getConfiguration())) {	return;	}	if (regionLocator.getName().isSystemTable()) {	return;	}	
calculating region sizes for table regionlocator getname 

if (regionLocator.getName().isSystemTable()) {	return;	}	Set<ServerName> tableServers = getRegionServersOfTable(regionLocator);	for (ServerName tableServerName : tableServers) {	for (RegionMetrics regionLoad : admin.getRegionMetrics( tableServerName,regionLocator.getName())) {	byte[] regionId = regionLoad.getRegionName();	long regionSizeBytes = ((long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE)) * MEGABYTE;	sizeMap.put(regionId, regionSizeBytes);	if (LOG.isDebugEnabled()) {	
region has size 

Set<ServerName> tableServers = getRegionServersOfTable(regionLocator);	for (ServerName tableServerName : tableServers) {	for (RegionMetrics regionLoad : admin.getRegionMetrics( tableServerName,regionLocator.getName())) {	byte[] regionId = regionLoad.getRegionName();	long regionSizeBytes = ((long) regionLoad.getStoreFileSize().get(Size.Unit.MEGABYTE)) * MEGABYTE;	sizeMap.put(regionId, regionSizeBytes);	if (LOG.isDebugEnabled()) {	}	}	}	
region sizes calculated 

public long getRegionSize(byte[] regionId) {	Long size = sizeMap.get(regionId);	if (size == null) {	
unknown region 

========================= hbase sample_3484 =========================

if (doubleExecution) {	ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);	long procId = procExec.submitProcedure(scp);	MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId);	} else {	ProcedureTestingUtility.submitAndWait(procExec, scp);	}	assertEquals(count, util.countRows(t));	assertEquals(checksum, util.checksumRows(t));	} catch(Throwable throwable) {	
test failed 

========================= hbase sample_1840 =========================

public void process() {	Exception error = null;	try {	callable.call();	} catch (Exception e) {	
catch exception when call rsprocedurecallable 

========================= hbase sample_2503 =========================

protected Flow executeFromState(MasterProcedureEnv env, PeerModificationState state) throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {	switch (state) {	case PRE_PEER_MODIFICATION: try {	prePeerModification(env);	} catch (IOException e) {	
failed to call pre cp hook or the pre check is failed for peer mark the procedure as failure and give up 

protected Flow executeFromState(MasterProcedureEnv env, PeerModificationState state) throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {	switch (state) {	case PRE_PEER_MODIFICATION: try {	prePeerModification(env);	} catch (IOException e) {	setFailure("master-" + getPeerOperationType().name().toLowerCase() + "-peer", e);	releaseLatch();	return Flow.NO_MORE_STATE;	} catch (ReplicationException e) {	
failed to call prepeermodification for peer retry 

releaseLatch();	return Flow.NO_MORE_STATE;	} catch (ReplicationException e) {	throw new ProcedureYieldException();	}	setNextState(PeerModificationState.UPDATE_PEER_STORAGE);	return Flow.HAS_MORE_STATE;	case UPDATE_PEER_STORAGE: try {	updatePeerStorage(env);	} catch (ReplicationException e) {	
update peer storage for peer failed retry 

throw new ProcedureYieldException();	}	setNextState(PeerModificationState.REFRESH_PEER_ON_RS);	return Flow.HAS_MORE_STATE;	case REFRESH_PEER_ON_RS: addChildProcedure(env.getMasterServices().getServerManager().getOnlineServersList().stream() .map(sn -> new RefreshPeerProcedure(peerId, getPeerOperationType(), sn)) .toArray(RefreshPeerProcedure[]::new));	setNextState(PeerModificationState.POST_PEER_MODIFICATION);	return Flow.HAS_MORE_STATE;	case POST_PEER_MODIFICATION: try {	postPeerModification(env);	} catch (ReplicationException e) {	
failed to call postpeermodification for peer retry 

setNextState(PeerModificationState.REFRESH_PEER_ON_RS);	return Flow.HAS_MORE_STATE;	case REFRESH_PEER_ON_RS: addChildProcedure(env.getMasterServices().getServerManager().getOnlineServersList().stream() .map(sn -> new RefreshPeerProcedure(peerId, getPeerOperationType(), sn)) .toArray(RefreshPeerProcedure[]::new));	setNextState(PeerModificationState.POST_PEER_MODIFICATION);	return Flow.HAS_MORE_STATE;	case POST_PEER_MODIFICATION: try {	postPeerModification(env);	} catch (ReplicationException e) {	throw new ProcedureYieldException();	} catch (IOException e) {	
failed to call post cp hook for peer ignore since the procedure has already done 

========================= hbase sample_2850 =========================

public void perform() throws IOException {	Algorithm[] possibleAlgos = Algorithm.values();	Algorithm algo;	do {	algo = possibleAlgos[random.nextInt(possibleAlgos.length)];	try {	Compressor c = algo.getCompressor();	algo.returnCompressor(c);	break;	} catch (Throwable t) {	
performing action changing compression algorithms to is not supported pick another one 

do {	algo = possibleAlgos[random.nextInt(possibleAlgos.length)];	try {	Compressor c = algo.getCompressor();	algo.returnCompressor(c);	break;	} catch (Throwable t) {	}	} while (true);	final Algorithm chosenAlgo = algo;	
performing action changing compression algorithms on to 

========================= hbase sample_3312 =========================

public BackupManifest(FileSystem fs, Path backupPath) throws BackupException {	if (LOG.isDebugEnabled()) {	
loading manifest from 

long len = subFile.getLen();	byte[] pbBytes = new byte[(int) len];	in.readFully(pbBytes);	BackupProtos.BackupImage proto = null;	try {	proto = BackupProtos.BackupImage.parseFrom(pbBytes);	} catch (Exception e) {	throw new BackupException(e);	}	this.backupImage = BackupImage.fromProto(proto);	
loaded manifest instance from manifest file 

public void store(Configuration conf) throws BackupException {	byte[] data = backupImage.toProto().toByteArray();	Path manifestFilePath = new Path(HBackupFileSystem.getBackupPath(backupImage.getRootDir(), backupImage.getBackupId()), MANIFEST_FILE_NAME);	try (FSDataOutputStream out = manifestFilePath.getFileSystem(conf).create(manifestFilePath, true)) {	out.write(data);	} catch (IOException e) {	throw new BackupException(e.getMessage());	}	
manifest file stored to 

for (int j = 0; j < image1TableList.size(); j++) {	if (image2TableList.get(i).equals(image1TableList.get(j))) {	found = true;	break;	}	}	if (!found) {	return false;	}	}	
backup image can cover 

ArrayList<String> image2TableList = new ArrayList<String>();	List<TableName> tableList = image.getTableNames();	for (TableName table : tableList) {	image2TableList.add(table.getNameAsString());	}	for (int i = 0; i < image2TableList.size(); i++) {	if (image1TableList.contains(image2TableList.get(i)) == false) {	return false;	}	}	
full image set can cover image 

========================= hbase sample_566 =========================

public void setUp() throws Exception {	
start 

public void tearDown() throws Exception {	
end 

private WALEdit getBulkLoadWALEdit(NavigableMap<byte[], Integer> scope) {	Map<byte[], List<Path>> storeFiles = new HashMap<>(1);	Map<String, Long> storeFilesSize = new HashMap<>(1);	List<Path> p = new ArrayList<>(1);	Path hfilePath1 = new Path(Bytes.toString(f1));	p.add(hfilePath1);	try {	storeFilesSize.put(hfilePath1.getName(), fs.getFileStatus(hfilePath1).getLen());	} catch (IOException e) {	
failed to calculate the size of hfile 

storeFilesSize.put(hfilePath1.getName(), 0L);	}	storeFiles.put(f1, p);	scope.put(f1, 1);	p = new ArrayList<>(1);	Path hfilePath2 = new Path(Bytes.toString(f2));	p.add(hfilePath2);	try {	storeFilesSize.put(hfilePath2.getName(), fs.getFileStatus(hfilePath2).getLen());	} catch (IOException e) {	
failed to calculate the size of hfile 

logZnodesMap = new HashMap<>();	List<String> queues = rq.getAllQueues(deadRS);	for (String queue : queues) {	Pair<String, SortedSet<String>> pair = rq.claimQueue(deadRS, queue, server.getServerName());	if (pair != null) {	logZnodesMap.put(pair.getFirst(), pair.getSecond());	}	}	server.abort("Done with testing", null);	} catch (Exception e) {	
got exception while running nodefailoverworker 

========================= hbase sample_1952 =========================

private static String parseMessage(String originalMessage) {	if (originalMessage != null && originalMessage.startsWith(MESSAGE_PREFIX)) {	try {	int index = originalMessage.indexOf(' ', MESSAGE_PREFIX.length());	return originalMessage.substring(index + 1);	} catch (Exception e) {	if (LOG.isTraceEnabled()) {	
failed to trim exception message 

========================= hbase sample_2368 =========================

if (!Bytes.equals(info.getTable().toBytes(), this.tableName)) {	return;	}	preWALWriteCalled = true;	List<Cell> cells = logEdit.getCells();	Cell deletedCell = null;	for (Cell cell : cells) {	byte[] family = CellUtil.cloneFamily(cell);	byte[] qulifier = CellUtil.cloneQualifier(cell);	if (Arrays.equals(family, ignoredFamily) && Arrays.equals(qulifier, ignoredQualifier)) {	
found the keyvalue from waledit which should be ignored 

preWALWriteCalled = true;	List<Cell> cells = logEdit.getCells();	Cell deletedCell = null;	for (Cell cell : cells) {	byte[] family = CellUtil.cloneFamily(cell);	byte[] qulifier = CellUtil.cloneQualifier(cell);	if (Arrays.equals(family, ignoredFamily) && Arrays.equals(qulifier, ignoredQualifier)) {	deletedCell = cell;	}	if (Arrays.equals(family, changedFamily) && Arrays.equals(qulifier, changedQualifier)) {	
found the keyvalue from waledit which should be changed 

deletedCell = cell;	}	if (Arrays.equals(family, changedFamily) && Arrays.equals(qulifier, changedQualifier)) {	cell.getValueArray()[cell.getValueOffset()] += 1;	}	}	if (null != row) {	cells.add(new KeyValue(row, addedFamily, addedQualifier));	}	if (deletedCell != null) {	
about to delete a keyvalue from waledit 

public boolean isPreWALRestoreCalled() {	
isprewalrestorecalled is called 

public boolean isPostWALRestoreCalled() {	
ispostwalrestorecalled is called 

========================= hbase sample_1544 =========================

ByteArrayOutputStream baos = new ByteArrayOutputStream();	byte[] buffer = new byte[4096];	int read;	do {	read = inputStream.read(buffer, 0, buffer.length);	if (read > 0) {	baos.write(buffer, 0, read);	}	} while (read > 0);	if (LOG.isTraceEnabled()) {	
read bytes from 

========================= hbase sample_3083 =========================

private void writeToStream(CellSetModel model, String contentType, OutputStream outStream) throws IOException {	byte[] objectBytes = model.createProtobufOutput();	outStream.write(Bytes.toBytes((short)objectBytes.length));	outStream.write(objectBytes);	outStream.flush();	if (LOG.isTraceEnabled()) {	
wrote rows to stream successfully 

========================= hbase sample_3129 =========================

public void doScan(int n, boolean caching) throws IOException {	Scan scan = new Scan();	if (caching) {	scan.setCaching(n);	} else {	scan.setCaching(1);	}	ResultScanner scanner = table.getScanner(scan);	for (int i = 0; i < n; i++) {	Result res = scanner.next();	
result row value 

========================= hbase sample_1682 =========================

hcd = new HColumnDescriptor(TEST_FAMILY2);	hcd.setMaxVersions(4);	htd.setOwner(USER_OWNER);	htd.addFamily(hcd);	try (Connection connection = ConnectionFactory.createConnection(TEST_UTIL.getConfiguration())) {	try (Admin admin = connection.getAdmin()) {	admin.createTable(htd, new byte[][] { Bytes.toBytes("s") });	}	}	TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());	
sleeping a second because of hbase 

public Object run() throws Exception {	try (Connection connection = ConnectionFactory.createConnection(conf)) {	try (Table t = connection.getTable(TEST_TABLE.getTableName())) {	Put p = new Put(TEST_ROW).addColumn(TEST_FAMILY1, TEST_Q2, ONE);	Map<String, Permission> readAndWritePerms = prepareCellPermissions(usersAndGroups, Action.READ, Action.WRITE);	p.setACL(readAndWritePerms);	t.put(p);	p = new Put(TEST_ROW).addColumn(TEST_FAMILY2, TEST_Q2, ONE);	p.setACL(readAndWritePerms);	t.put(p);	
stored at current time 

public void tearDown() throws Exception {	try {	TEST_UTIL.deleteTable(TEST_TABLE.getTableName());	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1378 =========================

do {	foundRegionsToMove = false;	for (Iterator<Address> iter = allSevers.iterator(); iter.hasNext();) {	Address rs = iter.next();	List<RegionInfo> regions = new ArrayList<>();	for (RegionInfo region : getRegions(rs)) {	if (!tables.contains(region.getTable())) {	regions.add(region);	}	}	
moving region s from for server move to 

}	}	}	if (!foundRegionsToMove) {	iter.remove();	}	}	try {	rsGroupInfoManager.wait(1000);	} catch (InterruptedException e) {	
sleep interrupted 

private void moveRegionsToServers(Set<Address> servers, Set<TableName> tables, String targetGroupName) throws IOException {	for (TableName table: tables) {	
moving region s from for table move to 

throw new ConstraintException("Cannot leave a RSGroup " + srcGrp.getName() + " that contains tables without servers to host them.");	}	Set<Address> movedServers = rsGroupInfoManager.moveServers(servers, srcGrp.getName(), targetGroupName);	List<Address> editableMovedServers = Lists.newArrayList(movedServers);	boolean foundRegionsToMove;	do {	foundRegionsToMove = false;	for (Iterator<Address> iter = editableMovedServers.iterator(); iter.hasNext();) {	Address rs = iter.next();	List<RegionInfo> regions = getRegions(rs);	
moving region s from for server move to 

boolean foundRegionsToMove;	do {	foundRegionsToMove = false;	for (Iterator<Address> iter = editableMovedServers.iterator(); iter.hasNext();) {	Address rs = iter.next();	List<RegionInfo> regions = getRegions(rs);	for (RegionInfo region: regions) {	if (targetGrp.containsTable(region.getTable())) {	continue;	}	
moving region 

}	foundRegionsToMove = true;	}	if (!foundRegionsToMove) {	iter.remove();	}	}	try {	rsGroupInfoManager.wait(1000);	} catch (InterruptedException e) {	
sleep interrupted 

public void moveTables(Set<TableName> tables, String targetGroup) throws IOException {	if (tables == null) {	throw new ConstraintException("The list of servers cannot be null.");	}	if (tables.size() < 1) {	
movetables passed an empty set ignoring 

}	if(destGroup.getServers().size() < 1) {	throw new ConstraintException("Target RSGroup must have at least one server.");	}	}	for (TableName table : tables) {	String srcGroup = rsGroupInfoManager.getRSGroupOfTable(table);	if(srcGroup != null && srcGroup.equals(targetGroup)) {	throw new ConstraintException( "Source RSGroup " + srcGroup + " is same as target " + targetGroup + " RSGroup for table " + table);	}	
moving table to rsgroup 

for (TableName table : tables) {	String srcGroup = rsGroupInfoManager.getRSGroupOfTable(table);	if(srcGroup != null && srcGroup.equals(targetGroup)) {	throw new ConstraintException( "Source RSGroup " + srcGroup + " is same as target " + targetGroup + " RSGroup for table " + table);	}	}	rsGroupInfoManager.moveTables(tables, targetGroup);	if (targetGroup != null) {	for (TableName table: tables) {	if (master.getAssignmentManager().isTableDisabled(table)) {	
skipping move regions because the table is disabled 

throw new ConstraintException( "Source RSGroup " + srcGroup + " is same as target " + targetGroup + " RSGroup for table " + table);	}	}	rsGroupInfoManager.moveTables(tables, targetGroup);	if (targetGroup != null) {	for (TableName table: tables) {	if (master.getAssignmentManager().isTableDisabled(table)) {	continue;	}	for (RegionInfo region : master.getAssignmentManager().getRegionStates().getRegionsOfTable(table)) {	
moving region to rsgroup 

return false;	}	if (master.getMasterCoprocessorHost() != null) {	master.getMasterCoprocessorHost().preBalanceRSGroup(groupName);	}	if (getRSGroupInfo(groupName) == null) {	throw new ConstraintException("RSGroup does not exist: "+groupName);	}	Map<String, RegionState> groupRIT = rsGroupGetRegionsInTransition(groupName);	if (groupRIT.size() > 0) {	
not running balancer because region s in transition 

master.getMasterCoprocessorHost().preBalanceRSGroup(groupName);	}	if (getRSGroupInfo(groupName) == null) {	throw new ConstraintException("RSGroup does not exist: "+groupName);	}	Map<String, RegionState> groupRIT = rsGroupGetRegionsInTransition(groupName);	if (groupRIT.size() > 0) {	return false;	}	if (serverManager.areDeadServersInProgress()) {	
not running balancer because processing dead regionserver s 

}	Map<String, RegionState> groupRIT = rsGroupGetRegionsInTransition(groupName);	if (groupRIT.size() > 0) {	return false;	}	if (serverManager.areDeadServersInProgress()) {	return false;	}	List<RegionPlan> plans = new ArrayList<>();	for(Map.Entry<TableName, Map<ServerName, List<RegionInfo>>> tableMap: getRSGroupAssignmentsByTable(groupName).entrySet()) {	
creating partial plan for table 

Map<String, RegionState> groupRIT = rsGroupGetRegionsInTransition(groupName);	if (groupRIT.size() > 0) {	return false;	}	if (serverManager.areDeadServersInProgress()) {	return false;	}	List<RegionPlan> plans = new ArrayList<>();	for(Map.Entry<TableName, Map<ServerName, List<RegionInfo>>> tableMap: getRSGroupAssignmentsByTable(groupName).entrySet()) {	List<RegionPlan> partialPlans = balancer.balanceCluster(tableMap.getValue());	
partial plan for table 

List<RegionPlan> plans = new ArrayList<>();	for(Map.Entry<TableName, Map<ServerName, List<RegionInfo>>> tableMap: getRSGroupAssignmentsByTable(groupName).entrySet()) {	List<RegionPlan> partialPlans = balancer.balanceCluster(tableMap.getValue());	if (partialPlans != null) {	plans.addAll(partialPlans);	}	}	long startTime = System.currentTimeMillis();	boolean balancerRan = !plans.isEmpty();	if (balancerRan) {	
rsgroup balance starting with plan count 

for(Map.Entry<TableName, Map<ServerName, List<RegionInfo>>> tableMap: getRSGroupAssignmentsByTable(groupName).entrySet()) {	List<RegionPlan> partialPlans = balancer.balanceCluster(tableMap.getValue());	if (partialPlans != null) {	plans.addAll(partialPlans);	}	}	long startTime = System.currentTimeMillis();	boolean balancerRan = !plans.isEmpty();	if (balancerRan) {	for (RegionPlan plan: plans) {	
balance 

if (partialPlans != null) {	plans.addAll(partialPlans);	}	}	long startTime = System.currentTimeMillis();	boolean balancerRan = !plans.isEmpty();	if (balancerRan) {	for (RegionPlan plan: plans) {	assignmentManager.moveAsync(plan);	}	
rsgroup balance completed after seconds 

}	synchronized (rsGroupInfoManager) {	if (master.getMasterCoprocessorHost() != null) {	master.getMasterCoprocessorHost().preRemoveServers(servers);	}	checkForDeadOrOnlineServers(servers);	rsGroupInfoManager.removeServers(servers);	if (master.getMasterCoprocessorHost() != null) {	master.getMasterCoprocessorHost().postRemoveServers(servers);	}	
remove decommissioned servers from rsgroup done 

========================= hbase sample_3345 =========================

Path hfile = new Path(dir, family(i));	byte[] fam = Bytes.toBytes(family(i));	createHFile(fs, hfile, fam, QUAL, val, 1000);	famPaths.add(new Pair<>(fam, hfile.toString()));	}	final ClusterConnection conn = (ClusterConnection)UTIL.getConnection();	Table table = conn.getTable(tableName);	final String bulkToken = new SecureBulkLoadClient(UTIL.getConfiguration(), table). prepareBulkLoad(conn);	ClientServiceCallable<Void> callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), new RpcControllerFactory(UTIL.getConfiguration()).newController(), HConstants.PRIORITY_UNSET) {	public Void rpcCall() throws Exception {	
going to connect to server for row 

}	return null;	}	};	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(conf);	RpcRetryingCaller<Void> caller = factory.<Void> newCaller();	caller.callWithRetries(callable, Integer.MAX_VALUE);	if (numBulkLoads.get() % 5 == 0) {	callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), new RpcControllerFactory(UTIL.getConfiguration()).newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
compacting for row 

public void setupTable(TableName table, int cfs) throws IOException {	try {	
creating table 

public void setupTable(TableName table, int cfs) throws IOException {	try {	HTableDescriptor htd = new HTableDescriptor(table);	htd.addCoprocessor(MyObserver.class.getName());	MyObserver.sleepDuration = this.sleepDuration;	for (int i = 0; i < 10; i++) {	htd.addFamily(new HColumnDescriptor(family(i)));	}	UTIL.getAdmin().createTable(htd);	} catch (TableExistsException tee) {	
table already exists 

========================= hbase sample_1728 =========================

protected boolean scheduleForRetry(final IOException e) {	final boolean hold = (e instanceof ServerNotRunningYetException);	if (hold) {	LOG.warn(String.format("waiting a little before trying on the same server=%s try=%d", serverName, numberOfAttemptsSoFar), e);	long now = EnvironmentEdgeManager.currentTime();	if (now < getMaxWaitTime()) {	if (LOG.isDebugEnabled()) {	
server is not yet up waiting up to dms 

final boolean hold = (e instanceof ServerNotRunningYetException);	if (hold) {	LOG.warn(String.format("waiting a little before trying on the same server=%s try=%d", serverName, numberOfAttemptsSoFar), e);	long now = EnvironmentEdgeManager.currentTime();	if (now < getMaxWaitTime()) {	if (LOG.isDebugEnabled()) {	}	submitTask(this, 100, TimeUnit.MILLISECONDS);	return true;	}	
server s is not up for a while try a new one 

if (LOG.isDebugEnabled()) {	}	submitTask(this, 100, TimeUnit.MILLISECONDS);	return true;	}	return false;	}	final boolean retry = !hold && (e instanceof SocketTimeoutException && master.getServerManager().isServerOnline(serverName));	if (retry) {	if (LOG.isDebugEnabled()) {	
retrying to same regionserver s because s 

}	List<RegionCloseOperation> closeOps = fetchType(reqsByType, RegionCloseOperation.class);	if (!closeOps.isEmpty()) {	resolver.dispatchCloseRequests(env, closeOps);	}	List<ServerOperation> refreshOps = fetchType(reqsByType, ServerOperation.class);	if (!refreshOps.isEmpty()) {	resolver.dispatchServerOperations(env, refreshOps);	}	if (!reqsByType.isEmpty()) {	
unknown request type in the queue 

========================= hbase sample_2807 =========================

EncryptionTest.testKeyProvider(conf);	EncryptionTest.testCipherProvider(conf);	byte[] keyBytes = builder.getEncryptionKey().toByteArray();	Key key = null;	String walKeyName = conf.get(HConstants.CRYPTO_WAL_KEY_NAME_CONF_KEY);	if (walKeyName != null) {	try {	key = EncryptionUtil.unwrapWALKey(conf, walKeyName, keyBytes);	} catch (KeyException e) {	if (LOG.isDebugEnabled()) {	
unable to unwrap key with wal key 

}	key = null;	}	}	if (key == null) {	String masterKeyName = conf.get(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, User.getCurrent().getShortName());	try {	key = EncryptionUtil.unwrapWALKey(conf, masterKeyName, keyBytes);	} catch (KeyException e) {	if (LOG.isDebugEnabled()) {	
unable to unwrap key with current master key 

========================= hbase sample_2554 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testSnapshotDeletionWithRegex() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	table.close();	byte[] snapshot1 = Bytes.toBytes("TableSnapshot1");	admin.snapshot(snapshot1, TABLE_NAME);	
completed 

public void testSnapshotDeletionWithRegex() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	table.close();	byte[] snapshot1 = Bytes.toBytes("TableSnapshot1");	admin.snapshot(snapshot1, TABLE_NAME);	byte[] snapshot2 = Bytes.toBytes("TableSnapshot2");	admin.snapshot(snapshot2, TABLE_NAME);	
completed 

SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	table.close();	byte[] snapshot1 = Bytes.toBytes("TableSnapshot1");	admin.snapshot(snapshot1, TABLE_NAME);	byte[] snapshot2 = Bytes.toBytes("TableSnapshot2");	admin.snapshot(snapshot2, TABLE_NAME);	String snapshot3 = "3rdTableSnapshot";	admin.snapshot(Bytes.toBytes(snapshot3), TABLE_NAME);	
completed 

public void testOfflineTableSnapshot() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM, false);	
fs state before disable 

public void testOfflineTableSnapshot() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM, false);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	
fs state before snapshot 

Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM, false);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	final String SNAPSHOT_NAME = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(SNAPSHOT_NAME);	admin.snapshot(new SnapshotDescription(SNAPSHOT_NAME, TABLE_NAME, SnapshotType.DISABLED, null, -1, SnapshotManifestV1.DESCRIPTOR_VERSION));	
snapshot completed 

UTIL.loadTable(table, TEST_FAM, false);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	final String SNAPSHOT_NAME = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(SNAPSHOT_NAME);	admin.snapshot(new SnapshotDescription(SNAPSHOT_NAME, TABLE_NAME, SnapshotType.DISABLED, null, -1, SnapshotManifestV1.DESCRIPTOR_VERSION));	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertOneSnapshotThatMatches(admin, snapshot, TABLE_NAME);	FileSystem fs = UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getFileSystem();	Path rootDir = UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getRootDir();	
fs state after snapshot 

public void testSnapshotFailsOnNonExistantTable() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	String tableName = "_not_a_table";	boolean fail = false;	do {	try {	admin.getTableDescriptor(TableName.valueOf(tableName));	fail = true;	
table already exists checking a new name 

fail = true;	tableName = tableName+"!";	} catch (TableNotFoundException e) {	fail = false;	}	} while (fail);	try {	admin.snapshot("fail", TableName.valueOf(tableName));	fail("Snapshot succeeded even though there is not table.");	} catch (SnapshotCreationException e) {	
correctly failed to snapshot a non existant table 

public void testOfflineTableSnapshotWithEmptyRegions() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	
fs state before disable 

public void testOfflineTableSnapshotWithEmptyRegions() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	
fs state before snapshot 

public void testOfflineTableSnapshotWithEmptyRegions() throws Exception {	Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	byte[] snapshot = Bytes.toBytes("testOfflineTableSnapshotWithEmptyRegions");	admin.snapshot(snapshot, TABLE_NAME);	
snapshot completed 

Admin admin = UTIL.getAdmin();	SnapshotTestingUtils.assertNoSnapshots(admin);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	admin.disableTable(TABLE_NAME);	FSUtils.logFileSystemState(UTIL.getTestFileSystem(), FSUtils.getRootDir(UTIL.getConfiguration()), LOG);	byte[] snapshot = Bytes.toBytes("testOfflineTableSnapshotWithEmptyRegions");	admin.snapshot(snapshot, TABLE_NAME);	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertOneSnapshotThatMatches(admin, snapshot, TABLE_NAME);	FileSystem fs = UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getFileSystem();	Path rootDir = UTIL.getHBaseCluster().getMaster().getMasterFileSystem().getRootDir();	
fs state after snapshot 

public void testListTableSnapshots() throws Exception {	Admin admin = null;	final TableName tableName = TableName.valueOf(name.getMethodName());	try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	
completed 

Admin admin = null;	final TableName tableName = TableName.valueOf(name.getMethodName());	try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	
completed 

try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	String table2Snapshot1 = "Table2Snapshot1";	admin.snapshot(Bytes.toBytes(table2Snapshot1), tableName);	
completed 

public void testListTableSnapshotsWithRegex() throws Exception {	Admin admin = null;	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	
completed 

public void testListTableSnapshotsWithRegex() throws Exception {	Admin admin = null;	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	
completed 

public void testListTableSnapshotsWithRegex() throws Exception {	Admin admin = null;	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	String table2Snapshot1 = "Table2Snapshot1";	admin.snapshot(Bytes.toBytes(table2Snapshot1), TABLE_NAME);	
completed 

public void testDeleteTableSnapshots() throws Exception {	Admin admin = null;	final TableName tableName = TableName.valueOf(name.getMethodName());	try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	
completed 

Admin admin = null;	final TableName tableName = TableName.valueOf(name.getMethodName());	try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	
completed 

try {	admin = UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(tableName);	UTIL.createTable(htd, new byte[][] { TEST_FAM }, UTIL.getConfiguration());	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	String table2Snapshot1 = "Table2Snapshot1";	admin.snapshot(Bytes.toBytes(table2Snapshot1), tableName);	
completed 

public void testDeleteTableSnapshotsWithRegex() throws Exception {	Admin admin = null;	Pattern tableNamePattern = Pattern.compile("test.*");	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	
completed 

public void testDeleteTableSnapshotsWithRegex() throws Exception {	Admin admin = null;	Pattern tableNamePattern = Pattern.compile("test.*");	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	
completed 

Admin admin = null;	Pattern tableNamePattern = Pattern.compile("test.*");	try {	admin = UTIL.getAdmin();	String table1Snapshot1 = "Table1Snapshot1";	admin.snapshot(table1Snapshot1, TABLE_NAME);	String table1Snapshot2 = "Table1Snapshot2";	admin.snapshot(table1Snapshot2, TABLE_NAME);	String table2Snapshot1 = "Table2Snapshot1";	admin.snapshot(Bytes.toBytes(table2Snapshot1), TABLE_NAME);	
completed 

========================= hbase sample_2104 =========================

dispatcher.addListener(listener1);	dispatcher.addListener(listener2);	dispatcher.receive(EXTEXN);	Mockito.verify(listener1, Mockito.times(1)).receive(EXTEXN);	Mockito.verify(listener2, Mockito.times(1)).receive(EXTEXN);	try {	dispatcher.rethrowException();	fail("Monitor should have thrown an exception after getting error.");	} catch (ForeignException ex) {	assertTrue("Got an unexpected exception:" + ex, ex.getCause() == EXTEXN.getCause());	
got the testing exception 

========================= hbase sample_1417 =========================

for (int i = 0; i < masterThreads.size(); i++) {	if (masterThreads.get(i).getMaster().isActiveMaster()) {	numActive++;	activeIndex = i;	active = masterThreads.get(activeIndex).getMaster();	activeName = active.getServerName();	}	}	assertEquals(1, numActive);	assertEquals(NUM_MASTERS, masterThreads.size());	
active master 

}	}	assertEquals(1, numActive);	assertEquals(NUM_MASTERS, masterThreads.size());	assertNotNull(active);	ClusterMetrics status = active.getClusterMetrics();	assertTrue(status.getMasterName().equals(activeName));	assertEquals(2, status.getBackupMasterNames().size());	int backupIndex = (activeIndex == 0 ? 1 : activeIndex - 1);	HMaster master = cluster.getMaster(backupIndex);	
stopping a backup master 

for (int i = 0; i < masterThreads.size(); i++) {	if (masterThreads.get(i).getMaster().isActiveMaster()) {	assertTrue(activeName.equals(masterThreads.get(i).getMaster().getServerName()));	activeIndex = i;	active = masterThreads.get(activeIndex).getMaster();	}	}	assertEquals(1, numActive);	assertEquals(2, masterThreads.size());	int rsCount = masterThreads.get(activeIndex).getMaster().getClusterMetrics() .getLiveServerMetrics().size();	
active master managing regions servers 

}	}	assertEquals(1, numActive);	assertEquals(2, masterThreads.size());	int rsCount = masterThreads.get(activeIndex).getMaster().getClusterMetrics() .getLiveServerMetrics().size();	assertEquals(3, rsCount);	assertNotNull(active);	status = active.getClusterMetrics();	assertTrue(status.getMasterName().equals(activeName));	assertEquals(1, status.getBackupMasterNames().size());	
stopping the active master 

assertEquals(2, masterThreads.size());	int rsCount = masterThreads.get(activeIndex).getMaster().getClusterMetrics() .getLiveServerMetrics().size();	assertEquals(3, rsCount);	assertNotNull(active);	status = active.getClusterMetrics();	assertTrue(status.getMasterName().equals(activeName));	assertEquals(1, status.getBackupMasterNames().size());	cluster.stopMaster(activeIndex, false);	cluster.waitOnMaster(activeIndex);	assertTrue(cluster.waitForActiveAndReadyMaster());	
verifying backup master is now active 

assertTrue(cluster.waitForActiveAndReadyMaster());	assertEquals(1, masterThreads.size());	active = masterThreads.get(0).getMaster();	assertNotNull(active);	status = active.getClusterMetrics();	ServerName mastername = status.getMasterName();	assertTrue(mastername.equals(active.getServerName()));	assertTrue(active.isActiveMaster());	assertEquals(0, status.getBackupMasterNames().size());	int rss = status.getLiveServerMetrics().size();	
active master managing region servers 

public void testMetaInTransitionWhenMasterFailover() throws Exception {	final int NUM_MASTERS = 1;	final int NUM_RS = 1;	HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS);	try {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	
cluster started 

public void testMetaInTransitionWhenMasterFailover() throws Exception {	final int NUM_MASTERS = 1;	final int NUM_RS = 1;	HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS);	try {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster activeMaster = cluster.getMaster();	ServerName metaServerName = cluster.getServerHoldingMeta();	HRegionServer hrs = cluster.getRegionServer(metaServerName);	
aborting master 

final int NUM_RS = 1;	HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS);	try {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster activeMaster = cluster.getMaster();	ServerName metaServerName = cluster.getServerHoldingMeta();	HRegionServer hrs = cluster.getRegionServer(metaServerName);	activeMaster.abort("test-kill");	cluster.waitForMasterToStop(activeMaster.getServerName(), 30000);	
master has aborted 

try {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster activeMaster = cluster.getMaster();	ServerName metaServerName = cluster.getServerHoldingMeta();	HRegionServer hrs = cluster.getRegionServer(metaServerName);	activeMaster.abort("test-kill");	cluster.waitForMasterToStop(activeMaster.getServerName(), 30000);	RegionState metaState = MetaTableLocator.getMetaRegionState(hrs.getZooKeeper());	assertEquals("hbase:meta should be online on RS", metaState.getServerName(), metaServerName);	assertEquals("hbase:meta should be online on RS", metaState.getState(), State.OPEN);	
starting up a new master 

MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster activeMaster = cluster.getMaster();	ServerName metaServerName = cluster.getServerHoldingMeta();	HRegionServer hrs = cluster.getRegionServer(metaServerName);	activeMaster.abort("test-kill");	cluster.waitForMasterToStop(activeMaster.getServerName(), 30000);	RegionState metaState = MetaTableLocator.getMetaRegionState(hrs.getZooKeeper());	assertEquals("hbase:meta should be online on RS", metaState.getServerName(), metaServerName);	assertEquals("hbase:meta should be online on RS", metaState.getState(), State.OPEN);	activeMaster = cluster.startMaster().getMaster();	
waiting for master to be ready 

HMaster activeMaster = cluster.getMaster();	ServerName metaServerName = cluster.getServerHoldingMeta();	HRegionServer hrs = cluster.getRegionServer(metaServerName);	activeMaster.abort("test-kill");	cluster.waitForMasterToStop(activeMaster.getServerName(), 30000);	RegionState metaState = MetaTableLocator.getMetaRegionState(hrs.getZooKeeper());	assertEquals("hbase:meta should be online on RS", metaState.getServerName(), metaServerName);	assertEquals("hbase:meta should be online on RS", metaState.getState(), State.OPEN);	activeMaster = cluster.startMaster().getMaster();	cluster.waitForActiveAndReadyMaster();	
master is ready 

========================= hbase sample_1801 =========================

public void tearDown() throws Exception {	try {	deleteTable(TEST_UTIL, TEST_TABLE.getTableName());	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1381 =========================

}	ReadyChunk readyChunk = new ReadyChunk();	readyChunk.chunkId = numChunks - 1;	readyChunk.chunk = chunk;	readyChunk.firstKey = firstKeyInChunk;	readyChunks.add(readyChunk);	long prevMaxKeys = chunk.getMaxKeys();	long prevByteSize = chunk.getByteSize();	chunk.compactBloom();	if (LOG.isTraceEnabled() && prevByteSize != chunk.getByteSize()) {	
compacted bloom chunk from max keys bytes to max keys bytes 

========================= hbase sample_2407 =========================

long now = EnvironmentEdgeManager.currentTime();	long minTimeAllowed = (long) (deltaSize long elapsedTime = now - operation.lastControlTime;	operation.lastControlSize = operation.totalSize;	if (elapsedTime >= minTimeAllowed) {	operation.lastControlTime = EnvironmentEdgeManager.currentTime();	return 0;	}	long sleepTime = minTimeAllowed - elapsedTime;	if (LOG.isDebugEnabled()) {	if (now - operation.lastLogTime > 5L * 1000) {	
deltasize bytes elapsetime ns 

protected abstract boolean skipControl(long deltaSize, long controlSize);	public void finish(String opName) {	ActiveOperation operation = activeOperations.remove(opName);	maxThroughputPerOperation = getMaxThroughput() / activeOperations.size();	long elapsedTime = EnvironmentEdgeManager.currentTime() - operation.startTime;	
average throughput is slept time s and total slept time is ms active operations remaining total limit is 

========================= hbase sample_2542 =========================

private void rollbackSetNamespaceQuota(final MasterProcedureEnv env) throws IOException {	try {	DeleteNamespaceProcedure.removeNamespaceQuota(env, nsDescriptor.getName());	} catch (Exception e) {	
rollback of setnamespacequota throws exception 

========================= hbase sample_2811 =========================

public static CoprocessorClassLoader getClassLoader(final Path path, final ClassLoader parent, final String pathPrefix, final Configuration conf) throws IOException {	CoprocessorClassLoader cl = getIfCached(path);	String pathStr = path.toString();	if (cl != null) {	
found classloader for 

if (cl != null) {	return cl;	}	if (path.getFileSystem(conf).isFile(path) && !pathStr.endsWith(".jar")) {	throw new IOException(pathStr + ": not a jar file?");	}	Lock lock = locker.acquireLock(pathStr);	try {	cl = getIfCached(path);	if (cl != null) {	
found classloader for 

return cl;	}	cl = AccessController.doPrivileged( new PrivilegedAction<CoprocessorClassLoader>() {	public CoprocessorClassLoader run() {	return new CoprocessorClassLoader(parent);	}	});	cl.init(path, pathPrefix, conf);	CoprocessorClassLoader prev = classLoadersCache.putIfAbsent(path, cl);	if (prev != null) {	
this should not happen a class loader is already cached for 

public Class<?> loadClass(String name, String[] includedClassPrefixes) throws ClassNotFoundException {	if (isClassExempt(name, includedClassPrefixes)) {	if (LOG.isDebugEnabled()) {	
skipping exempt class delegating directly to parent 

public Class<?> loadClass(String name, String[] includedClassPrefixes) throws ClassNotFoundException {	if (isClassExempt(name, includedClassPrefixes)) {	if (LOG.isDebugEnabled()) {	}	return parent.loadClass(name);	}	synchronized (getClassLoadingLock(name)) {	Class<?> clasz = findLoadedClass(name);	if (clasz != null) {	if (LOG.isDebugEnabled()) {	
class already loaded 

}	synchronized (getClassLoadingLock(name)) {	Class<?> clasz = findLoadedClass(name);	if (clasz != null) {	if (LOG.isDebugEnabled()) {	}	}	else {	try {	if (LOG.isDebugEnabled()) {	
finding class 

if (LOG.isDebugEnabled()) {	}	}	else {	try {	if (LOG.isDebugEnabled()) {	}	clasz = findClass(name);	} catch (ClassNotFoundException e) {	if (LOG.isDebugEnabled()) {	
class not found delegating to parent 

if (LOG.isDebugEnabled()) {	}	clasz = findClass(name);	} catch (ClassNotFoundException e) {	if (LOG.isDebugEnabled()) {	}	try {	clasz = parent.loadClass(name);	} catch (ClassNotFoundException e2) {	if (LOG.isDebugEnabled()) {	
class not found in parent loader 

public URL getResource(String name) {	URL resource = null;	boolean parentLoaded = false;	if (loadResourceUsingParentFirst(name)) {	if (LOG.isDebugEnabled()) {	
checking parent first for resource 

========================= hbase sample_1010 =========================

}	locs[DEFAULT_REPLICA_ID] = new HRegionLocation(getRegionInfoForDefaultReplica(FIRST_META_REGIONINFO), stateAndServerName.getSecond());	tryComplete(remaining, locs, future);	});	} else {	getAndConvert(path, ZKAsyncRegistry::getMetaProto).whenComplete((proto, error) -> {	if (future.isDone()) {	return;	}	if (error != null) {	
failed to fetch 

tryComplete(remaining, locs, future);	});	} else {	getAndConvert(path, ZKAsyncRegistry::getMetaProto).whenComplete((proto, error) -> {	if (future.isDone()) {	return;	}	if (error != null) {	locs[replicaId] = null;	} else if (proto == null) {	
meta znode for replica is null 

if (future.isDone()) {	return;	}	if (error != null) {	locs[replicaId] = null;	} else if (proto == null) {	locs[replicaId] = null;	} else {	Pair<RegionState.State, ServerName> stateAndServerName = getStateAndServerName(proto);	if (stateAndServerName.getFirst() != RegionState.State.OPEN) {	
meta region for replica is in state 

========================= hbase sample_462 =========================

public void testBalanceCluster() throws Exception {	conf.setLong(StochasticLoadBalancer.MAX_STEPS_KEY, 2000000L);	conf.setLong("hbase.master.balancer.stochastic.maxRunningTime", 90 * 1000);	conf.setFloat("hbase.master.balancer.stochastic.maxMovePercent", 1.0f);	loadBalancer.setConf(conf);	for (int[] mockCluster : clusterStateMocks) {	Map<ServerName, List<RegionInfo>> servers = mockClusterServers(mockCluster);	List<ServerAndLoad> list = convertToList(servers);	
mock cluster 

public void testBalanceCluster() throws Exception {	conf.setLong(StochasticLoadBalancer.MAX_STEPS_KEY, 2000000L);	conf.setLong("hbase.master.balancer.stochastic.maxRunningTime", 90 * 1000);	conf.setFloat("hbase.master.balancer.stochastic.maxMovePercent", 1.0f);	loadBalancer.setConf(conf);	for (int[] mockCluster : clusterStateMocks) {	Map<ServerName, List<RegionInfo>> servers = mockClusterServers(mockCluster);	List<ServerAndLoad> list = convertToList(servers);	List<RegionPlan> plans = loadBalancer.balanceCluster(servers);	List<ServerAndLoad> balancedCluster = reconcile(list, plans, servers);	
mock balance 

========================= hbase sample_1856 =========================

private TableAuthManager(ZKWatcher watcher, Configuration conf) throws IOException {	this.conf = conf;	globalCache = initGlobal(conf);	this.zkperms = new ZKPermissionWatcher(watcher, this, conf);	try {	this.zkperms.start();	} catch (KeeperException ke) {	
zookeeper initialization failed 

throw new IOException(e);	}	if (perms != null) {	if (Bytes.equals(table.getName(), AccessControlLists.ACL_GLOBAL_NAME)) {	updateGlobalCache(perms);	} else {	updateTableCache(table, perms);	}	}	} else {	
skipping permission cache refresh because writable data is empty 

ListMultimap<String,TablePermission> perms;	try {	perms = AccessControlLists.readPermissions(data, conf);	} catch (DeserializationException e) {	throw new IOException(e);	}	if (perms != null) {	updateNsCache(namespace, perms);	}	} else {	
skipping permission cache refresh because writable data is empty 

for (Map.Entry<String,TablePermission> entry : userPerms.entries()) {	if (AuthUtil.isGroupPrincipal(entry.getKey())) {	newCache.putGroup(AuthUtil.getGroupName(entry.getKey()), new Permission(entry.getValue().getActions()));	} else {	newCache.putUser(entry.getKey(), new Permission(entry.getValue().getActions()));	}	}	globalCache = newCache;	mtime.incrementAndGet();	} catch (IOException e) {	
error occurred while updating the global cache 

private boolean authorize(List<Permission> perms, Permission.Action action) {	if (perms != null) {	for (Permission p : perms) {	if (p.implies(action)) {	return true;	}	}	} else if (LOG.isDebugEnabled()) {	
no permissions found for 

LOG.trace("Perms for user " + user.getShortName() + " in cell " + cell + ": " + (perms != null ? perms : ""));	}	if (perms != null) {	for (Permission p: perms) {	if (p.implies(action)) {	return true;	}	}	}	} catch (IOException e) {	
failed parse of acl tag in cell 

========================= hbase sample_2283 =========================

LOG.info("port= " + port);	int ipcPort = -1;	boolean ok = false;	final String lookup = lbs[0].getHosts()[0];	StringBuilder sb = new StringBuilder();	for (DataNode dn : cluster.getDataNodes()) {	final String dnName = getHostName(dn);	sb.append(dnName).append(' ');	if (lookup.equals(dnName)) {	ok = true;	
killing datanode 

boolean ok = false;	final String lookup = lbs[0].getHosts()[0];	StringBuilder sb = new StringBuilder();	for (DataNode dn : cluster.getDataNodes()) {	final String dnName = getHostName(dn);	sb.append(dnName).append(' ');	if (lookup.equals(dnName)) {	ok = true;	ipcPort = dn.ipcServer.getListenerAddress().getPort();	dn.shutdown();	
killed datanode 

}	}	Assert.assertTrue( "didn't find the server to kill, was looking for " + lookup + " found " + sb, ok);	LOG.info("ipc port= " + ipcPort);	Assert.assertTrue(HFileSystem.addLocationsOrderInterceptor(conf, new HFileSystem.ReorderBlocks() {	public void reorderBlocks(Configuration c, LocatedBlocks lbs, String src) {	for (LocatedBlock lb : lbs.getLocatedBlocks()) {	if (lb.getLocations().length > 1) {	DatanodeInfo[] infos = lb.getLocations();	if (infos[0].getHostName().equals(lookup)) {	
hfilesystem bad host inverting 

}	}	}));	final int retries = 10;	ServerSocket ss = null;	ServerSocket ssI;	try {	ss = new ServerSocket(port);	ssI = new ServerSocket(ipcPort);	} catch (BindException be) {	
got bind exception trying to set up socket on or this means that the datanode has not closed the socket or someone else took it it may happen skipping this test for this time 

latch.countDown();	}	};	for (HRegion region : regions) {	region.getWAL().registerWALActionsListener(listener);	}	htu.getAdmin().rollWALWriter(targetRs.getServerName());	try {	latch.await();	} catch (InterruptedException exception) {	
interrupted while waiting for the wal of to roll if later tests fail it s probably because we should still be waiting 

}	Thread.sleep(100);	Put p = new Put(sb);	p.addColumn(sb, sb, sb);	h.put(p);	DirectoryListing dl = dfs.getClient().listPaths(rootDir, HdfsFileStatus.EMPTY_NAME);	HdfsFileStatus[] hfs = dl.getPartialListing();	Assert.assertTrue(hfs.length >= 1);	for (HdfsFileStatus hf : hfs) {	try {	
log file found in 

Put p = new Put(sb);	p.addColumn(sb, sb, sb);	h.put(p);	DirectoryListing dl = dfs.getClient().listPaths(rootDir, HdfsFileStatus.EMPTY_NAME);	HdfsFileStatus[] hfs = dl.getPartialListing();	Assert.assertTrue(hfs.length >= 1);	for (HdfsFileStatus hf : hfs) {	try {	String logFile = rootDir + "/" + hf.getLocalName();	FileStatus fsLog = rfs.getFileStatus(new Path(logFile));	
checking log file 

DirectoryListing dl = dfs.getClient().listPaths(rootDir, HdfsFileStatus.EMPTY_NAME);	HdfsFileStatus[] hfs = dl.getPartialListing();	Assert.assertTrue(hfs.length >= 1);	for (HdfsFileStatus hf : hfs) {	try {	String logFile = rootDir + "/" + hf.getLocalName();	FileStatus fsLog = rfs.getFileStatus(new Path(logFile));	BlockLocation[] bls = rfs.getFileBlockLocations(fsLog, 0, 1);	if (bls.length > 0) {	BlockLocation bl = bls[0];	
replicas for block in 

if (bls.length > 0) {	BlockLocation bl = bls[0];	for (int i = 0; i < bl.getHosts().length - 1; i++) {	LOG.info(bl.getHosts()[i] + "    " + logFile);	Assert.assertNotSame(bl.getHosts()[i], host4);	}	String last = bl.getHosts()[bl.getHosts().length - 1];	LOG.info(last + "    " + logFile);	if (host4.equals(last)) {	nbTest++;	
is on the new datanode and is ok 

LOG.info(last + "    " + logFile);	if (host4.equals(last)) {	nbTest++;	if (bl.getHosts().length == 3) {	testFromDFS(dfs, logFile, repCount, host4);	testFromDFS(mdfs, logFile, repCount, host4);	}	}	}	} catch (FileNotFoundException exception) {	
failed to find log file it probably was archived out from under us so we ll ignore and retry if this test hangs indefinitely you should treat this failure as a symptom 

nbTest++;	if (bl.getHosts().length == 3) {	testFromDFS(dfs, logFile, repCount, host4);	testFromDFS(mdfs, logFile, repCount, host4);	}	}	}	} catch (FileNotFoundException exception) {	} catch (RemoteException exception) {	if (exception.unwrapRemoteException() instanceof FileNotFoundException) {	
failed to find log file it probably was archived out from under us so we ll ignore and retry if this test hangs indefinitely you should treat this failure as a symptom 

========================= hbase sample_2000 =========================

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	
cluster size 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	long start = System.currentTimeMillis();	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	
writing some data to the table 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	long start = System.currentTimeMillis();	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	writeData(colsPerKey, recordSize, writeThreads, startKey, numKeys);	
flushing the table 

long start = System.currentTimeMillis();	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	writeData(colsPerKey, recordSize, writeThreads, startKey, numKeys);	Admin admin = util.getAdmin();	admin.flush(getTablename());	long refreshTime = conf.getLong(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, 0);	if (refreshTime > 0 && refreshTime <= 10000) {	
sleeping ms to ensure that the data is replicated 

long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	writeData(colsPerKey, recordSize, writeThreads, startKey, numKeys);	Admin admin = util.getAdmin();	admin.flush(getTablename());	long refreshTime = conf.getLong(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, 0);	if (refreshTime > 0 && refreshTime <= 10000) {	Threads.sleep(refreshTime*3);	} else {	
reopening the table 

admin.flush(getTablename());	long refreshTime = conf.getLong(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, 0);	if (refreshTime > 0 && refreshTime <= 10000) {	Threads.sleep(refreshTime*3);	} else {	admin.disableTable(getTablename());	admin.enableTable(getTablename());	}	long chaosMonkeyDelay = conf.getLong(String.format("%s.%s", TEST_NAME, CHAOS_MONKEY_DELAY_KEY) , DEFAUL_CHAOS_MONKEY_DELAY);	ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();	
chaosmonkey delay is d seconds will start s chaosmonkey after delay 

Threads.sleep(refreshTime*3);	} else {	admin.disableTable(getTablename());	admin.enableTable(getTablename());	}	long chaosMonkeyDelay = conf.getLong(String.format("%s.%s", TEST_NAME, CHAOS_MONKEY_DELAY_KEY) , DEFAUL_CHAOS_MONKEY_DELAY);	ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();	ScheduledFuture<?> result = executorService.schedule(new Runnable() {	public void run() {	try {	
starting chaosmonkey 

try {	monkey.start();	monkey.waitForStop();	} catch (Exception e) {	LOG.warn(StringUtils.stringifyException(e));	}	}	}, chaosMonkeyDelay, TimeUnit.MILLISECONDS);	long remainingTime = runtime - (System.currentTimeMillis() - start);	if (remainingTime <= 0) {	
the amount of time left for the test to perform random reads is non positive increase the test execution time via or reduce the amount of data written per server via 

monkey.waitForStop();	} catch (Exception e) {	LOG.warn(StringUtils.stringifyException(e));	}	}	}, chaosMonkeyDelay, TimeUnit.MILLISECONDS);	long remainingTime = runtime - (System.currentTimeMillis() - start);	if (remainingTime <= 0) {	throw new IllegalArgumentException("No time remains to execute random reads");	}	
reading random keys from the table for min 

public TimeBoundedMultiThreadedReader(LoadTestDataGenerator dataGen, Configuration conf, TableName tableName, double verifyPercent) throws IOException {	super(dataGen, conf, tableName, verifyPercent);	long timeoutMs = conf.getLong( String.format("%s.%s", TEST_NAME, GET_TIMEOUT_KEY), DEFAULT_GET_TIMEOUT);	timeoutNano = timeoutMs * 1000000;	
timeout for gets 

public void run() {	while (true) {	long rem = Math.min(timeout, reportInterval);	if (rem <= 0) {	break;	}	
remaining execution time min 

protected void verifyResultsAndUpdateMetrics(boolean verify, Get[] gets, long elapsedNano, Result[] results, Table table, boolean isNullExpected) throws IOException {	super.verifyResultsAndUpdateMetrics(verify, gets, elapsedNano, results, table, isNullExpected);	for (Result r : results) {	if (r.isStale()) staleReads.incrementAndGet();	}	if (elapsedNano > timeoutNano) {	timedOutReads.incrementAndGet();	numReadFailures.addAndGet(1);	for (Result r : results) {	
failed for 

for (Result r : results) {	if (r.isStale()) staleReads.incrementAndGet();	}	if (elapsedNano > timeoutNano) {	timedOutReads.incrementAndGet();	numReadFailures.addAndGet(1);	for (Result r : results) {	RegionLocations rl = ((ClusterConnection)connection). locateRegion(tableName, r.getRow(), true, true);	HRegionLocation locations[] = rl.getRegionLocations();	for (HRegionLocation h : locations) {	
location 

========================= hbase sample_3241 =========================

private void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e) {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	
we re the primary replicas 

private void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e) {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	CountDownLatch latch = getPrimaryCdl().get();	try {	if (sleepTime.get() > 0) {	
sleeping for ms 

private void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e) {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	CountDownLatch latch = getPrimaryCdl().get();	try {	if (sleepTime.get() > 0) {	Thread.sleep(sleepTime.get());	} else if (latch.getCount() > 0) {	
waiting for the countercountdownlatch 

} else if (latch.getCount() > 0) {	latch.await(2, TimeUnit.MINUTES);	if (latch.getCount() > 0) {	throw new RuntimeException("Can't wait more");	}	}	} catch (InterruptedException e1) {	LOG.error(e1.toString(), e1);	}	} else {	
we re not the primary replicas 

throw new RuntimeException("Can't wait more");	}	}	} catch (InterruptedException e1) {	LOG.error(e1.toString(), e1);	}	} else {	CountDownLatch latch = getSecondaryCdl().get();	try {	if (latch.getCount() > 0) {	
waiting for the secondary countercountdownlatch 

HTU.getConfiguration().setBoolean(MetricsConnection.CLIENT_SIDE_METRICS_ENABLED_KEY, true);	ConnectionUtils.setupMasterlessConnection(HTU.getConfiguration());	HTU.startMiniCluster(NB_SERVERS);	HTableDescriptor hdt = HTU.createTableDescriptor(TestReplicasClient.class.getSimpleName());	hdt.addCoprocessor(SlowMeCopro.class.getName());	table = HTU.createTable(hdt, new byte[][]{f}, null);	try (RegionLocator locator = HTU.getConnection().getRegionLocator(hdt.getTableName())) {	hriPrimary = locator.getRegionLocation(row, false).getRegionInfo();	}	hriSecondary = new HRegionInfo(hriPrimary.getTable(), hriPrimary.getStartKey(), hriPrimary.getEndKey(), hriPrimary.isSplit(), hriPrimary.getRegionId(), 1);	
master is going to be stopped 

HTableDescriptor hdt = HTU.createTableDescriptor(TestReplicasClient.class.getSimpleName());	hdt.addCoprocessor(SlowMeCopro.class.getName());	table = HTU.createTable(hdt, new byte[][]{f}, null);	try (RegionLocator locator = HTU.getConnection().getRegionLocator(hdt.getTableName())) {	hriPrimary = locator.getRegionLocation(row, false).getRegionInfo();	}	hriSecondary = new HRegionInfo(hriPrimary.getTable(), hriPrimary.getStartKey(), hriPrimary.getEndKey(), hriPrimary.isSplit(), hriPrimary.getRegionId(), 1);	TestRegionServerNoMaster.stopMasterAndAssignMeta(HTU);	Configuration c = new Configuration(HTU.getConfiguration());	c.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);	
master has stopped 

public void testUseRegionWithReplica() throws Exception {	byte[] b1 = "testUseRegionWithReplica".getBytes();	openRegion(hriSecondary);	try {	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	
put done 

byte[] b1 = "testUseRegionWithReplica".getBytes();	openRegion(hriSecondary);	try {	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	Get g = new Get(b1);	Result r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	
get works and is not stale done 

Get g = new Get(b1);	Result r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	SlowMeCopro.sleepTime.set(2000);	g = new Get(b1);	r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	SlowMeCopro.sleepTime.set(0);	
sleep and is not stale done 

Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	SlowMeCopro.sleepTime.set(0);	SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertTrue(r.getColumnCells(f, b1).isEmpty());	SlowMeCopro.getPrimaryCdl().get().countDown();	
stale done 

g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertTrue(r.getColumnCells(f, b1).isEmpty());	SlowMeCopro.getPrimaryCdl().get().countDown();	g = new Get(b1);	g.setCheckExistenceOnly(true);	r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertTrue(r.getExists());	
exists not stale done 

Assert.assertFalse(r.isStale());	Assert.assertTrue(r.getExists());	SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setCheckExistenceOnly(true);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertFalse("The secondary has stale data", r.getExists());	SlowMeCopro.getPrimaryCdl().get().countDown();	
exists stale before flush done 

SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setCheckExistenceOnly(true);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertFalse("The secondary has stale data", r.getExists());	SlowMeCopro.getPrimaryCdl().get().countDown();	flushRegion(hriPrimary);	flushRegion(hriSecondary);	
flush done 

flushRegion(hriPrimary);	flushRegion(hriSecondary);	Thread.sleep(1000 + REFRESH_PERIOD * 2);	SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertFalse(r.isEmpty());	SlowMeCopro.getPrimaryCdl().get().countDown();	
stale done 

Assert.assertFalse(r.isEmpty());	SlowMeCopro.getPrimaryCdl().get().countDown();	SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setCheckExistenceOnly(true);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertTrue(r.getExists());	SlowMeCopro.getPrimaryCdl().get().countDown();	
exists stale after flush done 

public void testHedgedRead() throws Exception {	byte[] b1 = "testHedgedRead".getBytes();	openRegion(hriSecondary);	try {	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	
put done 

byte[] b1 = "testHedgedRead".getBytes();	openRegion(hriSecondary);	try {	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	Get g = new Get(b1);	Result r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	
get works and is not stale done 

SlowMeCopro.getSecondaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertFalse(r.isStale());	Assert.assertFalse(r.getColumnCells(f, b1).isEmpty());	Assert.assertEquals(hedgedReadOps.getCount(), 1);	Assert.assertEquals(hedgedReadWin.getCount(), 0);	SlowMeCopro.sleepTime.set(0);	SlowMeCopro.getSecondaryCdl().get().countDown();	
hedged read occurred but not faster 

SlowMeCopro.getSecondaryCdl().get().countDown();	SlowMeCopro.getPrimaryCdl().set(new CountDownLatch(1));	g = new Get(b1);	g.setConsistency(Consistency.TIMELINE);	r = table.get(g);	Assert.assertTrue(r.isStale());	Assert.assertTrue(r.getColumnCells(f, b1).isEmpty());	Assert.assertEquals(hedgedReadOps.getCount(), 2);	Assert.assertEquals(hedgedReadWin.getCount(), 1);	SlowMeCopro.getPrimaryCdl().get().countDown();	
hedged read occurred and faster 

List<Put> puts = new ArrayList<>(2);	byte[] b1 = Bytes.toBytes("testCancelOfMultiGet" + 0);	Put p = new Put(b1);	p.addColumn(f, b1, b1);	puts.add(p);	byte[] b2 = Bytes.toBytes("testCancelOfMultiGet" + 1);	p = new Put(b2);	p.addColumn(f, b2, b2);	puts.add(p);	table.put(puts);	
put done 

byte[] b1 = Bytes.toBytes("testCancelOfMultiGet" + 0);	Put p = new Put(b1);	p.addColumn(f, b1, b1);	puts.add(p);	byte[] b2 = Bytes.toBytes("testCancelOfMultiGet" + 1);	p = new Put(b2);	p.addColumn(f, b2, b2);	puts.add(p);	table.put(puts);	flushRegion(hriPrimary);	
flush done 

public void testCancelOfScan() throws Exception {	openRegion(hriSecondary);	int NUMROWS = 100;	try {	for (int i = 0; i < NUMROWS; i++) {	byte[] b1 = Bytes.toBytes("testUseRegionWithReplica" + i);	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	}	
put done 

for (int i = 0; i < NUMROWS; i++) {	byte[] b1 = Bytes.toBytes("testUseRegionWithReplica" + i);	Put p = new Put(b1);	p.addColumn(f, b1, b1);	table.put(p);	}	int caching = 20;	byte[] start;	start = Bytes.toBytes("testUseRegionWithReplica" + 0);	flushRegion(hriPrimary);	
flush done 

for (int i = 0; i < NUMROWS; i++) {	byte[] b1 = Bytes.toBytes("testUseRegionWithReplica" + i);	for (int col = 0; col < NUMCOLS; col++) {	Put p = new Put(b1);	String qualifier = "qualifer" + col;	KeyValue kv = new KeyValue(b1, f, qualifier.getBytes());	p.add(kv);	table.put(p);	}	}	
put done 

int caching = 20;	long maxResultSize = Long.MAX_VALUE;	byte[] start;	if (reversed) start = Bytes.toBytes("testUseRegionWithReplica" + (NUMROWS - 1));	else start = Bytes.toBytes("testUseRegionWithReplica" + 0);	scanWithReplicas(reversed, small, Consistency.TIMELINE, caching, maxResultSize, start, NUMROWS, NUMCOLS, false, false);	SlowMeCopro.sleepTime.set(5000);	scanWithReplicas(reversed, small, Consistency.STRONG, caching, maxResultSize, start, NUMROWS, NUMCOLS, false, false);	SlowMeCopro.sleepTime.set(0);	flushRegion(hriPrimary);	
flush done 

map.put(row, true);	for (Cell cell : r.rawCells()) {	cellCount++;	}	if (!slowNext) Assert.assertTrue(r.isStale() == staleExpected);	if (r.isStale()) countOfStale++;	}	Assert.assertTrue("Count of rows " + rowCount + " num rows expected " + numRows, rowCount == numRows);	Assert.assertTrue("Count of cells: " + cellCount + " cells expected: " + numRows * numCols, cellCount == (numRows * numCols));	if (slowNext) {	
count of stale 

========================= hbase sample_2132 =========================

protected void writeWALTrailer() {	try {	int trailerSize = 0;	if (this.trailer == null) {	
waltrailer is null continuing with default 

protected void writeWALTrailer() {	try {	int trailerSize = 0;	if (this.trailer == null) {	this.trailer = buildWALTrailer(WALTrailer.newBuilder());	trailerSize = this.trailer.getSerializedSize();	} else if ((trailerSize = this.trailer.getSerializedSize()) > this.trailerWarnSize) {	
please investigate waltrailer usage trailer size maximum size 

try {	int trailerSize = 0;	if (this.trailer == null) {	this.trailer = buildWALTrailer(WALTrailer.newBuilder());	trailerSize = this.trailer.getSerializedSize();	} else if ((trailerSize = this.trailer.getSerializedSize()) > this.trailerWarnSize) {	}	length.set(writeWALTrailerAndMagic(trailer, ProtobufLogReader.PB_WAL_COMPLETE_MAGIC));	this.trailerWritten = true;	} catch (IOException ioe) {	
failed to write trailer non fatal continuing 

========================= hbase sample_2562 =========================

private void readResponse(ChannelHandlerContext ctx, ByteBuf buf) throws IOException {	int totalSize = buf.readInt();	ByteBufInputStream in = new ByteBufInputStream(buf);	ResponseHeader responseHeader = ResponseHeader.parseDelimitedFrom(in);	int id = responseHeader.getCallId();	if (LOG.isTraceEnabled()) {	
got response header totalsize bytes 

return;	}	} else {	remoteExc = null;	}	Call call = id2Call.remove(id);	if (call == null) {	int readSoFar = IPCUtil.getTotalSizeWhenWrittenDelimited(responseHeader);	int whatIsLeftToRead = totalSize - readSoFar;	if (LOG.isDebugEnabled()) {	
unknown callid skipping over this response of bytes 

public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {	if (evt instanceof IdleStateEvent) {	IdleStateEvent idleEvt = (IdleStateEvent) evt;	switch (idleEvt.state()) {	case WRITER_IDLE: if (id2Call.isEmpty()) {	if (LOG.isTraceEnabled()) {	
shutdown connection to because idle for a long time 

public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {	if (evt instanceof IdleStateEvent) {	IdleStateEvent idleEvt = (IdleStateEvent) evt;	switch (idleEvt.state()) {	case WRITER_IDLE: if (id2Call.isEmpty()) {	if (LOG.isTraceEnabled()) {	}	conn.shutdown();	}	break;	
unrecognized idle state 

========================= hbase sample_229 =========================

public void makeAssertions(ImmutableBytesWritable key, Result value) throws IOException {	if (value.size() != 1) {	throw new IOException("There should only be one input column");	}	Map<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> cf = value.getMap();	if (!cf.containsKey(INPUT_FAMILY)) {	throw new IOException("Wrong input columns. Missing: '" + Bytes.toString(INPUT_FAMILY) + "'.");	}	String val = Bytes.toStringBinary(value.getValue(INPUT_FAMILY, null));	
map key value 

protected void makeAssertions(ImmutableBytesWritable key, Iterable<ImmutableBytesWritable> values) {	int count = 0;	for (ImmutableBytesWritable value : values) {	String val = Bytes.toStringBinary(value.get());	
reduce key value 

protected void cleanup(Configuration c) {	String startRow = c.get(KEY_STARTROW);	String lastRow = c.get(KEY_LASTROW);	
cleanup first first start row startrow 

protected void cleanup(Configuration c) {	String startRow = c.get(KEY_STARTROW);	String lastRow = c.get(KEY_LASTROW);	
cleanup last last last row lastrow 

private void testScan(String start, String stop, String last) throws IOException, InterruptedException, ClassNotFoundException {	String jobName = "Scan" + (start != null ? start.toUpperCase(Locale.ROOT) : "Empty") + "To" + (stop != null ? stop.toUpperCase(Locale.ROOT) : "Empty");	
before map reduce startup job 

Scan scan = new Scan();	scan.addFamily(INPUT_FAMILY);	scan.setAttribute(Scan.SCAN_ATTRIBUTES_TABLE_NAME, Bytes.toBytes(tableName));	if (start != null) {	scan.setStartRow(Bytes.toBytes(start));	}	if (stop != null) {	scan.setStopRow(Bytes.toBytes(stop));	}	scans.add(scan);	
scan before 

protected void runJob(String jobName, Configuration c, List<Scan> scans) throws IOException, InterruptedException, ClassNotFoundException {	Job job = new Job(c, jobName);	initJob(scans, job);	job.setReducerClass(ScanReducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	
started 

protected void runJob(String jobName, Configuration c, List<Scan> scans) throws IOException, InterruptedException, ClassNotFoundException {	Job job = new Job(c, jobName);	initJob(scans, job);	job.setReducerClass(ScanReducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	job.waitForCompletion(true);	assertTrue(job.isSuccessful());	
after map reduce completion job 

========================= hbase sample_3373 =========================

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	
initializing checking cluster has servers 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	util.initializeCluster(getMinServerCount());	
done initializing checking cluster 

protected synchronized Connection getConnection(){	if (this.connection == null) {	try {	Connection connection = ConnectionFactory.createConnection(getConf());	setConnection(connection);	} catch (IOException e) {	
failed to establish connection 

protected ColumnFamilyDescriptor selectFamily(TableDescriptor td) {	if (td == null) {	return null;	}	ColumnFamilyDescriptor[] families = td.getColumnFamilies();	if (families.length == 0){	
no column families in table 

public void run() {	while (running.get()) {	ACTION selectedAction = ACTION.values()[RandomUtils.nextInt() % ACTION.values().length];	this.action = selectedAction;	
performing action 

case ALTER_FAMILYVERSIONS: new AlterFamilyVersionsAction().perform();	break;	case ALTER_FAMILYENCODING: new AlterFamilyEncodingAction().perform();	break;	}	} catch (Exception ex) {	this.savedException = ex;	return;	}	}	
stopped 

private void checkException(List<Worker> workers){	if(workers == null || workers.isEmpty()) return;	for (Worker worker : workers){	Exception e = worker.getSavedException();	if (e != null) {	
found exception in thread 

private int runTest() throws Exception {	
starting the test 

private int runTest() throws Exception {	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, DEFAULT_RUN_TIME);	String numThreadKey = String.format(NUM_THREADS_KEY, this.getClass().getSimpleName());	numThreads = util.getConfiguration().getInt(numThreadKey, DEFAULT_NUM_THREADS);	ArrayList<Worker> workers = new ArrayList<>(numThreads);	for (int i = 0; i < numThreads; i++) {	checkException(workers);	Worker worker = new Worker();	
launching worker thread 

String numThreadKey = String.format(NUM_THREADS_KEY, this.getClass().getSimpleName());	numThreads = util.getConfiguration().getInt(numThreadKey, DEFAULT_NUM_THREADS);	ArrayList<Worker> workers = new ArrayList<>(numThreads);	for (int i = 0; i < numThreads; i++) {	checkException(workers);	Worker worker = new Worker();	workers.add(worker);	worker.start();	}	Threads.sleep(runtime / 2);	
stopping creating new tables 

ArrayList<Worker> workers = new ArrayList<>(numThreads);	for (int i = 0; i < numThreads; i++) {	checkException(workers);	Worker worker = new Worker();	workers.add(worker);	worker.start();	}	Threads.sleep(runtime / 2);	create_table.set(false);	Threads.sleep(runtime / 2);	
runtime is up 

worker.start();	}	Threads.sleep(runtime / 2);	create_table.set(false);	Threads.sleep(runtime / 2);	running.set(false);	checkException(workers);	for (Worker worker : workers) {	worker.join();	}	
all worker threads stopped 

worker.start();	}	Threads.sleep(runtime / 2);	create_table.set(false);	Threads.sleep(runtime / 2);	running.set(false);	checkException(workers);	for (Worker worker : workers) {	worker.join();	}	
verify actions of all threads succeeded 

}	Threads.sleep(runtime / 2);	create_table.set(false);	Threads.sleep(runtime / 2);	running.set(false);	checkException(workers);	for (Worker worker : workers) {	worker.join();	}	checkException(workers);	
verify namespaces 

Threads.sleep(runtime / 2);	create_table.set(false);	Threads.sleep(runtime / 2);	running.set(false);	checkException(workers);	for (Worker worker : workers) {	worker.join();	}	checkException(workers);	verifyNamespaces();	
verify states of all tables 

running.set(false);	checkException(workers);	for (Worker worker : workers) {	worker.join();	}	checkException(workers);	verifyNamespaces();	verifyTables();	HBaseFsck hbck = null;	try {	
running hbck 

checkException(workers);	verifyNamespaces();	verifyTables();	HBaseFsck hbck = null;	try {	hbck = HbckTestingUtil.doFsck(util.getConfiguration(), false);	if (HbckTestingUtil.inconsistencyFound(hbck)) {	keepObjectsAtTheEnd = true;	}	HbckTestingUtil.assertNoErrors(hbck);	
finished hbck 

public static void main(String[] args) throws Exception {	Configuration conf = HBaseConfiguration.create();	IntegrationTestingUtility.setUseDistributedCluster(conf);	IntegrationTestDDLMasterFailover masterFailover = new IntegrationTestDDLMasterFailover();	Connection connection = null;	int ret = 1;	try {	
setting up connection 

Configuration conf = HBaseConfiguration.create();	IntegrationTestingUtility.setUseDistributedCluster(conf);	IntegrationTestDDLMasterFailover masterFailover = new IntegrationTestDDLMasterFailover();	Connection connection = null;	int ret = 1;	try {	connection = ConnectionFactory.createConnection(conf);	masterFailover.setConnection(connection);	ret = ToolRunner.run(conf, masterFailover, args);	} catch (IOException e){	
failed to establish connection aborting test 

========================= hbase sample_3236 =========================

public static long getDefaultBlockSize(final FileSystem fs, final Path path) throws IOException {	Method m = null;	Class<? extends FileSystem> cls = fs.getClass();	try {	m = cls.getMethod("getDefaultBlockSize", new Class<?>[] { Path.class });	} catch (NoSuchMethodException e) {	
filesystem doesn t support getdefaultblocksize 

public static long getDefaultBlockSize(final FileSystem fs, final Path path) throws IOException {	Method m = null;	Class<? extends FileSystem> cls = fs.getClass();	try {	m = cls.getMethod("getDefaultBlockSize", new Class<?>[] { Path.class });	} catch (NoSuchMethodException e) {	} catch (SecurityException e) {	
doesn t have access to getdefaultblocksize on filesystems 

public static short getDefaultReplication(final FileSystem fs, final Path path) throws IOException {	Method m = null;	Class<? extends FileSystem> cls = fs.getClass();	try {	m = cls.getMethod("getDefaultReplication", new Class<?>[] { Path.class });	} catch (NoSuchMethodException e) {	
filesystem doesn t support getdefaultreplication 

public static short getDefaultReplication(final FileSystem fs, final Path path) throws IOException {	Method m = null;	Class<? extends FileSystem> cls = fs.getClass();	try {	m = cls.getMethod("getDefaultReplication", new Class<?>[] { Path.class });	} catch (NoSuchMethodException e) {	} catch (SecurityException e) {	
doesn t have access to getdefaultreplication on filesystems 

if (enablePermissions) {	try {	FsPermission perm = new FsPermission(FULL_RWX_PERMISSIONS);	String mask = conf.get(permssionConfKey);	if (mask == null) {	return FsPermission.getFileDefault();	}	FsPermission umask = new FsPermission(mask);	return perm.applyUMask(umask);	} catch (IllegalArgumentException e) {	
incorrect umask attempted to be created using default file permissions 

public static void setStoragePolicy(final FileSystem fs, final Configuration conf, final Path path, final String policyKey, final String defaultPolicy) {	String storagePolicy = conf.get(policyKey, defaultPolicy).toUpperCase(Locale.ROOT);	if (storagePolicy.equals(defaultPolicy)) {	if (LOG.isTraceEnabled()) {	
default policy of requested exiting early 

public static void setStoragePolicy(final FileSystem fs, final Path path, final String storagePolicy) {	if (storagePolicy == null) {	if (LOG.isTraceEnabled()) {	
we were passed a null storagepolicy exiting early 

public static void setStoragePolicy(final FileSystem fs, final Path path, final String storagePolicy) {	if (storagePolicy == null) {	if (LOG.isTraceEnabled()) {	}	return;	}	final String trimmedStoragePolicy = storagePolicy.trim();	if (trimmedStoragePolicy.isEmpty()) {	if (LOG.isTraceEnabled()) {	
we were passed an empty storagepolicy exiting early 

if (!warningMap.containsKey(fs)) {	warningMap.put(fs, true);	LOG.warn("Unable to set storagePolicy=" + storagePolicy + " for path=" + path + ". " + "DEBUG log level might have more details.", e);	} else if (LOG.isDebugEnabled()) {	LOG.debug("Unable to set storagePolicy=" + storagePolicy + " for path=" + path, e);	}	if (e instanceof InvocationTargetException) {	final Throwable exception = e.getCause();	if (exception instanceof RemoteException && HadoopIllegalArgumentException.class.getName().equals( ((RemoteException)exception).getClassName())) {	if (LOG.isDebugEnabled()) {	
given storage policy was rejected and probably isn t a valid policy for the version of hadoop you re running i e if you re trying to use ssd related policies then you re likely missing hdfs for more information see the archivalstorage docs for your hadoop release 

} else if (LOG.isDebugEnabled()) {	LOG.debug("Unable to set storagePolicy=" + storagePolicy + " for path=" + path, e);	}	if (e instanceof InvocationTargetException) {	final Throwable exception = e.getCause();	if (exception instanceof RemoteException && HadoopIllegalArgumentException.class.getName().equals( ((RemoteException)exception).getClassName())) {	if (LOG.isDebugEnabled()) {	}	} else if (exception instanceof UnsupportedOperationException) {	if (LOG.isDebugEnabled()) {	
the underlying filesystem implementation doesn t support setstoragepolicy this is probably intentional on their part since hdfs appears to be present in your version of hadoop for more information check the hadoop documentation on archivalstorage the hadoop filesystem specification docs from hadoop and or related documentation from the provider of the underlying filesystem its name should appear in the stacktrace that accompanies this message note in particular that hadoop s local filesystem implementation doesn t support storage policies 

public static FileStatus [] listStatus(final FileSystem fs, final Path dir, final PathFilter filter) throws IOException {	FileStatus [] status = null;	try {	status = filter == null ? fs.listStatus(dir) : fs.listStatus(dir, filter);	} catch (FileNotFoundException fnfe) {	if (LOG.isTraceEnabled()) {	
doesn t exist 

try {	RemoteIterator<LocatedFileStatus> locatedFileStatusRemoteIterator = fs .listFiles(dir, false);	while (locatedFileStatusRemoteIterator.hasNext()) {	if (status == null) {	status = Lists.newArrayList();	}	status.add(locatedFileStatusRemoteIterator.next());	}	} catch (FileNotFoundException fnfe) {	if (LOG.isTraceEnabled()) {	
doesn t exist 

public static void setupShortCircuitRead(final Configuration conf) {	boolean shortCircuitSkipChecksum = conf.getBoolean("dfs.client.read.shortcircuit.skip.checksum", false);	boolean useHBaseChecksum = conf.getBoolean(HConstants.HBASE_CHECKSUM_VERIFICATION, true);	if (shortCircuitSkipChecksum) {	
configuration should not be set to true hbase checksum doesn t require it see https assert shortcircuitskipchecksum 

if (stream == null) {	throw new NullPointerException("stream parameter must not be null.");	}	boolean result = true;	if (StreamCapabilities.PRESENT) {	result = false;	if (StreamCapabilities.CLASS.isAssignableFrom(stream.getClass())) {	try {	result = ((Boolean)StreamCapabilities.METHOD.invoke(stream, capability)).booleanValue();	} catch (IllegalAccessException|IllegalArgumentException|InvocationTargetException exception) {	
your hadoop installation s streamcapabilities implementation doesn t match our understanding of how it s supposed to work please file a jira and include the following stack trace in the mean time we re interpreting this behavior difference as a lack of capability support which will probably cause a failure 

========================= hbase sample_946 =========================

public void initialize(RegionServerServices rss) throws KeeperException {	this.rss = rss;	ZKWatcher zkw = rss.getZooKeeper();	this.memberRpcs = new ZKProcedureMemberRpcs(zkw, getProcedureSignature());	ThreadPoolExecutor pool = ProcedureMember.defaultPool(rss.getServerName().toString(), 1);	this.member = new ProcedureMember(memberRpcs, pool, new SimleSubprocedureBuilder());	
initialized 

public void start() {	this.memberRpcs.start(rss.getServerName().toString(), member);	
started 

public void stop(boolean force) throws IOException {	
stop 

public Subprocedure buildSubprocedure(String name) {	if (rss.isStopping() || rss.isStopped()) {	throw new IllegalStateException("Can't start procedure on RS: " + rss.getServerName() + ", because stopping/stopped!");	}	
attempting to run a procedure 

public Subprocedure buildSubprocedure(String name, byte[] data) {	
building procedure 

public boolean waitForOutstandingTasks() throws ForeignException {	
waiting for procedure to finish 

public void abort(String why, Throwable e) {	if (this.aborted) return;	this.aborted = true;	
aborting because 

public SimpleSubprocedure(RegionServerServices rss, ProcedureMember member, ForeignExceptionDispatcher errorListener, SimpleSubprocedurePool taskManager, String name) {	super(member, name, errorListener, 500, 60000);	
constructing a simplesubprocedure 

public Void call() throws Exception {	
execute subprocedure on 

========================= hbase sample_1572 =========================

public void testFullRestoreRemote() throws Exception {	
test remote full backup on a single table 

public void testFullRestoreRemote() throws Exception {	String backupId = backupTables(BackupType.FULL, toList(table1.getNameAsString()), BACKUP_REMOTE_ROOT_DIR);	
backup complete 

========================= hbase sample_550 =========================

public void execute(Admin admin) {	
executing merging normalization plan 

public void execute(Admin admin) {	try {	admin.mergeRegionsAsync(firstRegion.getEncodedNameAsBytes(), secondRegion.getEncodedNameAsBytes(), true);	} catch (IOException ex) {	
error during region merge 

========================= hbase sample_2866 =========================

try {	locator = getLocator(table);	return ThriftUtilities.regionLocationsFromHBase(locator.getAllRegionLocations());	} catch (IOException e) {	throw getTIOError(e);	} finally {	if (locator != null) {	try {	locator.close();	} catch (IOException e) {	
couldn t close the locator 

byte[] rowBytes = byteBufferToByteArray(row);	HRegionLocation hrl = locator.getRegionLocation(rowBytes, reload);	return ThriftUtilities.regionLocationFromHBase(hrl);	} catch (IOException e) {	throw getTIOError(e);	} finally {	if (locator != null) {	try {	locator.close();	} catch (IOException e) {	
couldn t close the locator 

========================= hbase sample_784 =========================

public void start() throws IOException {	
namespace state manager started 

private NamespaceDescriptor getNamespaceDescriptor(String namespaceAsString) {	try {	return this.master.getClusterSchema().getNamespace(namespaceAsString);	} catch (IOException e) {	
error while fetching namespace descriptor for namespace 

addNamespace(namespace.getName());	List<TableName> tables = this.master.listTableNamesByNamespace(namespace.getName());	for (TableName table : tables) {	if (table.isSystemTable()) {	continue;	}	List<RegionInfo> regions = MetaTableAccessor.getTableRegions(this.master.getConnection(), table, true);	addTable(table, regions.size());	}	}	
finished updating state of namespaces 

========================= hbase sample_2470 =========================

return;	}	long now = System.currentTimeMillis();	if (firstRecordInBufferTimestamp.get() + writeBufferPeriodicFlushTimeoutMs.get() > now) {	return;	}	try {	executedWriteBufferPeriodicFlushes.incrementAndGet();	flush();	} catch (InterruptedIOException | RetriesExhaustedWithDetailsException e) {	
exception during timercallbackforwritebufferperiodicflush 

disableWriteBufferPeriodicFlush();	backgroundFlushCommits(true);	if (cleanupPoolOnClose) {	this.pool.shutdown();	boolean terminated;	int loopCnt = 0;	do {	terminated = this.pool.awaitTermination(60, TimeUnit.SECONDS);	loopCnt += 1;	if (loopCnt >= 10) {	
close failed to terminate pool after minutes abandoning pool 

int loopCnt = 0;	do {	terminated = this.pool.awaitTermination(60, TimeUnit.SECONDS);	loopCnt += 1;	if (loopCnt >= 10) {	break;	}	} while (!terminated);	}	} catch (InterruptedException e) {	
waitfortermination interrupted 

private void backgroundFlushCommits(boolean synchronous) throws InterruptedIOException, RetriesExhaustedWithDetailsException {	if (!synchronous && writeAsyncBuffer.isEmpty()) {	return;	}	if (!synchronous) {	QueueRowAccess taker = new QueueRowAccess();	AsyncProcessTask task = wrapAsyncProcessTask(taker);	try {	ap.submit(task);	if (ap.hasError()) {	
one or more of the operations have failed waiting for all operation in progress to finish successfully or not 

========================= hbase sample_442 =========================

});	} finally {	exec.shutdown();	}	} catch (Exception e) {	String reason = "Failed snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " due to exception:" + e.getMessage();	ForeignException ee = new ForeignException(reason, e);	monitor.receive(ee);	status.abort("Snapshot of table: "+ snapshotTable + " failed because " + e.getMessage());	} finally {	
marking snapshot as finished 

========================= hbase sample_2759 =========================

for (Thread t: threads) {	t.start();	}	for (Thread t: threads) {	try {	t.join();	} catch (InterruptedException e) {	e.printStackTrace();	}	}	
test took 

========================= hbase sample_1460 =========================

public void testSleepWithoutInterrupt() throws InterruptedException {	Thread sleeper = new Thread(new Runnable() {	public void run() {	
sleeper thread sleeping for 

public void testSleepWithoutInterrupt() throws InterruptedException {	Thread sleeper = new Thread(new Runnable() {	public void run() {	Threads.sleepWithoutInterrupt(SLEEP_TIME_MS);	
sleeper thread finished sleeping 

public void testSleepWithoutInterrupt() throws InterruptedException {	Thread sleeper = new Thread(new Runnable() {	public void run() {	Threads.sleepWithoutInterrupt(SLEEP_TIME_MS);	wasInterrupted.set(Thread.currentThread().isInterrupted());	}	});	
starting sleeper thread ms 

public void testSleepWithoutInterrupt() throws InterruptedException {	Thread sleeper = new Thread(new Runnable() {	public void run() {	Threads.sleepWithoutInterrupt(SLEEP_TIME_MS);	wasInterrupted.set(Thread.currentThread().isInterrupted());	}	});	sleeper.start();	long startTime = System.currentTimeMillis();	
main thread sleeping for ms 

public void testSleepWithoutInterrupt() throws InterruptedException {	Thread sleeper = new Thread(new Runnable() {	public void run() {	Threads.sleepWithoutInterrupt(SLEEP_TIME_MS);	wasInterrupted.set(Thread.currentThread().isInterrupted());	}	});	sleeper.start();	long startTime = System.currentTimeMillis();	Threads.sleep(200);	
interrupting the sleeper thread and sleeping for ms 

public void run() {	Threads.sleepWithoutInterrupt(SLEEP_TIME_MS);	wasInterrupted.set(Thread.currentThread().isInterrupted());	}	});	sleeper.start();	long startTime = System.currentTimeMillis();	Threads.sleep(200);	sleeper.interrupt();	Threads.sleep(500);	
interrupting the sleeper thread and sleeping for ms 

wasInterrupted.set(Thread.currentThread().isInterrupted());	}	});	sleeper.start();	long startTime = System.currentTimeMillis();	Threads.sleep(200);	sleeper.interrupt();	Threads.sleep(500);	sleeper.interrupt();	Threads.sleep(800);	
interrupting the sleeper thread again 

Threads.sleep(200);	sleeper.interrupt();	Threads.sleep(500);	sleeper.interrupt();	Threads.sleep(800);	sleeper.interrupt();	sleeper.join();	assertTrue("sleepWithoutInterrupt did not preserve the thread's " + "interrupted status", wasInterrupted.get());	long timeElapsed = System.currentTimeMillis() - startTime;	assertTrue("Elapsed time " + timeElapsed + " ms is out of the expected " + " sleep time of " + SLEEP_TIME_MS, SLEEP_TIME_MS - timeElapsed < TOLERANCE_MS);	
target sleep time time elapsed 

========================= hbase sample_854 =========================

private void rethrowEofException(IOException ioEx) throws IOException {	boolean isEof = false;	try {	isEof = this.in.available() == 0;	} catch (Throwable t) {	
error getting available for error message ignoring 

private void rethrowEofException(IOException ioEx) throws IOException {	boolean isEof = false;	try {	isEof = this.in.available() == 0;	} catch (Throwable t) {	}	if (!isEof) throw ioEx;	if (LOG.isTraceEnabled()) {	
partial cell read caused by eof 

========================= hbase sample_1030 =========================

Table htab1A = connection1.getTable(tabAName);	Table htab2A = connection2.getTable(tabAName);	Table htab1B = connection1.getTable(tabBName);	Table htab2B = connection2.getTable(tabBName);	ReplicationPeerConfig rpc = admin1.getReplicationPeerConfig(peerId);	admin1.updateReplicationPeerConfig(peerId, ReplicationPeerConfig.newBuilder(rpc).setReplicateAllUserTables(false).build());	rpc = admin1.getReplicationPeerConfig(peerId);	Set<String> namespaces = new HashSet<>();	namespaces.add(ns1);	admin1.updateReplicationPeerConfig(peerId, ReplicationPeerConfig.newBuilder(rpc).setNamespaces(namespaces).build());	
update peer config 

ensureRowNotExisted(htab2A, row, f1Name, f2Name);	put(htab1B, row, f1Name, f2Name);	ensureRowNotExisted(htab2B, row, f1Name, f2Name);	rpc = admin1.getReplicationPeerConfig(peerId);	namespaces = new HashSet<>();	namespaces.add(ns2);	Map<TableName, List<String>> tableCfs = new HashMap<>();	tableCfs.put(tabAName, new ArrayList<>());	tableCfs.get(tabAName).add("f1");	admin1.updateReplicationPeerConfig(peerId, ReplicationPeerConfig.newBuilder(rpc) .setNamespaces(namespaces).setTableCFsMap(tableCfs).build());	
update peer config 

private void ensureRowExisted(Table target, byte[] row, byte[]... families) throws Exception {	for (byte[] fam : families) {	Get get = new Get(row);	get.addFamily(fam);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = target.get(get);	if (res.isEmpty()) {	
row not available 

private void ensureRowNotExisted(Table target, byte[] row, byte[]... families) throws Exception {	for (byte[] fam : families) {	Get get = new Get(row);	get.addFamily(fam);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for delete replication");	}	Result res = target.get(get);	if (res.size() >= 1) {	
row not deleted 

========================= hbase sample_1933 =========================

public void clearChildZNodes() throws KeeperException {	
clearing all procedure znodes 

public void clearZNodes(String procedureName) throws KeeperException {	
clearing all znodes for procedure including nodes 

========================= hbase sample_2489 =========================

return false;	}	hfilePath = HFileLink.getHFileFromBackReference(MobUtils.getMobHome(getConf()), filePath);	if (fs.exists(hfilePath)) {	return false;	}	hfilePath = HFileLink.getHFileFromBackReference(FSUtils.getRootDir(getConf()), filePath);	return !fs.exists(hfilePath);	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
couldn t verify if the referenced file still exists keep it just in case 

========================= hbase sample_2870 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	
performing action merge random adjacent regions of table 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.size() < 2) {	
table doesn t have enough regions to merge 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.size() < 2) {	return;	}	int i = RandomUtils.nextInt(0, regions.size() - 1);	HRegionInfo a = regions.get(i++);	HRegionInfo b = regions.get(i);	
merging and 

}	int i = RandomUtils.nextInt(0, regions.size() - 1);	HRegionInfo a = regions.get(i++);	HRegionInfo b = regions.get(i);	if (context.isStopping()) {	return;	}	try {	admin.mergeRegionsAsync(a.getEncodedNameAsBytes(), b.getEncodedNameAsBytes(), false);	} catch (Exception ex) {	
merge failed might be caused by other chaos 

========================= hbase sample_3332 =========================

final TableName tableName = TableName.valueOf(name.getMethodName());	Table ht = TEST_UTIL.createTable(tableName, FAMILY);	byte[] r0 = Bytes.toBytes("row-0");	byte[] r1 = Bytes.toBytes("row-1");	byte[] r2 = Bytes.toBytes("row-2");	byte[] r3 = Bytes.toBytes("row-3");	putToTable(ht, r0);	putToTable(ht, r1);	putToTable(ht, r2);	putToTable(ht, r3);	
wrote our three values 

putToTable(ht, r2);	putToTable(ht, r3);	RSRpcServicesWithScanTimeout.seqNoToSleepOn = 1;	Scan scan = new Scan();	scan.setCaching(1);	ResultScanner scanner = ht.getScanner(scan);	Result result = scanner.next();	assertTrue("Expected row: row-0", Bytes.equals(r0, result.getRow()));	result = scanner.next();	assertTrue("Expected row: row-1", Bytes.equals(r1, result.getRow()));	
got expected first row 

public ScanResponse scan(final RpcController controller, final ScanRequest request) throws ServiceException {	if (request.hasScannerId()) {	ScanResponse scanResponse = super.scan(controller, request);	if (this.tableScannerId == request.getScannerId() && (sleepAlways || (!slept && seqNoToSleepOn == request.getNextCallSeq()))) {	try {	
sleeping 

========================= hbase sample_2036 =========================

private void checkBalance(int masterCount, int rsCount) throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.startMiniCluster(MASTERS, SLAVES);	TableName tn = TableName.valueOf(this.name.getMethodName());	try {	Table t = TEST_UTIL.createMultiRegionTable(tn, HConstants.CATALOG_FAMILY, REGIONS);	
server 

cluster.killMaster(oldMaster.getServerName());	oldMaster.join();	while (cluster.getMaster() == null || cluster.getMaster().getServerName().equals(oldMaster.getServerName())) {	Threads.sleep(10);	}	while (!cluster.getMaster().isInitialized()) {	Threads.sleep(10);	}	while (cluster.getMaster().getAssignmentManager(). computeRegionInTransitionStat().getTotalRITs() > 0) {	Threads.sleep(100);	
waiting on rit to go to zero before calling balancer 

oldMaster.join();	while (cluster.getMaster() == null || cluster.getMaster().getServerName().equals(oldMaster.getServerName())) {	Threads.sleep(10);	}	while (!cluster.getMaster().isInitialized()) {	Threads.sleep(10);	}	while (cluster.getMaster().getAssignmentManager(). computeRegionInTransitionStat().getTotalRITs() > 0) {	Threads.sleep(100);	}	
cluster is up running balancer 

while (cluster.getMaster().getAssignmentManager(). computeRegionInTransitionStat().getTotalRITs() > 0) {	Threads.sleep(100);	}	cluster.getMaster().balance();	regions = cluster.getMaster().getRegions();	int mNewActualCount = regions.size();	if (masterCount == 0 || masterCount == SYSTEM_REGIONS) {	assertEquals(masterCount, mNewActualCount);	}	} finally {	
running shutdown of cluster 

========================= hbase sample_1860 =========================

public void loadTableAndKillRS(HBaseTestingUtility util) throws Exception {	int rsToKill1 = util.getHBaseCluster().getServerWithMeta() == 0 ? 1 : 0;	Thread killer = killARegionServer(util, 5000, rsToKill1);	
start loading table 

public void loadTableAndKillRS(HBaseTestingUtility util) throws Exception {	int rsToKill1 = util.getHBaseCluster().getServerWithMeta() == 0 ? 1 : 0;	Thread killer = killARegionServer(util, 5000, rsToKill1);	int initialCount = utility1.loadTable(htable1, famName);	
done loading table 

public void loadTableAndKillRS(HBaseTestingUtility util) throws Exception {	int rsToKill1 = util.getHBaseCluster().getServerWithMeta() == 0 ? 1 : 0;	Thread killer = killARegionServer(util, 5000, rsToKill1);	int initialCount = utility1.loadTable(htable1, famName);	killer.join(5000);	
done waiting for threads 

killer.join(5000);	Result[] res;	while (true) {	try {	Scan scan = new Scan();	ResultScanner scanner = htable1.getScanner(scan);	res = scanner.next(initialCount);	scanner.close();	break;	} catch (UnknownScannerException ex) {	
cluster wasn t ready yet restarting scanner 

try {	Scan scan = new Scan();	ResultScanner scanner = htable1.getScanner(scan);	res = scanner.next(initialCount);	scanner.close();	break;	} catch (UnknownScannerException ex) {	}	}	if (res.length != initialCount) {	
we lost some rows on the master cluster 

private static Thread killARegionServer(final HBaseTestingUtility utility, final long timeout, final int rs) {	Thread killer = new Thread() {	public void run() {	try {	Thread.sleep(timeout);	utility.getHBaseCluster().getRegionServer(rs).stop("Stopping as part of the test");	} catch (Exception e) {	
couldn t kill a region server 

========================= hbase sample_1925 =========================

protected Writer createWriterInstance(final Path path) throws IOException {	if (!initialized || doFileRolls) {	
creating new writer instance 

protected Writer createWriterInstance(final Path path) throws IOException {	if (!initialized || doFileRolls) {	final ProtobufLogWriter writer = new IOTestWriter();	try {	writer.init(fs, path, conf, false);	} catch (CommonFSUtils.StreamLacksCapabilityException exception) {	throw new IOException("Can't create writer instance because underlying FileSystem " + "doesn't support needed stream capabilities.", exception);	}	if (!initialized) {	
storing initial writer instance in case file rolling isn t allowed 

try {	writer.init(fs, path, conf, false);	} catch (CommonFSUtils.StreamLacksCapabilityException exception) {	throw new IOException("Can't create writer instance because underlying FileSystem " + "doesn't support needed stream capabilities.", exception);	}	if (!initialized) {	noRollsWriter = writer;	}	return writer;	} else {	
wal rolling disabled returning the first writer 

public void init(FileSystem fs, Path path, Configuration conf, boolean overwritable) throws IOException, CommonFSUtils.StreamLacksCapabilityException {	Collection<String> operations = conf.getStringCollection(ALLOWED_OPERATIONS);	if (operations.isEmpty() || operations.contains(AllowedOperations.all.name())) {	doAppends = doSyncs = true;	} else if (operations.contains(AllowedOperations.none.name())) {	doAppends = doSyncs = false;	} else {	doAppends = operations.contains(AllowedOperations.append.name());	doSyncs = operations.contains(AllowedOperations.sync.name());	}	
iotestwriter initialized with appends enabled disabled and syncs enabled disabled 

========================= hbase sample_1358 =========================

super.setClusterMetrics(st);	updateRegionLoad();	for(CostFromRegionLoadFunction cost : regionLoadFunctions) {	cost.setClusterMetrics(st);	}	try {	int tablesCount = isByTable ? services.getTableDescriptors().getAll().size() : 1;	int functionsCount = getCostFunctionNames().length;	updateMetricsSize(tablesCount * (functionsCount + 1));	} catch (Exception e) {	
failed to get the size of all tables 

protected boolean needsBalance(Cluster cluster) {	ClusterLoadState cs = new ClusterLoadState(cluster.clusterState);	if (cs.getNumServers() < MIN_SERVER_BALANCE) {	if (LOG.isDebugEnabled()) {	
not running balancer because only active regionserver s 

return true;	}	double total = 0.0;	float sumMultiplier = 0.0f;	for (CostFunction c : costFunctions) {	float multiplier = c.getMultiplier();	if (multiplier <= 0) {	continue;	}	if (!c.isNeeded()) {	
indicated that its cost should not be considered 

continue;	}	if (!c.isNeeded()) {	continue;	}	sumMultiplier += multiplier;	total += c.cost() * multiplier;	}	if (total <= 0 || sumMultiplier <= 0 || (sumMultiplier > 0 && (total / sumMultiplier) < minCostNeedBalance)) {	if (LOG.isTraceEnabled()) {	
skipping load balancing because balanced cluster total cost is sum multiplier is min cost which need balance is 

if (EnvironmentEdgeManager.currentTime() - startTime > maxRunningTime) {	break;	}	}	long endTime = EnvironmentEdgeManager.currentTime();	metricsBalancer.balanceCluster(endTime - startTime);	updateStochasticCosts(tableName, curOverallCost, curFunctionCosts);	if (initCost > currentCost) {	plans = createRegionPlans(cluster);	if (LOG.isDebugEnabled()) {	
finished computing new load balance plan computation took ms to try different iterations found a solution that moves regions going from a computed cost of to a new cost of 

long endTime = EnvironmentEdgeManager.currentTime();	metricsBalancer.balanceCluster(endTime - startTime);	updateStochasticCosts(tableName, curOverallCost, curFunctionCosts);	if (initCost > currentCost) {	plans = createRegionPlans(cluster);	if (LOG.isDebugEnabled()) {	}	return plans;	}	if (LOG.isDebugEnabled()) {	
could not find a better load balance plan tried different configurations in ms and did not find anything with a computed cost less than 

List<RegionPlan> plans = new LinkedList<>();	for (int regionIndex = 0;	regionIndex < cluster.regionIndexToServerIndex.length; regionIndex++) {	int initialServerIndex = cluster.initialRegionIndexToServerIndex[regionIndex];	int newServerIndex = cluster.regionIndexToServerIndex[regionIndex];	if (initialServerIndex != newServerIndex) {	RegionInfo region = cluster.regions[regionIndex];	ServerName initialServer = cluster.servers[initialServerIndex];	ServerName newServer = cluster.servers[newServerIndex];	if (LOG.isTraceEnabled()) {	
moving region from server to 

========================= hbase sample_2827 =========================

static NonceGenerator injectNonceGeneratorForTesting( ClusterConnection conn, NonceGenerator cnm) {	ConnectionImplementation connImpl = (ConnectionImplementation)conn;	NonceGenerator ng = connImpl.getNonceGenerator();	
nonce generator is being replaced by test code for 

protected void retrieveClusterId() {	if (clusterId != null) {	return;	}	try {	this.clusterId = this.registry.getClusterId().get();	} catch (InterruptedException | ExecutionException e) {	
retrieve cluster id failed 

protected void retrieveClusterId() {	if (clusterId != null) {	return;	}	try {	this.clusterId = this.registry.getClusterId().get();	} catch (InterruptedException | ExecutionException e) {	}	if (clusterId == null) {	clusterId = HConstants.CLUSTER_ID_DEFAULT;	
clusterid came back null using default 

public boolean isTableAvailable(final TableName tableName, @Nullable final byte[][] splitKeys) throws IOException {	if (this.closed) {	throw new IOException(toString() + " closed");	}	try {	if (!isTableEnabled(tableName)) {	
table not enabled 

if (!isTableEnabled(tableName)) {	return false;	}	List<Pair<RegionInfo, ServerName>> locations = MetaTableAccessor.getTableRegionsAndLocations(this, tableName, true);	int notDeployed = 0;	int regionCount = 0;	for (Pair<RegionInfo, ServerName> pair : locations) {	RegionInfo info = pair.getFirst();	if (pair.getSecond() == null) {	if (LOG.isDebugEnabled()) {	
table has not deployed region 

regionCount++;	break;	}	}	} else {	regionCount++;	}	}	if (notDeployed > 0) {	if (LOG.isDebugEnabled()) {	
table has regions 

} else {	regionCount++;	}	}	if (notDeployed > 0) {	if (LOG.isDebugEnabled()) {	}	return false;	} else if (splitKeys != null && regionCount != splitKeys.length + 1) {	if (LOG.isDebugEnabled()) {	
table expected to have regions but only available 

if (notDeployed > 0) {	if (LOG.isDebugEnabled()) {	}	return false;	} else if (splitKeys != null && regionCount != splitKeys.length + 1) {	if (LOG.isDebugEnabled()) {	}	return false;	} else {	if (LOG.isDebugEnabled()) {	
table should be available 

} else if (splitKeys != null && regionCount != splitKeys.length + 1) {	if (LOG.isDebugEnabled()) {	}	return false;	} else {	if (LOG.isDebugEnabled()) {	}	return true;	}	} catch (TableNotFoundException tnfe) {	
table not enabled it is not exists 

private boolean isKeepAliveMasterConnectedAndRunning(MasterServiceState mss) {	if (mss.getStub() == null){	return false;	}	try {	return mss.isMasterRunning();	} catch (UndeclaredThrowableException e) {	
master connection is not running anymore 

private boolean isKeepAliveMasterConnectedAndRunning(MasterServiceState mss) {	if (mss.getStub() == null){	return false;	}	try {	return mss.isMasterRunning();	} catch (UndeclaredThrowableException e) {	return false;	} catch (IOException se) {	
checking master connection 

private void closeMasterService(MasterServiceState mss) {	if (mss.getStub() != null) {	
closing master protocol 

}	RegionInfo regionInfo = oldLocation.getRegion();	Throwable cause = ClientExceptionsUtil.findException(exception);	if (cause != null) {	if (!ClientExceptionsUtil.isMetaClearingException(cause)) {	return;	}	if (cause instanceof RegionMovedException) {	RegionMovedException rme = (RegionMovedException) cause;	if (LOG.isTraceEnabled()) {	
region moved to according to 

========================= hbase sample_395 =========================

private boolean waitLockTimeOut(EntityLock lock, long maxWaitTimeMillis) {	long startMillis = System.currentTimeMillis();	while (lock.isLocked()) {	
sleeping 

private boolean waitLockTimeOut(EntityLock lock, long maxWaitTimeMillis) {	long startMillis = System.currentTimeMillis();	while (lock.isLocked()) {	Threads.sleepWithoutInterrupt(100);	if (!lock.isLocked()) {	return true;	}	if (System.currentTimeMillis() - startMillis > maxWaitTimeMillis) {	
timedout 

========================= hbase sample_2061 =========================

public synchronized SinkPeer getReplicationSink() throws IOException {	if (endpoint.getLastRegionServerUpdate() > this.lastUpdateToPeers || sinks.isEmpty()) {	
current list of sinks is out of date or empty updating 

========================= hbase sample_2962 =========================

protected Message callExecService(final RpcController controller, final Descriptors.MethodDescriptor method, final Message request, final Message responsePrototype) throws IOException {	if (LOG.isTraceEnabled()) {	
call 

========================= hbase sample_403 =========================

public void testEnableNonDisabledTable() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	MasterProcedureTestingUtility.createTable(procExec, tableName, null, "f1", "f2");	long procId1 = procExec.submitProcedure( new EnableTableProcedure(procExec.getEnvironment(), tableName, false));	ProcedureTestingUtility.waitProcedure(procExec, procId1);	Procedure<?> result = procExec.getResult(procId1);	assertTrue(result.isFailed());	
enable failed with exception 

========================= hbase sample_1837 =========================

} else {	zooKeeper = null;	masterAddressTracker = null;	clusterStatusTracker = null;	}	this.choreService = new ChoreService(getServerName().toString(), true);	this.executorService = new ExecutorService(getServerName().toShortString());	this.rpcServices.start();	putUpWebUI();	} catch (Throwable t) {	
failed construction regionserver 

public boolean registerService(com.google.protobuf.Service instance) {	com.google.protobuf.Descriptors.ServiceDescriptor serviceDesc = instance.getDescriptorForType();	String serviceName = CoprocessorRpcUtils.getServiceName(serviceDesc);	if (coprocessorServiceHandlers.containsKey(serviceName)) {	
coprocessor executorservice already registered rejecting request from 

return;	}	blockAndCheckIfStopped(this.masterAddressTracker);	blockAndCheckIfStopped(this.clusterStatusTracker);	if (clusterId == null) {	try {	clusterId = ZKClusterId.readClusterIdZNode(this.zooKeeper);	if (clusterId == null) {	this.abort("Cluster ID has not been set");	}	
clusterid 

abort("Fatal exception during initialization", e);	}	try {	if (!isStopped() && !isAborted()) {	ShutdownHook.install(conf, fs, this, Thread.currentThread());	this.rsHost = new RegionServerCoprocessorHost(this, this.conf);	}	while (keepLooping()) {	RegionServerStartupResponse w = reportForDuty();	if (w == null) {	
reportforduty failed sleeping and then retrying 

}	}	long lastMsg = System.currentTimeMillis();	long oldRequestCount = -1;	while (!isStopped() && isHealthy()) {	if (!isClusterUp()) {	if (isOnlineRegionsEmpty()) {	stop("Exiting; cluster shutdown set and not carrying any regions");	} else if (!this.stopping) {	this.stopping = true;	
closing user regions 

boolean allUserRegionsOffline = areAllUserRegionsOffline();	if (allUserRegionsOffline) {	if (oldRequestCount == getWriteRequestCount()) {	stop("Stopped; only catalog regions remaining online");	break;	}	oldRequestCount = getWriteRequestCount();	} else {	closeUserRegions(this.abortRequested);	}	
waiting on 

}	if (mxBean != null) {	MBeans.unregister(mxBean);	mxBean = null;	}	if (this.leases != null) this.leases.closeAfterLeasesExpire();	if (this.splitLogWorker != null) {	splitLogWorker.stop();	}	if (this.infoServer != null) {	
stopping infoserver 

mxBean = null;	}	if (this.leases != null) this.leases.closeAfterLeasesExpire();	if (this.splitLogWorker != null) {	splitLogWorker.stop();	}	if (this.infoServer != null) {	try {	this.infoServer.stop();	} catch (Exception e) {	
failed to stop infoserver 

rsSpaceQuotaManager = null;	}	if (rspmHost != null) {	rspmHost.stop(this.abortRequested || this.killed);	}	if (this.killed) {	} else if (abortRequested) {	if (this.fsOk) {	closeUserRegions(abortRequested);	}	
aborting server 

if (rspmHost != null) {	rspmHost.stop(this.abortRequested || this.killed);	}	if (this.killed) {	} else if (abortRequested) {	if (this.fsOk) {	closeUserRegions(abortRequested);	}	} else {	closeUserRegions(abortRequested);	
stopping server 

closeUserRegions(abortRequested);	}	} else {	closeUserRegions(abortRequested);	}	if (this.metaTableLocator != null) this.metaTableLocator.stop();	if (this.clusterConnection != null && !clusterConnection.isClosed()) {	try {	this.clusterConnection.close();	} catch (IOException e) {	
attempt to close server s short circuit clusterconnection failed 

if (!abortRequested || this.fsOk) {	if (this.compactSplitThread != null) {	this.compactSplitThread.join();	this.compactSplitThread = null;	}	closeMetaTableRegions(abortRequested);	}	}	if (!this.killed && this.fsOk) {	waitOnAllRegionsToClose(abortRequested);	
stopping server all regions closed 

if (!killed) {	stopServiceThreads();	}	if (this.rpcServices != null) {	this.rpcServices.stop();	}	try {	deleteMyEphemeralNode();	} catch (KeeperException.NoNodeException nn) {	} catch (KeeperException e) {	
failed deleting my ephemeral node 

}	try {	deleteMyEphemeralNode();	} catch (KeeperException.NoNodeException nn) {	} catch (KeeperException e) {	}	ZNodeClearer.deleteMyEphemeralNodeOnDisk();	if (this.zooKeeper != null) {	this.zooKeeper.close();	}	
stopping server zookeeper connection closed 

}	try {	deleteMyEphemeralNode();	} catch (KeeperException.NoNodeException nn) {	} catch (KeeperException e) {	}	ZNodeClearer.deleteMyEphemeralNodeOnDisk();	if (this.zooKeeper != null) {	this.zooKeeper.close();	}	
exiting 

public boolean reportRegionSizesForQuotas(final Map<RegionInfo, Long> onlineRegionSizes) {	RegionServerStatusService.BlockingInterface rss = rssStub;	if (rss == null) {	
skipping region size report to hmaster as stub is null 

RegionServerStatusService.BlockingInterface rss = rssStub;	if (rss == null) {	return true;	}	try {	RegionSpaceUseReportRequest request = buildRegionSpaceUseReportRequest( Objects.requireNonNull(onlineRegionSizes));	rss.reportRegionSpaceUse(null, request);	} catch (ServiceException se) {	IOException ioe = ProtobufUtil.getRemoteException(se);	if (ioe instanceof PleaseHoldException) {	
failed to report region sizes to master because it is initializing this will be retried 

}	if (rssStub == rss) {	rssStub = null;	}	createRegionServerStatusStub(true);	if (ioe instanceof DoNotRetryIOException) {	DoNotRetryIOException doNotRetryEx = (DoNotRetryIOException) ioe;	if (doNotRetryEx.getCause() != null) {	Throwable t = doNotRetryEx.getCause();	if (t instanceof UnsupportedOperationException) {	
master doesn t support reportregionspaceuse pause before retrying 

createRegionServerStatusStub(true);	if (ioe instanceof DoNotRetryIOException) {	DoNotRetryIOException doNotRetryEx = (DoNotRetryIOException) ioe;	if (doNotRetryEx.getCause() != null) {	Throwable t = doNotRetryEx.getCause();	if (t instanceof UnsupportedOperationException) {	return false;	}	}	}	
failed to report region sizes to master this will be retried 

long previousLogTime = 0;	Set<String> closedRegions = new HashSet<>();	boolean interrupted = false;	try {	while (!isOnlineRegionsEmpty()) {	int count = getNumberOfOnlineRegions();	if (count != lastCount) {	if (System.currentTimeMillis() > (previousLogTime + 1000)) {	previousLogTime = System.currentTimeMillis();	lastCount = count;	
waiting on regions to close 

}	for (Map.Entry<String, HRegion> e : this.onlineRegions.entrySet()) {	RegionInfo hri = e.getValue().getRegionInfo();	if (!this.regionsInTransitionInRS.containsKey(hri.getEncodedNameAsBytes()) && !closedRegions.contains(hri.getEncodedName())) {	closedRegions.add(hri.getEncodedName());	closeRegionIgnoreErrors(hri, abort);	}	}	if (this.regionsInTransitionInRS.isEmpty()) {	if (!isOnlineRegionsEmpty()) {	
we were exiting though online regions are not empty because some regions failed closing 

private boolean sleep(long millis) {	boolean interrupted = false;	try {	Thread.sleep(millis);	} catch (InterruptedException e) {	
interrupted while sleeping 

private void shutdownWAL(final boolean close) {	if (this.walFactory != null) {	try {	if (close) {	walFactory.close();	} else {	walFactory.shutdown();	}	} catch (Throwable e) {	e = e instanceof RemoteException ? ((RemoteException) e).unwrapRemoteException() : e;	
shutdown close of wal failed 

private void shutdownWAL(final boolean close) {	if (this.walFactory != null) {	try {	if (close) {	walFactory.close();	} else {	walFactory.shutdown();	}	} catch (Throwable e) {	e = e instanceof RemoteException ? ((RemoteException) e).unwrapRemoteException() : e;	
shutdown close exception details 

this.instance.compactSplitThread.requestSystemCompaction(hr, s, getName() + " requests compaction");	} else if (s.shouldPerformMajorCompaction()) {	s.triggerMajorCompaction();	if (majorCompactPriority == DEFAULT_PRIORITY || majorCompactPriority > hr.getCompactPriority()) {	this.instance.compactSplitThread.requestCompaction(hr, s, getName() + " requests major compaction; use default priority", Store.NO_PRIORITY, CompactionLifeCycleTracker.DUMMY, null);	} else {	this.instance.compactSplitThread.requestCompaction(hr, s, getName() + " requests major compaction; use configured priority", this.majorCompactPriority, CompactionLifeCycleTracker.DUMMY, null);	}	}	} catch (IOException e) {	
failed major compaction check on 

protected void chore() {	final StringBuilder whyFlush = new StringBuilder();	for (HRegion r : this.server.onlineRegions.values()) {	if (r == null) continue;	if (r.shouldFlush(whyFlush)) {	FlushRequester requester = server.getFlushRequester();	if (requester != null) {	long randomDelay = RandomUtils.nextInt(0, RANGE_OF_DELAY) + MIN_DELAY_TIME;	
requesting flush of because after random delay ms 

if (this.fsUtilizationChore != null) choreService.scheduleChore(fsUtilizationChore);	Threads.setDaemonThreadRunning(this.leases.getThread(), getName() + ".leaseChecker", uncaughtExceptionHandler);	Configuration sinkConf = HBaseConfiguration.create(conf);	sinkConf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, conf.getInt("hbase.log.replay.retries.number", 8));	sinkConf.setInt(HConstants.HBASE_RPC_TIMEOUT_KEY, conf.getInt("hbase.log.replay.rpc.timeout", 30000));	sinkConf.setInt(HConstants.HBASE_CLIENT_SERVERSIDE_RETRIES_MULTIPLIER, 1);	if (this.csm != null) {	this.splitLogWorker = new SplitLogWorker(this, sinkConf, this, this, walFactory);	splitLogWorker.start();	} else {	
splitlogworker service not started coordinatedstatemanager is null 

boolean auto = this.conf.getBoolean(HConstants.REGIONSERVER_INFO_PORT_AUTO, false);	while (true) {	try {	this.infoServer = new InfoServer(getProcessName(), addr, port, false, this.conf);	infoServer.addServlet("dump", "/dump", getDumpServlet());	configureInfoServer();	this.infoServer.start();	break;	} catch (BindException e) {	if (!auto) {	
failed binding http info server to port 

try {	this.infoServer = new InfoServer(getProcessName(), addr, port, false, this.conf);	infoServer.addServlet("dump", "/dump", getDumpServlet());	configureInfoServer();	this.infoServer.start();	break;	} catch (BindException e) {	if (!auto) {	throw e;	}	
failed binding http info server to port 

public void stop(final String msg, final boolean force, final User user) {	if (!this.stopped) {	
stopping region server 

public void stop(final String msg, final boolean force, final User user) {	if (!this.stopped) {	if (this.rsHost != null) {	try {	this.rsHost.preStop(msg, user);	} catch (IOException ioe) {	if (!force) {	
the region server did not stop 

public void stop(final String msg, final boolean force, final User user) {	if (!this.stopped) {	if (this.rsHost != null) {	try {	this.rsHost.preStop(msg, user);	} catch (IOException ioe) {	if (!force) {	return;	}	
skipping coprocessor exception on prestop due to forced shutdown 

if (this.rsHost != null) {	try {	this.rsHost.preStop(msg, user);	} catch (IOException ioe) {	if (!force) {	return;	}	}	}	this.stopped = true;	
stopped 

public void postOpenDeployTasks(final PostOpenDeployContext context) throws KeeperException, IOException {	HRegion r = context.getRegion();	long masterSystemTime = context.getMasterSystemTime();	rpcServices.checkOpen();	
post open deploy tasks for 

HRegion r = context.getRegion();	long masterSystemTime = context.getMasterSystemTime();	rpcServices.checkOpen();	for (HStore s : r.stores.values()) {	if (s.hasReferences() || s.needsCompaction()) {	this.compactSplitThread.requestSystemCompaction(r, s, "Opening Region");	}	}	long openSeqNum = r.getOpenSeqNum();	if (openSeqNum == HConstants.NO_SEQNUM) {	
no sequence number found when opening 

}	}	long openSeqNum = r.getOpenSeqNum();	if (openSeqNum == HConstants.NO_SEQNUM) {	openSeqNum = 0;	}	if (!reportRegionStateTransition(new RegionStateTransitionContext( TransitionCode.OPENED, openSeqNum, masterSystemTime, r.getRegionInfo()))) {	throw new IOException("Failed to report opened region to master: " + r.getRegionInfo().getRegionNameAsString());	}	triggerFlushInPrimaryRegion(r);	
finished post open deploy task for 

long openSeqNum = context.getOpenSeqNum();	long masterSystemTime = context.getMasterSystemTime();	RegionInfo[] hris = context.getHris();	if (TEST_SKIP_REPORTING_TRANSITION) {	if (code == TransitionCode.OPENED) {	Preconditions.checkArgument(hris != null && hris.length == 1);	if (hris[0].isMetaRegion()) {	try {	MetaTableLocator.setMetaLocation(getZooKeeper(), serverName, hris[0].getReplicaId(),State.OPEN);	} catch (KeeperException e) {	
failed to update meta location 

if (hris[0].isMetaRegion()) {	try {	MetaTableLocator.setMetaLocation(getZooKeeper(), serverName, hris[0].getReplicaId(),State.OPEN);	} catch (KeeperException e) {	return false;	}	} else {	try {	MetaTableAccessor.updateRegionLocation(clusterConnection, hris[0], serverName, openSeqNum, masterSystemTime);	} catch (IOException e) {	
failed to update meta 

long pauseTime = INIT_PAUSE_TIME_MS;	while (this.clusterConnection != null && !this.clusterConnection.isClosed()) {	RegionServerStatusService.BlockingInterface rss = rssStub;	try {	if (rss == null) {	createRegionServerStatusStub();	continue;	}	ReportRegionStateTransitionResponse response = rss.reportRegionStateTransition(null, request);	if (response.hasErrorMessage()) {	
transition failed 

try {	if (rss == null) {	createRegionServerStatusStub();	continue;	}	ReportRegionStateTransitionResponse response = rss.reportRegionStateTransition(null, request);	if (response.hasErrorMessage()) {	break;	}	if (tries > 0 || LOG.isTraceEnabled()) {	
transition reported 

}	return true;	} catch (ServiceException se) {	IOException ioe = ProtobufUtil.getRemoteException(se);	boolean pause = ioe instanceof ServerNotRunningYetException || ioe instanceof PleaseHoldException;	if (pause) {	pauseTime = ConnectionUtils.getPauseTime(INIT_PAUSE_TIME_MS, tries);	} else {	pauseTime = INIT_PAUSE_TIME_MS;	}	
failed report transition retry after ms delay master is coming online immediately 

public void abort(String reason, Throwable cause) {	String msg = "***** ABORTING region server " + this + ": " + reason + " *****";	if (cause != null) {	LOG.error(HBaseMarkers.FATAL, msg, cause);	} else {	LOG.error(HBaseMarkers.FATAL, msg);	}	this.abortRequested = true;	
regionserver abort loaded coprocessors are 

public void abort(String reason, Throwable cause) {	String msg = "***** ABORTING region server " + this + ": " + reason + " *****";	if (cause != null) {	LOG.error(HBaseMarkers.FATAL, msg, cause);	} else {	LOG.error(HBaseMarkers.FATAL, msg);	}	this.abortRequested = true;	try {	
dump of metrics as json on abort 

public void abort(String reason, Throwable cause) {	String msg = "***** ABORTING region server " + this + ": " + reason + " *****";	if (cause != null) {	LOG.error(HBaseMarkers.FATAL, msg, cause);	} else {	LOG.error(HBaseMarkers.FATAL, msg);	}	this.abortRequested = true;	try {	} catch (MalformedObjectNameException | IOException e) {	
failed dumping metrics 

msg += "\nCause:\n" + Throwables.getStackTraceAsString(cause);	}	if (rssStub != null && this.serverName != null) {	ReportRSFatalErrorRequest.Builder builder = ReportRSFatalErrorRequest.newBuilder();	ServerName sn = ServerName.parseVersionedServerName(this.serverName.getVersionedBytes());	builder.setServer(ProtobufUtil.toServerName(sn));	builder.setErrorMessage(msg);	rssStub.reportRSFatalError(null, builder.build());	}	} catch (Throwable t) {	
unable to report fatal error to master 

ServerName sn = null;	long previousLogTime = 0;	RegionServerStatusService.BlockingInterface intRssStub = null;	LockService.BlockingInterface intLockStub = null;	boolean interrupted = false;	try {	while (keepLooping()) {	sn = this.masterAddressTracker.getMasterAddress(refresh);	if (sn == null) {	if (!keepLooping()) {	
no master found and cluster is stopped bailing out 

LockService.BlockingInterface intLockStub = null;	boolean interrupted = false;	try {	while (keepLooping()) {	sn = this.masterAddressTracker.getMasterAddress(refresh);	if (sn == null) {	if (!keepLooping()) {	return null;	}	if (System.currentTimeMillis() > (previousLogTime + 1000)) {	
no master found retry 

}	try {	BlockingRpcChannel channel = this.rpcClient.createBlockingRpcChannel(sn, userProvider.getCurrent(), shortOperationTimeout);	intRssStub = RegionServerStatusService.newBlockingStub(channel);	intLockStub = LockService.newBlockingStub(channel);	break;	} catch (IOException e) {	if (System.currentTimeMillis() > (previousLogTime + 1000)) {	e = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	if (e instanceof ServerNotRunningYetException) {	
master isn t available yet retrying 

try {	BlockingRpcChannel channel = this.rpcClient.createBlockingRpcChannel(sn, userProvider.getCurrent(), shortOperationTimeout);	intRssStub = RegionServerStatusService.newBlockingStub(channel);	intLockStub = LockService.newBlockingStub(channel);	break;	} catch (IOException e) {	if (System.currentTimeMillis() > (previousLogTime + 1000)) {	e = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	if (e instanceof ServerNotRunningYetException) {	} else {	
unable to connect to master retrying error was 

if (!StringUtils.isBlank(useThisHostnameInstead)) {	request.setUseThisHostnameInstead(useThisHostnameInstead);	}	request.setPort(port);	request.setServerStartCode(this.startcode);	request.setServerCurrentTime(now);	result = this.rssStub.regionServerStartup(null, request.build());	} catch (ServiceException se) {	IOException ioe = ProtobufUtil.getRemoteException(se);	if (ioe instanceof ClockOutOfSyncException) {	
master rejected startup because clock is out of sync 

}	request.setPort(port);	request.setServerStartCode(this.startcode);	request.setServerCurrentTime(now);	result = this.rssStub.regionServerStartup(null, request.build());	} catch (ServiceException se) {	IOException ioe = ProtobufUtil.getRemoteException(se);	if (ioe instanceof ClockOutOfSyncException) {	throw ioe;	} else if (ioe instanceof ServerNotRunningYetException) {	
master is not running yet 

request.setPort(port);	request.setServerStartCode(this.startcode);	request.setServerCurrentTime(now);	result = this.rssStub.regionServerStartup(null, request.build());	} catch (ServiceException se) {	IOException ioe = ProtobufUtil.getRemoteException(se);	if (ioe instanceof ClockOutOfSyncException) {	throw ioe;	} else if (ioe instanceof ServerNotRunningYetException) {	} else {	
error telling master we are up 

public RegionStoreSequenceIds getLastSequenceId(byte[] encodedRegionName) {	try {	GetLastFlushedSequenceIdRequest req = RequestConverter.buildGetLastFlushedSequenceIdRequest(encodedRegionName);	RegionServerStatusService.BlockingInterface rss = rssStub;	if (rss == null) {	createRegionServerStatusStub();	rss = rssStub;	if (rss == null) {	
unable to connect to the master to check the last flushed sequence id 

if (rss == null) {	createRegionServerStatusStub();	rss = rssStub;	if (rss == null) {	return RegionStoreSequenceIds.newBuilder().setLastFlushedSequenceId(HConstants.NO_SEQNUM) .build();	}	}	GetLastFlushedSequenceIdResponse resp = rss.getLastFlushedSequenceId(null, req);	return RegionStoreSequenceIds.newBuilder() .setLastFlushedSequenceId(resp.getLastFlushedSequenceId()) .addAllStoreSequenceId(resp.getStoreLastFlushedSequenceIdList()).build();	} catch (ServiceException e) {	
unable to connect to the master to check the last flushed sequence id 

public static void main(String[] args) throws Exception {	
starting executorservice 

public String[] getRegionServerCoprocessors() {	TreeSet<String> coprocessors = new TreeSet<>();	try {	coprocessors.addAll(getWAL(null).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	
exception attempting to fetch wal coprocessor information for the common wal skipping 

public String[] getRegionServerCoprocessors() {	TreeSet<String> coprocessors = new TreeSet<>();	try {	coprocessors.addAll(getWAL(null).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	
exception details for failure to fetch wal coprocessor information 

try {	coprocessors.addAll(getWAL(null).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	}	Collection<HRegion> regions = getOnlineRegionsLocalContext();	for (HRegion region: regions) {	coprocessors.addAll(region.getCoprocessorHost().getCoprocessors());	try {	coprocessors.addAll(getWAL(region.getRegionInfo()).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	
exception attempting to fetch wal coprocessor information for region skipping 

try {	coprocessors.addAll(getWAL(null).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	}	Collection<HRegion> regions = getOnlineRegionsLocalContext();	for (HRegion region: regions) {	coprocessors.addAll(region.getCoprocessorHost().getCoprocessors());	try {	coprocessors.addAll(getWAL(region.getRegionInfo()).getCoprocessorHost().getCoprocessors());	} catch (IOException exception) {	
exception details for failure to fetch wal coprocessor information 

private void closeRegionIgnoreErrors(RegionInfo region, final boolean abort) {	try {	if (!closeRegion(region.getEncodedName(), abort, null)) {	
failed to close ignoring and continuing 

private void closeRegionIgnoreErrors(RegionInfo region, final boolean abort) {	try {	if (!closeRegion(region.getEncodedName(), abort, null)) {	}	} catch (IOException e) {	
failed to close ignoring and continuing 

protected boolean closeRegion(String encodedName, final boolean abort, final ServerName sn) throws NotServingRegionException {	HRegion actualRegion = this.getRegion(encodedName);	if ((actualRegion != null) && (actualRegion.getCoprocessorHost() != null)) {	try {	actualRegion.getCoprocessorHost().preClose(false);	} catch (IOException exp) {	
unable to close region the coprocessor launched an error 

HRegion actualRegion = this.getRegion(encodedName);	if ((actualRegion != null) && (actualRegion.getCoprocessorHost() != null)) {	try {	actualRegion.getCoprocessorHost().preClose(false);	} catch (IOException exp) {	return false;	}	}	final Boolean previous = this.regionsInTransitionInRS.putIfAbsent(encodedName.getBytes(), Boolean.FALSE);	if (Boolean.TRUE.equals(previous)) {	
received close for the region which we are already trying to open cancelling opening 

if ((actualRegion != null) && (actualRegion.getCoprocessorHost() != null)) {	try {	actualRegion.getCoprocessorHost().preClose(false);	} catch (IOException exp) {	return false;	}	}	final Boolean previous = this.regionsInTransitionInRS.putIfAbsent(encodedName.getBytes(), Boolean.FALSE);	if (Boolean.TRUE.equals(previous)) {	if (!regionsInTransitionInRS.replace(encodedName.getBytes(), previous, Boolean.FALSE)){	
the opening for region was done before we could cancel it doing a standard close now 

return false;	}	}	final Boolean previous = this.regionsInTransitionInRS.putIfAbsent(encodedName.getBytes(), Boolean.FALSE);	if (Boolean.TRUE.equals(previous)) {	if (!regionsInTransitionInRS.replace(encodedName.getBytes(), previous, Boolean.FALSE)){	return closeRegion(encodedName, abort, sn);	}	actualRegion = this.getRegion(encodedName);	if (actualRegion == null) {	
the opening previously in progress has been cancelled by a close request 

final Boolean previous = this.regionsInTransitionInRS.putIfAbsent(encodedName.getBytes(), Boolean.FALSE);	if (Boolean.TRUE.equals(previous)) {	if (!regionsInTransitionInRS.replace(encodedName.getBytes(), previous, Boolean.FALSE)){	return closeRegion(encodedName, abort, sn);	}	actualRegion = this.getRegion(encodedName);	if (actualRegion == null) {	throw new NotServingRegionException("The region " + encodedName + " was opening but not yet served. Opening is cancelled.");	}	} else if (Boolean.FALSE.equals(previous)) {	
received close for the region which we are already trying to close but not completed yet 

return closeRegion(encodedName, abort, sn);	}	actualRegion = this.getRegion(encodedName);	if (actualRegion == null) {	throw new NotServingRegionException("The region " + encodedName + " was opening but not yet served. Opening is cancelled.");	}	} else if (Boolean.FALSE.equals(previous)) {	return true;	}	if (actualRegion == null) {	
received close for a region which is not online and we re not opening 

private Throwable cleanup(final Throwable t, final String msg) {	if (t instanceof NotServingRegionException) {	
notservingregionexception 

protected void addToMovedRegions(String encodedName, ServerName destination, long closeSeqNum) {	if (ServerName.isSameAddress(destination, this.getServerName())) {	
not adding moved region record to self 

protected void addToMovedRegions(String encodedName, ServerName destination, long closeSeqNum) {	if (ServerName.isSameAddress(destination, this.getServerName())) {	return;	}	
adding moved region record to as of 

public void updateConfiguration() {	
reloading the configuration from disk 

========================= hbase sample_2718 =========================

public void testStop() throws Exception {	MiniHBaseCluster cluster = UTIL.getHBaseCluster();	
shutdown hbase cluster 

public void testStop() throws Exception {	MiniHBaseCluster cluster = UTIL.getHBaseCluster();	cluster.shutdown();	
wait for the hbase cluster shutdown 

========================= hbase sample_1564 =========================

public void testBasics() throws Exception {	
lowkey 

========================= hbase sample_815 =========================

public void testFullRestoreSetToOtherTable() throws Exception {	
test full restore set 

assertNotNull(names);	assertTrue(names.size() == 1);	assertTrue(names.get(0).equals(table1));	String[] args = new String[] { "create", "full", BACKUP_ROOT_DIR, "-s", name };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	List<BackupInfo> backups = table.getBackupHistory();	assertTrue(backups.size() == 1);	String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	
backup complete 

assertTrue(backups.size() == 1);	String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	args = new String[] { BACKUP_ROOT_DIR, backupId, "-s", name, "-m", table1_restore.getNameAsString(), "-o" };	ret = ToolRunner.run(conf1, new RestoreDriver(), args);	assertTrue(ret == 0);	HBaseAdmin hba = TEST_UTIL.getHBaseAdmin();	assertTrue(hba.tableExists(table1_restore));	assertEquals(TEST_UTIL.countRows(table1), TEST_UTIL.countRows(table1_restore));	TEST_UTIL.deleteTable(table1_restore);	
restore into other table is complete 

public void testFullRestoreSetToSameTable() throws Exception {	
test full restore set to same table 

List<TableName> names = table.describeBackupSet(name);	assertNotNull(names);	assertTrue(names.size() == 1);	assertTrue(names.get(0).equals(table1));	String[] args = new String[] { "create", "full", BACKUP_ROOT_DIR, "-s", name };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	List<BackupInfo> backups = table.getBackupHistory();	String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	
backup complete 

String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	int count = TEST_UTIL.countRows(table1);	TEST_UTIL.deleteTable(table1);	args = new String[] { BACKUP_ROOT_DIR, backupId, "-s", name, "-o" };	ret = ToolRunner.run(conf1, new RestoreDriver(), args);	assertTrue(ret == 0);	HBaseAdmin hba = TEST_UTIL.getHBaseAdmin();	assertTrue(hba.tableExists(table1));	assertEquals(count, TEST_UTIL.countRows(table1));	
restore into same table is complete 

========================= hbase sample_546 =========================

String exceptionKey = errorType.getMetricName();	long preExceptionCounter = metricsHelper.checkCounterExists(exceptionKey, metrics.getSource()) ? metricsHelper.getCounter(exceptionKey, metrics.getSource()) : 0;	TGet tGet = new TGet(wrap(rowkey));	Map<ByteBuffer, ByteBuffer> attributes = new HashMap<>();	attributes.put(wrap(Bytes.toBytes(ErrorThrowingGetObserver.SHOULD_ERROR_ATTRIBUTE)), wrap(Bytes.toBytes(errorType.name())));	tGet.setAttributes(attributes);	try {	TResult tResult = handler.get(tTableName, tGet);	fail("Get with error attribute should have thrown an exception");	} catch (TException e) {	
received exception 

public void preGetOp(ObserverContext<RegionCoprocessorEnvironment> e, Get get, List<Cell> results) throws IOException {	try {	long start = System.currentTimeMillis();	TimeUnit.MILLISECONDS.sleep(delayMillis);	if (LOG.isTraceEnabled()) {	
slept for msec 

========================= hbase sample_751 =========================

this.useSasl = isSecurityEnabled;	Token<? extends TokenIdentifier> token = null;	String serverPrincipal = null;	if (useSasl && securityInfo != null) {	AuthenticationProtos.TokenIdentifier.Kind tokenKind = securityInfo.getTokenKind();	if (tokenKind != null) {	TokenSelector<? extends TokenIdentifier> tokenSelector = AbstractRpcClient.TOKEN_HANDLERS .get(tokenKind);	if (tokenSelector != null) {	token = tokenSelector.selectToken(new Text(clusterId), ticket.getTokens());	} else if (LOG.isDebugEnabled()) {	
no token selector found for type 

========================= hbase sample_244 =========================

private static Scan getConfiguredScanForJob(Configuration conf, String[] args) throws IOException {	Scan s = TableInputFormat.createScanFromConfiguration(conf);	if (conf.get(TableInputFormat.SCAN_MAXVERSIONS) == null) {	s.setMaxVersions(Integer.MAX_VALUE);	}	s.setCacheBlocks(false);	Filter rowFilter = getRowFilter(args);	if (rowFilter!= null) {	
setting row filter for counter 

if (conf.get(TableInputFormat.SCAN_MAXVERSIONS) == null) {	s.setMaxVersions(Integer.MAX_VALUE);	}	s.setCacheBlocks(false);	Filter rowFilter = getRowFilter(args);	if (rowFilter!= null) {	s.setFilter(rowFilter);	}	long timeRange[] = getTimeRange(args);	if (timeRange != null) {	
setting timerange for counter 

========================= hbase sample_3467 =========================

public void doFilter(ServletRequest paramServletRequest, ServletResponse paramServletResponse, FilterChain paramFilterChain) throws IOException, ServletException {	if (paramServletRequest instanceof HttpServletRequest && paramServletResponse instanceof HttpServletResponse) {	HttpServletRequest request = (HttpServletRequest) paramServletRequest;	HttpServletResponse response = (HttpServletResponse) paramServletResponse;	String path = request.getRequestURI();	LOG.info(path);	if (path.indexOf("/status/cluster") >= 0) {	
blocking cluster status request 

========================= hbase sample_3037 =========================

public void start(final RpcScheduler rpcScheduler) throws IOException {	if (!QuotaUtil.isQuotaEnabled(rsServices.getConfiguration())) {	
quota support disabled 

public void start(final RpcScheduler rpcScheduler) throws IOException {	if (!QuotaUtil.isQuotaEnabled(rsServices.getConfiguration())) {	return;	}	
initializing rpc quota support 

========================= hbase sample_2333 =========================

String[] tables = tableCFsConfig.split(";");	List<ReplicationProtos.TableCF> tableCFList = new ArrayList<>(tables.length);	for (String tab : tables) {	tab = tab.trim();	if (tab.length() == 0) {	continue;	}	String[] pair = tab.split(":");	String tabName = pair[0].trim();	if (pair.length > 2 || tabName.length() == 0) {	
incorrect format 

========================= hbase sample_478 =========================

puts.add(put);	if (puts.size() >= insert_batch) {	ht.put(puts);	puts.clear();	}	}	if (!puts.isEmpty()) {	ht.put(puts);	puts.clear();	}	
data generated in seconds 

scan.setFilter(filter);	scan.setLoadColumnFamiliesOnDemand(!slow);	ResultScanner result_scanner = table.getScanner(scan);	Result res;	long rows_count = 0;	while ((res = result_scanner.next()) != null) {	rows_count++;	}	double timeSec = (System.nanoTime() - time) / 1000000000.0;	result_scanner.close();	
Slow Joined scanner finished in seconds got rows 

========================= hbase sample_1661 =========================

public WALCoprocessor checkAndGetInstance(Class<?> implClass) throws InstantiationException, IllegalAccessException {	if (WALCoprocessor.class.isAssignableFrom(implClass)) {	return (WALCoprocessor)implClass.newInstance();	} else {	
is not of type walcoprocessor check the configuration 

========================= hbase sample_2558 =========================

public void setup() throws Exception {	TEST_UTIL.startMiniZKCluster();	Configuration conf = TEST_UTIL.getConfiguration();	zkw = new ZKWatcher(TEST_UTIL.getConfiguration(), "split-log-worker-tests", null);	ds = new DummyServer(zkw, conf);	ZKUtil.deleteChildrenRecursively(zkw, zkw.znodePaths.baseZNode);	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.baseZNode);	assertThat(ZKUtil.checkExists(zkw, zkw.znodePaths.baseZNode), not (is(-1)));	
created 

public void setup() throws Exception {	TEST_UTIL.startMiniZKCluster();	Configuration conf = TEST_UTIL.getConfiguration();	zkw = new ZKWatcher(TEST_UTIL.getConfiguration(), "split-log-worker-tests", null);	ds = new DummyServer(zkw, conf);	ZKUtil.deleteChildrenRecursively(zkw, zkw.znodePaths.baseZNode);	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.baseZNode);	assertThat(ZKUtil.checkExists(zkw, zkw.znodePaths.baseZNode), not (is(-1)));	ZKUtil.createAndFailSilent(zkw, zkw.znodePaths.splitLogZNode);	assertThat(ZKUtil.checkExists(zkw, zkw.znodePaths.splitLogZNode), not (is(-1)));	
created 

public void testAcquireTaskAtStartup() throws Exception {	
testAcquireTaskAtStartup 

public void testRaceForTask() throws Exception {	
testRaceForTask 

public void testPreemptTask() throws Exception {	
testPreemptTask 

public void testMultipleTasks() throws Exception {	
testMultipleTasks 

public void testRescan() throws Exception {	
testRescan 

public void testAcquireMultiTasks() throws Exception {	
testAcquireMultiTasks 

public void testAcquireMultiTasksByAvgTasksPerRS() throws Exception {	
testAcquireMultiTasks 

========================= hbase sample_1724 =========================

public void abort(String reason, Throwable e) {	
aborting 

========================= hbase sample_1374 =========================

Scan currentScan;	if ((endRow != null) && (endRow.length > 0)) {	if (trrRowFilter != null) {	Scan scan = new Scan(firstRow, endRow);	TableInputFormat.addColumns(scan, trrInputColumns);	scan.setFilter(trrRowFilter);	scan.setCacheBlocks(false);	this.scanner = this.htable.getScanner(scan);	currentScan = scan;	} else {	
tifb restart firstrow endrow 

scan.setCacheBlocks(false);	this.scanner = this.htable.getScanner(scan);	currentScan = scan;	} else {	Scan scan = new Scan(firstRow, endRow);	TableInputFormat.addColumns(scan, trrInputColumns);	this.scanner = this.htable.getScanner(scan);	currentScan = scan;	}	} else {	
tifb restart firstrow no endrow 

public void close() {	if (this.scanner != null) {	this.scanner.close();	}	try {	this.htable.close();	} catch (IOException ioe) {	
error closing table 

public boolean next(ImmutableBytesWritable key, Result value) throws IOException {	Result result;	try {	try {	result = this.scanner.next();	if (logScannerActivity) {	rowcount ++;	if (rowcount >= logPerRowCount) {	long now = System.currentTimeMillis();	
mapper took ms to process rows 

if (rowcount >= logPerRowCount) {	long now = System.currentTimeMillis();	timestamp = now;	rowcount = 0;	}	}	} catch (IOException e) {	if (e instanceof DoNotRetryIOException) {	throw e;	}	
recovered from 

long now = System.currentTimeMillis();	timestamp = now;	rowcount = 0;	}	}	} catch (IOException e) {	if (e instanceof DoNotRetryIOException) {	throw e;	}	if (lastSuccessfulRow == null) {	
we are restarting the first next invocation if your mapper has restarted a few other times like this then you should consider killing this job and investigate why it s taking so long 

if (result != null && result.size() > 0) {	key.set(result.getRow());	lastSuccessfulRow = key.get();	value.copyFrom(result);	return true;	}	return false;	} catch (IOException ioe) {	if (logScannerActivity) {	long now = System.currentTimeMillis();	
mapper took ms to process rows 

========================= hbase sample_3430 =========================

public Result get(Get get) throws IOException {	TimeRange range = get.getTimeRange();	String spec = buildRowSpec(get.getRow(), get.getFamilyMap(), range.getMin(), range.getMax(), get.getMaxVersions());	if (get.getFilter() != null) {	
filters not supported on gets 

public Result get(Get get) throws IOException {	TimeRange range = get.getTimeRange();	String spec = buildRowSpec(get.getRow(), get.getFamilyMap(), range.getMin(), range.getMax(), get.getMaxVersions());	if (get.getFilter() != null) {	}	Result[] results = getResults(spec);	if (results.length > 0) {	if (results.length > 1) {	
too many results for get 

public Result[] get(List<Get> gets) throws IOException {	byte[][] rows = new byte[gets.size()][];	int maxVersions = 1;	int count = 0;	for(Get g:gets) {	if ( count == 0 ) {	maxVersions = g.getMaxVersions();	} else if (g.getMaxVersions() != maxVersions) {	
maxversions on gets do not match using the first in the list 

public Result[] get(List<Get> gets) throws IOException {	byte[][] rows = new byte[gets.size()][];	int maxVersions = 1;	int count = 0;	for(Get g:gets) {	if ( count == 0 ) {	maxVersions = g.getMaxVersions();	} else if (g.getMaxVersions() != maxVersions) {	}	if (g.getFilter() != null) {	
filters not supported on gets 

public boolean exists(Get get) throws IOException {	
exists is really get just use get 

public boolean[] exists(List<Get> gets) throws IOException {	
exists list get is really list of get calls just use get 

========================= hbase sample_3125 =========================

public void start() {	if (!BackupManager.isBackupEnabled(rss.getConfiguration())) {	
backup is not enabled check your setting 

public void start() {	if (!BackupManager.isBackupEnabled(rss.getConfiguration())) {	return;	}	this.memberRpcs.start(rss.getServerName().toString(), member);	started = true;	
started region server backup manager 

public void stop(boolean force) throws IOException {	if (!started) {	return;	}	String mode = force ? "abruptly" : "gracefully";	
stopping regionserverbackupmanager 

public Subprocedure buildSubprocedure(byte[] data) {	if (rss.isStopping() || rss.isStopped()) {	throw new IllegalStateException("Can't start backup procedure on RS: " + rss.getServerName() + ", because stopping/stopped!");	}	
attempting to run a roll log procedure for backup 

public void initialize(RegionServerServices rss) throws KeeperException {	this.rss = rss;	if (!BackupManager.isBackupEnabled(rss.getConfiguration())) {	
backup is not enabled check your setting 

========================= hbase sample_585 =========================

sleepMultiplier++;	}	}	try {	WALEntryBatch entryBatch = entryReader.take();	for (Map.Entry<String, Long> entry : entryBatch.getLastSeqIds().entrySet()) {	waitingUntilCanPush(entry);	}	shipEdits(entryBatch);	} catch (InterruptedException e) {	
interrupted while waiting for next replication entry batch 

source.getSourceMetrics().setAgeOfLastShippedOp(EnvironmentEdgeManager.currentTime(), walGroupId);	}	return;	}	int currentSize = (int) entryBatch.getHeapSize();	while (isActive()) {	try {	try {	source.tryThrottle(currentSize);	} catch (InterruptedException e) {	
interrupted while sleeping for throttling control 

for (int i = 0; i < size; i++) {	cleanUpHFileRefs(entries.get(i).getEdit());	}	updateSerialRepPositions(entryBatch.getLastSeqIds());	updateLogPosition(lastReadPosition);	}	source.postShipEdits(entries, currentSize);	source.getSourceMetrics().shipBatch(entryBatch.getNbOperations(), currentSize, entryBatch.getNbHFiles());	source.getSourceMetrics().setAgeOfLastShippedOp( entries.get(entries.size() - 1).getKey().getWriteTime(), walGroupId);	if (LOG.isTraceEnabled()) {	
replicated entries or operations in ms 

updateSerialRepPositions(entryBatch.getLastSeqIds());	updateLogPosition(lastReadPosition);	}	source.postShipEdits(entries, currentSize);	source.getSourceMetrics().shipBatch(entryBatch.getNbOperations(), currentSize, entryBatch.getNbHFiles());	source.getSourceMetrics().setAgeOfLastShippedOp( entries.get(entries.size() - 1).getKey().getWriteTime(), walGroupId);	if (LOG.isTraceEnabled()) {	}	break;	} catch (Exception ex) {	
threw unknown exception 

long seq = entry.getValue();	boolean deleteKey = false;	if (seq <= 0) {	deleteKey = true;	seq = -seq;	}	if (!canSkipWaitingSet.getUnchecked(key)) {	try {	source.getSourceManager().waitUntilCanBePushed(Bytes.toBytes(key), seq, source.getPeerId());	} catch (IOException e) {	
waituntilcanbepushed fail 

if (seq <= 0) {	deleteKey = true;	seq = -seq;	}	if (!canSkipWaitingSet.getUnchecked(key)) {	try {	source.getSourceManager().waitUntilCanBePushed(Bytes.toBytes(key), seq, source.getPeerId());	} catch (IOException e) {	throw new RuntimeException("waitUntilCanBePushed fail");	} catch (InterruptedException e) {	
waituntilcanbepushed interrupted 

private void updateSerialRepPositions(Map<String, Long> lastPositionsForSerialScope) {	try {	MetaTableAccessor.updateReplicationPositions(source.getSourceManager().getConnection(), source.getPeerId(), lastPositionsForSerialScope);	} catch (IOException e) {	
updatereplicationpositions fail 

public boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	
sleeping times 

public boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	}	Thread.sleep(this.sleepForRetries * sleepMultiplier);	} catch (InterruptedException e) {	
interrupted while sleeping between retries 

========================= hbase sample_2958 =========================

TEST_UTIL.getAdmin().modifyColumnFamily(htd.getTableName(), hcd);	Thread.sleep(5000);	TEST_UTIL.getAdmin().majorCompact(htd.getTableName());	final List<Path> updatePaths = findCompactedStorefilePaths(htd.getTableName());	TEST_UTIL.waitFor(30000, 1000, true, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	boolean found = false;	for (Path path: updatePaths) {	found = TEST_UTIL.getTestFileSystem().exists(path);	if (found) {	
found 

========================= hbase sample_1698 =========================

public Response get(final @Context ServletContext context, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3076 =========================

regions[region.getRegionInfo().getReplicaId()] = region;	}	}	for (Region region : regions) {	assertNotNull(region);	}	for (int i = 1; i < regionReplication; i++) {	final Region region = regions[i];	Waiter.waitFor(HTU.getConfiguration(), 90000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	
verifying replication for region replica 

for (Region region : regions) {	assertNotNull(region);	}	for (int i = 1; i < regionReplication; i++) {	final Region region = regions[i];	Waiter.waitFor(HTU.getConfiguration(), 90000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	try {	HTU.verifyNumericRows(region, HBaseTestingUtility.fam1, startRow, endRow, present);	} catch(Throwable ex) {	
verification from secondary region is not complete yet 

htd.setRegionReplication(regionReplication);	htd.setRegionMemstoreReplication(false);	HTU.getAdmin().createTable(htd);	Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(tableName);	try {	final int STEP = 100;	for (int i = 0; i < 3; ++i) {	final int startRow = i * STEP;	final int endRow = (i + 1) * STEP;	
writing data from to 

HTU.getAdmin().createTable(htd);	Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(tableName);	try {	final int STEP = 100;	for (int i = 0; i < 3; ++i) {	final int startRow = i * STEP;	final int endRow = (i + 1) * STEP;	HTU.loadNumericRows(table, HBaseTestingUtility.fam1, startRow, endRow);	verifyReplication(tableName, regionReplication, startRow, endRow, false);	
flushing table 

public void testRegionReplicaReplicationForFlushAndCompaction() throws Exception {	int regionReplication = 3;	final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor htd = HTU.createTableDescriptor(tableName);	htd.setRegionReplication(regionReplication);	HTU.getAdmin().createTable(htd);	Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(tableName);	try {	for (int i = 0; i < 6000; i += 1000) {	
writing data from to 

int regionReplication = 3;	final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor htd = HTU.createTableDescriptor(tableName);	htd.setRegionReplication(regionReplication);	HTU.getAdmin().createTable(htd);	Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(tableName);	try {	for (int i = 0; i < 6000; i += 1000) {	HTU.loadNumericRows(table, HBaseTestingUtility.fam1, i, i+1000);	
flushing table 

final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor htd = HTU.createTableDescriptor(tableName);	htd.setRegionReplication(regionReplication);	HTU.getAdmin().createTable(htd);	Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(tableName);	try {	for (int i = 0; i < 6000; i += 1000) {	HTU.loadNumericRows(table, HBaseTestingUtility.fam1, i, i+1000);	HTU.flush(tableName);	
compacting table 

========================= hbase sample_1948 =========================

public static void setUpBeforeClass() throws Exception {	Configuration conf = TEST_UTIL.getConfiguration();	conf.setLong(HConstants.HREGION_MAX_FILESIZE, 768L * 1024L);	conf.setInt("hbase.regionserver.maxlogentries", 32);	
hbase regionserver logroll errors tolerated 

========================= hbase sample_1620 =========================

public void waitMetaRegionLocation(ZKWatcher zkw) throws InterruptedException {	long startTime = System.currentTimeMillis();	while (!stopped) {	try {	if (waitMetaRegionLocation(zkw, 100) != null) {	break;	}	long sleepTime = System.currentTimeMillis() - startTime;	if ((sleepTime + 1) % 10000 == 0) {	
have been waiting for meta to be assigned for ms 

while (!stopped) {	try {	if (waitMetaRegionLocation(zkw, 100) != null) {	break;	}	long sleepTime = System.currentTimeMillis() - startTime;	if ((sleepTime + 1) % 10000 == 0) {	}	} catch (NotAllMetaRegionsOnlineException e) {	if (LOG.isTraceEnabled()) {	
hbase meta still not available sleeping and retrying reason 

private boolean verifyRegionLocation(final ClusterConnection connection, AdminService.BlockingInterface hostingServer, final ServerName address, final byte [] regionName) {	if (hostingServer == null) {	
passed hostingserver is null 

}	AdminService.BlockingInterface service = null;	try {	service = connection.getAdmin(sn);	} catch (RetriesExhaustedException e) {	if (e.getCause() != null && e.getCause() instanceof ConnectException) {	} else {	throw e;	}	} catch (SocketTimeoutException e) {	
timed out connecting to 

AdminService.BlockingInterface service = null;	try {	service = connection.getAdmin(sn);	} catch (RetriesExhaustedException e) {	if (e.getCause() != null && e.getCause() instanceof ConnectException) {	} else {	throw e;	}	} catch (SocketTimeoutException e) {	} catch (NoRouteToHostException e) {	
connecting to 

try {	service = connection.getAdmin(sn);	} catch (RetriesExhaustedException e) {	if (e.getCause() != null && e.getCause() instanceof ConnectException) {	} else {	throw e;	}	} catch (SocketTimeoutException e) {	} catch (NoRouteToHostException e) {	} catch (SocketException e) {	
exception connecting to 

service = connection.getAdmin(sn);	} catch (RetriesExhaustedException e) {	if (e.getCause() != null && e.getCause() instanceof ConnectException) {	} else {	throw e;	}	} catch (SocketTimeoutException e) {	} catch (NoRouteToHostException e) {	} catch (SocketException e) {	} catch (UnknownHostException e) {	
unknown host exception connecting to 

if (e.getCause() != null && e.getCause() instanceof ConnectException) {	} else {	throw e;	}	} catch (SocketTimeoutException e) {	} catch (NoRouteToHostException e) {	} catch (SocketException e) {	} catch (UnknownHostException e) {	} catch (FailedServerException e) {	if (LOG.isDebugEnabled()) {	
server is in failed server list 

public static void setMetaLocation(ZKWatcher zookeeper, ServerName serverName, int replicaId, RegionState.State state) throws KeeperException {	if (serverName == null) {	
tried to set null servername in hbase meta skipping servername required 

if (serverName == null) {	return;	}	LOG.info("Setting hbase:meta (replicaId=" + replicaId + ") location in ZooKeeper as " + serverName);	MetaRegionServer pbrsr = MetaRegionServer.newBuilder() .setServer(ProtobufUtil.toServerName(serverName)) .setRpcVersion(HConstants.RPC_CURRENT_VERSION) .setState(state.convert()).build();	byte[] data = ProtobufUtil.prependPBMagic(pbrsr.toByteArray());	try {	ZKUtil.setData(zookeeper, zookeeper.znodePaths.getZNodeForReplica(replicaId), data);	} catch(KeeperException.NoNodeException nne) {	if (replicaId == RegionInfo.DEFAULT_REPLICA_ID) {	
meta region location doesn t exist create it 

public void deleteMetaLocation(ZKWatcher zookeeper, int replicaId) throws KeeperException {	if (replicaId == RegionInfo.DEFAULT_REPLICA_ID) {	
deleting hbase meta region location in zookeeper 

public void deleteMetaLocation(ZKWatcher zookeeper, int replicaId) throws KeeperException {	if (replicaId == RegionInfo.DEFAULT_REPLICA_ID) {	} else {	
deleting hbase meta for region location in zookeeper 

List<ServerName> servers = new ArrayList<>();	ServerName server = blockUntilAvailable(zkw, timeout);	if (server == null) {	return null;	}	servers.add(server);	try {	List<String> metaReplicaNodes = zkw.getMetaReplicaNodes();	numReplicasConfigured = metaReplicaNodes.size();	} catch (KeeperException e) {	
got zk exception 

public void stop() {	if (!stopped) {	
stopping metatablelocator 

========================= hbase sample_747 =========================

public void startHBase() throws IOException {	startDaemonLogTailer();	cleanupOldState();	
starting zookeeper on port 

cleanupOldState();	startZK();	HBaseTestingUtility.waitForHostPort(HConstants.LOCALHOST, zkClientPort);	for (int masterPort : masterPorts) {	startMaster(masterPort);	}	ZKUtil.waitForBaseZNode(conf);	for (int rsPort : rsPorts) {	startRegionServer(rsPort);	}	
waiting for hbase startup by scanning meta 

}	ZKUtil.waitForBaseZNode(conf);	for (int rsPort : rsPorts) {	startRegionServer(rsPort);	}	int attemptsLeft = 10;	while (attemptsLeft-- > 0) {	try {	testUtil.getConnection().getTable(TableName.META_TABLE_NAME);	} catch (Exception e) {	
waiting for hbase to startup retries left 

startRegionServer(rsPort);	}	int attemptsLeft = 10;	while (attemptsLeft-- > 0) {	try {	testUtil.getConnection().getTable(TableName.META_TABLE_NAME);	} catch (Exception e) {	Threads.sleep(1000);	}	}	
process based hbase cluster with region servers up and running 

private void executeCommand(String command, Map<String, String> envOverrides) {	ensureShutdownHookInstalled();	
command 

BufferedReader stdInput = new BufferedReader( new InputStreamReader(p.getInputStream()));	BufferedReader stdError = new BufferedReader( new InputStreamReader(p.getErrorStream()));	String s = null;	while ((s = stdInput.readLine()) != null) {	System.out.println(s);	}	while ((s = stdError.readLine()) != null) {	System.out.println(s);	}	} catch (IOException e) {	
error running 

private void shutdownAllProcesses() {	
killing daemons using pid files 

private void shutdownAllProcesses() {	final List<String> pidFiles = new ArrayList<>(daemonPidFiles);	for (String pidFile : pidFiles) {	int pid = 0;	try {	pid = readPidFromFile(pidFile);	} catch (IOException ex) {	
could not read pid from file 

private void shutdownAllProcesses() {	final List<String> pidFiles = new ArrayList<>(daemonPidFiles);	for (String pidFile : pidFiles) {	int pid = 0;	try {	pid = readPidFromFile(pidFile);	} catch (IOException ex) {	}	if (pid > 0) {	
killing pid 

private void writeStringToFile(String s, String fileName) {	try {	BufferedWriter out = new BufferedWriter(new FileWriter(fileName));	out.write(s);	out.close();	} catch (IOException e) {	
error writing to 

private void startServer(ServerType serverType, int rsPort) {	String dir = serverWorkingDir(serverType, rsPort);	String confStr = generateConfig(serverType, rsPort, dir);	
creating directory 

String confStr = generateConfig(serverType, rsPort, dir);	new File(dir).mkdirs();	writeStringToFile(confStr, dir + "/hbase-site.xml");	writeStringToFile( "unset HBASE_MASTER_OPTS\n" + "unset HBASE_REGIONSERVER_OPTS\n" + "unset HBASE_ZOOKEEPER_OPTS\n" + "HBASE_MASTER_DBG_OPTS=' '\n" + "HBASE_REGIONSERVER_DBG_OPTS=' '\n" + "HBASE_ZOOKEEPER_DBG_OPTS=' '\n" + "HBASE_MASTER_JMX_OPTS=' '\n" + "HBASE_REGIONSERVER_JMX_OPTS=' '\n" + "HBASE_ZOOKEEPER_JMX_OPTS=' '\n", dir + "/hbase-env.sh");	Map<String, String> envOverrides = new HashMap<>();	envOverrides.put("HBASE_LOG_DIR", dir);	envOverrides.put("HBASE_PID_DIR", dir);	try {	FileUtils.copyFile( new File(hbaseHome, "conf/log4j.properties"), new File(dir, "log4j.properties"));	} catch (IOException ex) {	
could not install properties into 

private static void reportWebUIPort(String daemon, int port) {	
local web ui is at http hconstants localhost port 

private void runInternal() throws IOException {	Thread.currentThread().setName(getClass().getSimpleName());	while (true) {	scanDirs();	try {	Thread.sleep(500);	} catch (InterruptedException e) {	
log tailer thread interrupted 

private void startTailingFile(final String filePath) throws FileNotFoundException {	final PrintStream dest = filePath.endsWith(".log") ? System.err : System.out;	final ServerType serverType;	final int serverPort;	Matcher m = LOG_PATH_FORMAT_RE.matcher(filePath);	if (m.matches()) {	serverType = ServerType.valueOf(m.group(1));	serverPort = Integer.valueOf(m.group(2));	} else {	
unrecognized log path format 

final ServerType serverType;	final int serverPort;	Matcher m = LOG_PATH_FORMAT_RE.matcher(filePath);	if (m.matches()) {	serverType = ServerType.valueOf(m.group(1));	serverPort = Integer.valueOf(m.group(2));	} else {	return;	}	final String logMsgPrefix = "[" + serverType + (serverPort != 0 ? ":" + serverPort : "") + "] ";	
tailing 

Thread t = new Thread(new Runnable() {	public void run() {	try {	FileInputStream fis = new FileInputStream(filePath);	BufferedReader br = new BufferedReader(new InputStreamReader(fis));	String line;	while (true) {	try {	Thread.sleep(200);	} catch (InterruptedException e) {	
tailer for interrupted 

if (line.endsWith("\n")) {	dest.print(line);	} else {	dest.println(line);	}	dest.flush();	}	}	}	} catch (IOException ex) {	
failed tailing 

========================= hbase sample_1335 =========================

public void perform() throws Exception {	
performing action batch restarting d of region servers 

public void perform() throws Exception {	List<ServerName> selectedServers = PolicyBasedChaosMonkey.selectRandomItems(getCurrentServers(), ratio);	Set<ServerName> killedServers = new HashSet<>();	for (ServerName server : selectedServers) {	if (context.isStopping()) {	break;	}	
killing region server 

for (ServerName server : selectedServers) {	if (context.isStopping()) {	break;	}	cluster.killRegionServer(server);	killedServers.add(server);	}	for (ServerName server : killedServers) {	cluster.waitForRegionServerToStop(server, PolicyBasedChaosMonkey.TIMEOUT);	}	
killed region servers reported num of rs 

break;	}	cluster.killRegionServer(server);	killedServers.add(server);	}	for (ServerName server : killedServers) {	cluster.waitForRegionServerToStop(server, PolicyBasedChaosMonkey.TIMEOUT);	}	sleep(sleepTime);	for (ServerName server : killedServers) {	
starting region server 

for (ServerName server : killedServers) {	cluster.waitForRegionServerToStop(server, PolicyBasedChaosMonkey.TIMEOUT);	}	sleep(sleepTime);	for (ServerName server : killedServers) {	cluster.startRegionServer(server.getHostname(), server.getPort());	}	for (ServerName server : killedServers) {	cluster.waitForRegionServerToStart(server.getHostname(), server.getPort(), PolicyBasedChaosMonkey.TIMEOUT);	}	
started region servers reported num of rs 

========================= hbase sample_3308 =========================

public void close() {	if (this.scanner != null) {	try {	this.scanner.close();	this.scanner = null;	} catch (IOException ex) {	
exception while closing scanner 

this.scanner = null;	} catch (IOException ex) {	}	}	if (this.region != null) {	try {	this.region.closeRegionOperation();	this.region.close(true);	this.region = null;	} catch (IOException ex) {	
exception while closing region 

========================= hbase sample_3021 =========================

public TableRecordWriter() throws IOException {	String tableName = conf.get(OUTPUT_TABLE);	this.connection = ConnectionFactory.createConnection(conf);	this.mutator = connection.getBufferedMutator(TableName.valueOf(tableName));	
created table instance for 

========================= hbase sample_3471 =========================

public void run() {	try {	if (call.disconnectSince() >= 0) {	if (RpcServer.LOG.isDebugEnabled()) {	
skipped 

public void run() {	try {	if (call.disconnectSince() >= 0) {	if (RpcServer.LOG.isDebugEnabled()) {	}	return;	}	call.setStartTime(System.currentTimeMillis());	if (call.getStartTime() > call.getDeadline()) {	
dropping timed out call 

return;	}	call.setStartTime(System.currentTimeMillis());	if (call.getStartTime() > call.getDeadline()) {	return;	}	this.status.setStatus("Setting up call");	this.status.setConnection(call.getRemoteAddress().getHostAddress(), call.getRemotePort());	if (RpcServer.LOG.isTraceEnabled()) {	Optional<User> remoteUser = call.getRequestUser();	
executing as null principal 

if (!this.rpcServer.isStarted()) {	InetSocketAddress address = rpcServer.getListenerAddress();	throw new ServerNotRunningYetException("Server " + (address != null ? address : "(channel closed)") + " is not running yet");	}	String serviceName = call.getService() != null ? call.getService().getDescriptorForType().getName() : "";	String methodName = (call.getMethod() != null) ? call.getMethod().getName() : "";	String traceString = serviceName + "." + methodName;	TraceUtil.createTrace(traceString);	resultPair = this.rpcServer.call(call, this.status);	} catch (TimeoutIOException e){	
can not complete this request in time drop it 

call.cleanup();	Message param = resultPair != null ? resultPair.getFirst() : null;	CellScanner cells = resultPair != null ? resultPair.getSecond() : null;	call.setResponse(param, cells, errorThrowable, error);	call.sendResponseIfReady();	this.status.markComplete("Sent response");	this.status.pause("Waiting for a call");	} catch (OutOfMemoryError e) {	if (this.rpcServer.getErrorHandler() != null) {	if (this.rpcServer.getErrorHandler().checkOOME(e)) {	
exiting on outofmemoryerror 

if (this.rpcServer.getErrorHandler().checkOOME(e)) {	return;	}	} else {	throw e;	}	} catch (ClosedChannelException cce) {	InetSocketAddress address = rpcServer.getListenerAddress();	RpcServer.LOG.warn(Thread.currentThread().getName() + ": caught a ClosedChannelException, " + "this means that the server " + (address != null ? address : "(channel closed)") + " was processing a request but the client went away. The error message was: " + cce.getMessage());	} catch (Exception e) {	
caught 

public void drop() {	try {	if (call.disconnectSince() >= 0) {	if (RpcServer.LOG.isDebugEnabled()) {	
skipped 

}	return;	}	InetSocketAddress address = rpcServer.getListenerAddress();	call.setResponse(null, null, CALL_DROPPED_EXCEPTION, "Call dropped, server " + (address != null ? address : "(channel closed)") + " is overloaded, please retry.");	call.sendResponseIfReady();	} catch (ClosedChannelException cce) {	InetSocketAddress address = rpcServer.getListenerAddress();	RpcServer.LOG.warn(Thread.currentThread().getName() + ": caught a ClosedChannelException, " + "this means that the server " + (address != null ? address : "(channel closed)") + " was processing a request but the client went away. The error message was: " + cce.getMessage());	} catch (Exception e) {	
caught 

========================= hbase sample_2904 =========================

private void failSnapshotStart(Admin admin, SnapshotDescription snapshot) throws IOException {	try {	admin.snapshot(snapshot);	fail("Snapshot should not have succeed with name:" + snapshot.getName());	} catch (IllegalArgumentException e) {	
correctly failed to start snapshot 

private void failSnapshotDescriptorCreation(final String snapshotName, final String tableName) {	try {	new SnapshotDescription(snapshotName, tableName);	fail("SnapshotDescription should not have succeed with name:" + snapshotName);	} catch (IllegalArgumentException e) {	
correctly failed to create snapshotdescription 

========================= hbase sample_79 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	String snapshotName = tableName + "-it-" + System.currentTimeMillis();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	
performing action snapshot table 

========================= hbase sample_3303 =========================

public void requestMobCompaction(Configuration conf, FileSystem fs, TableName tableName, List<ColumnFamilyDescriptor> columns, boolean allFiles) throws IOException {	master.reportMobCompactionStart(tableName);	try {	masterMobPool.execute(new CompactionRunner(fs, tableName, columns, allFiles, mobCompactorPool));	} catch (RejectedExecutionException e) {	try {	master.reportMobCompactionEnd(tableName);	} catch (IOException e1) {	
failed to mark end of mob compaction 

try {	masterMobPool.execute(new CompactionRunner(fs, tableName, columns, allFiles, mobCompactorPool));	} catch (RejectedExecutionException e) {	try {	master.reportMobCompactionEnd(tableName);	} catch (IOException e1) {	}	throw e;	}	if (LOG.isDebugEnabled()) {	
the mob compaction is requested for the columns of the table 

public void run() {	final LockManager.MasterLock lock = master.getLockManager().createMasterLock( MobUtils.getTableLockName(tableName), LockType.EXCLUSIVE, this.getClass().getName() + ": mob compaction");	try {	for (ColumnFamilyDescriptor hcd : hcds) {	MobUtils.doMobCompaction(conf, fs, tableName, hcd, pool, allFiles, lock);	}	} catch (IOException e) {	
failed to perform the mob compaction 

final LockManager.MasterLock lock = master.getLockManager().createMasterLock( MobUtils.getTableLockName(tableName), LockType.EXCLUSIVE, this.getClass().getName() + ": mob compaction");	try {	for (ColumnFamilyDescriptor hcd : hcds) {	MobUtils.doMobCompaction(conf, fs, tableName, hcd, pool, allFiles, lock);	}	} catch (IOException e) {	} finally {	try {	master.reportMobCompactionEnd(tableName);	} catch (IOException e) {	
failed to mark end of mob compaction 

private void waitFor(ExecutorService t, String name) {	boolean done = false;	while (!done) {	try {	done = t.awaitTermination(60, TimeUnit.SECONDS);	
waiting for to finish 

private void waitFor(ExecutorService t, String name) {	boolean done = false;	while (!done) {	try {	done = t.awaitTermination(60, TimeUnit.SECONDS);	if (!done) {	t.shutdownNow();	}	} catch (InterruptedException ie) {	
interrupted waiting for to finish 

========================= hbase sample_2791 =========================

final TableName tn = helper.createTableWithRegions(numRegions);	QuotaSettings settings = QuotaSettingsFactory.limitTableSpace( tn, sizeLimit, SpaceViolationPolicy.NO_INSERTS);	TEST_UTIL.getAdmin().setQuota(settings);	QuotaSettings nsSettings = QuotaSettingsFactory.limitNamespaceSpace( tn.getNamespaceAsString(), nsLimit, SpaceViolationPolicy.NO_INSERTS);	TEST_UTIL.getAdmin().setQuota(nsSettings);	helper.writeData(tn, tableSize);	final Connection conn = TEST_UTIL.getConnection();	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	SpaceQuotaSnapshot snapshot = QuotaTableUtil.getCurrentSnapshot(conn, tn);	
table snapshot after initial ingest 

if (snapshot == null) {	return false;	}	return snapshot.getLimit() == sizeLimit && snapshot.getUsage() > 0L;	}	});	final AtomicReference<Long> nsUsage = new AtomicReference<>();	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000 * 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	SpaceQuotaSnapshot snapshot = QuotaTableUtil.getCurrentSnapshot( conn, tn.getNamespaceAsString());	
namespace snapshot after initial ingest 

return snapshot.getLimit() == nsLimit && snapshot.getUsage() > 0;	}	});	try {	helper.writeData(tn, tableSize * 2L);	} catch (RetriesExhaustedWithDetailsException | SpaceLimitingException e) {	}	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	SpaceQuotaSnapshot snapshot = QuotaTableUtil.getCurrentSnapshot(conn, tn);	
table snapshot after second ingest 

SpaceQuotaSnapshot snapshot = QuotaTableUtil.getCurrentSnapshot(conn, tn);	if (snapshot == null) {	return false;	}	return snapshot.getQuotaStatus().isInViolation();	}	});	Waiter.waitFor(TEST_UTIL.getConfiguration(), 30 * 1000, new Predicate<Exception>() {	public boolean evaluate() throws Exception {	SpaceQuotaSnapshot snapshot = QuotaTableUtil.getCurrentSnapshot( conn, tn.getNamespaceAsString());	
namespace snapshot after second ingest 

========================= hbase sample_1447 =========================

private void readIndex(boolean useTags) throws IOException {	long fileSize = fs.getFileStatus(path).getLen();	
size of 

FSDataInputStream istream = fs.open(path);	HFileContext meta = new HFileContextBuilder() .withHBaseCheckSum(true) .withIncludesMvcc(includesMemstoreTS) .withIncludesTags(useTags) .withCompression(compr) .build();	HFileBlock.FSReader blockReader = new HFileBlock.FSReaderImpl(istream, fs.getFileStatus(path) .getLen(), meta);	BlockReaderWrapper brw = new BlockReaderWrapper(blockReader);	HFileBlockIndex.BlockIndexReader indexReader = new HFileBlockIndex.CellBasedKeyBlockIndexReader( CellComparatorImpl.COMPARATOR, numLevels, brw);	indexReader.readRootIndex(blockReader.blockRange(rootIndexOffset, fileSize).nextBlockWithBlockType(BlockType.ROOT_INDEX), numRootEntries);	long prevOffset = -1;	int i = 0;	int expectedHitCount = 0;	int expectedMissCount = 0;	
total number of keys 

if (PrivateCellUtil.compare(CellComparatorImpl.COMPARATOR, keyOnlyKey, firstKeyInFile, 0, firstKeyInFile.length) < 0) {	assertTrue(b == null);	++i;	continue;	}	String keyStr = "key #" + i + ", " + Bytes.toStringBinary(key);	assertTrue("seekToDataBlock failed for " + keyStr, b != null);	if (prevOffset == b.getOffset()) {	assertEquals(++expectedHitCount, brw.hitCount);	} else {	
first key in a new block block offset 

private void writeInlineBlocks(HFileBlock.Writer hbw, FSDataOutputStream outputStream, HFileBlockIndex.BlockIndexWriter biw, boolean isClosing) throws IOException {	while (biw.shouldWriteBlock(isClosing)) {	long offset = outputStream.getPos();	biw.writeInlineBlock(hbw.startWriting(biw.getInlineBlockType()));	hbw.writeHeaderAndData(outputStream);	biw.blockWritten(offset, hbw.getOnDiskSizeWithHeader(), hbw.getUncompressedSizeWithoutHeader());	
wrote an inline index block at size 

byte[] k = RandomKeyValueUtil.randomOrderedKey(rand, i * 2);	KeyValue cell = new KeyValue(k, Bytes.toBytes("f"), Bytes.toBytes("q"), Bytes.toBytes("val"));	keys.add(cell.getKey());	String msgPrefix = "Key #" + i + " (" + Bytes.toStringBinary(k) + "): ";	StringBuilder padding = new StringBuilder();	while (msgPrefix.length() + padding.length() < 70) padding.append(' ');	msgPrefix += padding;	if (i % 2 == 1) {	dos.writeInt(curAllEntriesSize);	secondaryIndexEntries[i] = curAllEntriesSize;	
secondary index entry offset 

StringBuilder padding = new StringBuilder();	while (msgPrefix.length() + padding.length() < 70) padding.append(' ');	msgPrefix += padding;	if (i % 2 == 1) {	dos.writeInt(curAllEntriesSize);	secondaryIndexEntries[i] = curAllEntriesSize;	curAllEntriesSize += cell.getKey().length + HFileBlockIndex.SECONDARY_INDEX_ENTRY_OVERHEAD;	++numEntriesAdded;	} else {	secondaryIndexEntries[i] = -1;	
not in the searched array 

assertEquals(numSearchedKeys, numEntriesAdded);	int secondaryIndexOffset = dos.size();	assertEquals(Bytes.SIZEOF_INT * (numSearchedKeys + 2), secondaryIndexOffset);	for (int i = 1; i <= numTotalKeys - 1; i += 2) {	assertEquals(dos.size(), secondaryIndexOffset + secondaryIndexEntries[i]);	long dummyFileOffset = getDummyFileOffset(i);	int dummyOnDiskSize = getDummyOnDiskSize(i);	LOG.debug("Storing file offset=" + dummyFileOffset + " and onDiskSize=" + dummyOnDiskSize + " at offset " + dos.size());	dos.writeLong(dummyFileOffset);	dos.writeInt(dummyOnDiskSize);	
stored key at offset 

public void testHFileWriterAndReader() throws IOException {	Path hfilePath = new Path(TEST_UTIL.getDataTestDir(), "hfile_for_block_index");	CacheConfig cacheConf = new CacheConfig(conf);	BlockCache blockCache = cacheConf.getBlockCache();	for (int testI = 0; testI < INDEX_CHUNK_SIZES.length; ++testI) {	int indexBlockSize = INDEX_CHUNK_SIZES[testI];	int expectedNumLevels = EXPECTED_NUM_LEVELS[testI];	
index block size compression 

if (i > 0) {	assertTrue((PrivateCellUtil.compare(CellComparatorImpl.COMPARATOR, kv, keys[i - 1], 0, keys[i - 1].length)) > 0);	}	}	writer.close();	}	HFile.Reader reader = HFile.createReader(fs, hfilePath, cacheConf, true, conf);	assertEquals(expectedNumLevels, reader.getTrailer().getNumDataIndexLevels());	assertTrue(Bytes.equals(keys[0], ((KeyValue)reader.getFirstKey().get()).getKey()));	assertTrue(Bytes.equals(keys[NUM_KV - 1], ((KeyValue)reader.getLastKey().get()).getKey()));	
last key 

========================= hbase sample_1502 =========================

String[] receiverNames = conf.getStrings(SPAN_RECEIVERS_CONF_KEY);	if (receiverNames == null || receiverNames.length == 0) {	return;	}	SpanReceiver.Builder builder = new SpanReceiver.Builder(new HBaseHTraceConfiguration(conf));	for (String className : receiverNames) {	className = className.trim();	SpanReceiver receiver = builder.className(className).build();	if (receiver != null) {	receivers.add(receiver);	
spanreceiver was loaded successfully 

public synchronized void closeReceivers() {	if (closed) return;	closed = true;	for (SpanReceiver rcvr : receivers) {	try {	rcvr.close();	} catch (IOException e) {	
unable to close spanreceiver correctly 

========================= hbase sample_936 =========================

public CacheConfig(Configuration conf, ColumnFamilyDescriptor family) {	this(CacheConfig.instantiateBlockCache(conf), conf.getBoolean(CACHE_DATA_ON_READ_KEY, DEFAULT_CACHE_DATA_ON_READ) && family.isBlockCacheEnabled(), family.isInMemory(), conf.getBoolean(CACHE_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_DATA_ON_WRITE) || family.isCacheDataOnWrite(), conf.getBoolean(CACHE_INDEX_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_INDEXES_ON_WRITE) || family.isCacheIndexesOnWrite(), conf.getBoolean(CACHE_BLOOM_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_BLOOMS_ON_WRITE) || family.isCacheBloomsOnWrite(), conf.getBoolean(EVICT_BLOCKS_ON_CLOSE_KEY, DEFAULT_EVICT_ON_CLOSE) || family.isEvictBlocksOnClose(), conf.getBoolean(CACHE_DATA_BLOCKS_COMPRESSED_KEY, DEFAULT_CACHE_DATA_COMPRESSED), conf.getBoolean(PREFETCH_BLOCKS_ON_OPEN_KEY, DEFAULT_PREFETCH_ON_OPEN) || family.isPrefetchBlocksOnOpen(), conf.getBoolean(DROP_BEHIND_CACHE_COMPACTION_KEY, DROP_BEHIND_CACHE_COMPACTION_DEFAULT) );	
created cacheconfig for 

public CacheConfig(Configuration conf) {	this(CacheConfig.instantiateBlockCache(conf), conf.getBoolean(CACHE_DATA_ON_READ_KEY, DEFAULT_CACHE_DATA_ON_READ), DEFAULT_IN_MEMORY, conf.getBoolean(CACHE_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_DATA_ON_WRITE), conf.getBoolean(CACHE_INDEX_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_INDEXES_ON_WRITE), conf.getBoolean(CACHE_BLOOM_BLOCKS_ON_WRITE_KEY, DEFAULT_CACHE_BLOOMS_ON_WRITE), conf.getBoolean(EVICT_BLOCKS_ON_CLOSE_KEY, DEFAULT_EVICT_ON_CLOSE), conf.getBoolean(CACHE_DATA_BLOCKS_COMPRESSED_KEY, DEFAULT_CACHE_DATA_COMPRESSED), conf.getBoolean(PREFETCH_BLOCKS_ON_OPEN_KEY, DEFAULT_PREFETCH_ON_OPEN), conf.getBoolean(DROP_BEHIND_CACHE_COMPACTION_KEY, DROP_BEHIND_CACHE_COMPACTION_DEFAULT) );	
created cacheconfig 

private static BlockCache getExternalBlockcache(Configuration c) {	if (LOG.isDebugEnabled()) {	
trying to use external cache 

try {	klass = ExternalBlockCaches.valueOf(c.get(EXTERNAL_BLOCKCACHE_CLASS_KEY, "memcache")).clazz;	} catch (IllegalArgumentException exception) {	try {	klass = c.getClass(EXTERNAL_BLOCKCACHE_CLASS_KEY, Class.forName( "org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache"));	} catch (ClassNotFoundException e) {	return null;	}	}	try {	
creating external block cache of type 

} catch (IllegalArgumentException exception) {	try {	klass = c.getClass(EXTERNAL_BLOCKCACHE_CLASS_KEY, Class.forName( "org.apache.hadoop.hbase.io.hfile.MemcachedBlockCache"));	} catch (ClassNotFoundException e) {	return null;	}	}	try {	return (BlockCache) ReflectionUtils.newInstance(klass, c);	} catch (Exception e) {	
error creating external block cache 

static BucketCache getBucketCache(Configuration c) {	String bucketCacheIOEngineName = c.get(BUCKET_CACHE_IOENGINE_KEY, null);	if (bucketCacheIOEngineName == null || bucketCacheIOEngineName.length() <= 0) return null;	int blockSize = c.getInt(BLOCKCACHE_BLOCKSIZE_KEY, HConstants.DEFAULT_BLOCKSIZE);	final long bucketCacheSize = MemorySizeUtil.getBucketCacheSize(c);	if (bucketCacheSize <= 0) {	throw new IllegalStateException("bucketCacheSize <= 0; Check " + BUCKET_CACHE_SIZE_KEY + " setting and/or server java heap size");	}	if (c.get("hbase.bucketcache.percentage.in.combinedcache") != null) {	
configuration hbase bucketcache percentage in combinedcache is no longer respected see comments in http 

throw new IllegalArgumentException("Illegal value: " + bucketSize + " configured for '" + BUCKET_CACHE_BUCKETS_KEY + "'. All bucket sizes to be multiples of 256");	}	bucketSizes[i] = bucketSize;	}	}	BucketCache bucketCache = null;	try {	int ioErrorsTolerationDuration = c.getInt( "hbase.bucketcache.ioengine.errors.tolerated.duration", BucketCache.DEFAULT_ERROR_TOLERATION_DURATION);	bucketCache = new BucketCache(bucketCacheIOEngineName, bucketCacheSize, blockSize, bucketSizes, writerThreads, writerQueueLen, persistentPath, ioErrorsTolerationDuration, c);	} catch (IOException ioex) {	
can t instantiate bucket cache 

if (blockCacheDisabled) return null;	LruBlockCache onHeapCache = getOnHeapCacheInternal(conf);	if (blockCacheDisabled) return null;	boolean useExternal = conf.getBoolean(EXTERNAL_BLOCKCACHE_KEY, EXTERNAL_BLOCKCACHE_DEFAULT);	if (useExternal) {	L2_CACHE_INSTANCE = getExternalBlockcache(conf);	GLOBAL_BLOCK_CACHE_INSTANCE = L2_CACHE_INSTANCE == null ? onHeapCache : new InclusiveCombinedBlockCache(onHeapCache, L2_CACHE_INSTANCE);	} else {	L2_CACHE_INSTANCE = getBucketCache(conf);	if (!conf.getBoolean("hbase.bucketcache.combinedcache.enabled", true)) {	
from hbase onwards only combined mode of lru cache and bucket cache is available 

========================= hbase sample_2400 =========================

public void tearDownTestCoprocessorWhitelistMasterObserver() throws Exception {	Admin admin = UTIL.getAdmin();	try {	try {	admin.disableTable(TEST_TABLE);	} catch (TableNotEnabledException ex) {	
table was left disabled by test 

public void tearDownTestCoprocessorWhitelistMasterObserver() throws Exception {	Admin admin = UTIL.getAdmin();	try {	try {	admin.disableTable(TEST_TABLE);	} catch (TableNotEnabledException ex) {	}	admin.deleteTable(TEST_TABLE);	} catch (TableNotFoundException ex) {	
table was not created for some reason 

conf.set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, CoprocessorWhitelistMasterObserver.class.getName());	conf.setStrings( CoprocessorWhitelistMasterObserver.CP_COPROCESSOR_WHITELIST_PATHS_KEY, whitelistedPaths);	conf.setInt("hbase.client.retries.number", 1);	UTIL.startMiniCluster();	UTIL.createTable(TEST_TABLE, new byte[][] { TEST_FAMILY });	UTIL.waitUntilAllRegionsAssigned(TEST_TABLE);	Connection connection = ConnectionFactory.createConnection(conf);	Table t = connection.getTable(TEST_TABLE);	HTableDescriptor htd = new HTableDescriptor(t.getTableDescriptor());	htd.addCoprocessor("net.clayb.hbase.coprocessor.NotWhitelisted", new Path(coprocessorPath), Coprocessor.PRIORITY_USER, null);	
modifying table 

UTIL.waitUntilAllRegionsAssigned(TEST_TABLE);	Connection connection = ConnectionFactory.createConnection(conf);	Table t = connection.getTable(TEST_TABLE);	HTableDescriptor htd = new HTableDescriptor(t.getTableDescriptor());	htd.addCoprocessor("net.clayb.hbase.coprocessor.NotWhitelisted", new Path(coprocessorPath), Coprocessor.PRIORITY_USER, null);	try {	connection.getAdmin().modifyTable(TEST_TABLE, htd);	fail("Expected coprocessor to raise IOException");	} catch (IOException e) {	}	
done modifying table 

conf.setStrings( CoprocessorWhitelistMasterObserver.CP_COPROCESSOR_WHITELIST_PATHS_KEY, whitelistedPaths);	UTIL.startMiniCluster();	UTIL.createTable(TEST_TABLE, new byte[][] { TEST_FAMILY });	UTIL.waitUntilAllRegionsAssigned(TEST_TABLE);	Connection connection = ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin();	admin.disableTable(TEST_TABLE);	Table t = connection.getTable(TEST_TABLE);	HTableDescriptor htd = new HTableDescriptor(t.getTableDescriptor());	htd.addCoprocessor("net.clayb.hbase.coprocessor.Whitelisted", new Path(coprocessorPath), Coprocessor.PRIORITY_USER, null);	
modifying table 

UTIL.createTable(TEST_TABLE, new byte[][] { TEST_FAMILY });	UTIL.waitUntilAllRegionsAssigned(TEST_TABLE);	Connection connection = ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin();	admin.disableTable(TEST_TABLE);	Table t = connection.getTable(TEST_TABLE);	HTableDescriptor htd = new HTableDescriptor(t.getTableDescriptor());	htd.addCoprocessor("net.clayb.hbase.coprocessor.Whitelisted", new Path(coprocessorPath), Coprocessor.PRIORITY_USER, null);	admin.modifyTable(TEST_TABLE, htd);	assertEquals(1, t.getTableDescriptor().getCoprocessors().size());	
done modifying table 

========================= hbase sample_1386 =========================

infoServerKeytab = new File(keytabDir, serverPrincipal.replace('/', '_') + ".keytab");	clientKeytab = new File(keytabDir, CLIENT_PRINCIPAL + ".keytab");	setupUser(kdc, clientKeytab, CLIENT_PRINCIPAL);	setupUser(kdc, infoServerKeytab, serverPrincipal);	Configuration conf = buildSpnegoConfiguration(serverPrincipal, infoServerKeytab);	server = createTestServerWithSecurity(conf);	server.addServlet("echo", "/echo", EchoServlet.class);	server.addJerseyResourcePackage(JerseyResource.class.getPackage().getName(), "/jersey/*");	server.start();	baseUrl = getServerURL(server);	
http server started 

public static void stopServer() throws Exception {	try {	if (null != server) {	server.stop();	}	} catch (Exception e) {	
failed to stop info server 

if (null != server) {	server.stop();	}	} catch (Exception e) {	}	try {	if (null != kdc) {	kdc.stop();	}	} catch (Exception e) {	
failed to stop mini kdc 

if (kdcDir.exists()) {	deleteRecursively(kdcDir);	}	kdcDir.mkdirs();	kdc.setWorkDir(kdcDir);	kdc.setKdcHost(KDC_SERVER_HOST);	int kdcPort = getFreePort();	kdc.setAllowTcp(true);	kdc.setAllowUdp(false);	kdc.setKdcTcpPort(kdcPort);	
starting kdc server at 

========================= hbase sample_3211 =========================

final long done = EnvironmentEdgeManager.currentTime() + waitTime;	boolean logged = false;	do {	T result = predicate.evaluate();	if (result != null && !result.equals(Boolean.FALSE)) {	return result;	}	try {	Thread.sleep(waitingTimeForEvents);	} catch (InterruptedException e) {	
interrupted while sleeping waiting on 

T result = predicate.evaluate();	if (result != null && !result.equals(Boolean.FALSE)) {	return result;	}	try {	Thread.sleep(waitingTimeForEvents);	} catch (InterruptedException e) {	throw (InterruptedIOException)new InterruptedIOException().initCause(e);	}	if (LOG.isTraceEnabled()) {	
waitfor 

if (result != null && !result.equals(Boolean.FALSE)) {	return result;	}	try {	Thread.sleep(waitingTimeForEvents);	} catch (InterruptedException e) {	throw (InterruptedIOException)new InterruptedIOException().initCause(e);	}	if (LOG.isTraceEnabled()) {	} else {	
waitfor 

========================= hbase sample_2816 =========================

do {	assignments = master.getMaster().getAssignmentManager().getRegionStates().getRegionAssignments();	} while (assignments == null || assignments.size() < 2);	RegionInfo hri = null;	for (Map.Entry<RegionInfo, ServerName> e: assignments.entrySet()) {	if (e.getKey().isMetaRegion()) continue;	hri = e.getKey();	break;	}	assertEquals(expectedTotalRegionServers, master.getMaster().getServerManager().getOnlineServersList().size());	
move to 

========================= hbase sample_1693 =========================

private Path getDestinationDir() {	Path path = new Path(new Path(testDir, "export-test"), "export-" + System.currentTimeMillis());	
hdfs export destination path 

========================= hbase sample_3354 =========================

private void tune(double compactionPressure) {	double maxThroughputToSet;	if (compactionPressure > 1.0) {	maxThroughputToSet = Double.MAX_VALUE;	} else if (offPeakHours.isOffPeakHour()) {	maxThroughputToSet = maxThroughputOffpeak;	} else {	maxThroughputToSet = maxThroughputLowerBound + (maxThroughputUpperBound - maxThroughputLowerBound) }	if (LOG.isTraceEnabled()) {	
compactionpressure is tune throughput to 

if (conf == null) {	return;	}	this.maxThroughputUpperBound = conf.getLong(HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_HIGHER_BOUND, DEFAULT_HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_HIGHER_BOUND);	this.maxThroughputLowerBound = conf.getLong(HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_LOWER_BOUND, DEFAULT_HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_LOWER_BOUND);	this.maxThroughputOffpeak = conf.getLong(HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_OFFPEAK, DEFAULT_HBASE_HSTORE_COMPACTION_MAX_THROUGHPUT_OFFPEAK);	this.offPeakHours = OffPeakHours.getInstance(conf);	this.controlPerSize = conf.getLong(HBASE_HSTORE_COMPACTION_THROUGHPUT_CONTROL_CHECK_INTERVAL, this.maxThroughputLowerBound);	this.setMaxThroughput(this.maxThroughputLowerBound);	this.tuningPeriod = getConf().getInt(HBASE_HSTORE_COMPACTION_THROUGHPUT_TUNE_PERIOD, DEFAULT_HSTORE_COMPACTION_THROUGHPUT_TUNE_PERIOD);	
compaction throughput configurations higher bound lower bound off peak tuning period ms 

========================= hbase sample_2545 =========================

if (blockWriter != null) {	throw new IllegalStateException("finishInit called twice");	}	blockWriter = new HFileBlock.Writer(blockEncoder, hFileContext);	boolean cacheIndexesOnWrite = cacheConf.shouldCacheIndexesOnWrite();	dataBlockIndexWriter = new HFileBlockIndex.BlockIndexWriter(blockWriter, cacheIndexesOnWrite ? cacheConf : null, cacheIndexesOnWrite ? name : null);	dataBlockIndexWriter.setMaxChunkSize( HFileBlockIndex.getMaxChunkSize(conf));	dataBlockIndexWriter.setMinIndexNumEntries( HFileBlockIndex.getMinIndexNumEntries(conf));	inlineBlockWriters.add(dataBlockIndexWriter);	metaBlockIndexWriter = new HFileBlockIndex.BlockIndexWriter();	
initialized with 

========================= hbase sample_2396 =========================

private void createAndRestoreTable(Connection conn, TableName tableName, TableName newTableName, Path tableBackupPath, boolean truncateIfExists, String lastIncrBackupId) throws IOException {	if (newTableName == null) {	newTableName = tableName;	}	FileSystem fileSys = tableBackupPath.getFileSystem(this.conf);	TableDescriptor tableDescriptor = getTableDescriptor(fileSys, tableName, lastIncrBackupId);	if (tableDescriptor != null) {	
retrieved descriptor thru 

if (fileSys.exists(tableSnapshotPath)) {	if (snapshotMap.get(tableName) != null) {	SnapshotDescription desc = SnapshotDescriptionUtils.readSnapshotInfo(fileSys, tableSnapshotPath);	SnapshotManifest manifest = SnapshotManifest.open(conf, fileSys, tableSnapshotPath, desc);	tableDescriptor = manifest.getTableDescriptor();	} else {	tableDescriptor = getTableDesc(tableName);	snapshotMap.put(tableName, getTableInfoPath(tableName));	}	if (tableDescriptor == null) {	
found no table descriptor in the snapshot dir previous schema would be lost 

if (tableDescriptor == null) {	}	} else {	throw new IOException("Table snapshot directory: " + tableSnapshotPath + " does not exist.");	}	}	Path tableArchivePath = getTableArchivePath(tableName);	if (tableArchivePath == null) {	if (tableDescriptor != null) {	if (LOG.isDebugEnabled()) {	
find table descriptor but no archive dir for table will only create table 

private void checkAndCreateTable(Connection conn, Path tableBackupPath, TableName tableName, TableName targetTableName, ArrayList<Path> regionDirList, TableDescriptor htd, boolean truncateIfExists) throws IOException {	try (Admin admin = conn.getAdmin()) {	boolean createNew = false;	if (admin.tableExists(targetTableName)) {	if (truncateIfExists) {	
truncating exising target table preserving region splits 

private void checkAndCreateTable(Connection conn, Path tableBackupPath, TableName tableName, TableName targetTableName, ArrayList<Path> regionDirList, TableDescriptor htd, boolean truncateIfExists) throws IOException {	try (Admin admin = conn.getAdmin()) {	boolean createNew = false;	if (admin.tableExists(targetTableName)) {	if (truncateIfExists) {	admin.disableTable(targetTableName);	admin.truncateTable(targetTableName, true);	} else {	
using exising target table 

if (admin.tableExists(targetTableName)) {	if (truncateIfExists) {	admin.disableTable(targetTableName);	admin.truncateTable(targetTableName, true);	} else {	}	} else {	createNew = true;	}	if (createNew) {	
creating target table 

========================= hbase sample_577 =========================

public void run(String[] backupIds) throws IOException {	String bulkOutputConfKey;	player = new MapReduceHFileSplitterJob();	bulkOutputConfKey = MapReduceHFileSplitterJob.BULK_OUTPUT_CONF_KEY;	String bids = StringUtils.join(backupIds, ",");	if (LOG.isDebugEnabled()) {	
merge backup images 

FileSystem fs = FileSystem.get(getConf());	try {	table.startBackupExclusiveOperation();	table.startMergeOperation(backupIds);	String mergedBackupId = findMostRecentBackupId(backupIds);	TableName[] tableNames = getTableNamesInBackupImages(backupIds);	String backupRoot = null;	BackupInfo bInfo = table.readBackupInfo(backupIds[0]);	backupRoot = bInfo.getBackupRootDir();	for (int i = 0; i < tableNames.length; i++) {	
merge backup images for 

TableName[] tableNames = getTableNamesInBackupImages(backupIds);	String backupRoot = null;	BackupInfo bInfo = table.readBackupInfo(backupIds[0]);	backupRoot = bInfo.getBackupRootDir();	for (int i = 0; i < tableNames.length; i++) {	Path[] dirPaths = findInputDirectories(fs, backupRoot, tableNames[i], backupIds);	String dirs = StringUtils.join(dirPaths, ",");	Path bulkOutputPath = BackupUtils.getBulkOutputDir(BackupUtils.getFileNameCompatibleString(tableNames[i]), getConf(), false);	if (fs.exists(bulkOutputPath)) {	if (!fs.delete(bulkOutputPath, true)) {	
can not delete 

Configuration conf = getConf();	conf.set(bulkOutputConfKey, bulkOutputPath.toString());	String[] playerArgs = { dirs, tableNames[i].getNameAsString() };	int result = 0;	player.setConf(getConf());	result = player.run(playerArgs);	if (!succeeded(result)) {	throw new IOException("Can not merge backup images for " + dirs + " (check Hadoop/MR and HBase logs). Player return code =" + result);	}	processedTableList.add(new Pair<TableName, Path>(tableNames[i], bulkOutputPath));	
merge job finished 

protected void cleanupBulkLoadDirs(FileSystem fs, List<Path> pathList) throws IOException {	for (Path path : pathList) {	if (!fs.delete(path, true)) {	
can t delete 

protected void deleteBackupImages(List<String> backupIds, Connection conn, FileSystem fs, String backupRoot) throws IOException {	try (BackupSystemTable table = new BackupSystemTable(conn)) {	for (String backupId : backupIds) {	table.deleteBackupInfo(backupId);	}	}	for (String backupId : backupIds) {	Path backupDirPath = HBackupFileSystem.getBackupPath(backupRoot, backupId);	if (!fs.delete(backupDirPath, true)) {	
could not delete 

protected Path[] findInputDirectories(FileSystem fs, String backupRoot, TableName tableName, String[] backupIds) throws IOException {	List<Path> dirs = new ArrayList<Path>();	for (String backupId : backupIds) {	Path fileBackupDirPath = new Path(HBackupFileSystem.getTableBackupDataDir(backupRoot, backupId, tableName));	if (fs.exists(fileBackupDirPath)) {	dirs.add(fileBackupDirPath);	} else {	if (LOG.isTraceEnabled()) {	
file does not exist 

========================= hbase sample_598 =========================

protected abstract String getWalProvider();	private void startCluster(int numRS) throws Exception {	SplitLogCounters.resetCounters();	
starting cluster 

SplitLogCounters.resetCounters();	conf.setLong("hbase.splitlog.max.resubmit", 0);	conf.setInt("zookeeper.recovery.retry", 0);	conf.setInt(HConstants.REGIONSERVER_INFO_PORT, -1);	conf.setFloat(HConstants.LOAD_BALANCER_SLOP_KEY, (float) 100.0);	conf.setInt("hbase.regionserver.wal.max.splitters", 3);	conf.setInt(HConstants.REGION_SERVER_HIGH_PRIORITY_HANDLER_COUNT, 10);	conf.set("hbase.wal.provider", getWalProvider());	TEST_UTIL.startMiniHBaseCluster(NUM_MASTERS, numRS);	cluster = TEST_UTIL.getHBaseCluster();	
waiting for active ready master 

if (region.getTable().getNamespaceAsString() .equals(NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR)) {	it.remove();	}	}	makeWAL(hrs, regions, numLogLines, 100);	slm.splitLogDistributed(logDir);	int count = 0;	for (RegionInfo hri : regions) {	Path tdir = FSUtils.getTableDir(rootdir, table);	Path editsdir = WALSplitter .getRegionDirRecoveredEditsDir(HRegion.getRegionDir(tdir, hri.getEncodedName()));	
checking edits dir 

return false;	}	return true;	}	});	assertTrue( "edits dir should have more than a single file in it. instead has " + files.length, files.length > 1);	for (int i = 0; i < files.length; i++) {	int c = countWAL(files[i].getPath(), fs, conf);	count += c;	}	
edits in recovered edits files 

public void testWorkerAbort() throws Exception {	
testWorkerAbort 

public void testThreeRSAbort() throws Exception {	
testThreeRSAbort 

public void testDelayedDeleteOnFailure() throws Exception {	
testDelayedDeleteOnFailure 

public void testReadWriteSeqIdFiles() throws Exception {	
testReadWriteSeqIdFiles 

private Table installTable(ZKWatcher zkw, int nrs, int existingRegions) throws Exception {	byte[] family = Bytes.toBytes("family");	
creating table with regions 

private Table installTable(ZKWatcher zkw, int nrs, int existingRegions) throws Exception {	byte[] family = Bytes.toBytes("family");	Table table = TEST_UTIL.createMultiRegionTable(tableName, family, nrs);	int numRegions = -1;	try (RegionLocator r = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	
waiting for no more rit 

private Table installTable(ZKWatcher zkw, int nrs, int existingRegions) throws Exception {	byte[] family = Bytes.toBytes("family");	Table table = TEST_UTIL.createMultiRegionTable(tableName, family, nrs);	int numRegions = -1;	try (RegionLocator r = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	
disabling table 

private Table installTable(ZKWatcher zkw, int nrs, int existingRegions) throws Exception {	byte[] family = Bytes.toBytes("family");	Table table = TEST_UTIL.createMultiRegionTable(tableName, family, nrs);	int numRegions = -1;	try (RegionLocator r = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	
waiting for no more rit 

Table table = TEST_UTIL.createMultiRegionTable(tableName, family, nrs);	int numRegions = -1;	try (RegionLocator r = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	blockUntilNoRIT(zkw, master);	NavigableSet<String> regions = HBaseTestingUtility.getAllOnlineRegions(cluster);	
verifying only catalog and namespace regions are assigned 

int numRegions = -1;	try (RegionLocator r = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	blockUntilNoRIT(zkw, master);	NavigableSet<String> regions = HBaseTestingUtility.getAllOnlineRegions(cluster);	if (regions.size() != 2) {	
region still online 

numRegions = r.getStartKeys().length;	}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	blockUntilNoRIT(zkw, master);	NavigableSet<String> regions = HBaseTestingUtility.getAllOnlineRegions(cluster);	if (regions.size() != 2) {	}	assertEquals(2 + existingRegions, regions.size());	
enabling table 

}	assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	blockUntilNoRIT(zkw, master);	NavigableSet<String> regions = HBaseTestingUtility.getAllOnlineRegions(cluster);	if (regions.size() != 2) {	}	assertEquals(2 + existingRegions, regions.size());	TEST_UTIL.getAdmin().enableTable(tableName);	
waiting for no more rit 

assertEquals(nrs, numRegions);	blockUntilNoRIT(zkw, master);	TEST_UTIL.getAdmin().disableTable(tableName);	blockUntilNoRIT(zkw, master);	NavigableSet<String> regions = HBaseTestingUtility.getAllOnlineRegions(cluster);	if (regions.size() != 2) {	}	assertEquals(2 + existingRegions, regions.size());	TEST_UTIL.getAdmin().enableTable(tableName);	blockUntilNoRIT(zkw, master);	
verifying there are assigned on cluster 

}	}	byte[] value = new byte[editSize];	List<RegionInfo> hris = new ArrayList<>();	for (RegionInfo region : regions) {	if (region.getTable() != tableName) {	continue;	}	hris.add(region);	}	
creating wal edits across regions 

WAL log = hrs.getWAL(info);	log.sync();	}	if (cleanShutdown) {	for (RegionInfo info : hris) {	WAL log = hrs.getWAL(info);	log.shutdown();	}	}	for (int i = 0; i < n; i++) {	
region has edits 

private void abortMaster(MiniHBaseCluster cluster) throws InterruptedException {	for (MasterThread mt : cluster.getLiveMasterThreads()) {	if (mt.getMaster().isActiveMaster()) {	mt.getMaster().abort("Aborting for tests", new Exception("Trace info"));	mt.join();	break;	}	}	
master is aborted 

========================= hbase sample_1806 =========================

throw new RuntimeException("Failed to create local dir " + localDir.getPath() + ", DynamicClassLoader failed to init");	}	String remotePath = conf.get(DYNAMIC_JARS_DIR_KEY);	if (remotePath == null || remotePath.equals(localDirPath)) {	remoteDir = null;	} else {	remoteDir = new Path(remotePath);	try {	remoteDirFs = remoteDir.getFileSystem(conf);	} catch (IOException ioe) {	
failed to identify the fs of dir ignored 

public Class<?> loadClass(String name) throws ClassNotFoundException {	try {	return parent.loadClass(name);	} catch (ClassNotFoundException e) {	if (LOG.isDebugEnabled()) {	
class not found using dynamical class loader 

private Class<?> tryRefreshClass(String name) throws ClassNotFoundException {	synchronized (getClassLoadingLock(name)) {	Class<?> clasz = findLoadedClass(name);	if (clasz != null) {	if (LOG.isDebugEnabled()) {	
class already loaded 

private Class<?> tryRefreshClass(String name) throws ClassNotFoundException {	synchronized (getClassLoadingLock(name)) {	Class<?> clasz = findLoadedClass(name);	if (clasz != null) {	if (LOG.isDebugEnabled()) {	}	}	else {	try {	if (LOG.isDebugEnabled()) {	
finding class 

if (LOG.isDebugEnabled()) {	}	}	else {	try {	if (LOG.isDebugEnabled()) {	}	clasz = findClass(name);	} catch (ClassNotFoundException cnfe) {	if (LOG.isDebugEnabled()) {	
loading new jar files if any 

else {	try {	if (LOG.isDebugEnabled()) {	}	clasz = findClass(name);	} catch (ClassNotFoundException cnfe) {	if (LOG.isDebugEnabled()) {	}	loadNewJars();	if (LOG.isDebugEnabled()) {	
finding class again 

String fileName = file.getName();	if (jarModifiedTime.containsKey(fileName)) {	continue;	}	if (file.isFile() && fileName.endsWith(".jar")) {	jarModifiedTime.put(fileName, Long.valueOf(file.lastModified()));	try {	URL url = file.toURI().toURL();	addURL(url);	} catch (MalformedURLException mue) {	
failed to load new jar 

} catch (MalformedURLException mue) {	}	}	}	}	FileStatus[] statuses = null;	if (remoteDir != null) {	try {	statuses = remoteDirFs.listStatus(remoteDir);	} catch (IOException ioe) {	
failed to check remote dir status 

}	if (statuses == null || statuses.length == 0) {	return;	}	for (FileStatus status: statuses) {	if (status.isDirectory()) continue;	Path path = status.getPath();	String fileName = path.getName();	if (!fileName.endsWith(".jar")) {	if (LOG.isDebugEnabled()) {	
ignored non jar file 

continue;	}	}	try {	File dst = new File(localDir, fileName);	remoteDirFs.copyToLocalFile(path, new Path(dst.getPath()));	jarModifiedTime.put(fileName, Long.valueOf(dst.lastModified()));	URL url = dst.toURI().toURL();	addURL(url);	} catch (IOException ioe) {	
failed to load new jar 

========================= hbase sample_961 =========================

ResultGenerator generator = ResultGenerator.fromRowSpec(this.tableResource.getName(), rowSpec, null, !params.containsKey(NOCACHE_PARAM_NAME));	Cell value = null;	RowModel rowModel = new RowModel(rk);	if (generator.hasNext()) {	while ((value = generator.next()) != null) {	rowModel.addCell(new CellModel(CellUtil.cloneFamily(value), CellUtil .cloneQualifier(value), value.getTimestamp(), CellUtil.cloneValue(value)));	}	model.addRow(rowModel);	} else {	if (LOG.isTraceEnabled()) {	
the row not found in the table 

========================= hbase sample_3092 =========================

KeyStoreTestUtil.setupSSLConfig(keystoresDir, sslConfDir, conf, false);	Configuration sslConf = new Configuration(false);	sslConf.addResource("ssl-server.xml");	sslConf.addResource("ssl-client.xml");	clientSslFactory = new SSLFactory(SSLFactory.Mode.CLIENT, sslConf);	clientSslFactory.init();	server = new HttpServer.Builder() .setName("test") .addEndpoint(new URI("https: .setConf(conf) .keyPassword(HBaseConfiguration.getPassword(sslConf, "ssl.server.keystore.keypassword", null)) .keyStore(sslConf.get("ssl.server.keystore.location"), HBaseConfiguration.getPassword(sslConf, "ssl.server.keystore.password", null), sslConf.get("ssl.server.keystore.type", "jks")) .trustStore(sslConf.get("ssl.server.truststore.location"), HBaseConfiguration.getPassword(sslConf, "ssl.server.truststore.password", null), sslConf.get("ssl.server.truststore.type", "jks")).build();	server.addServlet("echo", "/echo", TestHttpServer.EchoServlet.class);	server.start();	baseUrl = new URL("https: + NetUtils.getHostPortString(server.getConnectorAddress(0)));	
http server started 

========================= hbase sample_3207 =========================

public void testWithVersionDeletes(boolean flushTables) throws IOException {	
flush noflush 

========================= hbase sample_2103 =========================

protected void beginBackup(BackupManager backupManager, BackupInfo backupInfo) throws IOException {	BackupSystemTable.snapshot(conn);	backupManager.setBackupInfo(backupInfo);	long startTs = EnvironmentEdgeManager.currentTime();	backupInfo.setStartTs(startTs);	backupInfo.setState(BackupState.RUNNING);	backupInfo.setPhase(BackupPhase.REQUEST);	
backup started at 

protected void beginBackup(BackupManager backupManager, BackupInfo backupInfo) throws IOException {	BackupSystemTable.snapshot(conn);	backupManager.setBackupInfo(backupInfo);	long startTs = EnvironmentEdgeManager.currentTime();	backupInfo.setStartTs(startTs);	backupInfo.setState(BackupState.RUNNING);	backupInfo.setPhase(BackupPhase.REQUEST);	backupManager.updateBackupInfo(backupInfo);	if (LOG.isDebugEnabled()) {	
backup session has been started 

protected static void deleteSnapshots(final Connection conn, BackupInfo backupInfo, Configuration conf) throws IOException {	
trying to delete snapshot for full backup 

protected static void deleteSnapshots(final Connection conn, BackupInfo backupInfo, Configuration conf) throws IOException {	for (String snapshotName : backupInfo.getSnapshotNames()) {	if (snapshotName == null) {	continue;	}	
trying to delete snapshot 

protected static void deleteSnapshots(final Connection conn, BackupInfo backupInfo, Configuration conf) throws IOException {	for (String snapshotName : backupInfo.getSnapshotNames()) {	if (snapshotName == null) {	continue;	}	try (Admin admin = conn.getAdmin()) {	admin.deleteSnapshot(snapshotName);	}	
deleting the snapshot for backup succeeded 

protected static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	
trying to cleanup up target dir current backup phase 

protected static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	if (backupInfo.getPhase().equals(BackupPhase.SNAPSHOTCOPY) || backupInfo.getPhase().equals(BackupPhase.INCREMENTAL_COPY) || backupInfo.getPhase().equals(BackupPhase.STORE_MANIFEST)) {	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(HBackupFileSystem.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	
cleaning up uncompleted backup data at done 

protected static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	if (backupInfo.getPhase().equals(BackupPhase.SNAPSHOTCOPY) || backupInfo.getPhase().equals(BackupPhase.INCREMENTAL_COPY) || backupInfo.getPhase().equals(BackupPhase.STORE_MANIFEST)) {	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(HBackupFileSystem.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	
no data has been copied to 

FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(HBackupFileSystem.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	}	Path tableDir = targetDirPath.getParent();	FileStatus[] backups = FSUtils.listStatus(outputFs, tableDir);	if (backups == null || backups.length == 0) {	outputFs.delete(tableDir, true);	
is empty remove it 

} else {	}	Path tableDir = targetDirPath.getParent();	FileStatus[] backups = FSUtils.listStatus(outputFs, tableDir);	if (backups == null || backups.length == 0) {	outputFs.delete(tableDir, true);	}	}	}	} catch (IOException e1) {	
cleaning up uncompleted backup data of at failed due to 

try {	LOG.error(msg + getMessage(e), e);	backupInfo.setCompleteTs(EnvironmentEdgeManager.currentTime());	backupInfo.setFailedMsg(e.getMessage());	backupInfo.setState(BackupState.FAILED);	String backupFailedData = "BackupId=" + backupInfo.getBackupId() + ",startts=" + backupInfo.getStartTs() + ",failedts=" + backupInfo.getCompleteTs() + ",failedphase=" + backupInfo.getPhase() + ",failedmessage=" + backupInfo.getFailedMsg();	LOG.error(backupFailedData);	cleanupAndRestoreBackupSystem(conn, backupInfo, conf);	backupManager.updateBackupInfo(backupInfo);	backupManager.finishBackupSession();	
backup failed 

LOG.error(msg + getMessage(e), e);	backupInfo.setCompleteTs(EnvironmentEdgeManager.currentTime());	backupInfo.setFailedMsg(e.getMessage());	backupInfo.setState(BackupState.FAILED);	String backupFailedData = "BackupId=" + backupInfo.getBackupId() + ",startts=" + backupInfo.getStartTs() + ",failedts=" + backupInfo.getCompleteTs() + ",failedphase=" + backupInfo.getPhase() + ",failedmessage=" + backupInfo.getFailedMsg();	LOG.error(backupFailedData);	cleanupAndRestoreBackupSystem(conn, backupInfo, conf);	backupManager.updateBackupInfo(backupInfo);	backupManager.finishBackupSession();	} catch (IOException ee) {	
please run backup repair tool manually to restore backup system integrity 

protected void completeBackup(final Connection conn, BackupInfo backupInfo, BackupManager backupManager, BackupType type, Configuration conf) throws IOException {	backupInfo.setCompleteTs(EnvironmentEdgeManager.currentTime());	backupInfo.setState(BackupState.COMPLETE);	backupInfo.setProgress(100);	addManifest(backupInfo, backupManager, type, conf);	String backupCompleteData = obtainBackupMetaDataStr(backupInfo) + ",startts=" + backupInfo.getStartTs() + ",completets=" + backupInfo.getCompleteTs() + ",bytescopied=" + backupInfo.getTotalBytesCopied();	if (LOG.isDebugEnabled()) {	
backup finished 

}	if (type == BackupType.FULL) {	deleteSnapshots(conn, backupInfo, conf);	cleanupExportSnapshotLog(conf);	} else if (type == BackupType.INCREMENTAL) {	cleanupDistCpLog(backupInfo, conf);	}	BackupSystemTable.deleteSnapshot(conn);	backupManager.updateBackupInfo(backupInfo);	backupManager.finishBackupSession();	
backup completed 

========================= hbase sample_561 =========================

public Permission(byte[] actionCodes) {	if (actionCodes != null) {	Action acts[] = new Action[actionCodes.length];	int j = 0;	for (int i=0; i<actionCodes.length; i++) {	byte b = actionCodes[i];	Action a = ACTION_BY_CODE.get(b);	if (a == null) {	
ignoring unknown action code 

========================= hbase sample_131 =========================

private static PipelineAckStatusGetter createPipelineAckStatusGetter() throws NoSuchMethodException {	try {	return createPipelineAckStatusGetter27();	} catch (NoSuchMethodException e) {	
can not get expected method this usually because your hadoop is pre try the methods in hadoop x instead 

private static PBHelper createPBHelper() throws NoSuchMethodException {	Class<?> helperClass;	String clazzName = "org.apache.hadoop.hdfs.protocolPB.PBHelperClient";	try {	helperClass = Class.forName(clazzName);	} catch (ClassNotFoundException e) {	helperClass = org.apache.hadoop.hdfs.protocolPB.PBHelper.class;	
not found hadoop is pre using instead 

private static ChecksumCreater createChecksumCreater() throws NoSuchMethodException, ClassNotFoundException {	Method getConfMethod = DFSClient.class.getMethod("getConf");	try {	return createChecksumCreater28(getConfMethod, Class.forName("org.apache.hadoop.hdfs.client.impl.DfsClientConf"));	} catch (ClassNotFoundException e) {	
no dfsclientconf class found should be hadoop 

private static FileCreator createFileCreator() throws NoSuchMethodException {	try {	return createFileCreator3();	} catch (NoSuchMethodException e) {	
clientprotocol create wrong number of arguments should be hadoop x 

try {	if (namenode.complete(src, clientName, block, fileId)) {	endFileLease(client, fileId);	return;	} else {	LOG.warn("complete file " + src + " not finished, retry = " + retry);	}	} catch (RemoteException e) {	IOException ioe = e.unwrapRemoteException();	if (ioe instanceof LeaseExpiredException) {	
lease for file is expired give up 

========================= hbase sample_2380 =========================

public Compressor getCompressor() {	CompressionCodec codec = getCodec(conf);	if (codec != null) {	Compressor compressor = CodecPool.getCompressor(codec);	
retrieved compressor from pool 

public Compressor getCompressor() {	CompressionCodec codec = getCodec(conf);	if (codec != null) {	Compressor compressor = CodecPool.getCompressor(codec);	if (compressor != null) {	if (compressor.finished()) {	
compressor obtained from codecpool is already finished 

public void returnCompressor(Compressor compressor) {	if (compressor != null) {	
returning compressor to pool 

public Decompressor getDecompressor() {	CompressionCodec codec = getCodec(conf);	if (codec != null) {	Decompressor decompressor = CodecPool.getDecompressor(codec);	
retrieved decompressor from pool 

public Decompressor getDecompressor() {	CompressionCodec codec = getCodec(conf);	if (codec != null) {	Decompressor decompressor = CodecPool.getDecompressor(codec);	if (decompressor != null) {	if (decompressor.finished()) {	
deompressor obtained from codecpool is already finished 

public void returnDecompressor(Decompressor decompressor) {	if (decompressor != null) {	
returning decompressor to pool 

public void returnDecompressor(Decompressor decompressor) {	if (decompressor != null) {	CodecPool.returnDecompressor(decompressor);	if (decompressor.getClass().isAnnotationPresent(DoNotPool.class)) {	
ending decompressor 

========================= hbase sample_1056 =========================

FileInputStream in = new FileInputStream(tobeJared[i]);	while (true) {	int nRead = in.read(buffer, 0, buffer.length);	if (nRead <= 0) break;	out.write(buffer, 0, nRead);	}	in.close();	}	out.close();	stream.close();	
adding classes to jar file completed 

int nRead = in.read(buffer, 0, buffer.length);	if (nRead <= 0) break;	out.write(buffer, 0, nRead);	}	in.close();	}	out.close();	stream.close();	return true;	} catch (Exception ex) {	
error 

JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();	ArrayList<String> srcFileNames = new ArrayList<>(1);	srcFileNames.add(sourceCodeFile.toString());	StandardJavaFileManager fm = compiler.getStandardFileManager(null, null, null);	Iterable<? extends JavaFileObject> cu = fm.getJavaFileObjects(sourceCodeFile);	List<String> options = new ArrayList<>(2);	options.add("-classpath");	String currentDir = new File(".").getAbsolutePath();	String classpath = currentDir + File.separator + "target"+ File.separator + "classes" + System.getProperty("path.separator") + System.getProperty("java.class.path") + System.getProperty("path.separator") + System.getProperty("surefire.test.class.path");	options.add(classpath);	
setting classpath to 

FileInputStream in = new FileInputStream(jarFile);	while (true) {	int nRead = in.read(buffer, 0, buffer.length);	if (nRead <= 0) break;	out.write(buffer, 0, nRead);	}	in.close();	}	out.close();	stream.close();	
adding jar file to outer jar file completed 

========================= hbase sample_832 =========================

protected void abortWriter(T writer) throws IOException {	FileSystem fs = store.getFileSystem();	for (Path leftoverFile : writer.abortWriters()) {	try {	fs.delete(leftoverFile, false);	} catch (IOException e) {	
failed to delete the leftover file after an unfinished compaction 

========================= hbase sample_2695 =========================

public static void setUp() throws Exception {	threadPool = Threads.getBoundedCachedThreadPool(32, 60L, TimeUnit.SECONDS, Threads.newDaemonThreadFactory("ProcedureDispatcher", new UncaughtExceptionHandler() {	public void uncaughtException(Thread t, Throwable e) {	
failed thread 

final int regionId = i;	executorService.submit(new Callable<Object>() {	public Object call() {	RegionInfo hri = createRegionInfo(TABLE_NAME, regionId);	return stateMap.getOrCreateRegionStateNode(hri);	}	});	}	waitExecutorService(NRUNS);	long et = System.currentTimeMillis();	
perf statemap insert s s sec 

final int regionId = i;	executorService.submit(new Callable<Object>() {	public Object call() {	RegionInfo hri = createRegionInfo(TABLE_NAME, regionId);	return stateMap.getRegionState(hri);	}	});	}	waitExecutorService(NRUNS);	et = System.currentTimeMillis();	
perf statemap get s s sec 

public void testPerfSingleThread() {	final TableName TABLE_NAME = TableName.valueOf("testPerf");	final int NRUNS = 1 * 1000000;	final RegionStates stateMap = new RegionStates();	long st = System.currentTimeMillis();	for (int i = 0; i < NRUNS; ++i) {	stateMap.createRegionStateNode(createRegionInfo(TABLE_NAME, i));	}	long et = System.currentTimeMillis();	
perf singlethread s s sec 

========================= hbase sample_1810 =========================

private void alterForPolicyTest(final MobCompactPartitionPolicy type) throws Exception {	hcd1.setMobCompactPartitionPolicy(type);	desc.modifyFamily(hcd1);	admin.modifyTable(tableName, desc);	Pair<Integer, Integer> st;	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	
regions left to update 

private void alterForPolicyTest(final MobCompactPartitionPolicy type) throws Exception {	hcd1.setMobCompactPartitionPolicy(type);	desc.modifyFamily(hcd1);	admin.modifyTable(tableName, desc);	Pair<Integer, Integer> st;	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	Thread.sleep(40);	}	
alter status finished 

========================= hbase sample_2011 =========================

Put put = new Put(Hashing.md5().hashLong(i).asBytes());	rand.setSeed(i);	rand.nextBytes(value1);	rand.nextBytes(value2);	rand.nextBytes(value3);	put.addColumn(FAMILY1, qf, value1);	put.addColumn(FAMILY2, qf, value2);	put.addColumn(FAMILY3, qf, value3);	table.put(put);	if (i % 10000 == 0) {	
rows put 

========================= hbase sample_1778 =========================

public boolean isTableState(TableName tableName, TableState.State... states) {	try {	TableState.State tableState = getTableState(tableName);	return TableState.isInStates(tableState, states);	} catch (IOException e) {	
unable to get table state 

public boolean visit(Result r) throws IOException {	TableState state = MetaTableAccessor.getTableState(r);	if (state != null) states.put(state.getTableName().getNameAsString(), state);	return true;	}	});	for (Map.Entry<String, TableDescriptor> entry : allDescriptors.entrySet()) {	String table = entry.getKey();	if (table.equals(TableName.META_TABLE_NAME.getNameAsString())) continue;	if (!states.containsKey(table)) {	
found table with no state assuming enabled 

========================= hbase sample_2857 =========================

public void perform() throws Exception {	
performing action restart random data node 

========================= hbase sample_3315 =========================

public void process() throws IOException {	boolean openSuccessful = false;	final String regionName = regionInfo.getRegionNameAsString();	HRegion region = null;	try {	if (this.server.isStopped() || this.rsServices.isStopping()) {	return;	}	final String encodedName = regionInfo.getEncodedName();	if (this.rsServices.getRegion(encodedName) != null) {	
region was already online when we started processing the opening marking this new attempt as failed 

HRegion region = null;	try {	if (this.server.isStopped() || this.rsServices.isStopping()) {	return;	}	final String encodedName = regionInfo.getEncodedName();	if (this.rsServices.getRegion(encodedName) != null) {	return;	}	if (!isRegionStillOpening()){	
region opening cancelled 

return;	}	if (!updateMeta(region, masterSystemTime) || this.server.isStopped() || this.rsServices.isStopping()) {	return;	}	if (!isRegionStillOpening()) {	return;	}	this.rsServices.addRegion(region);	openSuccessful = true;	
opened on 

public boolean progress() {	if (!isRegionStillOpening()) {	
open region aborted since it isn t opening any more 

========================= hbase sample_2504 =========================

public void cleanup() {	try {	fs.delete(root, true);	} catch (IOException e) {	
failed to delete files recursively from path 

========================= hbase sample_536 =========================

queue.addBack(rootProc);	Procedure parentProc = queue.poll();	assertEquals(rootProc, parentProc);	assertEquals(false, queue.waitTableExclusiveLock(parentProc, tableName));	for (int i = 0; i < childProcs.length; ++i) {	queue.addFront(childProcs[i]);	}	queue.addBack(new TestTableProcedure(100, tableName, TableProcedureInterface.TableOperationType.EDIT));	for (int i = 0; i < childProcs.length; ++i) {	TestRegionProcedure childProc = (TestRegionProcedure)queue.poll();	
fetch children 

========================= hbase sample_1847 =========================

public void init(RegionCoprocessorEnvironment e) throws IOException {	ZKWatcher zk = ((HasRegionServerServices)e).getRegionServerServices().getZooKeeper();	try {	labelsCache = VisibilityLabelsCache.createAndGet(zk, this.conf);	} catch (IOException ioe) {	
error creating visibilitylabelscache 

ExtendedCellBuilder builder = ExtendedCellBuilderFactory.create(CellBuilderType.SHALLOW_COPY);	for (byte[] label : labels) {	String labelStr = Bytes.toString(label);	if (this.labelsCache.getLabelOrdinal(labelStr) > 0) {	finalOpStatus[i] = new OperationStatus(OperationStatusCode.FAILURE, new LabelAlreadyExistsException("Label '" + labelStr + "' already exists"));	} else {	byte[] row = Bytes.toBytes(ordinalCounter.get());	Put p = new Put(row);	p.add(builder.clear() .setRow(row) .setFamily(LABELS_TABLE_FAMILY) .setQualifier(LABEL_QUALIFIER) .setTimestamp(p.getTimeStamp()) .setType(Type.Put) .setValue(label) .setTags(TagUtil.fromList(Arrays.asList(LABELS_TABLE_TAGS))) .build());	if (LOG.isDebugEnabled()) {	
adding the label 

public boolean havingSystemAuth(User user) throws IOException {	if (Superusers.isSuperUser(user)) {	return true;	}	List<String> auths = this.getUserAuths(Bytes.toBytes(user.getShortName()), true);	if (LOG.isTraceEnabled()) {	
the auths for user are 

return true;	}	List<String> auths = this.getUserAuths(Bytes.toBytes(user.getShortName()), true);	if (LOG.isTraceEnabled()) {	}	if (auths.contains(SYSTEM_LABEL)) {	return true;	}	auths = this.getGroupAuths(user.getGroupNames(), true);	if (LOG.isTraceEnabled()) {	
the auths for groups of user are 

========================= hbase sample_2292 =========================

public void tearDown() throws Exception {	EnvironmentEdgeManagerTestHelper.reset();	
cleaning test directory 

========================= hbase sample_1514 =========================

memstore.add(new KeyValue(row1, fam2, col5, 1, data));	memstore.add(new KeyValue(row2, fam1, col1, data));	List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(memstore.size());	KeyValue k = memstore.get(0);	qm.setToNewRow(k);	for (KeyValue kv : memstore) {	actual.add(qm.match(kv));	}	assertEquals(expected.size(), actual.size());	for (int i = 0; i < expected.size(); i++) {	
expected actual 

memstore.add(new KeyValue(row1, fam2, col5, 1, data));	memstore.add(new KeyValue(row2, fam1, col1, 1, data));	List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(memstore.size());	KeyValue k = memstore.get(0);	qm.setToNewRow(k);	for (KeyValue kv : memstore) {	actual.add(qm.match(kv));	}	assertEquals(expected.size(), actual.size());	for (int i = 0; i < expected.size(); i++) {	
expected actual 

UserScanQueryMatcher qm = UserScanQueryMatcher.create(scan, new ScanInfo(this.conf, fam2, 0, 1, testTTL, KeepDeletedCells.FALSE, HConstants.DEFAULT_BLOCKSIZE, 0, rowComparator, false), get.getFamilyMap().get(fam2), now - testTTL, now, null);	KeyValue[] kvs = new KeyValue[] { new KeyValue(row1, fam2, col1, now - 100, data), new KeyValue(row1, fam2, col2, now - 50, data), new KeyValue(row1, fam2, col3, now - 5000, data), new KeyValue(row1, fam2, col4, now - 500, data), new KeyValue(row1, fam2, col5, now - 10000, data), new KeyValue(row2, fam1, col1, now - 10, data) };	KeyValue k = kvs[0];	qm.setToNewRow(k);	List<MatchCode> actual = new ArrayList<>(kvs.length);	for (KeyValue kv : kvs) {	actual.add(qm.match(kv));	}	assertEquals(expected.length, actual.size());	for (int i = 0; i < expected.length; i++) {	
expected actual 

UserScanQueryMatcher qm = UserScanQueryMatcher.create(scan, new ScanInfo(this.conf, fam2, 0, 1, testTTL, KeepDeletedCells.FALSE, HConstants.DEFAULT_BLOCKSIZE, 0, rowComparator, false), null, now - testTTL, now, null);	KeyValue[] kvs = new KeyValue[] { new KeyValue(row1, fam2, col1, now - 100, data), new KeyValue(row1, fam2, col2, now - 50, data), new KeyValue(row1, fam2, col3, now - 5000, data), new KeyValue(row1, fam2, col4, now - 500, data), new KeyValue(row1, fam2, col5, now - 10000, data), new KeyValue(row2, fam1, col1, now - 10, data) };	KeyValue k = kvs[0];	qm.setToNewRow(k);	List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(kvs.length);	for (KeyValue kv : kvs) {	actual.add(qm.match(kv));	}	assertEquals(expected.length, actual.size());	for (int i = 0; i < expected.length; i++) {	
expected actual 

memstore.add(new KeyValue(row1, fam2, col2, 1, data));	memstore.add(new KeyValue(row2, fam1, col1, data));	List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(memstore.size());	KeyValue k = memstore.get(0);	qm.setToNewRow(k);	for (KeyValue kv : memstore) {	actual.add(qm.match(kv));	}	assertEquals(expected.size(), actual.size());	for (int i = 0; i < expected.size(); i++) {	
expected actual 

========================= hbase sample_1703 =========================

public void setUp() throws Exception {	
cleaning up cluster for new test 

public void tearDown() throws Exception {	try {	wals.close();	} catch(IOException exception) {	
ignoring an error while closing down our walfactory fine for some tests but if you see a failure look here 

public void tearDown() throws Exception {	try {	wals.close();	} catch(IOException exception) {	
exception details 

public Integer run() throws Exception {	StringBuilder ls = new StringBuilder("Contents of WALDIR (").append(WALDIR) .append("):\n");	for (FileStatus status : fs.listStatus(WALDIR)) {	ls.append("\t").append(status.toString()).append("\n");	}	LOG.debug(Objects.toString(ls));	
splitting wals out from under zombie expecting files 

public Integer run() throws Exception {	StringBuilder ls = new StringBuilder("Contents of WALDIR (").append(WALDIR) .append("):\n");	for (FileStatus status : fs.listStatus(WALDIR)) {	ls.append("\t").append(status.toString()).append("\n");	}	LOG.debug(Objects.toString(ls));	WALSplitter.split(HBASEDIR, WALDIR, OLDLOGDIR, fs, conf2, wals);	
finished splitting out from under zombie 

public void run() {	try {	doWriting();	} catch (IOException e) {	
writer exiting 

public void run() {	try {	doWriting();	} catch (IOException e) {	} catch (InterruptedException e) {	
writer exiting 

writer = generateWALs(numOfWriters, ENTRIES, walToKeepOpen);	} catch (IOException e1) {	throw new RuntimeException("Failed", e1);	}	editsCount.addAndGet(numOfWriters * ENTRIES);	loop(writer);	try {	writer.close();	fail("Writing closing after parsing should give an error.");	} catch (IOException exception) {	
ignoring error when closing final writer 

while (!stop.get()) {	try {	long seq = appendEntry(writer, TABLE_NAME, regionBytes, ("r" + editsCount.get()).getBytes(), regionBytes, QUALIFIER, VALUE, 0);	long count = editsCount.incrementAndGet();	LOG.info(getName() + " sync count=" + count + ", seq=" + seq);	try {	Thread.sleep(1);	} catch (InterruptedException e) {	}	} catch (IOException ex) {	
ex 

try {	long seq = appendEntry(writer, TABLE_NAME, regionBytes, ("r" + editsCount.get()).getBytes(), regionBytes, QUALIFIER, VALUE, 0);	long count = editsCount.incrementAndGet();	LOG.info(getName() + " sync count=" + count + ", seq=" + seq);	try {	Thread.sleep(1);	} catch (InterruptedException e) {	}	} catch (IOException ex) {	if (ex instanceof RemoteException) {	
juliet got remoteexception while writing 

long seq = appendEntry(writer, TABLE_NAME, regionBytes, ("r" + editsCount.get()).getBytes(), regionBytes, QUALIFIER, VALUE, 0);	long count = editsCount.incrementAndGet();	LOG.info(getName() + " sync count=" + count + ", seq=" + seq);	try {	Thread.sleep(1);	} catch (InterruptedException e) {	}	} catch (IOException ex) {	if (ex instanceof RemoteException) {	} else {	
failed to write at 

Thread.sleep(1);	} catch (InterruptedException e) {	}	} catch (IOException ex) {	if (ex instanceof RemoteException) {	} else {	fail("Failed to write " + editsCount.get());	}	break;	} catch (Throwable t) {	
how 

Thread.sleep(1);	} catch (InterruptedException e) {	}	} catch (IOException ex) {	if (ex instanceof RemoteException) {	} else {	fail("Failed to write " + editsCount.get());	}	break;	} catch (Throwable t) {	
exception details 

} catch (IOException ex) {	if (ex instanceof RemoteException) {	} else {	fail("Failed to write " + editsCount.get());	}	break;	} catch (Throwable t) {	break;	}	}	
writer exiting 

public void testSplitLeavesCompactionEventsEdits() throws IOException{	RegionInfo hri = RegionInfoBuilder.newBuilder(TABLE_NAME).build();	REGIONS.clear();	REGIONS.add(hri.getEncodedName());	Path regionDir = new Path(FSUtils.getTableDir(HBASEDIR, TABLE_NAME), hri.getEncodedName());	
creating region directory 

index++;	return ret;	}	}).when(mockReader).next();	return mockReader;	}	};	logSplitter.splitLogFile(fs.getFileStatus(logPath), null);	Map<byte[], Long> outputCounts = logSplitter.outputSink.getOutputCounts();	for (Map.Entry<byte[], Long> entry : outputCounts.entrySet()) {	
got output edits for region 

private void makeRegionDirs(List<String> regions) throws IOException {	for (String region : regions) {	
creating dir for region 

String row_key = region + prefix++ + i + j;	appendEntry(ws[i], TABLE_NAME, region.getBytes(), row_key.getBytes(), FAMILY, QUALIFIER, VALUE, seq++);	if (numRegionEventsAdded < regionEvents) {	numRegionEventsAdded ++;	appendRegionEvent(ws[i], region);	}	}	}	if (i != leaveOpen) {	ws[i].close();	
closing writer 

public static long appendEntry(Writer writer, TableName table, byte[] region, byte[] row, byte[] family, byte[] qualifier, byte[] value, long seq) throws IOException {	
append 

public static long appendEntry(Writer writer, TableName table, byte[] region, byte[] row, byte[] family, byte[] qualifier, byte[] value, long seq) throws IOException {	writer.append(createTestEntry(table, region, row, family, qualifier, value, seq));	
sync 

========================= hbase sample_1353 =========================

public static void clearJmxCache() {	if (LOG.isTraceEnabled()) {	
clearing jmx cache 

public void run() {	if (LOG.isTraceEnabled()) {	
clearing jmx mbean cache 

public void run() {	if (LOG.isTraceEnabled()) {	}	try {	if (DefaultMetricsSystem.instance() != null) {	DefaultMetricsSystem.instance().stop();	Thread.sleep(500);	DefaultMetricsSystem.instance().start();	}	}  catch (Exception exception)  {	
error clearing the jmx it appears the metrics system hasn t been started 

========================= hbase sample_664 =========================

if (!loc.getRegionInfo().isOffline()) {	regionName = loc.getRegionInfo().getRegionName();	server = connection.getAdmin(loc.getServerName());	if (ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() <= 1) {	break;	}	}	Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() <= 1);	
hbase hstore compaction min should now be 

}	}	Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() <= 1);	HTableDescriptor htd = new HTableDescriptor(hTable.getTableDescriptor());	htd.setValue("hbase.hstore.compaction.min", String.valueOf(5));	admin.modifyTable(tableName, htd);	Pair<Integer, Integer> st;	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	
regions left to update 

Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() <= 1);	HTableDescriptor htd = new HTableDescriptor(hTable.getTableDescriptor());	htd.setValue("hbase.hstore.compaction.min", String.valueOf(5));	admin.modifyTable(tableName, htd);	Pair<Integer, Integer> st;	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	Thread.sleep(40);	}	
alter status finished 

Thread.sleep(40);	}	performMultiplePutAndFlush((HBaseAdmin) admin, hTable, row, FAMILY, 3, 10);	admin.compact(tableName);	Thread.sleep(10 * 1000);	loc = locator.getRegionLocation(row, true);	regionName = loc.getRegionInfo().getRegionName();	server = connection.getAdmin(loc.getServerName());	int sfCount = ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size();	assertTrue(sfCount > 1);	
hbase hstore compaction min should now be 

loc = locator.getRegionLocation(row, true);	regionName = loc.getRegionInfo().getRegionName();	server = connection.getAdmin(loc.getServerName());	int sfCount = ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size();	assertTrue(sfCount > 1);	HColumnDescriptor hcd = new HColumnDescriptor(htd.getFamily(FAMILY));	hcd.setValue("hbase.hstore.compaction.min", String.valueOf(2));	htd.modifyFamily(hcd);	admin.modifyTable(tableName, htd);	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	
regions left to update 

server = connection.getAdmin(loc.getServerName());	int sfCount = ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size();	assertTrue(sfCount > 1);	HColumnDescriptor hcd = new HColumnDescriptor(htd.getFamily(FAMILY));	hcd.setValue("hbase.hstore.compaction.min", String.valueOf(2));	htd.modifyFamily(hcd);	admin.modifyTable(tableName, htd);	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	Thread.sleep(40);	}	
alter status finished 

admin.compact(tableName);	for (int i = 0; i < 10 * 1000 / 40; ++i) {	loc = locator.getRegionLocation(row, true);	regionName = loc.getRegionInfo().getRegionName();	try {	server = connection.getAdmin(loc.getServerName());	if (ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() < sfCount) {	break;	}	} catch (Exception e) {	
waiting for region to come online 

try {	server = connection.getAdmin(loc.getServerName());	if (ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() < sfCount) {	break;	}	} catch (Exception e) {	}	Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles( server, regionName, FAMILY).size() < sfCount);	
removing cf config value 

try {	server = connection.getAdmin(loc.getServerName());	if (ProtobufUtil.getStoreFiles(server, regionName, FAMILY).size() < sfCount) {	break;	}	} catch (Exception e) {	}	Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles( server, regionName, FAMILY).size() < sfCount);	
hbase hstore compaction min should now be 

} catch (Exception e) {	}	Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles( server, regionName, FAMILY).size() < sfCount);	hcd = new HColumnDescriptor(htd.getFamily(FAMILY));	hcd.setValue("hbase.hstore.compaction.min", null);	htd.modifyFamily(hcd);	admin.modifyTable(tableName, htd);	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	
regions left to update 

Thread.sleep(40);	}	assertTrue(ProtobufUtil.getStoreFiles( server, regionName, FAMILY).size() < sfCount);	hcd = new HColumnDescriptor(htd.getFamily(FAMILY));	hcd.setValue("hbase.hstore.compaction.min", null);	htd.modifyFamily(hcd);	admin.modifyTable(tableName, htd);	while (null != (st = admin.getAlterStatus(tableName)) && st.getFirst() > 0) {	Thread.sleep(40);	}	
alter status finished 

public void testBatchWithRowMutation() throws Exception {	
starting testbatchwithrowmutation 

public void testHTableExistsMethodMultipleRegionsMultipleGets() throws Exception {	Table table = TEST_UTIL.createTable( TableName.valueOf(name.getMethodName()), new byte[][] { FAMILY }, 1, new byte[] { 0x00 }, new byte[] { (byte) 0xff }, 255);	Put put = new Put(ROW);	put.addColumn(FAMILY, QUALIFIER, VALUE);	table.put (put);	List<Get> gets = new ArrayList<>();	gets.add(new Get(ANOTHERROW));	gets.add(new Get(Bytes.add(ROW, new byte[] { 0x00 })));	gets.add(new Get(ROW));	gets.add(new Get(Bytes.add(ANOTHERROW, new byte[] { 0x00 })));	
calling exists 

putService.shutdown();	putService.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS);	try (Table table = con.getTable(tableName)) {	Result r = table.get(new Get(ROW));	assertFalse(r.isEmpty());	assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), VALUE));	}	}	HRegion region = (HRegion) find(tableName);	int readLockCount = region.getReadLockCount();	
readlockcount 

========================= hbase sample_2085 =========================

public void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {	if (value.size() != 2) {	throw new IOException("There should be two input columns");	}	Map<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> cfMap = value.getMap();	if (!cfMap.containsKey(INPUT_FAMILYS[0]) || !cfMap.containsKey(INPUT_FAMILYS[1])) {	throw new IOException("Wrong input columns. Missing: '" + Bytes.toString(INPUT_FAMILYS[0]) + "' or '" + Bytes.toString(INPUT_FAMILYS[1]) + "'.");	}	String val0 = Bytes.toStringBinary(value.getValue(INPUT_FAMILYS[0], null));	String val1 = Bytes.toStringBinary(value.getValue(INPUT_FAMILYS[1], null));	
map key value 

protected void reduce(ImmutableBytesWritable key, Iterable<ImmutableBytesWritable> values, Context context) throws IOException ,InterruptedException {	int count = 0;	for (ImmutableBytesWritable value : values) {	String val = Bytes.toStringBinary(value.get());	
reduce key value 

protected void cleanup(Context context) throws IOException, InterruptedException {	Configuration c = context.getConfiguration();	String startRow = c.get(KEY_STARTROW);	String lastRow = c.get(KEY_LASTROW);	
cleanup first first start row startrow 

protected void cleanup(Context context) throws IOException, InterruptedException {	Configuration c = context.getConfiguration();	String startRow = c.get(KEY_STARTROW);	String lastRow = c.get(KEY_LASTROW);	
cleanup last last last row lastrow 

protected void testScan(String start, String stop, String last) throws IOException, InterruptedException, ClassNotFoundException {	String jobName = "Scan" + (start != null ? start.toUpperCase(Locale.ROOT) : "Empty") + "To" + (stop != null ? stop.toUpperCase(Locale.ROOT) : "Empty");	
before map reduce startup job 

scan.addFamily(INPUT_FAMILYS[0]);	scan.addFamily(INPUT_FAMILYS[1]);	if (start != null) {	scan.setStartRow(Bytes.toBytes(start));	}	c.set(KEY_STARTROW, start != null ? start : "");	if (stop != null) {	scan.setStopRow(Bytes.toBytes(stop));	}	c.set(KEY_LASTROW, last != null ? last : "");	
scan before 

c.set(KEY_STARTROW, start != null ? start : "");	if (stop != null) {	scan.setStopRow(Bytes.toBytes(stop));	}	c.set(KEY_LASTROW, last != null ? last : "");	Job job = new Job(c, jobName);	TableMapReduceUtil.initTableMapperJob( TABLE_NAME, scan, ScanMapper.class, ImmutableBytesWritable.class, ImmutableBytesWritable.class, job);	job.setReducerClass(ScanReducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	
started 

if (stop != null) {	scan.setStopRow(Bytes.toBytes(stop));	}	c.set(KEY_LASTROW, last != null ? last : "");	Job job = new Job(c, jobName);	TableMapReduceUtil.initTableMapperJob( TABLE_NAME, scan, ScanMapper.class, ImmutableBytesWritable.class, ImmutableBytesWritable.class, job);	job.setReducerClass(ScanReducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	assertTrue(job.waitForCompletion(true));	
after map reduce completion job 

public void testNumOfSplits(int splitsPerRegion, int expectedNumOfSplits) throws IOException, InterruptedException, ClassNotFoundException {	String jobName = "TestJobForNumOfSplits";	
before map reduce startup job 

public void testNumOfSplitsMR(int splitsPerRegion, int expectedNumOfSplits) throws IOException, InterruptedException, ClassNotFoundException {	String jobName = "TestJobForNumOfSplits-MR";	
before map reduce startup job 

========================= hbase sample_3381 =========================

protected synchronized void setChildrenLatch(final int numChildren) {	this.childrenLatch = numChildren;	if (LOG.isTraceEnabled()) {	
child latch increment set 

protected synchronized void incChildrenLatch() {	this.childrenLatch++;	if (LOG.isTraceEnabled()) {	
child latch increment 

private synchronized boolean childrenCountDown() {	assert childrenLatch > 0: this;	boolean b = --childrenLatch == 0;	if (LOG.isTraceEnabled()) {	
child latch decrement 

========================= hbase sample_1216 =========================

private boolean flushOneForGlobalPressure() {	SortedMap<Long, HRegion> regionsBySize = server.getCopyOfOnlineRegionsSortedBySize();	Set<HRegion> excludedRegions = new HashSet<>();	double secondaryMultiplier = ServerRegionReplicaUtil.getRegionReplicaStoreFileRefreshMultiplier(conf);	boolean flushedOne = false;	while (!flushedOne) {	HRegion bestFlushableRegion = getBiggestMemStoreRegion(regionsBySize, excludedRegions, true);	HRegion bestAnyRegion = getBiggestMemStoreRegion( regionsBySize, excludedRegions, false);	HRegion bestRegionReplica = getBiggestMemStoreOfRegionReplica(regionsBySize, excludedRegions);	if (bestAnyRegion == null && bestRegionReplica == null) {	
above memory mark but there are no flushable regions 

while (!flushedOne) {	HRegion bestFlushableRegion = getBiggestMemStoreRegion(regionsBySize, excludedRegions, true);	HRegion bestAnyRegion = getBiggestMemStoreRegion( regionsBySize, excludedRegions, false);	HRegion bestRegionReplica = getBiggestMemStoreOfRegionReplica(regionsBySize, excludedRegions);	if (bestAnyRegion == null && bestRegionReplica == null) {	return false;	}	HRegion regionToFlush;	if (bestFlushableRegion != null && bestAnyRegion.getMemStoreSize() > 2 * bestFlushableRegion.getMemStoreSize()) {	if (LOG.isDebugEnabled()) {	
under global heap pressure region has too many store files but is vs best flushable region s choosing the bigger 

regionToFlush = bestAnyRegion;	} else {	regionToFlush = bestFlushableRegion;	}	}	Preconditions.checkState( (regionToFlush != null && regionToFlush.getMemStoreSize() > 0) || (bestRegionReplica != null && bestRegionReplica.getMemStoreSize() > 0));	if (regionToFlush == null || (bestRegionReplica != null && ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) && (bestRegionReplica.getMemStoreSize() > secondaryMultiplier * regionToFlush.getMemStoreSize()))) {	LOG.info("Refreshing storefiles of region " + bestRegionReplica + " due to global heap pressure. Total memstore datasize=" + TraditionalBinaryPrefix.long2String( server.getRegionServerAccounting().getGlobalMemStoreDataSize(), "", 1) + " memstore heap size=" + TraditionalBinaryPrefix.long2String( server.getRegionServerAccounting().getGlobalMemStoreHeapSize(), "", 1));	flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);	if (!flushedOne) {	
excluding secondary region trying to find a different region to refresh files 

if (regionToFlush == null || (bestRegionReplica != null && ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) && (bestRegionReplica.getMemStoreSize() > secondaryMultiplier * regionToFlush.getMemStoreSize()))) {	LOG.info("Refreshing storefiles of region " + bestRegionReplica + " due to global heap pressure. Total memstore datasize=" + TraditionalBinaryPrefix.long2String( server.getRegionServerAccounting().getGlobalMemStoreDataSize(), "", 1) + " memstore heap size=" + TraditionalBinaryPrefix.long2String( server.getRegionServerAccounting().getGlobalMemStoreHeapSize(), "", 1));	flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);	if (!flushedOne) {	excludedRegions.add(bestRegionReplica);	}	} else {	LOG.info("Flush of region " + regionToFlush + " due to global heap pressure. " + "Total Memstore size=" + TraditionalBinaryPrefix.long2String( server.getRegionServerAccounting().getGlobalMemStoreDataSize(), "", 1) + ", Region memstore size=" + TraditionalBinaryPrefix.long2String(regionToFlush.getMemStoreSize(), "", 1));	flushedOne = flushRegion(regionToFlush, true, false, FlushLifeCycleTracker.DUMMY);	if (!flushedOne) {	
excluding unflushable region trying to find a different region to flush 

}	FlushRegionEntry fre = (FlushRegionEntry) fqe;	if (!flushRegion(fre)) {	break;	}	} catch (InterruptedException ex) {	continue;	} catch (ConcurrentModificationException ex) {	continue;	} catch (Exception ex) {	
cache flusher failed for entry 

if (!server.checkFileSystem()) {	break;	}	}	}	synchronized (regionsInQueue) {	regionsInQueue.clear();	flushQueue.clear();	}	wakeUpIfBlocking();	
exiting 

private boolean refreshStoreFilesAndReclaimMemory(Region region) {	try {	return region.refreshStoreFiles();	} catch (IOException e) {	
refreshing store files failed with exception 

private boolean flushRegion(final FlushRegionEntry fqe) {	HRegion region = fqe.region;	if (!region.getRegionInfo().isMetaRegion() && isTooManyStoreFiles(region)) {	if (fqe.isMaximumWait(this.blockingWaitTime)) {	
waited ms on a compaction to clean up too many store files waited long enough proceeding with flush of 

private boolean flushRegion(final FlushRegionEntry fqe) {	HRegion region = fqe.region;	if (!region.getRegionInfo().isMetaRegion() && isTooManyStoreFiles(region)) {	if (fqe.isMaximumWait(this.blockingWaitTime)) {	} else {	if (fqe.getRequeueCount() <= 0) {	
region has too many store files delaying flush up to ms 

HRegion region = fqe.region;	if (!region.getRegionInfo().isMetaRegion() && isTooManyStoreFiles(region)) {	if (fqe.isMaximumWait(this.blockingWaitTime)) {	} else {	if (fqe.getRequeueCount() <= 0) {	if (!this.server.compactSplitThread.requestSplit(region)) {	try {	this.server.compactSplitThread.requestSystemCompaction(region, Thread.currentThread().getName());	} catch (IOException e) {	e = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	
cache flush failed for region 

break;	default: break;	}	}	}	blocked = true;	wakeupFlushThread();	try {	blockSignal.wait(5 * 1000);	} catch (InterruptedException ie) {	
interrupted while waiting 

}	}	blocked = true;	wakeupFlushThread();	try {	blockSignal.wait(5 * 1000);	} catch (InterruptedException ie) {	interrupted = true;	}	long took = EnvironmentEdgeManager.currentTime() - start;	
memstore is above high water mark and block ms 

} finally {	if (interrupted) {	Thread.currentThread().interrupt();	}	}	if(blocked){	final long totalTime = EnvironmentEdgeManager.currentTime() - startTime;	if(totalTime > 0){	this.updatesBlockedMsHighWater.add(totalTime);	}	
unblocking updates for server 

========================= hbase sample_2713 =========================

public synchronized void start() throws IOException {	if (!QuotaUtil.isQuotaEnabled(rsServices.getConfiguration())) {	
quota support disabled not starting space quota manager 

public synchronized void start() throws IOException {	if (!QuotaUtil.isQuotaEnabled(rsServices.getConfiguration())) {	return;	}	if (started) {	
regionserverspacequotamanager has already been started 

public void enforceViolationPolicy(TableName tableName, SpaceQuotaSnapshot snapshot) {	SpaceQuotaStatus status = snapshot.getQuotaStatus();	if (!status.isInViolation()) {	throw new IllegalStateException( tableName + " is not in violation. Violation policy should not be enabled.");	}	if (LOG.isTraceEnabled()) {	
enabling violation policy enforcement on with policy 

if (!status.isInViolation()) {	throw new IllegalStateException( tableName + " is not in violation. Violation policy should not be enabled.");	}	if (LOG.isTraceEnabled()) {	}	final SpaceViolationPolicyEnforcement enforcement = getFactory().create( getRegionServerServices(), tableName, snapshot);	synchronized (enforcedPolicies) {	try {	enforcement.enable();	} catch (IOException e) {	
failed to enable space violation policy for this table will not enter violation 

public void disableViolationPolicyEnforcement(TableName tableName) {	if (LOG.isTraceEnabled()) {	
disabling violation policy enforcement on 

public void disableViolationPolicyEnforcement(TableName tableName) {	if (LOG.isTraceEnabled()) {	}	synchronized (enforcedPolicies) {	SpaceViolationPolicyEnforcement enforcement = enforcedPolicies.remove(tableName);	if (enforcement != null) {	try {	enforcement.disable();	} catch (IOException e) {	
failed to disable space violation policy for this table will remain in violation 

========================= hbase sample_2343 =========================

}	int realNumSplits = numSplits > startKeys.length? startKeys.length: numSplits;	InputSplit[] splits = new InputSplit[realNumSplits];	int middle = startKeys.length / realNumSplits;	int startPos = 0;	for (int i = 0; i < realNumSplits; i++) {	int lastPos = startPos + middle;	lastPos = startKeys.length % realNumSplits > i ? lastPos + 1 : lastPos;	String regionLocation = regionLocator.getRegionLocation(startKeys[startPos]). getHostname();	splits[i] = new TableSplit(this.table.getName(), startKeys[startPos], ((i + 1) < realNumSplits) ? startKeys[lastPos]: HConstants.EMPTY_START_ROW, regionLocation);	
split 

protected void initializeTable(Connection connection, TableName tableName) throws IOException {	if (this.table != null || this.connection != null) {	
initializetable called multiple times overwriting connection and table reference tableinputformatbase will not close these old references when done 

========================= hbase sample_3417 =========================

protected void configureForRegion(HRegion region) {	super.configureForRegion(region);	String delimiterString = region.getTableDescriptor().getValue(DELIMITER_KEY);	if (delimiterString == null || delimiterString.length() == 0) {	
not specified for table using default regionsplitpolicy 

protected byte[] getSplitPoint() {	byte[] splitPoint = super.getSplitPoint();	if (splitPoint != null && delimiter != null) {	int index = org.apache.hbase.thirdparty.com.google.common.primitives.Bytes.indexOf(splitPoint, delimiter);	if (index < 0) {	
delimiter not found for split key 

========================= hbase sample_2528 =========================

public RegionServerFlushTableProcedureManager() {}	public void start() {	
start region server flush procedure manager 

public void stop(boolean force) throws IOException {	String mode = force ? "abruptly" : "gracefully";	
stopping region server flush procedure manager 

public Subprocedure buildSubprocedure(String table) {	if (rss.isStopping() || rss.isStopped()) {	throw new IllegalStateException("Can't start flush region subprocedure on RS: " + rss.getServerName() + ", because stopping/stopped!");	}	List<HRegion> involvedRegions;	try {	involvedRegions = getRegionsToFlush(table);	} catch (IOException e1) {	throw new IllegalStateException("Failed to figure out if there is region to flush.", e1);	}	
launching subprocedure to flush regions for 

========================= hbase sample_2482 =========================

protected void closeTable() {	for (Table table : userVsTable.values()) {	try {	table.close();	} catch (Exception e) {	
error while closing the table 

========================= hbase sample_1304 =========================

final HRegionServer killRS = ((MiniHBaseCluster)cluster).getRegionServer(0);	final HRegionServer groupRS = ((MiniHBaseCluster)cluster).getRegionServer(1);	final HRegionServer failoverRS = ((MiniHBaseCluster)cluster).getRegionServer(2);	String newGroup =  "my_group";	RSGroupAdmin groupAdmin = new RSGroupAdminClient(TEST_UTIL.getConnection());	groupAdmin.addRSGroup(newGroup);	if(master.getAssignmentManager().getRegionStates().getRegionAssignments() .containsValue(failoverRS.getServerName())) {	for (HRegionInfo regionInfo : hbaseAdmin.getOnlineRegions(failoverRS.getServerName())) {	hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(failoverRS.getServerName().getServerName()));	}	
waiting for region unassignments on failover rs 

========================= hbase sample_3339 =========================

public void preBatchMutate(ObserverContext<RegionCoprocessorEnvironment> c, MiniBatchOperationInProgress<Mutation> miniBatchOp) throws IOException {	Mutation mut = miniBatchOp.getOperation(0);	List<Cell> cells = mut.getFamilyCellMap().get(test);	Put[] puts = new Put[] {	new Put(row1).addColumn(test, dummy, cells.get(0).getTimestamp(), Bytes.toBytes("cpdummy")), new Put(row2).addColumn(test, dummy, cells.get(0).getTimestamp(), dummy), new Put(row3).addColumn(test, dummy, cells.get(0).getTimestamp(), dummy), };	
putting 

public void preBatchMutate(ObserverContext<RegionCoprocessorEnvironment> c, MiniBatchOperationInProgress<Mutation> miniBatchOp) throws IOException {	Mutation mut = miniBatchOp.getOperation(0);	if (mut instanceof Delete) {	List<Cell> cells = mut.getFamilyCellMap().get(test);	Delete[] deletes = new Delete[] {	new Delete(row1).addColumns(test, dummy, cells.get(0).getTimestamp()), new Delete(row2).addColumns(test, dummy, cells.get(0).getTimestamp()), };	
deleting 

public void preBatchMutate(ObserverContext<RegionCoprocessorEnvironment> c, MiniBatchOperationInProgress<Mutation> miniBatchOp) throws IOException {	Mutation mut = miniBatchOp.getOperation(0);	if (mut instanceof Delete) {	List<Cell> cells = mut.getFamilyCellMap().get(test);	Delete[] deletes = new Delete[] {	new Delete(row1).addFamily(test, cells.get(0).getTimestamp()), new Delete(row2).addFamily(test, cells.get(0).getTimestamp()), };	
deleting 

public void preBatchMutate(ObserverContext<RegionCoprocessorEnvironment> c, MiniBatchOperationInProgress<Mutation> miniBatchOp) throws IOException {	Mutation mut = miniBatchOp.getOperation(0);	if (mut instanceof Delete) {	List<Cell> cells = mut.getFamilyCellMap().get(test);	Delete[] deletes = new Delete[] {	new Delete(row1, cells.get(0).getTimestamp()), new Delete(row2, cells.get(0).getTimestamp()), };	
deleting 

========================= hbase sample_1538 =========================

public HBaseSaslRpcServer(AuthMethod method, Map<String, String> saslProps, SecretManager<TokenIdentifier> secretManager) throws IOException {	switch (method) {	case DIGEST: if (secretManager == null) {	throw new AccessDeniedException("Server is not configured to do DIGEST authentication.");	}	saslServer = Sasl.createSaslServer(AuthMethod.DIGEST.getMechanismName(), null, SaslUtil.SASL_DEFAULT_REALM, saslProps, new SaslDigestCallbackHandler(secretManager));	break;	case KERBEROS: UserGroupInformation current = UserGroupInformation.getCurrentUser();	String fullName = current.getUserName();	if (LOG.isDebugEnabled()) {	
kerberos principal name is 

} else {	throw new UnsupportedCallbackException(callback, "Unrecognized SASL DIGEST-MD5 Callback");	}	}	if (pc != null) {	TokenIdentifier tokenIdentifier = getIdentifier(nc.getDefaultName(), secretManager);	char[] password = getPassword(tokenIdentifier);	UserGroupInformation user = tokenIdentifier.getUser();	attemptingUser = user;	if (LOG.isTraceEnabled()) {	
sasl server digest callback setting password for client 

String authid = ac.getAuthenticationID();	String authzid = ac.getAuthorizationID();	if (authid.equals(authzid)) {	ac.setAuthorized(true);	} else {	ac.setAuthorized(false);	}	if (ac.isAuthorized()) {	if (LOG.isTraceEnabled()) {	String username = getIdentifier(authzid, secretManager).getUser().getUserName();	
sasl server digest callback setting canonicalized client id 

if (ac != null) {	String authid = ac.getAuthenticationID();	String authzid = ac.getAuthorizationID();	if (authid.equals(authzid)) {	ac.setAuthorized(true);	} else {	ac.setAuthorized(false);	}	if (ac.isAuthorized()) {	if (LOG.isDebugEnabled()) {	
sasl server gssapi callback setting canonicalized client id 

========================= hbase sample_2314 =========================

public static void startCluster() throws Exception {	
starting cluster 

public static void startCluster() throws Exception {	TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniCluster(1, 1, 1, null, MyMaster.class, null);	cluster = TEST_UTIL.getHBaseCluster();	
waiting for active ready master 

========================= hbase sample_1884 =========================

public void run() {	int jitter = RandomUtils.nextInt(0, (int) periodMs);	
sleeping for to add jitter 

public void run() {	int jitter = RandomUtils.nextInt(0, (int) periodMs);	Threads.sleep(jitter);	while (!isStopped()) {	long start = System.currentTimeMillis();	runOneIteration();	if (isStopped()) return;	long sleepTime = periodMs - (System.currentTimeMillis() - start);	if (sleepTime > 0) {	
sleeping for 

protected abstract void runOneIteration();	public void init(PolicyContext context) throws Exception {	super.init(context);	
using chaosmonkey policy period 

========================= hbase sample_3285 =========================

assert member != null : "procedure member should be non-null";	assert member.getRpcs() != null : "rpc handlers should be non-null";	assert procName != null : "procedure name should be non-null";	assert monitor != null : "monitor should be non-null";	this.rpcs = member.getRpcs();	this.barrierName = procName;	this.monitor = monitor;	this.monitor.addListener(new ForeignExceptionListener() {	public void receive(ForeignException ee) {	if (ee.isRemote()) {	
was remote foreign exception not redispatching error 

assert monitor != null : "monitor should be non-null";	this.rpcs = member.getRpcs();	this.barrierName = procName;	this.monitor = monitor;	this.monitor.addListener(new ForeignExceptionListener() {	public void receive(ForeignException ee) {	if (ee.isRemote()) {	return;	}	if (ee.getCause() instanceof KeeperException) {	
was keeperexception not redispatching error 

public void receive(ForeignException ee) {	if (ee.isRemote()) {	return;	}	if (ee.getCause() instanceof KeeperException) {	return;	}	try {	rpcs.sendMemberAborted(Subprocedure.this, ee);	} catch (IOException e) {	
can t reach controller not propagating error 

========================= hbase sample_2494 =========================

private boolean loadSnapshotInfo(final String snapshotName) throws IOException {	Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshotName, rootDir);	if (!fs.exists(snapshotDir)) {	
snapshot not found in 

========================= hbase sample_2181 =========================

public void shutdown() {	for(Entry<String, Executor> entry: this.executorMap.entrySet()) {	List<Runnable> wasRunning = entry.getValue().threadPoolExecutor.shutdownNow();	if (!wasRunning.isEmpty()) {	
had on shutdown 

public void startExecutorService(final ExecutorType type, final int maxThreads) {	String name = type.getExecutorName(this.servername);	if (isExecutorServiceRunning(name)) {	
executor service already running on 

public void submit(final EventHandler eh) {	Executor executor = getExecutor(eh.getEventType().getExecutorServiceType());	if (executor == null) {	
cannot submit because the executor is missing is this process shutting down 

public ExecutorStatus getStatus() {	List<EventHandler> queuedEvents = Lists.newArrayList();	for (Runnable r : q) {	if (!(r instanceof EventHandler)) {	
non eventhandler queued in 

for (Runnable r : q) {	if (!(r instanceof EventHandler)) {	continue;	}	queuedEvents.add((EventHandler)r);	}	List<RunningEventStatus> running = Lists.newArrayList();	for (Map.Entry<Thread, Runnable> e : threadPoolExecutor.getRunningTasks().entrySet()) {	Runnable r = e.getValue();	if (!(r instanceof EventHandler)) {	
non eventhandler running in 

========================= hbase sample_2928 =========================

public static <TEnv> void restart(final ProcedureExecutor<TEnv> procExecutor, final boolean avoidTestKillDuringRestart, final boolean failOnCorrupted, final Callable<Void> stopAction, final Callable<Void> startAction) throws Exception {	final ProcedureStore procStore = procExecutor.getStore();	final int storeThreads = procExecutor.getCorePoolSize();	final int execThreads = procExecutor.getCorePoolSize();	final ProcedureExecutor.Testing testing = procExecutor.testing;	if (avoidTestKillDuringRestart) {	procExecutor.testing = null;	}	
restart stop 

if (avoidTestKillDuringRestart) {	procExecutor.testing = null;	}	procExecutor.stop();	procStore.stop(false);	if (stopAction != null) {	stopAction.call();	}	procExecutor.join();	procExecutor.getScheduler().clear();	
restart start 

public static <TEnv> void setKillBeforeStoreUpdate(ProcedureExecutor<TEnv> procExecutor, boolean value) {	createExecutorTesting(procExecutor);	procExecutor.testing.killBeforeStoreUpdate = value;	
set kill before store update to 

public static <TEnv> void toggleKillBeforeStoreUpdate(ProcedureExecutor<TEnv> procExecutor) {	createExecutorTesting(procExecutor);	procExecutor.testing.killBeforeStoreUpdate = !procExecutor.testing.killBeforeStoreUpdate;	
set kill before store update to 

public static <TEnv> void testRecoveryAndDoubleExecution(final ProcedureExecutor<TEnv> procExec, final long procId, final boolean expectFailure, final Runnable customRestart) throws Exception {	Procedure proc = procExec.getProcedure(procId);	waitProcedure(procExec, procId);	assertEquals(false, procExec.isRunning());	for (int i = 0; !procExec.isFinished(procId); ++i) {	proc = procExec.getProcedure(procId);	
restart exec state 

========================= hbase sample_1191 =========================

public void testPerTableCFReplication() throws Exception {	
testPerTableCFReplication 

Get get = new Get(row);	get.addFamily(fam);	for (int i = 0; i < NB_RETRIES; i++) {	if (i==NB_RETRIES-1) {	fail("Waited too much time for del replication");	}	boolean removedFromAll = true;	for (Table target : targets) {	Result res = target.get(get);	if (res.size() >= 1) {	
row not deleted 

Get get = new Get(row);	get.addFamily(fam);	for (int i = 0; i < NB_RETRIES; i++) {	if (i==NB_RETRIES-1) {	fail("Waited too much time for put replication");	}	boolean replicatedToAll = true;	for (Table target : targets) {	Result res = target.get(get);	if (res.isEmpty()) {	
row not available 

========================= hbase sample_1938 =========================

public static void shutdown(final List<MasterThread> masters, final List<RegionServerThread> regionservers) {	
shutting down hbase cluster 

public static void shutdown(final List<MasterThread> masters, final List<RegionServerThread> regionservers) {	if (masters != null) {	JVMClusterUtil.MasterThread activeMaster = null;	for (JVMClusterUtil.MasterThread t : masters) {	if (!t.master.isActiveMaster()) {	try {	t.master.stopMaster();	} catch (IOException e) {	
exception occurred while stopping master 

} catch (IOException e) {	}	} else {	activeMaster = t;	}	}	if (activeMaster != null) {	try {	activeMaster.master.shutdown();	} catch (IOException e) {	
exception occurred in hmaster shutdown 

if (regionservers != null) {	for (RegionServerThread t : regionservers) {	t.getRegionServer().stop("Shutdown requested");	}	for (RegionServerThread t : regionservers) {	long now = System.currentTimeMillis();	if (t.isAlive() && !wasInterrupted && now < maxTime) {	try {	t.join(maxTime - now);	} catch (InterruptedException e) {	
got interruptedexception on shutdown not waiting anymore on region server ends 

wasInterrupted = true;	}	}	}	for (int i = 0; i < 100; ++i) {	boolean atLeastOneLiveServer = false;	for (RegionServerThread t : regionservers) {	if (t.isAlive()) {	atLeastOneLiveServer = true;	try {	
regionserverthreads remaining give one more chance before interrupting 

try {	t.join(1000);	} catch (InterruptedException e) {	wasInterrupted = true;	}	}	}	if (!atLeastOneLiveServer) break;	for (RegionServerThread t : regionservers) {	if (t.isAlive()) {	
regionserverthreads taking too long to stop interrupting 

}	}	}	}	if (masters != null) {	for (JVMClusterUtil.MasterThread t : masters) {	while (t.master.isAlive() && !wasInterrupted) {	try {	Threads.threadDumpingIsAlive(t.master.getThread());	} catch(InterruptedException e) {	
got interruptedexception on shutdown not waiting anymore on master ends 

========================= hbase sample_2247 =========================

scanner = ht.getScanner(scan);	HRegionLocation loc;	try (RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	loc = locator.getRegionLocation(ROW);	}	HRegionInfo hri = loc.getRegionInfo();	MiniHBaseCluster cluster = TEST_UTIL.getMiniHBaseCluster();	byte[] regionName = hri.getRegionName();	int i = cluster.getServerWith(regionName);	HRegionServer rs = cluster.getRegionServer(i);	
unassigning 

long timeOut = 10000;	boolean offline = false;	while (true) {	if (rs.getOnlineRegion(regionName) == null) {	offline = true;	break;	}	assertTrue("Timed out in closing the testing region", EnvironmentEdgeManager.currentTime() < startTime + timeOut);	}	assertTrue(offline);	
assigning 

========================= hbase sample_2093 =========================

public boolean isSplitParent() {	if (!isSplit()) return false;	if (!isOffline()) {	
region is split but not offline 

========================= hbase sample_222 =========================

protected static Tool doMROnTableTest(HBaseTestingUtility util, String family, String data, String[] args, int valueMultiplier) throws Exception {	TableName table = TableName.valueOf(args[args.length - 1]);	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util .getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	
wrote test data to file s 

protected static Tool doMROnTableTest(HBaseTestingUtility util, String family, String data, String[] args, int valueMultiplier) throws Exception {	TableName table = TableName.valueOf(args[args.length - 1]);	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util .getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	
forcing combiner 

Path inputPath = fs.makeQualified(new Path(util .getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	conf.setInt("mapreduce.map.combine.minspills", 1);	}	List<String> argv = new ArrayList<>(Arrays.asList(args));	argv.add(inputPath.toString());	Tool tool = new ImportTsv();	
running importtsv with arguments 

if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	conf.setInt("mapreduce.map.combine.minspills", 1);	}	List<String> argv = new ArrayList<>(Arrays.asList(args));	argv.add(inputPath.toString());	Tool tool = new ImportTsv();	try {	assertEquals(0, ToolRunner.run(conf, tool, argv.toArray(args)));	} finally {	if (conf.getBoolean(DELETE_AFTER_LOAD_CONF, true)) {	
deleting test subdirectory 

========================= hbase sample_3378 =========================

public void start() throws KeeperException {	
starting hfile archive tracker 

public void start() throws KeeperException {	this.checkEnabledAndUpdate();	
finished starting hfile archive tracker 

public void nodeCreated(String path) {	if (!path.startsWith(archiveHFileZNode)) return;	
archive node created 

public void nodeCreated(String path) {	if (!path.startsWith(archiveHFileZNode)) return;	String table = path.substring(archiveHFileZNode.length());	if (table.length() == 0) {	checkEnabledAndUpdate();	return;	}	try {	addAndReWatchTable(path);	} catch (KeeperException e) {	
couldn t read zookeeper data for table for path not preserving a table 

public void nodeChildrenChanged(String path) {	if (!path.startsWith(archiveHFileZNode)) return;	
archive node children changed 

public void nodeChildrenChanged(String path) {	if (!path.startsWith(archiveHFileZNode)) return;	try {	updateWatchedTables();	} catch (KeeperException e) {	
failed to update tables to archive 

public void nodeDeleted(String path) {	if (!path.startsWith(archiveHFileZNode)) return;	
archive node deleted 

private void checkEnabledAndUpdate() {	try {	if (ZKUtil.watchAndCheckExists(watcher, archiveHFileZNode)) {	
znode does exist checking for tables to archive 

private void checkEnabledAndUpdate() {	try {	if (ZKUtil.watchAndCheckExists(watcher, archiveHFileZNode)) {	updateWatchedTables();	} else {	
archiving not currently enabled waiting 

private void checkEnabledAndUpdate() {	try {	if (ZKUtil.watchAndCheckExists(watcher, archiveHFileZNode)) {	updateWatchedTables();	} else {	}	} catch (KeeperException e) {	
failed to watch for archiving znode 

private void updateWatchedTables() throws KeeperException {	
updating watches on tables to archive 

private void updateWatchedTables() throws KeeperException {	List<String> tables = ZKUtil.listChildrenAndWatchThem(watcher, archiveHFileZNode);	
starting archive for tables 

private void updateWatchedTables() throws KeeperException {	List<String> tables = ZKUtil.listChildrenAndWatchThem(watcher, archiveHFileZNode);	if (tables != null && tables.size() > 0) {	getMonitor().setArchiveTables(tables);	} else {	
no tables to archive 

========================= hbase sample_2990 =========================

}	RegionScanner regionScanner = region.getScanner(new Scan());	List<Cell> cells = new ArrayList<>(THREAD_COUNT);	while(regionScanner.next(cells)) continue;	assertEquals(THREAD_COUNT, cells.size());	long total = 0;	for (Cell cell: cells) total += Bytes.toLong(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());	assertEquals(INCREMENT_COUNT * THREAD_COUNT, total);	} finally {	closeRegion(region);	
ms 

}	RegionScanner regionScanner = region.getScanner(new Scan());	List<Cell> cells = new ArrayList<>(100);	while(regionScanner.next(cells)) continue;	assertEquals(THREAD_COUNT, cells.size());	long total = 0;	for (Cell cell: cells) total += Bytes.toLong(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());	assertEquals(INCREMENT_COUNT * THREAD_COUNT, total);	} finally {	closeRegion(region);	
ms 

========================= hbase sample_1715 =========================

protected static void createTableAndSnapshot(HBaseTestingUtility util, TableName tableName, String snapshotName, byte[] startRow, byte[] endRow, int numRegions) throws Exception {	try {	
ensuring table doesn t exist 

protected static void createTableAndSnapshot(HBaseTestingUtility util, TableName tableName, String snapshotName, byte[] startRow, byte[] endRow, int numRegions) throws Exception {	try {	util.deleteTable(tableName);	} catch(Exception ex) {	}	
creating table 

try {	util.deleteTable(tableName);	} catch(Exception ex) {	}	if (numRegions > 1) {	util.createTable(tableName, FAMILIES, 1, startRow, endRow, numRegions);	} else {	util.createTable(tableName, FAMILIES);	}	Admin admin = util.getAdmin();	
put some stuff in the table 

if (numRegions > 1) {	util.createTable(tableName, FAMILIES, 1, startRow, endRow, numRegions);	} else {	util.createTable(tableName, FAMILIES);	}	Admin admin = util.getAdmin();	Table table = util.getConnection().getTable(tableName);	util.loadTable(table, FAMILIES);	Path rootDir = FSUtils.getRootDir(util.getConfiguration());	FileSystem fs = rootDir.getFileSystem(util.getConfiguration());	
snapshot 

util.createTable(tableName, FAMILIES, 1, startRow, endRow, numRegions);	} else {	util.createTable(tableName, FAMILIES);	}	Admin admin = util.getAdmin();	Table table = util.getConnection().getTable(tableName);	util.loadTable(table, FAMILIES);	Path rootDir = FSUtils.getRootDir(util.getConfiguration());	FileSystem fs = rootDir.getFileSystem(util.getConfiguration());	SnapshotTestingUtils.createSnapshotAndValidate(admin, tableName, Arrays.asList(FAMILIES), null, snapshotName, rootDir, fs, true);	
load different values 

util.createTable(tableName, FAMILIES);	}	Admin admin = util.getAdmin();	Table table = util.getConnection().getTable(tableName);	util.loadTable(table, FAMILIES);	Path rootDir = FSUtils.getRootDir(util.getConfiguration());	FileSystem fs = rootDir.getFileSystem(util.getConfiguration());	SnapshotTestingUtils.createSnapshotAndValidate(admin, tableName, Arrays.asList(FAMILIES), null, snapshotName, rootDir, fs, true);	byte[] value = Bytes.toBytes("after_snapshot_value");	util.loadTable(table, FAMILIES, value);	
cause flush to create new files in the region 

========================= hbase sample_3397 =========================

try {	if (!rollLog.get()) {	rollLog.wait(this.threadWakeFrequency);	}	} catch (InterruptedException e) {	}	}	continue;	}	if (LOG.isDebugEnabled()) {	
wal roll period ms elapsed 

rollLog.wait(this.threadWakeFrequency);	}	} catch (InterruptedException e) {	}	}	continue;	}	if (LOG.isDebugEnabled()) {	}	} else if (LOG.isDebugEnabled()) {	
wal roll requested 

for (byte [] r: regionsToFlush) scheduleFlush(r);	}	}	} catch (FailedLogCloseException e) {	server.abort("Failed log close in log roller", e);	} catch (java.net.ConnectException e) {	server.abort("Failed log close in log roller", e);	} catch (IOException ex) {	server.abort("IOE in log roller", ex instanceof RemoteException ? ((RemoteException) ex).unwrapRemoteException() : ex);	} catch (Exception ex) {	
log rolling failed 

} catch (Exception ex) {	server.abort("Log rolling failed", ex);	} finally {	try {	rollLog.set(false);	} finally {	rollLock.unlock();	}	}	}	
logroller exiting 

========================= hbase sample_2586 =========================

public void tearDown() throws Exception {	EnvironmentEdgeManagerTestHelper.reset();	
cleaning test directory 

public void testLockupWhenSyncInMiddleOfZigZagSetup() throws IOException {	class DodgyFSLog extends FSHLog {	volatile boolean throwException = false;	CountDownLatch latch = new CountDownLatch(1);	public DodgyFSLog(FileSystem fs, Path root, String logDir, Configuration conf) throws IOException {	super(fs, root, logDir, conf);	}	protected void afterCreatingZigZagLatch() {	if (throwException) {	try {	
LATCHED 

class DodgyFSLog extends FSHLog {	volatile boolean throwException = false;	CountDownLatch latch = new CountDownLatch(1);	public DodgyFSLog(FileSystem fs, Path root, String logDir, Configuration conf) throws IOException {	super(fs, root, logDir, conf);	}	protected void afterCreatingZigZagLatch() {	if (throwException) {	try {	if (!this.latch.await(5, TimeUnit.SECONDS)) {	
give up failed waiting on latch test is aborted 

try {	if (!this.latch.await(5, TimeUnit.SECONDS)) {	}	} catch (InterruptedException e) {	e.printStackTrace();	}	}	}	protected void beforeWaitOnSafePoint() {	if (throwException) {	
COUNTDOWN 

Put put = new Put(bytes);	put.addColumn(COLUMN_FAMILY_BYTES, Bytes.toBytes("1"), bytes);	WALKeyImpl key = new WALKeyImpl(region.getRegionInfo().getEncodedNameAsBytes(), htd.getTableName(), System.currentTimeMillis(), mvcc, scopes);	WALEdit edit = new WALEdit();	CellScanner CellScanner = put.cellScanner();	assertTrue(CellScanner.advance());	edit.add(CellScanner.current());	for (int i = 0; i < 1000; i++) {	region.put(put);	}	
set throwing of exception on append 

}	assertTrue("Did not get sync exception", exception);	Thread t = new Thread ("Flusher") {	public void run() {	try {	if (region.getMemStoreSize() <= 0) {	throw new IOException("memstore size=" + region.getMemStoreSize());	}	region.flush(false);	} catch (IOException e) {	
in flush 

assertTrue("Did not get sync exception", exception);	Thread t = new Thread ("Flusher") {	public void run() {	try {	if (region.getMemStoreSize() <= 0) {	throw new IOException("memstore size=" + region.getMemStoreSize());	}	region.flush(false);	} catch (IOException e) {	}	
Exiting 

}	};	t.setDaemon(true);	t.start();	while (dodgyWAL.latch.getCount() > 0) Threads.sleep(1);	assertTrue(originalWAL != dodgyWAL.getCurrentFileName());	dodgyWAL.throwException = false;	try {	region.put(put);	} catch (Exception e) {	
in the put 

region.put(put);	} catch (Exception e) {	}	} finally {	Mockito.when(server.isStopped()).thenReturn(true);	if (logRoller != null) logRoller.close();	try {	if (region != null) region.close();	if (dodgyWAL != null) dodgyWAL.close();	} catch (Exception e) {	
on way out 

scopes.put(COLUMN_FAMILY_BYTES, 0);	MultiVersionConcurrencyControl mvcc = new MultiVersionConcurrencyControl();	try {	Put put = new Put(bytes);	put.addColumn(COLUMN_FAMILY_BYTES, Bytes.toBytes("1"), bytes);	WALKeyImpl key = new WALKeyImpl(region.getRegionInfo().getEncodedNameAsBytes(), htd.getTableName(), System.currentTimeMillis(), mvcc, scopes);	WALEdit edit = new WALEdit();	CellScanner CellScanner = put.cellScanner();	assertTrue(CellScanner.advance());	edit.add(CellScanner.current());	
set throwing of exception on append 

e.printStackTrace();	}	final CountDownLatch latch = new CountDownLatch(1);	key = new WALKeyImpl(region.getRegionInfo().getEncodedNameAsBytes(), TableName.valueOf("sleep"), System.currentTimeMillis(), mvcc, scopes);	dodgyWAL2.append(region.getRegionInfo(), key, edit, true);	Thread t = new Thread("Sync") {	public void run() {	try {	dodgyWAL2.sync();	} catch (IOException e) {	
in sync 

final CountDownLatch latch = new CountDownLatch(1);	key = new WALKeyImpl(region.getRegionInfo().getEncodedNameAsBytes(), TableName.valueOf("sleep"), System.currentTimeMillis(), mvcc, scopes);	dodgyWAL2.append(region.getRegionInfo(), key, edit, true);	Thread t = new Thread("Sync") {	public void run() {	try {	dodgyWAL2.sync();	} catch (IOException e) {	}	latch.countDown();	
sync exiting 

if (region != null) {	region.close();	}	if (dodgyWAL1 != null) {	dodgyWAL1.close();	}	if (dodgyWAL2 != null) {	dodgyWAL2.close();	}	} catch (Exception e) {	
on way out 

public void abort(String why, Throwable e) {	
aborting 

========================= hbase sample_1579 =========================

protected void checkHFile(Path p) throws IOException {	HFile.Reader r = null;	try {	r = HFile.createReader(fs, p, cacheConf, true, conf);	} catch (CorruptHFileException che) {	
found corrupt hfile 

protected void checkHFile(Path p) throws IOException {	HFile.Reader r = null;	try {	r = HFile.createReader(fs, p, cacheConf, true, conf);	} catch (CorruptHFileException che) {	corrupted.add(p);	if (inQuarantineMode) {	Path dest = createQuarantinePath(p);	
quarantining corrupt hfile into 

boolean success = fs.mkdirs(dest.getParent());	success = success ? fs.rename(p, dest): false;	if (!success) {	failures.add(p);	} else {	quarantined.add(dest);	}	}	return;	} catch (FileNotFoundException fnfe) {	
hfile was missing likely removed due to compaction split 

protected void checkColFamDir(Path cfDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(cfDir);	} catch (FileNotFoundException fnfe) {	
colfam directory does not exist likely due to concurrent split compaction skipping 

protected void checkColFamDir(Path cfDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(cfDir);	} catch (FileNotFoundException fnfe) {	missing.add(cfDir);	return;	}	List<FileStatus> hfs = FSUtils.filterFileStatuses(statuses, new HFileFilter(fs));	if (hfs.isEmpty() && !fs.exists(cfDir)) {	
colfam directory does not exist likely due to concurrent split compaction skipping 

protected void checkMobColFamDir(Path cfDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(cfDir);	} catch (FileNotFoundException fnfe) {	
mob colfam directory does not exist likely the table is deleted skipping 

protected void checkMobColFamDir(Path cfDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(cfDir);	} catch (FileNotFoundException fnfe) {	missedMobFiles.add(cfDir);	return;	}	List<FileStatus> hfs = FSUtils.filterFileStatuses(statuses, new HFileFilter(fs));	if (hfs.isEmpty() && !fs.exists(cfDir)) {	
mob colfam directory does not exist likely the table is deleted skipping 

protected void checkMobFile(Path p) throws IOException {	HFile.Reader r = null;	try {	r = HFile.createReader(fs, p, cacheConf, true, conf);	} catch (CorruptHFileException che) {	
found corrupt mob file 

protected void checkMobFile(Path p) throws IOException {	HFile.Reader r = null;	try {	r = HFile.createReader(fs, p, cacheConf, true, conf);	} catch (CorruptHFileException che) {	corruptedMobFiles.add(p);	if (inQuarantineMode) {	Path dest = createQuarantinePath(p);	
quarantining corrupt mob file into 

boolean success = fs.mkdirs(dest.getParent());	success = success ? fs.rename(p, dest): false;	if (!success) {	failureMobFiles.add(p);	} else {	quarantinedMobFiles.add(dest);	}	}	return;	} catch (FileNotFoundException fnfe) {	
mob file was missing likely removed due to compaction 

private void checkMobRegionDir(Path regionDir) throws IOException {	if (!fs.exists(regionDir)) {	return;	}	FileStatus[] hfs = null;	try {	hfs = fs.listStatus(regionDir, new FamilyDirFilter(fs));	} catch (FileNotFoundException fnfe) {	
mob directory does not exist likely the table is deleted skipping 

return;	}	FileStatus[] hfs = null;	try {	hfs = fs.listStatus(regionDir, new FamilyDirFilter(fs));	} catch (FileNotFoundException fnfe) {	missedMobFiles.add(regionDir);	return;	}	if (hfs.length == 0 && !fs.exists(regionDir)) {	
mob directory does not exist likely the table is deleted skipping 

protected void checkRegionDir(Path regionDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(regionDir);	} catch (FileNotFoundException fnfe) {	
region directory does not exist likely due to concurrent split compaction skipping 

protected void checkRegionDir(Path regionDir) throws IOException {	FileStatus[] statuses = null;	try {	statuses = fs.listStatus(regionDir);	} catch (FileNotFoundException fnfe) {	missing.add(regionDir);	return;	}	List<FileStatus> cfs = FSUtils.filterFileStatuses(statuses, new FamilyDirFilter(fs));	if (cfs.isEmpty() && !fs.exists(regionDir)) {	
region directory does not exist likely due to concurrent split compaction skipping 

========================= hbase sample_2210 =========================

private void readConf(Configuration conf) {	int selectorThreads = conf.getInt( SELECTOR_THREADS_CONF_KEY, getSelectorThreads());	int workerThreads = conf.getInt( WORKER_THREADS_CONF_KEY, getWorkerThreads());	int stopTimeoutVal = conf.getInt( STOP_TIMEOUT_CONF_KEY, getStopTimeoutVal());	int acceptQueueSizePerThread = conf.getInt( ACCEPT_QUEUE_SIZE_PER_THREAD_CONF_KEY, getAcceptQueueSizePerThread());	AcceptPolicy acceptPolicy = AcceptPolicy.valueOf(conf.get( ACCEPT_POLICY_CONF_KEY, getAcceptPolicy().toString()).toUpperCase(Locale.ROOT));	super.selectorThreads(selectorThreads) .workerThreads(workerThreads) .stopTimeoutVal(stopTimeoutVal) .acceptQueueSizePerThread(acceptQueueSizePerThread) .acceptPolicy(acceptPolicy);	
read configuration selectorthreads workerthreads stoptimeoutval sec acceptqueuesizeperthread acceptpolicy 

========================= hbase sample_808 =========================

String tmpHostname = null;	int tmpPort = -1;	long tmpStartCode = -1;	long tmpSeqNum = HConstants.NO_SEQNUM;	try {	tmpHostname = s.substring(posHostname, s.indexOf(' ', posHostname));	tmpPort = Integer.parseInt(s.substring(posPort, s.indexOf(' ', posPort)));	tmpStartCode =  Long.parseLong(s.substring(posStartCode, s.indexOf('.', posStartCode)));	tmpSeqNum = Long.parseLong(s.substring(posSeqNum, s.indexOf('.', posSeqNum)));	} catch (Exception ignored) {	
can t parse the hostname port and startcode from this string continuing 

========================= hbase sample_193 =========================

public int getMasterInfoPort() {	try {	final ZooKeeperProtos.Master master = parse(this.getData(false));	if (master == null) {	return 0;	}	return master.getInfoPort();	} catch (DeserializationException e) {	
failed parse master zk node data 

public int getBackupMasterInfoPort(final ServerName sn) {	String backupZNode = ZNodePaths.joinZNode(watcher.znodePaths.backupMasterAddressesZNode, sn.toString());	try {	byte[] data = ZKUtil.getData(watcher, backupZNode);	final ZooKeeperProtos.Master backup = parse(data);	if (backup == null) {	return 0;	}	return backup.getInfoPort();	} catch (Exception e) {	
failed to get backup master s info port 

public ServerName getMasterAddress(final boolean refresh) {	try {	return ProtobufUtil.parseServerNameFrom(super.getData(refresh));	} catch (DeserializationException e) {	
failed parse 

throw new IllegalArgumentException("Content must not be null");	}	try {	Stat stat = new Stat();	byte[] data = ZKUtil.getDataNoWatch(zkw, zkw.znodePaths.masterAddressZNode, stat);	ServerName sn = ProtobufUtil.parseServerNameFrom(data);	if (sn != null && content.equals(sn.toString())) {	return (ZKUtil.deleteNode(zkw, zkw.znodePaths.masterAddressZNode, stat.getVersion()));	}	} catch (KeeperException e) {	
can t get or delete the master znode 

}	try {	Stat stat = new Stat();	byte[] data = ZKUtil.getDataNoWatch(zkw, zkw.znodePaths.masterAddressZNode, stat);	ServerName sn = ProtobufUtil.parseServerNameFrom(data);	if (sn != null && content.equals(sn.toString())) {	return (ZKUtil.deleteNode(zkw, zkw.znodePaths.masterAddressZNode, stat.getVersion()));	}	} catch (KeeperException e) {	} catch (DeserializationException e) {	
can t get or delete the master znode 

========================= hbase sample_740 =========================

} catch (IOException e) {	LOG.error(e.toString(), e);	}	}	});	Threads.sleep(3000);	exec.submit(new Runnable() {	public void run() {	try {	HRegion.FlushResult flushResult = region.flush(true);	
flush result 

} catch (IOException e) {	LOG.error(e.toString(), e);	}	}	});	Threads.sleep(3000);	exec.submit(new Runnable() {	public void run() {	try {	HRegion.FlushResult flushResult = region.flush(true);	
flush succeeded 

========================= hbase sample_1627 =========================

private void cleanupIdleConnections() {	long closeBeforeTime = EnvironmentEdgeManager.currentTime() - minIdleTimeBeforeClose;	synchronized (connections) {	for (T conn : connections.values()) {	if (conn.getLastTouched() < closeBeforeTime && !conn.isActive()) {	
cleanup idle connection to 

private T getConnection(ConnectionId remoteId) throws IOException {	if (failedServers.isFailedServer(remoteId.getAddress())) {	if (LOG.isDebugEnabled()) {	
not trying to connect to this server is in the failed servers list 

protected abstract T createConnection(ConnectionId remoteId) throws IOException;	private void onCallFinished(Call call, HBaseRpcController hrc, InetSocketAddress addr, RpcCallback<Message> callback) {	call.callStats.setCallTimeMs(EnvironmentEdgeManager.currentTime() - call.getStartTime());	if (metrics != null) {	metrics.updateRpc(call.md, call.param, call.callStats);	}	if (LOG.isTraceEnabled()) {	
call calltime ms 

public void cancelConnections(ServerName sn) {	synchronized (connections) {	for (T connection : connections.values()) {	ConnectionId remoteId = connection.remoteId();	if (remoteId.address.getPort() == sn.getPort() && remoteId.address.getHostName().equals(sn.getHostname())) {	
the server on is dead stopping the connection 

protected abstract void closeInternal();	public void close() {	if (LOG.isDebugEnabled()) {	
stopping rpc client 

========================= hbase sample_255 =========================

RemoteAdmin admin = new RemoteAdmin(client, HBaseConfiguration.create(), null);	Response resp = new Response(200, null, externalEntitiesXml.getBytes());	when(client.get("/version/cluster", Constants.MIMETYPE_XML)).thenReturn(resp);	try {	admin.getClusterVersion();	fail("Expected getClusterVersion() to throw an exception");	} catch (IOException e) {	assertEquals("Cause of exception ought to be a failure to parse the stream due to our " + "invalid external entity. Make sure this isn't just a false positive due to " + "implementation. see HBASE-19020.", UnmarshalException.class, e.getCause().getClass());	final String exceptionText = StringUtils.stringifyException(e);	final String expectedText = "\"xee\"";	
exception text 

========================= hbase sample_3071 =========================

File saslConfFile = File.createTempFile("tmp", "jaas.conf");	FileWriter fwriter = new FileWriter(saslConfFile);	fwriter.write("" + "Server {\n" + "org.apache.zookeeper.server.auth.DigestLoginModule required\n" + "user_hbase=\"secret\";\n" + "};\n" + "Client {\n" + "org.apache.zookeeper.server.auth.DigestLoginModule required\n" + "username=\"hbase\"\n" + "password=\"secret\";\n" + "};" + "\n");	fwriter.close();	System.setProperty("java.security.auth.login.config", saslConfFile.getAbsolutePath());	System.setProperty("zookeeper.authProvider.1", "org.apache.zookeeper.server.auth.SASLAuthenticationProvider");	TEST_UTIL.getConfiguration().setInt("hbase.zookeeper.property.maxClientCnxns", 1000);	try {	TEST_UTIL.startMiniCluster();	} catch (IOException e) {	
hadoop is missing hadoop 

========================= hbase sample_1559 =========================

public static Class<? extends ThroughputController> getThroughputControllerClass( Configuration conf) {	String className = conf.get(HBASE_THROUGHPUT_CONTROLLER_KEY, DEFAULT_THROUGHPUT_CONTROLLER_CLASS.getName());	className = resolveDeprecatedClassName(className);	try {	return Class.forName(className).asSubclass(ThroughputController.class);	} catch (Exception e) {	
unable to load configured throughput controller load default throughput controller instead 

private static String resolveDeprecatedClassName(String oldName) {	String className = oldName.trim();	if (className.equals(DEPRECATED_NAME_OF_PRESSURE_AWARE_THROUGHPUT_CONTROLLER_CLASS)) {	className = PressureAwareCompactionThroughputController.class.getName();	} else if (className.equals(DEPRECATED_NAME_OF_NO_LIMIT_THROUGHPUT_CONTROLLER_CLASS)) {	className = NoLimitThroughputController.class.getName();	}	if (!className.equals(oldName)) {	
is deprecated please use instead 

========================= hbase sample_2549 =========================

protected void applyColumnFamilyOptions(TableName tableName, byte[][] columnFamilies) throws IOException {	try (Connection conn = ConnectionFactory.createConnection(conf);	Admin admin = conn.getAdmin()) {	TableDescriptor tableDesc = admin.getDescriptor(tableName);	
disabling table 

if (mobThreshold >= 0) {	columnDescBuilder.setMobEnabled(true);	columnDescBuilder.setMobThreshold(mobThreshold);	}	if (isNewCf) {	admin.addColumnFamily(tableName, columnDescBuilder.build());	} else {	admin.modifyColumnFamily(tableName, columnDescBuilder.build());	}	}	
enabling table 

protected int loadTable() throws IOException {	if (cmd.hasOption(OPT_ZK_QUORUM)) {	conf.set(HConstants.ZOOKEEPER_QUORUM, cmd.getOptionValue(OPT_ZK_QUORUM));	}	if (cmd.hasOption(OPT_ZK_PARENT_NODE)) {	conf.set(HConstants.ZOOKEEPER_ZNODE_PARENT, cmd.getOptionValue(OPT_ZK_PARENT_NODE));	}	if (isInitOnly) {	
initializing only no reads or writes 

}	if (!isSkipInit) {	initTestTable();	}	LoadTestDataGenerator dataGen = null;	if (cmd.hasOption(OPT_GENERATOR)) {	String[] clazzAndArgs = cmd.getOptionValue(OPT_GENERATOR).split(COLON);	dataGen = getLoadGeneratorInstance(clazzAndArgs[0]);	String[] args;	if (dataGen instanceof LoadTestDataGeneratorWithACL) {	
using loadtestdatageneratorwithacl 

if (!isSkipInit) {	initTestTable();	}	LoadTestDataGenerator dataGen = null;	if (cmd.hasOption(OPT_GENERATOR)) {	String[] clazzAndArgs = cmd.getOptionValue(OPT_GENERATOR).split(COLON);	dataGen = getLoadGeneratorInstance(clazzAndArgs[0]);	String[] args;	if (dataGen instanceof LoadTestDataGeneratorWithACL) {	if (User.isHBaseSecurityEnabled(conf)) {	
security is enabled 

userOwner = User.createUserForTesting(conf, superUser, new String[0]);	}	} else {	args = clazzAndArgs.length == 1 ? new String[0] : Arrays.copyOfRange(clazzAndArgs, 1, clazzAndArgs.length);	}	dataGen.initialize(args);	} else {	dataGen = new MultiThreadedAction.DefaultDataGenerator(minColDataSize, maxColDataSize, minColsPerKey, maxColsPerKey, families);	}	if (userOwner != null) {	
granting permissions for user 

dataGen.initialize(args);	} else {	dataGen = new MultiThreadedAction.DefaultDataGenerator(minColDataSize, maxColDataSize, minColsPerKey, maxColsPerKey, families);	}	if (userOwner != null) {	Permission.Action[] actions = {	Permission.Action.ADMIN, Permission.Action.CREATE, Permission.Action.READ, Permission.Action.WRITE };	try {	AccessControlClient.grant(ConnectionFactory.createConnection(conf), tableName, userOwner.getShortName(), null, null, actions);	} catch (Throwable e) {	
error in granting permission for the user 

readerClass = MultiThreadedReader.class.getCanonicalName();	}	readerThreads = getMultiThreadedReaderInstance(readerClass, dataGen);	}	readerThreads.setMaxErrors(maxReadErrors);	readerThreads.setKeyWindow(keyWindow);	readerThreads.setMultiGetBatchSize(multiGetBatchSize);	readerThreads.setRegionReplicaId(regionReplicaId);	}	if (isUpdate && isWrite) {	
concurrent write update workload making updaters aware of the write point 

}	readerThreads.setMaxErrors(maxReadErrors);	readerThreads.setKeyWindow(keyWindow);	readerThreads.setMultiGetBatchSize(multiGetBatchSize);	readerThreads.setRegionReplicaId(regionReplicaId);	}	if (isUpdate && isWrite) {	updaterThreads.linkToWriter(writerThreads);	}	if (isRead && (isUpdate || isWrite)) {	
concurrent write read workload making readers aware of the write point 

updaterThreads.linkToWriter(writerThreads);	}	if (isRead && (isUpdate || isWrite)) {	readerThreads.linkToWriter(isUpdate ? updaterThreads : writerThreads);	}	if (isWrite) {	System.out.println("Starting to write data...");	writerThreads.start(startKey, endKey, numWriterThreads);	}	if (isUpdate) {	
starting to mutate data 

} else if (newArgs[j].endsWith(NUM_TABLES)) {	newArgs[j + 1] = "1";	}	}	List<WorkerThread> workers = new ArrayList<>();	for (int i = 0; i < numTables; i++) {	String[] workerArgs = newArgs.clone();	workerArgs[tableNameValueIndex] = tableName + "_" + (i+1);	WorkerThread worker = new WorkerThread(i, workerArgs);	workers.add(worker);	
starting 

}	}	List<WorkerThread> workers = new ArrayList<>();	for (int i = 0; i < numTables; i++) {	String[] workerArgs = newArgs.clone();	workerArgs[tableNameValueIndex] = tableName + "_" + (i+1);	WorkerThread worker = new WorkerThread(i, workerArgs);	workers.add(worker);	worker.start();	}	
waiting for worker threads to finish 

public void run() {	try {	int ret = ToolRunner.run(HBaseConfiguration.create(), new LoadTestTool(), workerArgs);	if (ret != 0) {	throw new RuntimeException("LoadTestTool exit with non-zero return code.");	}	} catch (Exception ex) {	
error in worker thread 

for (String user : users) {	String keyTabFileConfKey = "hbase." + user + ".keytab.file";	String principalConfKey = "hbase." + user + ".kerberos.principal";	if (!authConfig.containsKey(keyTabFileConfKey) || !authConfig.containsKey(principalConfKey)) {	throw new IOException("Authentication configs missing for user : " + user);	}	}	for (String key : authConfig.stringPropertyNames()) {	conf.set(key, authConfig.getProperty(key));	}	
added authentication properties to config successfully 

========================= hbase sample_3358 =========================

}	CommandLineParser parser = new PosixParser();	CommandLine cmdLine;	try {	cmdLine = parser.parse(options, args);	} catch (ParseException ex) {	LOG.error(ex.toString(), ex);	return false;	}	if (!cmdLine.hasOption(OUTPUT_DIR_OPTION)) {	
output directory is not specified 

try {	cmdLine = parser.parse(options, args);	} catch (ParseException ex) {	LOG.error(ex.toString(), ex);	return false;	}	if (!cmdLine.hasOption(OUTPUT_DIR_OPTION)) {	return false;	}	if (!cmdLine.hasOption(NUM_KV_OPTION)) {	
the number of keys values not specified 

LOG.error(ex.toString(), ex);	return false;	}	if (!cmdLine.hasOption(OUTPUT_DIR_OPTION)) {	return false;	}	if (!cmdLine.hasOption(NUM_KV_OPTION)) {	return false;	}	if (!cmdLine.hasOption(KEY_SIZE_OPTION)) {	
key size is not specified 

if (!cmdLine.hasOption(OUTPUT_DIR_OPTION)) {	return false;	}	if (!cmdLine.hasOption(NUM_KV_OPTION)) {	return false;	}	if (!cmdLine.hasOption(KEY_SIZE_OPTION)) {	return false;	}	if (!cmdLine.hasOption(VALUE_SIZE_OPTION)) {	
value size not specified 

if (cmdLine.hasOption(BLOCK_SIZE_OPTION)) blockSize = Integer.valueOf(cmdLine.getOptionValue(BLOCK_SIZE_OPTION));	if (cmdLine.hasOption(BLOOM_BLOCK_SIZE_OPTION)) {	conf.setInt(BloomFilterFactory.IO_STOREFILE_BLOOM_BLOCK_SIZE, Integer.valueOf(cmdLine.getOptionValue(BLOOM_BLOCK_SIZE_OPTION)));	}	if (cmdLine.hasOption(INDEX_BLOCK_SIZE_OPTION)) {	conf.setInt(HFileBlockIndex.MAX_CHUNK_SIZE_KEY, Integer.valueOf(cmdLine.getOptionValue(INDEX_BLOCK_SIZE_OPTION)));	}	HFileContext meta = new HFileContextBuilder().withCompression(compr) .withBlockSize(blockSize).build();	StoreFileWriter sfw = new StoreFileWriter.Builder(conf, new CacheConfig(conf), fs) .withOutputDir(outputDir) .withBloomType(bloomType) .withMaxKeyCount(numKV) .withFileContext(meta) .build();	rand = new Random();	
writing key value pairs 

if (cmdLine.hasOption(INDEX_BLOCK_SIZE_OPTION)) {	conf.setInt(HFileBlockIndex.MAX_CHUNK_SIZE_KEY, Integer.valueOf(cmdLine.getOptionValue(INDEX_BLOCK_SIZE_OPTION)));	}	HFileContext meta = new HFileContextBuilder().withCompression(compr) .withBlockSize(blockSize).build();	StoreFileWriter sfw = new StoreFileWriter.Builder(conf, new CacheConfig(conf), fs) .withOutputDir(outputDir) .withBloomType(bloomType) .withMaxKeyCount(numKV) .withFileContext(meta) .build();	rand = new Random();	for (long i = 0; i < numKV; ++i) {	sfw.append(generateKeyValue(i));	}	int numMetaBlocks = rand.nextInt(10) + 1;	
writing meta blocks 

for (long i = 0; i < numKV; ++i) {	sfw.append(generateKeyValue(i));	}	int numMetaBlocks = rand.nextInt(10) + 1;	for (int metaI = 0; metaI < numMetaBlocks; ++metaI) {	sfw.getHFileWriter().appendMetaBlock(generateString(), new BytesWritable(generateValue()));	}	sfw.close();	Path storeFilePath = sfw.getPath();	long fileSize = fs.getFileStatus(storeFilePath).getLen();	
created bytes 

========================= hbase sample_1735 =========================

public Response get(final @Context ServletContext context, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3088 =========================

public void testScanAndSyncFlush() throws Exception {	this.region = TEST_UTIL.createLocalHRegion(TESTTABLEDESC, null, null);	Table hri = new RegionAsTable(region);	try {	
added 

public void testScanAndSyncFlush() throws Exception {	this.region = TEST_UTIL.createLocalHRegion(TESTTABLEDESC, null, null);	Table hri = new RegionAsTable(region);	try {	int count = count(hri, -1, false);	assertEquals(count, count(hri, 100, false));	} catch (Exception e) {	
Failed 

public void testScanAndRealConcurrentFlush() throws Exception {	this.region = TEST_UTIL.createLocalHRegion(TESTTABLEDESC, null, null);	Table hri = new RegionAsTable(region);	try {	
added 

public void testScanAndRealConcurrentFlush() throws Exception {	this.region = TEST_UTIL.createLocalHRegion(TESTTABLEDESC, null, null);	Table hri = new RegionAsTable(region);	try {	int count = count(hri, -1, false);	assertEquals(count, count(hri, 100, true));	} catch (Exception e) {	
Failed 

private int count(final Table countTable, final int flushIndex, boolean concurrent) throws IOException {	
taking out counting scan 

private int count(final Table countTable, final int flushIndex, boolean concurrent) throws IOException {	Scan scan = new Scan();	for (byte [] qualifier: EXPLICIT_COLS) {	scan.addColumn(HConstants.CATALOG_FAMILY, qualifier);	}	ResultScanner s = countTable.getScanner(scan);	int count = 0;	boolean justFlushed = false;	while (s.next() != null) {	if (justFlushed) {	
after next just after next flush 

}	ResultScanner s = countTable.getScanner(scan);	int count = 0;	boolean justFlushed = false;	while (s.next() != null) {	if (justFlushed) {	justFlushed = false;	}	count++;	if (flushIndex == count) {	
starting flush at flush index 

while (s.next() != null) {	if (justFlushed) {	justFlushed = false;	}	count++;	if (flushIndex == count) {	Thread t = new Thread() {	public void run() {	try {	region.flush(true);	
finishing flush 

if (justFlushed) {	justFlushed = false;	}	count++;	if (flushIndex == count) {	Thread t = new Thread() {	public void run() {	try {	region.flush(true);	} catch (IOException e) {	
failed flush cache 

region.flush(true);	} catch (IOException e) {	}	}	};	if (concurrent) {	t.start();	} else {	t.run();	}	
continuing on after kicking off background flush 

};	if (concurrent) {	t.start();	} else {	t.run();	}	justFlushed = true;	}	}	s.close();	
found items 

========================= hbase sample_1666 =========================

static ReplicationSourceInterface create(Configuration conf, String queueId) {	ReplicationQueueInfo replicationQueueInfo = new ReplicationQueueInfo(queueId);	boolean isQueueRecovered = replicationQueueInfo.isQueueRecovered();	ReplicationSourceInterface src;	try {	String defaultReplicationSourceImpl = isQueueRecovered ? RecoveredReplicationSource.class.getCanonicalName() : ReplicationSource.class.getCanonicalName();	Class c = Class.forName( conf.get("replication.replicationsource.implementation", defaultReplicationSourceImpl));	src = (ReplicationSourceInterface) c.newInstance();	} catch (Exception e) {	
passed replication source implementation throws errors defaulting to replicationsource 

========================= hbase sample_2949 =========================

}	return this.encodedRegionNameAsBytes;	}	};	Path hbaseRootDir = TEST_UTIL.getDataTestDir();	ChunkCreator.initialize(MemStoreLABImpl.CHUNK_SIZE_DEFAULT, false, 0, 0, 0, null);	FileSystem fs = FileSystem.get(TEST_UTIL.getConfiguration());	Path tableDir = FSUtils.getTableDir(hbaseRootDir, htd.getTableName());	HRegionFileSystem hrfs = new HRegionFileSystem(TEST_UTIL.getConfiguration(), fs, tableDir, hri);	if (fs.exists(hrfs.getRegionDir())) {	
region directory already exists deleting 

assertTrue(fs.exists(destination));	region = HRegion.openHRegion(region, null);	assertEquals(encodedRegionName, region.getRegionInfo().getEncodedName());	storeFiles = region.getStoreFileList(columnFamilyAsByteArray);	if(policy == MemoryCompactionPolicy.EAGER || policy == MemoryCompactionPolicy.ADAPTIVE) {	assertTrue("Files count=" + storeFiles.size(), storeFiles.size() >= 1);	} else {	assertTrue("Files count=" + storeFiles.size(), storeFiles.size() > 10);	}	int count = verifyAllEditsMadeItIn(fs, conf, recoveredEditsFile, region);	
checked edits made it in 

========================= hbase sample_1723 =========================

for (int i = 0; i < NUM_CFS; i++) {	Path hfile = new Path(dir, family(i));	byte[] fam = Bytes.toBytes(family(i));	createHFile(fs, hfile, fam, QUAL, val, 1000);	famPaths.add(new Pair<>(fam, hfile.toString()));	}	final ClusterConnection conn = (ClusterConnection) UTIL.getAdmin().getConnection();	RpcControllerFactory rpcControllerFactory = new RpcControllerFactory(UTIL.getConfiguration());	ClientServiceCallable<Void> callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), rpcControllerFactory.newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
non secure old client 

getStub().bulkLoadHFile(null, request);	return null;	}	};	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(conf);	RpcRetryingCaller<Void> caller = factory.<Void> newCaller();	caller.callWithRetries(callable, Integer.MAX_VALUE);	if (numBulkLoads.get() % 5 == 0) {	callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), rpcControllerFactory.newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
compacting for row 

========================= hbase sample_1689 =========================

public void abort(String reason, Throwable e) {	
aborting 

while (KEY_MASTER == null) {	for (int i=0; i<2; i++) {	if (tmp[i].isMaster()) {	KEY_MASTER = tmp[i];	KEY_SLAVE = tmp[ (i+1) % 2 ];	break;	}	}	Thread.sleep(500);	}	
master is slave is 

public void testKeyUpdate() throws Exception {	assertTrue(KEY_MASTER.isMaster());	assertFalse(KEY_SLAVE.isMaster());	int maxKeyId = 0;	KEY_MASTER.rollCurrentKey();	AuthenticationKey key1 = KEY_MASTER.getCurrentKey();	assertNotNull(key1);	
master current key 

assertTrue(KEY_MASTER.isMaster());	assertFalse(KEY_SLAVE.isMaster());	int maxKeyId = 0;	KEY_MASTER.rollCurrentKey();	AuthenticationKey key1 = KEY_MASTER.getCurrentKey();	assertNotNull(key1);	Thread.sleep(1000);	AuthenticationKey slaveCurrent = KEY_SLAVE.getCurrentKey();	assertNotNull(slaveCurrent);	assertEquals(key1, slaveCurrent);	
slave current key 

int maxKeyId = 0;	KEY_MASTER.rollCurrentKey();	AuthenticationKey key1 = KEY_MASTER.getCurrentKey();	assertNotNull(key1);	Thread.sleep(1000);	AuthenticationKey slaveCurrent = KEY_SLAVE.getCurrentKey();	assertNotNull(slaveCurrent);	assertEquals(key1, slaveCurrent);	KEY_MASTER.rollCurrentKey();	AuthenticationKey key2 = KEY_MASTER.getCurrentKey();	
master new current key 

AuthenticationKey key1 = KEY_MASTER.getCurrentKey();	assertNotNull(key1);	Thread.sleep(1000);	AuthenticationKey slaveCurrent = KEY_SLAVE.getCurrentKey();	assertNotNull(slaveCurrent);	assertEquals(key1, slaveCurrent);	KEY_MASTER.rollCurrentKey();	AuthenticationKey key2 = KEY_MASTER.getCurrentKey();	KEY_MASTER.rollCurrentKey();	AuthenticationKey key3 = KEY_MASTER.getCurrentKey();	
master new current key 

assertNull(KEY_MASTER.getKey(key1.getKeyId()));	KEY_SLAVE.getLatch().await();	AuthenticationKey slave2 = KEY_SLAVE.getKey(key2.getKeyId());	assertNotNull(slave2);	assertEquals(key2, slave2);	AuthenticationKey slave3 = KEY_SLAVE.getKey(key3.getKeyId());	assertNotNull(slave3);	assertEquals(key3, slave3);	slaveCurrent = KEY_SLAVE.getCurrentKey();	assertEquals(key3, slaveCurrent);	
slave current key 

break;	}	}	if (newMaster == null) {	Thread.sleep(500);	}	}	assertNotNull(newMaster);	AuthenticationKey current = newMaster.getCurrentKey();	assertTrue(current.getKeyId() >= slaveCurrent.getKeyId());	
new master current key 

}	if (newMaster == null) {	Thread.sleep(500);	}	}	assertNotNull(newMaster);	AuthenticationKey current = newMaster.getCurrentKey();	assertTrue(current.getKeyId() >= slaveCurrent.getKeyId());	newMaster.rollCurrentKey();	AuthenticationKey newCurrent = newMaster.getCurrentKey();	
new master rolled new current key 

break;	}	}	if (newMaster == null) {	Thread.sleep(500);	}	}	assertNotNull(newMaster);	AuthenticationKey current2 = newMaster.getCurrentKey();	assertTrue(current2.getKeyId() >= newCurrent.getKeyId());	
new master current key 

}	if (newMaster == null) {	Thread.sleep(500);	}	}	assertNotNull(newMaster);	AuthenticationKey current2 = newMaster.getCurrentKey();	assertTrue(current2.getKeyId() >= newCurrent.getKeyId());	newMaster.rollCurrentKey();	AuthenticationKey newCurrent2 = newMaster.getCurrentKey();	
new master rolled new current key 

========================= hbase sample_1373 =========================

static MetricRegistries load(List<MetricRegistries> availableImplementations) {	if (availableImplementations.size() == 1) {	MetricRegistries impl = availableImplementations.get(0);	
loaded metricregistries 

throw new RuntimeException(e);	}	} else {	StringBuilder sb = new StringBuilder();	for (MetricRegistries factory : availableImplementations) {	if (sb.length() > 0) {	sb.append(", ");	}	sb.append(factory.getClass());	}	
found multiple metricregistries implementations using first found implementation 

========================= hbase sample_34 =========================

public static AsyncWriter createAsyncWriter(Configuration conf, FileSystem fs, Path path, boolean overwritable, EventLoopGroup eventLoopGroup, Class<? extends Channel> channelClass) throws IOException {	Class<? extends AsyncWriter> logWriterClass = conf.getClass( "hbase.regionserver.hlog.async.writer.impl", AsyncProtobufLogWriter.class, AsyncWriter.class);	try {	AsyncWriter writer = logWriterClass.getConstructor(EventLoopGroup.class, Class.class) .newInstance(eventLoopGroup, channelClass);	writer.init(fs, path, conf, overwritable);	return writer;	} catch (Exception e) {	if (e instanceof CommonFSUtils.StreamLacksCapabilityException) {	
the regionserver async write ahead log provider relies on the ability to call for proper operation during component failures but the current filesystem does not support doing so please check the config value of and ensure it points to a filesystem mount that has suitable capabilities for output streams 

public static AsyncWriter createAsyncWriter(Configuration conf, FileSystem fs, Path path, boolean overwritable, EventLoopGroup eventLoopGroup, Class<? extends Channel> channelClass) throws IOException {	Class<? extends AsyncWriter> logWriterClass = conf.getClass( "hbase.regionserver.hlog.async.writer.impl", AsyncProtobufLogWriter.class, AsyncWriter.class);	try {	AsyncWriter writer = logWriterClass.getConstructor(EventLoopGroup.class, Class.class) .newInstance(eventLoopGroup, channelClass);	writer.init(fs, path, conf, overwritable);	return writer;	} catch (Exception e) {	if (e instanceof CommonFSUtils.StreamLacksCapabilityException) {	} else {	
error instantiating log writer 

========================= hbase sample_2271 =========================

public Map<LoadQueueItem, ByteBuffer> doBulkLoad(Map<byte[], List<Path>> map, final Admin admin, Table table, RegionLocator regionLocator, boolean silence, boolean copyFile) throws TableNotFoundException, IOException {	if (!admin.isTableAvailable(regionLocator.getName())) {	throw new TableNotFoundException("Table " + table.getName() + " is not currently available.");	}	Deque<LoadQueueItem> queue = new ArrayDeque<>();	ExecutorService pool = null;	SecureBulkLoadClient secureClient = null;	try {	prepareHFileQueue(map, table, queue, silence);	if (queue.isEmpty()) {	
bulk load operation did not get any files to load 

public Map<LoadQueueItem, ByteBuffer> doBulkLoad(Path hfofDir, final Admin admin, Table table, RegionLocator regionLocator, boolean silence, boolean copyFile) throws TableNotFoundException, IOException {	if (!admin.isTableAvailable(regionLocator.getName())) {	throw new TableNotFoundException("Table " + table.getName() + " is not currently available.");	}	boolean validateHFile = getConf().getBoolean("hbase.loadincremental.validate.hfile", true);	if (!validateHFile) {	
you are skipping hfiles validation it might cause some data loss if files are not correct if you fail to read data from your table after using this option consider removing the files and bulkload again without this option see hbase 

private Map<LoadQueueItem, ByteBuffer> performBulkLoad(Admin admin, Table table, RegionLocator regionLocator, Deque<LoadQueueItem> queue, ExecutorService pool, SecureBulkLoadClient secureClient, boolean copyFile) throws IOException {	int count = 0;	if (isSecureBulkLoadEndpointAvailable()) {	
securebulkloadendpoint is deprecated it will be removed in future releases 

private Map<LoadQueueItem, ByteBuffer> performBulkLoad(Admin admin, Table table, RegionLocator regionLocator, Deque<LoadQueueItem> queue, ExecutorService pool, SecureBulkLoadClient secureClient, boolean copyFile) throws IOException {	int count = 0;	if (isSecureBulkLoadEndpointAvailable()) {	
secure bulk load has been integrated into hbase core 

int count = 0;	if (isSecureBulkLoadEndpointAvailable()) {	}	fsDelegationToken.acquireDelegationToken(queue.peek().getFilePath().getFileSystem(getConf()));	bulkToken = secureClient.prepareBulkLoad(admin.getConnection());	Pair<Multimap<ByteBuffer, LoadQueueItem>, Set<String>> pair = null;	Map<LoadQueueItem, ByteBuffer> item2RegionMap = new HashMap<>();	while (!queue.isEmpty()) {	final Pair<byte[][], byte[][]> startEndKeys = regionLocator.getStartEndKeys();	if (count != 0) {	
split occurred while grouping hfiles retry attempt with files remaining to group or split 

for (LoadQueueItem lqi : toRetry) {	item2RegionMap.remove(lqi);	}	}	queue.addAll(toRetry);	} catch (ExecutionException e1) {	Throwable t = e1.getCause();	if (t instanceof IOException) {	throw new IOException("BulkLoad encountered an unrecoverable problem", t);	}	
unexpected execution exception during bulk load 

}	}	queue.addAll(toRetry);	} catch (ExecutionException e1) {	Throwable t = e1.getCause();	if (t instanceof IOException) {	throw new IOException("BulkLoad encountered an unrecoverable problem", t);	}	throw new IllegalStateException(t);	} catch (InterruptedException e1) {	
unexpected interrupted exception during bulk load 

protected ClientServiceCallable<byte[]> buildClientServiceCallable(Connection conn, TableName tableName, byte[] first, Collection<LoadQueueItem> lqis, boolean copyFile) {	List<Pair<byte[], String>> famPaths = lqis.stream().map(lqi -> Pair.newPair(lqi.getFamily(), lqi.getFilePath().toString())) .collect(Collectors.toList());	return new ClientServiceCallable<byte[]>(conn, tableName, first, rpcControllerFactory.newController(), HConstants.PRIORITY_UNSET) {	protected byte[] rpcCall() throws Exception {	SecureBulkLoadClient secureClient = null;	boolean success = false;	try {	if (LOG.isDebugEnabled()) {	
going to connect to server for row with hfile group 

if (secureClient != null && !success) {	FileSystem targetFs = FileSystem.get(getConf());	FileSystem sourceFs = lqis.iterator().next().getFilePath().getFileSystem(getConf());	if (FSHDFSUtils.isSameHdfs(getConf(), sourceFs, targetFs)) {	for (Pair<byte[], String> el : famPaths) {	Path hfileStagingPath = null;	Path hfileOrigPath = new Path(el.getSecond());	try {	hfileStagingPath = new Path(new Path(bulkToken, Bytes.toString(el.getFirst())), hfileOrigPath.getName());	if (targetFs.rename(hfileStagingPath, hfileOrigPath)) {	
moved back file from 

FileSystem targetFs = FileSystem.get(getConf());	FileSystem sourceFs = lqis.iterator().next().getFilePath().getFileSystem(getConf());	if (FSHDFSUtils.isSameHdfs(getConf(), sourceFs, targetFs)) {	for (Pair<byte[], String> el : famPaths) {	Path hfileStagingPath = null;	Path hfileOrigPath = new Path(el.getSecond());	try {	hfileStagingPath = new Path(new Path(bulkToken, Bytes.toString(el.getFirst())), hfileOrigPath.getName());	if (targetFs.rename(hfileStagingPath, hfileOrigPath)) {	} else if (targetFs.exists(hfileStagingPath)) {	
unable to move back file from 

if (FSHDFSUtils.isSameHdfs(getConf(), sourceFs, targetFs)) {	for (Pair<byte[], String> el : famPaths) {	Path hfileStagingPath = null;	Path hfileOrigPath = new Path(el.getSecond());	try {	hfileStagingPath = new Path(new Path(bulkToken, Bytes.toString(el.getFirst())), hfileOrigPath.getName());	if (targetFs.rename(hfileStagingPath, hfileOrigPath)) {	} else if (targetFs.exists(hfileStagingPath)) {	}	} catch (Exception ex) {	
unable to move back file from 

private boolean checkHFilesCountPerRegionPerFamily( final Multimap<ByteBuffer, LoadQueueItem> regionGroups) {	for (Map.Entry<ByteBuffer, Collection<LoadQueueItem>> e : regionGroups.asMap().entrySet()) {	Map<byte[], MutableInt> filesMap = new TreeMap<>(Bytes.BYTES_COMPARATOR);	for (LoadQueueItem lqi : e.getValue()) {	MutableInt count = filesMap.computeIfAbsent(lqi.getFamily(), k -> new MutableInt());	count.increment();	if (count.intValue() > maxFilesPerRegionPerFamily) {	
trying to load more than hfiles to family of region with start key 

if (splits != null) {	if (splits.getFirst() != null) {	queue.addAll(splits.getFirst());	} else {	missingHFiles.add(splits.getSecond());	}	}	} catch (ExecutionException e1) {	Throwable t = e1.getCause();	if (t instanceof IOException) {	
ioexception during splitting 

queue.addAll(splits.getFirst());	} else {	missingHFiles.add(splits.getSecond());	}	}	} catch (ExecutionException e1) {	Throwable t = e1.getCause();	if (t instanceof IOException) {	throw (IOException) t;	}	
unexpected execution exception during splitting 

missingHFiles.add(splits.getSecond());	}	}	} catch (ExecutionException e1) {	Throwable t = e1.getCause();	if (t instanceof IOException) {	throw (IOException) t;	}	throw new IllegalStateException(t);	} catch (InterruptedException e1) {	
unexpected interrupted exception during splitting 

private List<LoadQueueItem> splitStoreFile(final LoadQueueItem item, final Table table, byte[] startKey, byte[] splitKey) throws IOException {	Path hfilePath = item.getFilePath();	byte[] family = item.getFamily();	Path tmpDir = hfilePath.getParent();	if (!tmpDir.getName().equals(TMP_DIR)) {	tmpDir = new Path(tmpDir, TMP_DIR);	}	
hfile at no longer fits inside a single region splitting 

fs.setPermission(botOut, FsPermission.valueOf("-rwxrwxrwx"));	fs.setPermission(topOut, FsPermission.valueOf("-rwxrwxrwx"));	List<LoadQueueItem> lqis = new ArrayList<>(2);	lqis.add(new LoadQueueItem(family, botOut));	lqis.add(new LoadQueueItem(family, topOut));	try {	if (tmpDir.getName().equals(TMP_DIR)) {	fs.delete(hfilePath, false);	}	} catch (IOException e) {	
unable to delete temporary split file 

fs.setPermission(topOut, FsPermission.valueOf("-rwxrwxrwx"));	List<LoadQueueItem> lqis = new ArrayList<>(2);	lqis.add(new LoadQueueItem(family, botOut));	lqis.add(new LoadQueueItem(family, topOut));	try {	if (tmpDir.getName().equals(TMP_DIR)) {	fs.delete(hfilePath, false);	}	} catch (IOException e) {	}	
successfully split into new hfiles and 

protected Pair<List<LoadQueueItem>, String> groupOrSplit( Multimap<ByteBuffer, LoadQueueItem> regionGroups, final LoadQueueItem item, final Table table, final Pair<byte[][], byte[][]> startEndKeys) throws IOException {	Path hfilePath = item.getFilePath();	Optional<byte[]> first, last;	try (HFile.Reader hfr = HFile.createReader(hfilePath.getFileSystem(getConf()), hfilePath, new CacheConfig(getConf()), true, getConf())) {	hfr.loadFileInfo();	first = hfr.getFirstRowKey();	last = hfr.getLastRowKey();	} catch (FileNotFoundException fnfe) {	
encountered 

try (HFile.Reader hfr = HFile.createReader(hfilePath.getFileSystem(getConf()), hfilePath, new CacheConfig(getConf()), true, getConf())) {	hfr.loadFileInfo();	first = hfr.getFirstRowKey();	last = hfr.getLastRowKey();	} catch (FileNotFoundException fnfe) {	return new Pair<>(null, hfilePath.getName());	}	LOG.info("Trying to load hfile=" + hfilePath + " first=" + first.map(Bytes::toStringBinary) + " last=" + last.map(Bytes::toStringBinary));	if (!first.isPresent() || !last.isPresent()) {	assert !first.isPresent() && !last.isPresent();	
hfile has no entries skipping 

protected List<LoadQueueItem> tryAtomicRegionLoad(ClientServiceCallable<byte[]> serviceCallable, final TableName tableName, final byte[] first, final Collection<LoadQueueItem> lqis) throws IOException {	try {	List<LoadQueueItem> toRetry = new ArrayList<>();	Configuration conf = getConf();	byte[] region = RpcRetryingCallerFactory.instantiate(conf, null).<byte[]> newCaller() .callWithRetries(serviceCallable, Integer.MAX_VALUE);	if (region == null) {	
attempt to bulk load region containing into table with files failed this is recoverable and they will be retried 

protected List<LoadQueueItem> tryAtomicRegionLoad(ClientServiceCallable<byte[]> serviceCallable, final TableName tableName, final byte[] first, final Collection<LoadQueueItem> lqis) throws IOException {	try {	List<LoadQueueItem> toRetry = new ArrayList<>();	Configuration conf = getConf();	byte[] region = RpcRetryingCallerFactory.instantiate(conf, null).<byte[]> newCaller() .callWithRetries(serviceCallable, Integer.MAX_VALUE);	if (region == null) {	toRetry.addAll(lqis);	}	return toRetry;	} catch (IOException e) {	
encountered unrecoverable error from region server additional details 

public ColumnFamilyDescriptorBuilder bulkFamily(byte[] familyName) {	ColumnFamilyDescriptorBuilder builder = ColumnFamilyDescriptorBuilder.newBuilder(familyName);	familyBuilders.add(builder);	return builder;	}	public void bulkHFile(ColumnFamilyDescriptorBuilder builder, FileStatus hfileStatus) throws IOException {	Path hfile = hfileStatus.getPath();	try (HFile.Reader reader = HFile.createReader(fs, hfile, new CacheConfig(getConf()), true, getConf())) {	if (builder.getCompressionType() != reader.getFileContext().getCompression()) {	builder.setCompressionType(reader.getFileContext().getCompression());	
setting compression for family 

map.put(first, value + 1);	value = map.containsKey(last) ? map.get(last) : 0;	map.put(last, value - 1);	}	}	});	byte[][] keys = inferBoundaries(map);	TableDescriptorBuilder tdBuilder = TableDescriptorBuilder.newBuilder(tableName);	familyBuilders.stream().map(ColumnFamilyDescriptorBuilder::build) .forEachOrdered(tdBuilder::addColumnFamily);	admin.createTable(tdBuilder.build(), keys);	
table is available 

private void discoverLoadQueue(final Deque<LoadQueueItem> ret, final Path hfofDir, final boolean validateHFile) throws IOException {	visitBulkHFiles(hfofDir.getFileSystem(getConf()), hfofDir, new BulkHFileVisitor<byte[]>() {	public byte[] bulkFamily(final byte[] familyName) {	return familyName;	}	public void bulkHFile(final byte[] family, final FileStatus hfile) throws IOException {	long length = hfile.getLen();	if (length > getConf().getLong(HConstants.HREGION_MAX_FILESIZE, HConstants.DEFAULT_MAX_FILE_SIZE)) {	
trying to bulk load hfile with size bytes can be problematic as it may lead to oversplitting 

private static <TFamily> void visitBulkHFiles(FileSystem fs, Path bulkDir, BulkHFileVisitor<TFamily> visitor, boolean validateHFile) throws IOException {	FileStatus[] familyDirStatuses = fs.listStatus(bulkDir);	for (FileStatus familyStat : familyDirStatuses) {	if (!familyStat.isDirectory()) {	
skipping non directory 

FileStatus[] familyDirStatuses = fs.listStatus(bulkDir);	for (FileStatus familyStat : familyDirStatuses) {	if (!familyStat.isDirectory()) {	continue;	}	Path familyDir = familyStat.getPath();	byte[] familyName = familyDir.getName().getBytes();	try {	ColumnFamilyDescriptorBuilder.isLegalColumnFamilyName(familyName);	} catch (IllegalArgumentException e) {	
skipping invalid 

byte[] familyName = familyDir.getName().getBytes();	try {	ColumnFamilyDescriptorBuilder.isLegalColumnFamilyName(familyName);	} catch (IllegalArgumentException e) {	continue;	}	TFamily family = visitor.bulkFamily(familyName);	FileStatus[] hfileStatuses = fs.listStatus(familyDir);	for (FileStatus hfileStatus : hfileStatuses) {	if (!fs.isFile(hfileStatus.getPath())) {	
skipping non file 

for (FileStatus hfileStatus : hfileStatuses) {	if (!fs.isFile(hfileStatus.getPath())) {	continue;	}	Path hfile = hfileStatus.getPath();	String fileName = hfile.getName();	if (fileName.startsWith("_")) {	continue;	}	if (StoreFileInfo.isReference(fileName)) {	
skipping reference 

}	Path hfile = hfileStatus.getPath();	String fileName = hfile.getName();	if (fileName.startsWith("_")) {	continue;	}	if (StoreFileInfo.isReference(fileName)) {	continue;	}	if (HFileLink.isHFileLink(fileName)) {	
skipping hfilelink 

}	if (StoreFileInfo.isReference(fileName)) {	continue;	}	if (HFileLink.isHFileLink(fileName)) {	continue;	}	if (validateHFile) {	try {	if (!HFile.isHFileFormat(fs, hfile)) {	
the file doesn t seems to be an hfile skipping 

}	if (HFileLink.isHFileLink(fileName)) {	continue;	}	if (validateHFile) {	try {	if (!HFile.isHFileFormat(fs, hfile)) {	continue;	}	} catch (FileNotFoundException e) {	
the file was removed 

for (Map.Entry<byte[], byte[]> entry : fileInfo.entrySet()) {	if (shouldCopyHFileMetaKey(entry.getKey())) {	halfWriter.appendFileInfo(entry.getKey(), entry.getValue());	}	}	} finally {	if (halfReader != null) {	try {	halfReader.close(cacheConf.shouldEvictOnClose());	} catch (IOException e) {	
failed to close hfile reader for 

========================= hbase sample_3030 =========================

public static void setUp(String regionImpl) {	try {	CONF.set(HConstants.REGION_IMPL, regionImpl);	CONF.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 2);	CONF.setStrings(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY, RefreshHFilesEndpoint.class.getName());	cluster = HTU.startMiniCluster(NUM_MASTER, NUM_RS);	table = HTU.createTable(TABLE_NAME, FAMILY, SPLIT_KEY);	HTU.loadNumericRows(table, FAMILY, 1, 20);	HTU.flush(TABLE_NAME);	} catch (Exception ex) {	
couldn t finish setup 

public List<HStore> getStores() {	List<HStore> list = new ArrayList<>(stores.size());	try {	if (this.store == null) {	store = new HStoreWithFaultyRefreshHFilesAPI(this, ColumnFamilyDescriptorBuilder.of(FAMILY), this.conf);	}	list.add(store);	} catch (IOException ioe) {	
couldn t instantiate custom store implementation 

========================= hbase sample_1148 =========================

public void doTestThriftMetrics() throws Exception {	
start dotestthriftmetrics 

createTestTables(handler);	dropTestTables(handler);	metricsHelper.assertCounter("createTable_num_ops", currentCountCreateTable + 2, metrics.getSource());	metricsHelper.assertCounter("deleteTable_num_ops", currentCountDeleteTable + 2, metrics.getSource());	metricsHelper.assertCounter("disableTable_num_ops", currentCountDisableTable + 2, metrics.getSource());	handler.getTableNames();	try {	metricsHelper.assertGaugeGt("getTableNames_avg_time", 3L * 1000 * 1000 * 1000, metrics.getSource());	metricsHelper.assertGaugeLt("getTableNames_avg_time",6L * 1000 * 1000 * 1000, metrics.getSource());	} catch (AssertionError e) {	
fix me why does this happen a concurrent cluster running 

public static void doTestGetTableRegions(Hbase.Iface handler) throws Exception {	assertEquals(handler.getTableNames().size(), 0);	handler.createTable(tableAname, getColumnDescriptors());	assertEquals(handler.getTableNames().size(), 1);	List<TRegionInfo> regions = handler.getTableRegions(tableAname);	int regionCount = regions.size();	assertEquals("empty table should have only 1 region, " + "but found " + regionCount, regionCount, 1);	
region found 

private void testExceptionType(Hbase.Iface handler, ThriftMetrics metrics, ByteBuffer tTableName, String rowkey, ErrorThrowingGetObserver.ErrorType errorType) throws Exception {	long preGetCounter = metricsHelper.getCounter("getRow_num_ops", metrics.getSource());	String exceptionKey = errorType.getMetricName();	long preExceptionCounter = metricsHelper.checkCounterExists(exceptionKey, metrics.getSource()) ? metricsHelper.getCounter(exceptionKey, metrics.getSource()) : 0;	Map<ByteBuffer, ByteBuffer> attributes = new HashMap<>();	attributes.put(asByteBuffer(ErrorThrowingGetObserver.SHOULD_ERROR_ATTRIBUTE), asByteBuffer(errorType.name()));	try {	List<TRowResult> tRowResult = handler.getRow(tTableName, asByteBuffer(rowkey), attributes);	fail("Get with error attribute should have thrown an exception");	} catch (IOError e) {	
received exception 

========================= hbase sample_756 =========================

public void allowCompactions() {	
allowing compactions 

public void waitForCompactionToBlock() throws IOException {	try {	
waiting for compaction to block 

public void waitForCompactionToBlock() throws IOException {	try {	compactionsWaiting.await();	
compaction block reached 

public void doTest(Class<?> regionClass, MemoryCompactionPolicy policy) throws Exception {	Configuration c = TEST_UTIL.getConfiguration();	c.setClass(HConstants.REGION_IMPL, regionClass, HRegion.class);	c.setLong("hbase.hregion.memstore.flush.size", 25000);	c.set(HConstants.HBASE_REGION_SPLIT_POLICY_KEY, ConstantSizeRegionSplitPolicy.class.getName());	c.setInt("hbase.hstore.compaction.min",1);	c.setInt("hbase.hstore.compactionThreshold", 1000);	c.setLong("hbase.hstore.blockingStoreFiles", 1000);	c.setInt("hbase.regionserver.thread.splitcompactcheckfrequency", 1000);	c.set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY, String.valueOf(policy));	
starting mini cluster 

c.set(HConstants.HBASE_REGION_SPLIT_POLICY_KEY, ConstantSizeRegionSplitPolicy.class.getName());	c.setInt("hbase.hstore.compaction.min",1);	c.setInt("hbase.hstore.compactionThreshold", 1000);	c.setLong("hbase.hstore.blockingStoreFiles", 1000);	c.setInt("hbase.regionserver.thread.splitcompactcheckfrequency", 1000);	c.set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY, String.valueOf(policy));	TEST_UTIL.startMiniCluster(1);	CompactionBlockerRegion compactingRegion = null;	Admin admin = null;	try {	
creating admin 

c.setInt("hbase.hstore.compaction.min",1);	c.setInt("hbase.hstore.compactionThreshold", 1000);	c.setLong("hbase.hstore.blockingStoreFiles", 1000);	c.setInt("hbase.regionserver.thread.splitcompactcheckfrequency", 1000);	c.set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY, String.valueOf(policy));	TEST_UTIL.startMiniCluster(1);	CompactionBlockerRegion compactingRegion = null;	Admin admin = null;	try {	admin = TEST_UTIL.getConnection().getAdmin();	
creating table 

c.setLong("hbase.hstore.blockingStoreFiles", 1000);	c.setInt("hbase.regionserver.thread.splitcompactcheckfrequency", 1000);	c.set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY, String.valueOf(policy));	TEST_UTIL.startMiniCluster(1);	CompactionBlockerRegion compactingRegion = null;	Admin admin = null;	try {	admin = TEST_UTIL.getConnection().getAdmin();	TEST_UTIL.createTable(TABLE_NAME, FAMILY);	Table table = TEST_UTIL.getConnection().getTable(TABLE_NAME);	
loading test table 

TEST_UTIL.startMiniCluster(1);	CompactionBlockerRegion compactingRegion = null;	Admin admin = null;	try {	admin = TEST_UTIL.getConnection().getAdmin();	TEST_UTIL.createTable(TABLE_NAME, FAMILY);	Table table = TEST_UTIL.getConnection().getTable(TABLE_NAME);	List<HRegion> testRegions = TEST_UTIL.getMiniHBaseCluster().findRegionsForTable(TABLE_NAME);	assertEquals(1, testRegions.size());	compactingRegion = (CompactionBlockerRegion)testRegions.get(0);	
blocking compactions 

assertEquals(1, testRegions.size());	compactingRegion = (CompactionBlockerRegion)testRegions.get(0);	compactingRegion.stopCompactions();	long lastFlushTime = compactingRegion.getEarliestFlushTimeForAllStores();	TEST_UTIL.loadNumericRows(table, FAMILY, 0, FIRST_BATCH_COUNT);	HRegionInfo oldHri = new HRegionInfo(table.getName(), HConstants.EMPTY_START_ROW, HConstants.EMPTY_END_ROW);	CompactionDescriptor compactionDescriptor = ProtobufUtil.toCompactionDescriptor(oldHri, FAMILY, Lists.newArrayList(new Path("/a")), Lists.newArrayList(new Path("/b")), new Path("store_dir"));	WALUtil.writeCompactionMarker(compactingRegion.getWAL(), ((HRegion)compactingRegion).getReplicationScope(), oldHri, compactionDescriptor, compactingRegion.getMVCC());	long startWaitTime = System.currentTimeMillis();	while (compactingRegion.getEarliestFlushTimeForAllStores() <= lastFlushTime || compactingRegion.countStoreFiles() <= 1) {	
waiting for the region to flush 

CompactionDescriptor compactionDescriptor = ProtobufUtil.toCompactionDescriptor(oldHri, FAMILY, Lists.newArrayList(new Path("/a")), Lists.newArrayList(new Path("/b")), new Path("store_dir"));	WALUtil.writeCompactionMarker(compactingRegion.getWAL(), ((HRegion)compactingRegion).getReplicationScope(), oldHri, compactionDescriptor, compactingRegion.getMVCC());	long startWaitTime = System.currentTimeMillis();	while (compactingRegion.getEarliestFlushTimeForAllStores() <= lastFlushTime || compactingRegion.countStoreFiles() <= 1) {	Thread.sleep(1000);	admin.flush(table.getName());	assertTrue("Timed out waiting for the region to flush", System.currentTimeMillis() - startWaitTime < 30000);	}	assertTrue(compactingRegion.countStoreFiles() > 1);	final byte REGION_NAME[] = compactingRegion.getRegionInfo().getRegionName();	
asking for compaction 

WALUtil.writeCompactionMarker(compactingRegion.getWAL(), ((HRegion)compactingRegion).getReplicationScope(), oldHri, compactionDescriptor, compactingRegion.getMVCC());	long startWaitTime = System.currentTimeMillis();	while (compactingRegion.getEarliestFlushTimeForAllStores() <= lastFlushTime || compactingRegion.countStoreFiles() <= 1) {	Thread.sleep(1000);	admin.flush(table.getName());	assertTrue("Timed out waiting for the region to flush", System.currentTimeMillis() - startWaitTime < 30000);	}	assertTrue(compactingRegion.countStoreFiles() > 1);	final byte REGION_NAME[] = compactingRegion.getRegionInfo().getRegionName();	admin.majorCompact(TABLE_NAME);	
waiting for compaction to be about to start 

long startWaitTime = System.currentTimeMillis();	while (compactingRegion.getEarliestFlushTimeForAllStores() <= lastFlushTime || compactingRegion.countStoreFiles() <= 1) {	Thread.sleep(1000);	admin.flush(table.getName());	assertTrue("Timed out waiting for the region to flush", System.currentTimeMillis() - startWaitTime < 30000);	}	assertTrue(compactingRegion.countStoreFiles() > 1);	final byte REGION_NAME[] = compactingRegion.getRegionInfo().getRegionName();	admin.majorCompact(TABLE_NAME);	compactingRegion.waitForCompactionToBlock();	
starting a new server 

Thread.sleep(1000);	admin.flush(table.getName());	assertTrue("Timed out waiting for the region to flush", System.currentTimeMillis() - startWaitTime < 30000);	}	assertTrue(compactingRegion.countStoreFiles() > 1);	final byte REGION_NAME[] = compactingRegion.getRegionInfo().getRegionName();	admin.majorCompact(TABLE_NAME);	compactingRegion.waitForCompactionToBlock();	RegionServerThread newServerThread = TEST_UTIL.getMiniHBaseCluster().startRegionServer();	final HRegionServer newServer = newServerThread.getRegionServer();	
killing region server zk lease 

}	assertTrue(compactingRegion.countStoreFiles() > 1);	final byte REGION_NAME[] = compactingRegion.getRegionInfo().getRegionName();	admin.majorCompact(TABLE_NAME);	compactingRegion.waitForCompactionToBlock();	RegionServerThread newServerThread = TEST_UTIL.getMiniHBaseCluster().startRegionServer();	final HRegionServer newServer = newServerThread.getRegionServer();	TEST_UTIL.expireRegionServerSession(0);	CompactionBlockerRegion newRegion = null;	startWaitTime = System.currentTimeMillis();	
waiting for the new server to pick up the region 

public boolean evaluate() throws Exception {	Region newRegion = newServer.getOnlineRegion(REGION_NAME);	return newRegion != null;	}	});	newRegion = (CompactionBlockerRegion)newServer.getOnlineRegion(REGION_NAME);	FileSystem fs = newRegion.getFilesystem();	for (String f: newRegion.getStoreFileList(new byte [][] {FAMILY})) {	assertTrue("After compaction, does not exist: " + f, fs.exists(new Path(f)));	}	
allowing compaction to proceed 

});	newRegion = (CompactionBlockerRegion)newServer.getOnlineRegion(REGION_NAME);	FileSystem fs = newRegion.getFilesystem();	for (String f: newRegion.getStoreFileList(new byte [][] {FAMILY})) {	assertTrue("After compaction, does not exist: " + f, fs.exists(new Path(f)));	}	compactingRegion.allowCompactions();	while (compactingRegion.compactCount == 0) {	Thread.sleep(1000);	}	
compaction finished 

========================= hbase sample_2158 =========================

public void perform() throws Exception {	
performing action rolling batch restarting d of region servers 

private int invocations = 0;	protected ServerName[] getCurrentServers() throws IOException {	final int count = 4;	List<ServerName> serverNames = new ArrayList<>(count);	for (int i = 0; i < 4; i++) {	serverNames.add(ServerName.valueOf(i + ".example.org", i, i));	}	return serverNames.toArray(new ServerName[serverNames.size()]);	}	protected void killRs(ServerName server) throws IOException {	
killed 

serverNames.add(ServerName.valueOf(i + ".example.org", i, i));	}	return serverNames.toArray(new ServerName[serverNames.size()]);	}	protected void killRs(ServerName server) throws IOException {	if (this.invocations++ % 3 == 0) {	throw new org.apache.hadoop.util.Shell.ExitCodeException(-1, "Failed");	}	}	protected void startRs(ServerName server) throws IOException {	
started 

========================= hbase sample_3319 =========================

public HBaseConfiguration() {	super();	addHbaseResources(this);	
instantiating hbaseconfiguration is deprecated please use hbaseconfiguration create to construct a plain configuration 

public static boolean isShowConfInServlet() {	boolean isShowConf = false;	try {	if (Class.forName("org.apache.hadoop.conf.ConfServlet") != null) {	isShowConf = true;	}	} catch (LinkageError e) {	
error thrown 

public static boolean isShowConfInServlet() {	boolean isShowConf = false;	try {	if (Class.forName("org.apache.hadoop.conf.ConfServlet") != null) {	isShowConf = true;	}	} catch (LinkageError e) {	} catch (ClassNotFoundException ce) {	
classnotfound confservlet 

public static int getInt(Configuration conf, String name, String deprecatedName, int defaultValue) {	if (conf.get(deprecatedName) != null) {	
config option is deprecated instead use 

public static String getPassword(Configuration conf, String alias, String defPass) throws IOException {	String passwd = null;	try {	Method m = Configuration.class.getMethod("getPassword", String.class);	char[] p = (char[]) m.invoke(conf, alias);	if (p != null) {	
config option was found through the configuration getpassword method 

public static String getPassword(Configuration conf, String alias, String defPass) throws IOException {	String passwd = null;	try {	Method m = Configuration.class.getMethod("getPassword", String.class);	char[] p = (char[]) m.invoke(conf, alias);	if (p != null) {	passwd = new String(p);	} else {	
config option was not found using provided default value 

String passwd = null;	try {	Method m = Configuration.class.getMethod("getPassword", String.class);	char[] p = (char[]) m.invoke(conf, alias);	if (p != null) {	passwd = new String(p);	} else {	passwd = defPass;	}	} catch (NoSuchMethodException e) {	
credential getpassword method is not available falling back to configuration 

========================= hbase sample_1133 =========================

private void onComplete(Action action, RegionRequest regionReq, int tries, ServerName serverName, RegionResult regionResult, List<Action> failedActions) {	Object result = regionResult.result.get(action.getOriginalIndex());	if (result == null) {	
server sent us neither result nor exception for row of 

private void onComplete(Map<byte[], RegionRequest> actionsByRegion, int tries, ServerName serverName, MultiResponse resp) {	List<Action> failedActions = new ArrayList<>();	actionsByRegion.forEach((rn, regionReq) -> {	RegionResult regionResult = resp.getResults().get(rn);	if (regionResult != null) {	regionReq.actions.forEach( action -> onComplete(action, regionReq, tries, serverName, regionResult, failedActions));	} else {	Throwable t = resp.getException(rn);	Throwable error;	if (t == null) {	
server sent us neither results nor exceptions for 

========================= hbase sample_404 =========================

public void testCloneSnapshotToSameTable() throws Exception {	SnapshotProtos.SnapshotDescription snapshotDesc = getSnapshot();	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	final TableName clonedTableName = TableName.valueOf(snapshotDesc.getTable());	final HTableDescriptor htd = createHTableDescriptor(clonedTableName, CF);	long procId = ProcedureTestingUtility.submitAndWait( procExec, new CloneSnapshotProcedure(procExec.getEnvironment(), htd, snapshotDesc));	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
clone snapshot failed with exception 

========================= hbase sample_1830 =========================

public void testFullBackupSetExist() throws Exception {	
test full backup backup set exists 

assertNotNull(names);	assertTrue(names.size() == 1);	assertTrue(names.get(0).equals(table1));	String[] args = new String[] { "create", "full", BACKUP_ROOT_DIR, "-s", name };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	List<BackupInfo> backups = table.getBackupHistory();	assertTrue(backups.size() == 1);	String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	
backup complete 

assertTrue(backups.size() == 1);	String backupId = backups.get(0).getBackupId();	assertTrue(checkSucceeded(backupId));	args = new String[] { BACKUP_ROOT_DIR, backupId, "-s", name, "-m", table1_restore.getNameAsString(), "-o" };	ret = ToolRunner.run(conf1, new RestoreDriver(), args);	assertTrue(ret == 0);	HBaseAdmin hba = TEST_UTIL.getHBaseAdmin();	assertTrue(hba.tableExists(table1_restore));	assertEquals(TEST_UTIL.countRows(table1), TEST_UTIL.countRows(table1_restore));	TEST_UTIL.deleteTable(table1_restore);	
restore into other table is complete 

public void testFullBackupSetDoesNotExist() throws Exception {	
test full backup backup set does not exist 

========================= hbase sample_541 =========================

protected Flow executeFromState(MasterProcedureEnv env, ServerCrashState state) throws ProcedureSuspendedException, ProcedureYieldException {	final MasterServices services = env.getMasterServices();	if (!notifiedDeadServer) {	services.getServerManager().getDeadServers().notifyServer(serverName);	notifiedDeadServer = true;	}	try {	switch (state) {	
start 

private void processMeta(final MasterProcedureEnv env) throws IOException {	
processing hbase meta that was on 

if (regions == null) return;	AssignmentManager am = env.getMasterServices().getAssignmentManager();	final Iterator<RegionInfo> it = regions.iterator();	ServerCrashException sce = null;	while (it.hasNext()) {	final RegionInfo hri = it.next();	RegionTransitionProcedure rtp = am.getRegionStates().getRegionTransitionProcedure(hri);	if (rtp == null) continue;	ServerName rtpServerName = rtp.getServer(env);	if (rtpServerName == null) {	
rit with servername null 

========================= hbase sample_2820 =========================

public void testFsUriSetProperly() throws Exception {	HMaster master = UTIL.getMiniHBaseCluster().getMaster();	MasterFileSystem fs = master.getMasterFileSystem();	Path masterRoot = FSUtils.getRootDir(fs.getConfiguration());	Path rootDir = FSUtils.getRootDir(fs.getFileSystem().getConf());	
from fs uri 

public void testFsUriSetProperly() throws Exception {	HMaster master = UTIL.getMiniHBaseCluster().getMaster();	MasterFileSystem fs = master.getMasterFileSystem();	Path masterRoot = FSUtils.getRootDir(fs.getConfiguration());	Path rootDir = FSUtils.getRootDir(fs.getFileSystem().getConf());	
from configuration uri 

========================= hbase sample_1867 =========================

setHeartbeatMessage(false);	incRPCCallsMetrics(scanMetrics, isRegionServerRemote);	ScanRequest request = RequestConverter.buildScanRequest(scannerId, caching, false, nextCallSeq, this.scanMetrics != null, renew, scan.getLimit());	try {	ScanResponse response = getStub().scan(getRpcController(), request);	nextCallSeq++;	return response;	} catch (Exception e) {	IOException ioe = ProtobufUtil.handleRemoteException(e);	if (logScannerActivity) {	
got exception making request to 

} catch (Exception e) {	IOException ioe = ProtobufUtil.handleRemoteException(e);	if (logScannerActivity) {	}	if (logScannerActivity) {	if (ioe instanceof UnknownScannerException) {	try {	HRegionLocation location = getConnection().relocateRegion(getTableName(), scan.getStartRow());	LOG.info("Scanner=" + scannerId + " expired, current region location is " + location.toString());	} catch (Throwable t) {	
failed to relocate region 

incRPCCallsMetrics(scanMetrics, isRegionServerRemote);	ScanRequest request = RequestConverter.buildScanRequest(this.scannerId, 0, true, this.scanMetrics != null);	try {	getStub().scan(getRpcController(), request);	} catch (Exception e) {	throw ProtobufUtil.handleRemoteException(e);	}	} catch (IOException e) {	TableName table = getTableName();	String tableDetails = (table == null) ? "" : (" on table: " + table.getNameAsString());	
ignore probably already closed current scan 

========================= hbase sample_453 =========================

private boolean dispatch(HFileDeleteTask task) {	if (task.fileLength >= this.throttlePoint) {	if (!this.largeFileQueue.offer(task)) {	
large file deletion queue is full 

private boolean dispatch(HFileDeleteTask task) {	if (task.fileLength >= this.throttlePoint) {	if (!this.largeFileQueue.offer(task)) {	return false;	}	} else {	if (!this.smallFileQueue.offer(task)) {	
small file deletion queue is full 

running = true;	for (int i = 0; i < largeFileDeleteThreadNumber; i++) {	Thread large = new Thread() {	public void run() {	consumerLoop(largeFileQueue);	}	};	large.setDaemon(true);	large.setName(n + "-HFileCleaner.large." + i + "-" + System.currentTimeMillis());	large.start();	
starting hfile cleaner for large files 

}	for (int i = 0; i < smallFileDeleteThreadNumber; i++) {	Thread small = new Thread() {	public void run() {	consumerLoop(smallFileQueue);	}	};	small.setDaemon(true);	small.setName(n + "-HFileCleaner.small." + i + "-" + System.currentTimeMillis());	small.start();	
starting hfile cleaner for small files 

protected void consumerLoop(BlockingQueue<HFileDeleteTask> queue) {	try {	while (running) {	HFileDeleteTask task = null;	try {	task = queue.take();	} catch (InterruptedException e) {	
interrupted while trying to take a task from queue 

protected void consumerLoop(BlockingQueue<HFileDeleteTask> queue) {	try {	while (running) {	HFileDeleteTask task = null;	try {	task = queue.take();	} catch (InterruptedException e) {	break;	}	if (task != null) {	
removing from archive 

try {	task = queue.take();	} catch (InterruptedException e) {	break;	}	if (task != null) {	boolean succeed;	try {	succeed = this.fs.delete(task.filePath, false);	} catch (IOException e) {	
failed to delete file 

} catch (IOException e) {	succeed = false;	}	task.setResult(succeed);	if (succeed) {	countDeletedFiles(task.fileLength >= throttlePoint, queue == largeFileQueue);	}	}	}	} finally {	
exit thread 

private void countDeletedFiles(boolean isLargeFile, boolean fromLargeQueue) {	if (isLargeFile) {	if (deletedLargeFiles.get() == Long.MAX_VALUE) {	
deleted more than long max value large files reset counter to 

private void countDeletedFiles(boolean isLargeFile, boolean fromLargeQueue) {	if (isLargeFile) {	if (deletedLargeFiles.get() == Long.MAX_VALUE) {	deletedLargeFiles.set(0L);	}	deletedLargeFiles.incrementAndGet();	} else {	if (deletedSmallFiles.get() == Long.MAX_VALUE) {	
deleted more than long max value small files reset counter to 

if (isLargeFile) {	if (deletedLargeFiles.get() == Long.MAX_VALUE) {	deletedLargeFiles.set(0L);	}	deletedLargeFiles.incrementAndGet();	} else {	if (deletedSmallFiles.get() == Long.MAX_VALUE) {	deletedSmallFiles.set(0L);	}	if (fromLargeQueue) {	
stolen a small file deletion task in large file thread 

private void stopHFileDeleteThreads() {	running = false;	
stopping file delete threads 

public synchronized boolean getResult() {	long waitTime = 0;	try {	while (!done) {	wait(WAIT_UNIT);	waitTime += WAIT_UNIT;	if (done) {	return this.result;	}	if (waitTime > MAX_WAIT) {	
wait more than ms for deleting exit 

wait(WAIT_UNIT);	waitTime += WAIT_UNIT;	if (done) {	return this.result;	}	if (waitTime > MAX_WAIT) {	return false;	}	}	} catch (InterruptedException e) {	
interrupted while waiting for result of deleting will return false 

public void onConfigurationChange(Configuration conf) {	super.onConfigurationChange(conf);	if (!checkAndUpdateConfigurations(conf)) {	
update configuration triggered but nothing changed for this cleaner 

private boolean checkAndUpdateConfigurations(Configuration conf) {	boolean updated = false;	int throttlePoint = conf.getInt(HFILE_DELETE_THROTTLE_THRESHOLD, DEFAULT_HFILE_DELETE_THROTTLE_THRESHOLD);	if (throttlePoint != this.throttlePoint) {	
updating throttle point from to 

private boolean checkAndUpdateConfigurations(Configuration conf) {	boolean updated = false;	int throttlePoint = conf.getInt(HFILE_DELETE_THROTTLE_THRESHOLD, DEFAULT_HFILE_DELETE_THROTTLE_THRESHOLD);	if (throttlePoint != this.throttlePoint) {	this.throttlePoint = throttlePoint;	updated = true;	}	int largeQueueInitSize = conf.getInt(LARGE_HFILE_QUEUE_INIT_SIZE, DEFAULT_LARGE_HFILE_QUEUE_INIT_SIZE);	if (largeQueueInitSize != this.largeQueueInitSize) {	
updating largequeueinitsize from to 

this.throttlePoint = throttlePoint;	updated = true;	}	int largeQueueInitSize = conf.getInt(LARGE_HFILE_QUEUE_INIT_SIZE, DEFAULT_LARGE_HFILE_QUEUE_INIT_SIZE);	if (largeQueueInitSize != this.largeQueueInitSize) {	this.largeQueueInitSize = largeQueueInitSize;	updated = true;	}	int smallQueueInitSize = conf.getInt(SMALL_HFILE_QUEUE_INIT_SIZE, DEFAULT_SMALL_HFILE_QUEUE_INIT_SIZE);	if (smallQueueInitSize != this.smallQueueInitSize) {	
updating smallqueueinitsize from to 

this.largeQueueInitSize = largeQueueInitSize;	updated = true;	}	int smallQueueInitSize = conf.getInt(SMALL_HFILE_QUEUE_INIT_SIZE, DEFAULT_SMALL_HFILE_QUEUE_INIT_SIZE);	if (smallQueueInitSize != this.smallQueueInitSize) {	this.smallQueueInitSize = smallQueueInitSize;	updated = true;	}	int largeFileDeleteThreadNumber = conf.getInt(LARGE_HFILE_DELETE_THREAD_NUMBER, DEFAULT_LARGE_HFILE_DELETE_THREAD_NUMBER);	if (largeFileDeleteThreadNumber != this.largeFileDeleteThreadNumber) {	
updating largefiledeletethreadnumber from to 

this.smallQueueInitSize = smallQueueInitSize;	updated = true;	}	int largeFileDeleteThreadNumber = conf.getInt(LARGE_HFILE_DELETE_THREAD_NUMBER, DEFAULT_LARGE_HFILE_DELETE_THREAD_NUMBER);	if (largeFileDeleteThreadNumber != this.largeFileDeleteThreadNumber) {	this.largeFileDeleteThreadNumber = largeFileDeleteThreadNumber;	updated = true;	}	int smallFileDeleteThreadNumber = conf.getInt(SMALL_HFILE_DELETE_THREAD_NUMBER, DEFAULT_SMALL_HFILE_DELETE_THREAD_NUMBER);	if (smallFileDeleteThreadNumber != this.smallFileDeleteThreadNumber) {	
updating smallfiledeletethreadnumber from to 

========================= hbase sample_2877 =========================

public void setUp() throws Exception {	
initializing cluster with servers 

public void setUp() throws Exception {	util.initializeCluster(NUM_SERVERS);	
done initializing cluster 

private void createTable() throws Exception {	deleteTable();	
creating table 

DataBlockEncoding blockEncoding = DataBlockEncoding.valueOf(conf.get(encodingKey, "FAST_DIFF"));	HTableDescriptor htd = new HTableDescriptor(TABLE_NAME);	for (byte[] cf : dataGen.getColumnFamilies()) {	HColumnDescriptor hcd = new HColumnDescriptor(cf);	hcd.setDataBlockEncoding(blockEncoding);	htd.addFamily(hcd);	}	int serverCount = util.getHBaseClusterInterface().getClusterMetrics() .getLiveServerMetrics().size();	byte[][] splits = new RegionSplitter.HexStringSplit().split(serverCount * REGIONS_PER_SERVER);	util.getAdmin().createTable(htd, splits);	
created table 

private void deleteTable() throws Exception {	if (util.getAdmin().tableExists(TABLE_NAME)) {	
deleting table 

private void deleteTable() throws Exception {	if (util.getAdmin().tableExists(TABLE_NAME)) {	util.deleteTable(TABLE_NAME);	
deleted table 

public void tearDown() throws Exception {	deleteTable();	
restoring the cluster 

public void tearDown() throws Exception {	deleteTable();	util.restoreCluster();	
done restoring the cluster 

public void testReadersAndWriters() throws Exception {	Configuration conf = util.getConfiguration();	String timeoutKey = String.format(TIMEOUT_KEY, this.getClass().getSimpleName());	long maxRuntime = conf.getLong(timeoutKey, DEFAULT_TIMEOUT_MINUTES);	long serverCount = util.getHBaseClusterInterface().getClusterMetrics() .getLiveServerMetrics().size();	long keysToWrite = serverCount * KEYS_TO_WRITE_PER_SERVER;	Connection connection = ConnectionFactory.createConnection(conf);	Table table = connection.getTable(TABLE_NAME);	MultiThreadedWriter writer = new MultiThreadedWriter(dataGen, conf, TABLE_NAME);	writer.setMultiPut(true);	
starting writer the number of keys to write is 

long keysToWrite = serverCount * KEYS_TO_WRITE_PER_SERVER;	Connection connection = ConnectionFactory.createConnection(conf);	Table table = connection.getTable(TABLE_NAME);	MultiThreadedWriter writer = new MultiThreadedWriter(dataGen, conf, TABLE_NAME);	writer.setMultiPut(true);	writer.start(1, keysToWrite, WRITER_THREADS);	long now = EnvironmentEdgeManager.currentTime();	long timeLimit = now + (maxRuntime * 60000);	boolean isWriterDone = false;	while (now < timeLimit && !isWriterDone) {	
starting the scan wrote approximately keys 

Table table = connection.getTable(TABLE_NAME);	MultiThreadedWriter writer = new MultiThreadedWriter(dataGen, conf, TABLE_NAME);	writer.setMultiPut(true);	writer.start(1, keysToWrite, WRITER_THREADS);	long now = EnvironmentEdgeManager.currentTime();	long timeLimit = now + (maxRuntime * 60000);	boolean isWriterDone = false;	while (now < timeLimit && !isWriterDone) {	isWriterDone = writer.isDone();	if (isWriterDone) {	
scanning full result writer is done 

boolean isOk = writer.verifyResultAgainstDataGenerator(result, true, true);	Assert.assertTrue("Failed to verify [" + Bytes.toString(result.getRow())+ "]", isOk);	++resultCount;	}	long timeTaken = EnvironmentEdgeManager.currentTime() - startTs;	long onesGennedAfterScan = dataGen.getExpectedNumberOfKeys();	Assert.assertTrue("Read " + resultCount + " keys when at most " + onesGennedAfterScan + " were generated ", onesGennedAfterScan >= resultCount);	if (isWriterDone) {	Assert.assertTrue("Read " + resultCount + " keys; the writer is done and " + onesGennedAfterScan + " keys were generated", onesGennedAfterScan == resultCount);	} else if (onesGennedBeforeScan * 0.9 > resultCount) {	
read way too few keys there might be a problem or the writer might just be slow 

Assert.assertTrue("Failed to verify [" + Bytes.toString(result.getRow())+ "]", isOk);	++resultCount;	}	long timeTaken = EnvironmentEdgeManager.currentTime() - startTs;	long onesGennedAfterScan = dataGen.getExpectedNumberOfKeys();	Assert.assertTrue("Read " + resultCount + " keys when at most " + onesGennedAfterScan + " were generated ", onesGennedAfterScan >= resultCount);	if (isWriterDone) {	Assert.assertTrue("Read " + resultCount + " keys; the writer is done and " + onesGennedAfterScan + " keys were generated", onesGennedAfterScan == resultCount);	} else if (onesGennedBeforeScan * 0.9 > resultCount) {	}	
scan took ms 

========================= hbase sample_3335 =========================

public void start(long startKey, long endKey, int numThreads) throws IOException {	super.start(startKey, endKey, numThreads);	if (verbose) {	
inserting keys 

if (e instanceof RetriesExhaustedWithDetailsException) {	RetriesExhaustedWithDetailsException aggEx = (RetriesExhaustedWithDetailsException)e;	exceptionInfo = aggEx.getExhaustiveDescription();	} else {	StringWriter stackWriter = new StringWriter();	PrintWriter pw = new PrintWriter(stackWriter);	e.printStackTrace(pw);	pw.flush();	exceptionInfo = StringUtils.stringifyException(e);	}	
failed to insert after ms region information errors 

protected void closeHTable() {	try {	if (table != null) {	table.close();	}	} catch (IOException e) {	
error closing table 

========================= hbase sample_1308 =========================

public static void install(final Configuration conf, final FileSystem fs, final Stoppable stop, final Thread threadToJoin) {	Runnable fsShutdownHook = suppressHdfsShutdownHook(fs);	Thread t = new ShutdownHookThread(conf, stop, threadToJoin, fsShutdownHook);	ShutdownHookManager.affixShutdownHook(t, 0);	
installed shutdown hook thread 

public void run() {	boolean b = this.conf.getBoolean(RUN_SHUTDOWN_HOOK, true);	LOG.info("Shutdown hook starting; " + RUN_SHUTDOWN_HOOK + "=" + b + "; fsShutdownHook=" + this.fsShutdownHook);	if (b) {	this.stop.stop("Shutdown hook");	Threads.shutdown(this.threadToJoin);	if (this.fsShutdownHook != null) {	synchronized (fsShutdownHooks) {	int refs = fsShutdownHooks.get(fsShutdownHook);	if (refs == 1) {	
starting fs shutdown hook thread 

Thread fsShutdownHookThread = (fsShutdownHook instanceof Thread) ? (Thread)fsShutdownHook : new Thread(fsShutdownHook, fsShutdownHook.getClass().getSimpleName() + "-shutdown-hook");	fsShutdownHookThread.start();	Threads.shutdown(fsShutdownHookThread, this.conf.getLong(FS_SHUTDOWN_HOOK_WAIT, 30000));	}	if (refs > 0) {	fsShutdownHooks.put(fsShutdownHook, refs - 1);	}	}	}	}	
shutdown hook finished 

synchronized (fsShutdownHooks) {	boolean isFSCacheDisabled = fs.getConf().getBoolean("fs.hdfs.impl.disable.cache", false);	if (!isFSCacheDisabled && !fsShutdownHooks.containsKey(hdfsClientFinalizer) && !ShutdownHookManager.deleteShutdownHook(hdfsClientFinalizer)) {	throw new RuntimeException( "Failed suppression of fs shutdown hook: " + hdfsClientFinalizer);	}	Integer refs = fsShutdownHooks.get(hdfsClientFinalizer);	fsShutdownHooks.put(hdfsClientFinalizer, refs == null ? 1 : refs + 1);	}	return hdfsClientFinalizer;	} catch (NoSuchFieldException nsfe) {	
couldn t find field clientfinalizer in filesystem 

if (!isFSCacheDisabled && !fsShutdownHooks.containsKey(hdfsClientFinalizer) && !ShutdownHookManager.deleteShutdownHook(hdfsClientFinalizer)) {	throw new RuntimeException( "Failed suppression of fs shutdown hook: " + hdfsClientFinalizer);	}	Integer refs = fsShutdownHooks.get(hdfsClientFinalizer);	fsShutdownHooks.put(hdfsClientFinalizer, refs == null ? 1 : refs + 1);	}	return hdfsClientFinalizer;	} catch (NoSuchFieldException nsfe) {	throw new RuntimeException("Failed to suppress HDFS shutdown hook");	} catch (IllegalAccessException iae) {	
couldn t access field clientfinalizer in filesystem 

========================= hbase sample_2524 =========================

public void testClientTracksServerPushback() throws Exception{	Configuration conf = UTIL.getConfiguration();	ClusterConnection conn = (ClusterConnection) ConnectionFactory.createConnection(conf);	BufferedMutatorImpl mutator = (BufferedMutatorImpl) conn.getBufferedMutator(tableName);	HRegionServer rs = UTIL.getHBaseCluster().getRegionServer(0);	Region region = rs.getRegions(tableName).get(0);	
writing some data to 

assertTrue("Backoff policy is not correctly configured", backoffPolicy instanceof ExponentialClientBackoffPolicy);	ServerStatisticTracker stats = conn.getStatisticsTracker();	assertNotNull( "No stats configured for the client!", stats);	ServerName server = rs.getServerName();	byte[] regionName = region.getRegionInfo().getRegionName();	ServerStatistics serverStats = stats.getServerStatsForTesting(server);	ServerStatistics.RegionStatistics regionStats = serverStats.getStatsForRegion(regionName);	assertEquals("We did not find some load on the memstore", load, regionStats.getMemStoreLoadPercent());	long backoffTime = backoffPolicy.getBackoffTime(server, regionName, serverStats);	assertNotEquals("Reported load does not produce a backoff", backoffTime, 0);	
backoff calculated for is 

========================= hbase sample_2031 =========================

public Cell filterCell(Cell cell, Predicate<byte[]> famPredicate) {	byte[] fam;	BulkLoadDescriptor bld = null;	try {	bld = WALEdit.getBulkLoadDescriptor(cell);	} catch (IOException e) {	
failed to get bulk load events information from the wal file 

========================= hbase sample_2932 =========================

public void saslReadAndProcess(ByteBuff saslToken) throws IOException, InterruptedException {	if (saslContextEstablished) {	
have read input token of size for processing by saslserver unwrap 

} else {	byte[] replyToken;	try {	if (saslServer == null) {	saslServer = new HBaseSaslRpcServer(authMethod, rpcServer.saslProps, rpcServer.secretManager);	if (RpcServer.LOG.isDebugEnabled()) {	RpcServer.LOG .debug("Created SASL server with mechanism = " + authMethod.getMechanismName());	}	}	if (RpcServer.LOG.isDebugEnabled()) {	
have read input token of size for processing by saslserver evaluateresponse 

cause = cause.getCause();	}	doRawSaslReply(SaslStatus.ERROR, null, sendToClient.getClass().getName(), sendToClient.getLocalizedMessage());	this.rpcServer.metrics.authenticationFailure();	String clientIP = this.toString();	RpcServer.AUDITLOG .warn(RpcServer.AUTH_FAILED_FOR + clientIP + ":" + saslServer.getAttemptingUser());	throw e;	}	if (replyToken != null) {	if (RpcServer.LOG.isDebugEnabled()) {	
will send token of size from saslserver 

if (replyToken != null) {	if (RpcServer.LOG.isDebugEnabled()) {	}	doRawSaslReply(SaslStatus.SUCCESS, new BytesWritable(replyToken), null, null);	}	if (saslServer.isComplete()) {	String qop = saslServer.getNegotiatedQop();	useWrap = qop != null && !"auth".equalsIgnoreCase(qop);	ugi = getAuthorizedUgi(saslServer.getAuthorizationID());	if (RpcServer.LOG.isDebugEnabled()) {	
sasl server context established authenticated client negotiated qop is 

while (true) {	int count;	if (unwrappedDataLengthBuffer.remaining() > 0) {	count = this.rpcServer.channelRead(ch, unwrappedDataLengthBuffer);	if (count <= 0 || unwrappedDataLengthBuffer.remaining() > 0) return;	}	if (unwrappedData == null) {	unwrappedDataLengthBuffer.flip();	int unwrappedDataLength = unwrappedDataLengthBuffer.getInt();	if (unwrappedDataLength == RpcClient.PING_CALL_ID) {	
received ping message 

private boolean authorizeConnection() throws IOException {	try {	if (ugi != null && ugi.getRealUser() != null && (authMethod != AuthMethod.DIGEST)) {	ProxyUsers.authorize(ugi, this.getHostAddress(), this.rpcServer.conf);	}	this.rpcServer.authorize(ugi, connectionHeader, getHostInetAddress());	this.rpcServer.metrics.authorizationSuccess();	} catch (AuthorizationException ae) {	if (RpcServer.LOG.isDebugEnabled()) {	
connection authorization failed 

RPCProtos.ConnectionHeaderResponse.Builder chrBuilder = RPCProtos.ConnectionHeaderResponse.newBuilder();	setupCryptoCipher(this.connectionHeader, chrBuilder);	responseConnectionHeader(chrBuilder);	UserGroupInformation protocolUser = createUser(connectionHeader);	if (!useSasl) {	ugi = protocolUser;	if (ugi != null) {	ugi.setAuthenticationMethod(AuthMethod.SIMPLE.authenticationMethod);	}	if (authenticatedWithFallback) {	
allowed fallback to simple auth for connecting from 

throw new AccessDeniedException("Authenticated user (" + ugi + ") doesn't match what the client claims to be (" + protocolUser + ")");	} else {	UserGroupInformation realUser = ugi;	ugi = UserGroupInformation.createProxyUser(protocolUser .getUserName(), realUser);	ugi.setAuthenticationMethod(AuthenticationMethod.PROXY);	}	}	}	if (connectionHeader.hasVersionInfo()) {	retryImmediatelySupported = VersionInfoUtil.hasMinimumVersion(getVersionInfo(), 1, 2);	
connection from port with version info 

} else {	UserGroupInformation realUser = ugi;	ugi = UserGroupInformation.createProxyUser(protocolUser .getUserName(), realUser);	ugi.setAuthenticationMethod(AuthenticationMethod.PROXY);	}	}	}	if (connectionHeader.hasVersionInfo()) {	retryImmediatelySupported = VersionInfoUtil.hasMinimumVersion(getVersionInfo(), 1, 2);	} else {	
connection from port with unknown version info 

}	cis.enableAliasing(true);	int headerSize = cis.readRawVarint32();	offset = cis.getTotalBytesRead();	Message.Builder builder = RequestHeader.newBuilder();	ProtobufUtil.mergeFrom(builder, cis, headerSize);	RequestHeader header = (RequestHeader) builder.build();	offset += headerSize;	int id = header.getCallId();	if (RpcServer.LOG.isTraceEnabled()) {	
requestheader totalrequestsize bytes 

========================= hbase sample_2898 =========================

public void testReferenceSize() {	
classsize reference is 

public void testObjectSize() throws IOException {	
header 

public void testObjectSize() throws IOException {	
array header 

========================= hbase sample_1522 =========================

}	++entriesRead;	}	++blocksRead;	curBlockPos += block.getOnDiskSizeWithHeader();	}	LOG.info("Finished reading: entries=" + entriesRead + ", blocksRead=" + blocksRead);	assertEquals(entryCount, entriesRead);	int metaCounter = 0;	while (fsdis.getPos() < trailer.getLoadOnOpenDataOffset()) {	
current offset scanning until 

while (fsdis.getPos() < trailer.getLoadOnOpenDataOffset()) {	HFileBlock block = blockReader.readBlockData(curBlockPos, -1, false, false) .unpack(context, blockReader);	assertEquals(BlockType.META, block.getBlockType());	Text t = new Text();	ByteBuff buf = block.getBufferWithoutHeader();	if (Writables.getWritable(buf.array(), buf.arrayOffset(), buf.limit(), t) == null) {	throw new IOException("Failed to deserialize block " + this + " into a " + t.getClass().getSimpleName());	}	Text expectedText = (metaCounter == 0 ? new Text("Paris") : metaCounter == 1 ? new Text( "Moscow") : new Text("Washington, D.C."));	assertEquals(expectedText, t);	
read meta block data 

========================= hbase sample_1488 =========================

public void callMethod(Descriptors.MethodDescriptor method, RpcController controller, Message request, Message responsePrototype, RpcCallback<Message> callback) {	Message response = null;	try {	response = callExecService(controller, method, request, responsePrototype);	} catch (IOException ioe) {	
call failed on ioexception 

========================= hbase sample_445 =========================

protected AbstractHBaseSaslRpcClient(AuthMethod method, Token<? extends TokenIdentifier> token, String serverPrincipal, boolean fallbackAllowed, String rpcProtection) throws IOException {	this.fallbackAllowed = fallbackAllowed;	saslProps = SaslUtil.initSaslProperties(rpcProtection);	switch (method) {	
creating sasl client to authenticate to service at 

protected AbstractHBaseSaslRpcClient(AuthMethod method, Token<? extends TokenIdentifier> token, String serverPrincipal, boolean fallbackAllowed, String rpcProtection) throws IOException {	this.fallbackAllowed = fallbackAllowed;	saslProps = SaslUtil.initSaslProperties(rpcProtection);	switch (method) {	saslClient = createDigestSaslClient(new String[] { AuthMethod.DIGEST.getMechanismName() }, SaslUtil.SASL_DEFAULT_REALM, new SaslClientCallbackHandler(token));	break;	case KERBEROS: if (LOG.isDebugEnabled()) {	
creating sasl client server s kerberos principal name is 

} else if (callback instanceof PasswordCallback) {	pc = (PasswordCallback) callback;	} else if (callback instanceof RealmCallback) {	rc = (RealmCallback) callback;	} else {	throw new UnsupportedCallbackException(callback, "Unrecognized SASL client callback");	}	}	if (nc != null) {	if (LOG.isDebugEnabled()) {	
sasl client callback setting username 

throw new UnsupportedCallbackException(callback, "Unrecognized SASL client callback");	}	}	if (nc != null) {	if (LOG.isDebugEnabled()) {	}	nc.setName(userName);	}	if (pc != null) {	if (LOG.isDebugEnabled()) {	
sasl client callback setting userpassword 

}	nc.setName(userName);	}	if (pc != null) {	if (LOG.isDebugEnabled()) {	}	pc.setPassword(userPassword);	}	if (rc != null) {	if (LOG.isDebugEnabled()) {	
sasl client callback setting realm 

========================= hbase sample_150 =========================

private static TProtocolFactory getTProtocolFactory(boolean isCompact) {	if (isCompact) {	
using compact protocol 

private static TProtocolFactory getTProtocolFactory(boolean isCompact) {	if (isCompact) {	return new TCompactProtocol.Factory();	} else {	
using binary protocol 

private static TTransportFactory getTTransportFactory( SaslUtil.QualityOfProtection qop, String name, String host, boolean framed, int frameSize) {	if (framed) {	if (qop != null) {	throw new RuntimeException("Thrift server authentication" + " doesn't work with framed transport yet");	}	
using framed transport 

}	}	if (ac != null) {	String authid = ac.getAuthenticationID();	String authzid = ac.getAuthorizationID();	if (!authid.equals(authzid)) {	ac.setAuthorized(false);	} else {	ac.setAuthorized(true);	String userName = SecurityUtil.getUserFromPrincipal(authzid);	
effective user 

private static TServer getTNonBlockingServer(TProtocolFactory protocolFactory, TProcessor processor, TTransportFactory transportFactory, InetSocketAddress inetSocketAddress) throws TTransportException {	TNonblockingServerTransport serverTransport = new TNonblockingServerSocket(inetSocketAddress);	
starting hbase nonblocking thrift server on 

private static TServer getTHsHaServer(TProtocolFactory protocolFactory, TProcessor processor, TTransportFactory transportFactory, int workerThreads, int maxCallQueueSize, InetSocketAddress inetSocketAddress, ThriftMetrics metrics) throws TTransportException {	TNonblockingServerTransport serverTransport = new TNonblockingServerSocket(inetSocketAddress);	
starting hbase hsha thrift server on 

private static TServer getTThreadedSelectorServer(TProtocolFactory protocolFactory, TProcessor processor, TTransportFactory transportFactory, int workerThreads, int selectorThreads, int maxCallQueueSize, InetSocketAddress inetSocketAddress, ThriftMetrics metrics) throws TTransportException {	TNonblockingServerTransport serverTransport = new TNonblockingServerSocket(inetSocketAddress);	
starting hbase threadedselector thrift server on 

private static TServer getTThreadPoolServer(TProtocolFactory protocolFactory, TProcessor processor, TTransportFactory transportFactory, int workerThreads, InetSocketAddress inetSocketAddress, int backlog, int clientTimeout, ThriftMetrics metrics) throws TTransportException {	TServerTransport serverTransport = new TServerSocket( new TServerSocket.ServerSocketTransportArgs(). bindAddr(inetSocketAddress).backlog(backlog). clientTimeout(clientTimeout));	
starting hbase threadpool thrift server on 

protected static void registerFilters(Configuration conf) {	String[] filters = conf.getStrings("hbase.thrift.filters");	if(filters != null) {	for(String filterClass: filters) {	String[] filterPart = filterClass.split(":");	if(filterPart.length != 2) {	
invalid filter specification skipping 

int workerThreads = 0;	int selectorThreads = 0;	int maxCallQueueSize = -1;	if (checkArguments(cmd)) {	return 1;	}	String bindAddress = getBindAddress(conf, cmd);	if (cmd.hasOption("readonly")) {	conf.setBoolean("hbase.thrift.readonly", true);	if (log.isDebugEnabled()) {	
readonly set to true 

if (cmd.hasOption("s")) {	selectorThreads = Integer.parseInt(cmd.getOptionValue("s"));	}	if (cmd.hasOption("q")) {	maxCallQueueSize = Integer.parseInt(cmd.getOptionValue("q"));	}	try {	if (cmd.hasOption("infoport")) {	String val = cmd.getOptionValue("infoport");	conf.setInt("hbase.thrift.info.port", Integer.parseInt(val));	
web ui port set to 

}	if (cmd.hasOption("q")) {	maxCallQueueSize = Integer.parseInt(cmd.getOptionValue("q"));	}	try {	if (cmd.hasOption("infoport")) {	String val = cmd.getOptionValue("infoport");	conf.setInt("hbase.thrift.info.port", Integer.parseInt(val));	}	} catch (NumberFormatException e) {	
could not parse the value provided for the infoport option 

========================= hbase sample_783 =========================

public boolean filterRow() throws IOException {	try {	boolean result = dynamicLogicExpression.execute(columnToCurrentRowValueMap, valueFromQueryArray);	columnToCurrentRowValueMap = null;	return !result;	} catch (Throwable e) {	
error running dynamic logic on row 

========================= hbase sample_629 =========================

protected void killMaster(ServerName server) throws IOException {	
killing master 

protected void killMaster(ServerName server) throws IOException {	cluster.killMaster(server);	cluster.waitForMasterToStop(server, killMasterTimeout);	
killed master server 

protected void startMaster(ServerName server) throws IOException {	
starting master 

protected void startMaster(ServerName server) throws IOException {	cluster.startMaster(server.getHostname(), server.getPort());	cluster.waitForActiveAndReadyMaster(startMasterTimeout);	
started master 

protected void killRs(ServerName server) throws IOException {	
killing region server 

protected void killRs(ServerName server) throws IOException {	cluster.killRegionServer(server);	cluster.waitForRegionServerToStop(server, killRsTimeout);	
killed region server reported num of rs 

protected void startRs(ServerName server) throws IOException {	
starting region server 

protected void startRs(ServerName server) throws IOException {	cluster.startRegionServer(server.getHostname(), server.getPort());	cluster.waitForRegionServerToStart(server.getHostname(), server.getPort(), startRsTimeout);	
started region server reported num of rs 

protected void killZKNode(ServerName server) throws IOException {	
killing zookeeper node 

protected void killZKNode(ServerName server) throws IOException {	cluster.killZkNode(server);	cluster.waitForZkNodeToStop(server, killZkNodeTimeout);	
killed zookeeper node reported num of rs 

protected void startZKNode(ServerName server) throws IOException {	
starting zookeeper node 

protected void startZKNode(ServerName server) throws IOException {	cluster.startZkNode(server.getHostname(), server.getPort());	cluster.waitForZkNodeToStart(server, startZkNodeTimeout);	
started zookeeper node 

protected void killDataNode(ServerName server) throws IOException {	
killing datanode 

protected void killDataNode(ServerName server) throws IOException {	cluster.killDataNode(server);	cluster.waitForDataNodeToStop(server, killDataNodeTimeout);	
killed datanode reported num of rs 

protected void startDataNode(ServerName server) throws IOException {	
starting datanode 

protected void startDataNode(ServerName server) throws IOException {	cluster.startDataNode(server);	cluster.waitForDataNodeToStart(server, startDataNodeTimeout);	
started datanode 

protected void unbalanceRegions(ClusterMetrics clusterStatus, List<ServerName> fromServers, List<ServerName> toServers, double fractionOfRegions) throws Exception {	List<byte[]> victimRegions = new LinkedList<>();	for (Map.Entry<ServerName, ServerMetrics> entry : clusterStatus.getLiveServerMetrics().entrySet()) {	ServerName sn = entry.getKey();	ServerMetrics serverLoad = entry.getValue();	List<byte[]> regions = new LinkedList<>(serverLoad.getRegionMetrics().keySet());	int victimRegionCount = (int)Math.ceil(fractionOfRegions * regions.size());	
removing regions from 

ServerName sn = entry.getKey();	ServerMetrics serverLoad = entry.getValue();	List<byte[]> regions = new LinkedList<>(serverLoad.getRegionMetrics().keySet());	int victimRegionCount = (int)Math.ceil(fractionOfRegions * regions.size());	for (int i = 0; i < victimRegionCount; ++i) {	int victimIx = RandomUtils.nextInt(0, regions.size());	String regionId = HRegionInfo.encodeRegionName(regions.remove(victimIx));	victimRegions.add(Bytes.toBytes(regionId));	}	}	
moving regions from servers to different servers 

protected void forceBalancer() throws Exception {	Admin admin = this.context.getHBaseIntegrationTestingUtility().getAdmin();	boolean result = false;	try {	result = admin.balancer();	} catch (Exception e) {	
got exception while doing balance 

protected void forceBalancer() throws Exception {	Admin admin = this.context.getHBaseIntegrationTestingUtility().getAdmin();	boolean result = false;	try {	result = admin.balancer();	} catch (Exception e) {	}	if (!result) {	
balancer didn t succeed 

========================= hbase sample_3323 =========================

public void testRpcWithWriteThread() throws IOException, InterruptedException {	
starting test 

public void testRpcWithChaosMonkey(boolean isSyncClient) throws Throwable {	
starting test 

public void testRpcWithChaosMonkey(boolean isSyncClient) throws Throwable {	Cluster cluster = new Cluster(10, 100);	for (int i = 0; i < 10; i++) {	cluster.startServer();	}	ArrayList<SimpleClient> clients = new ArrayList<>(30);	AbstractRpcClient<?> rpcClient = createRpcClient(conf, isSyncClient);	for (int i = 0; i < 30; i++) {	String clientId = "client_" + i + "_";	
starting client 

cluster.startServer();	}	ArrayList<SimpleClient> clients = new ArrayList<>(30);	AbstractRpcClient<?> rpcClient = createRpcClient(conf, isSyncClient);	for (int i = 0; i < 30; i++) {	String clientId = "client_" + i + "_";	SimpleClient client = new SimpleClient(cluster, rpcClient, clientId);	client.start();	clients.add(client);	}	
starting minichaosmonkey 

AbstractRpcClient<?> rpcClient = createRpcClient(conf, isSyncClient);	for (int i = 0; i < 30; i++) {	String clientId = "client_" + i + "_";	SimpleClient client = new SimpleClient(cluster, rpcClient, clientId);	client.start();	clients.add(client);	}	MiniChaosMonkey cm = new MiniChaosMonkey(cluster);	cm.start();	Threads.sleep(30000);	
stopping minichaosmonkey 

SimpleClient client = new SimpleClient(cluster, rpcClient, clientId);	client.start();	clients.add(client);	}	MiniChaosMonkey cm = new MiniChaosMonkey(cluster);	cm.start();	Threads.sleep(30000);	cm.stopRunning();	cm.join();	cm.rethrowException();	
stopping clients 

client.start();	clients.add(client);	}	MiniChaosMonkey cm = new MiniChaosMonkey(cluster);	cm.start();	Threads.sleep(30000);	cm.stopRunning();	cm.join();	cm.rethrowException();	for (SimpleClient client : clients) {	
stopping client 

client.start();	clients.add(client);	}	MiniChaosMonkey cm = new MiniChaosMonkey(cluster);	cm.start();	Threads.sleep(30000);	cm.stopRunning();	cm.join();	cm.rethrowException();	for (SimpleClient client : clients) {	
numcalls 

Threads.sleep(30000);	cm.stopRunning();	cm.join();	cm.rethrowException();	for (SimpleClient client : clients) {	client.stopRunning();	client.join();	client.rethrowException();	assertTrue(client.numCalls > 10);	}	
stopping rpcclient 

cm.stopRunning();	cm.join();	cm.rethrowException();	for (SimpleClient client : clients) {	client.stopRunning();	client.join();	client.rethrowException();	assertTrue(client.numCalls > 10);	}	rpcClient.close();	
stopping cluster 

========================= hbase sample_3266 =========================

List<Put> puts = new ArrayList<>();	for (long i = 0; i < numRows; i++) {	byte[] rowKey = longToByteArrayKey(i);	Put put = new Put(rowKey);	byte[] value = rowKey;	put.addColumn(FAMILY, QUALIFIER, value);	puts.add(put);	}	try (Table table = connection.getTable(TableName.valueOf(tableName))) {	table.put(puts);	
written all puts 

futures.add(service.submit(new Callable<Boolean>() {	public Boolean call() throws Exception {	try (Table table = connection.getTable(TableName.valueOf(tableName))) {	Thread.sleep(Math.abs(random.nextInt()) % 250);	byte[] row = longToByteArrayKey(Math.abs(random.nextLong()) % numRows);	Get g = new Get(row);	g.addColumn(FAMILY, QUALIFIER);	try {	table.get(g);	} catch (Exception e) {	
get failed 

return false;	} finally {	long enTime = System.currentTimeMillis();	totalTimeTaken.addAndGet(enTime - startTime);	if ((enTime - startTime) >= SLEEPTIME) {	numBlockedWorkers.addAndGet(1);	}	}	return true;	} catch (Exception e) {	
caught unknown exception 

int numThreadsReturnedTrue = 0;	int numThreadsThrewExceptions = 0;	for (Future<Boolean> f : futures) {	try {	numThreadsReturnedTrue += f.get() ? 1 : 0;	numThreadsReturnedFalse += f.get() ? 0 : 1;	} catch (Exception e) {	numThreadsThrewExceptions++;	}	}	
numthreadsreturnedfalse numthreadsreturnedtrue numthreadsthrewexceptions numfailedthreads numsuccessfullthreads numblockedworkers totaltimewaited numpffes 

========================= hbase sample_2027 =========================

public void tearDown() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testWalRecoverLease() throws Exception {	final ProcedureStore masterStore = getMasterProcedureExecutor().getStore();	assertTrue("expected WALStore for this test", masterStore instanceof WALProcedureStore);	HMaster firstMaster = UTIL.getHBaseCluster().getMaster();	final CountDownLatch masterStoreAbort = new CountDownLatch(1);	masterStore.registerListener(new ProcedureStore.ProcedureStoreListener() {	public void postSync() {}	public void abortProcess() {	
abort store of master 

}	});	HMaster backupMaster3 = Mockito.mock(HMaster.class);	Mockito.doReturn(firstMaster.getConfiguration()).when(backupMaster3).getConfiguration();	Mockito.doReturn(true).when(backupMaster3).isActiveMaster();	final WALProcedureStore backupStore3 = new WALProcedureStore(firstMaster.getConfiguration(), ((WALProcedureStore)masterStore).getWALDir(), null, new MasterProcedureEnv.WALStoreLeaseRecovery(backupMaster3));	final CountDownLatch backupStore3Abort = new CountDownLatch(1);	backupStore3.registerListener(new ProcedureStore.ProcedureStoreListener() {	public void postSync() {}	public void abortProcess() {	
abort store of 

public void postSync() {}	public void abortProcess() {	backupStore3Abort.countDown();	backupStore3.stop(true);	}	});	backupStore3.start(1);	backupStore3.recoverLease();	TableDescriptor htd = MasterProcedureTestingUtility.createHTD(TableName.valueOf(name.getMethodName()), "f");	RegionInfo[] regions = ModifyRegionUtils.createRegionInfos(htd, null);	
submit proc 

}	});	backupStore3.start(1);	backupStore3.recoverLease();	TableDescriptor htd = MasterProcedureTestingUtility.createHTD(TableName.valueOf(name.getMethodName()), "f");	RegionInfo[] regions = ModifyRegionUtils.createRegionInfos(htd, null);	try {	getMasterProcedureExecutor().submitProcedure( new CreateTableProcedure(getMasterProcedureExecutor().getEnvironment(), htd, regions));	fail("expected RuntimeException 'sync aborted'");	} catch (RuntimeException e) {	
got 

});	backupStore3.start(1);	backupStore3.recoverLease();	TableDescriptor htd = MasterProcedureTestingUtility.createHTD(TableName.valueOf(name.getMethodName()), "f");	RegionInfo[] regions = ModifyRegionUtils.createRegionInfos(htd, null);	try {	getMasterProcedureExecutor().submitProcedure( new CreateTableProcedure(getMasterProcedureExecutor().getEnvironment(), htd, regions));	fail("expected RuntimeException 'sync aborted'");	} catch (RuntimeException e) {	}	
wait master store abort 

backupStore3.start(1);	backupStore3.recoverLease();	TableDescriptor htd = MasterProcedureTestingUtility.createHTD(TableName.valueOf(name.getMethodName()), "f");	RegionInfo[] regions = ModifyRegionUtils.createRegionInfos(htd, null);	try {	getMasterProcedureExecutor().submitProcedure( new CreateTableProcedure(getMasterProcedureExecutor().getEnvironment(), htd, regions));	fail("expected RuntimeException 'sync aborted'");	} catch (RuntimeException e) {	}	masterStoreAbort.await();	
wait backup master to startup 

TableDescriptor htd = MasterProcedureTestingUtility.createHTD(TableName.valueOf(name.getMethodName()), "f");	RegionInfo[] regions = ModifyRegionUtils.createRegionInfos(htd, null);	try {	getMasterProcedureExecutor().submitProcedure( new CreateTableProcedure(getMasterProcedureExecutor().getEnvironment(), htd, regions));	fail("expected RuntimeException 'sync aborted'");	} catch (RuntimeException e) {	}	masterStoreAbort.await();	MasterProcedureTestingUtility.waitBackupMaster(UTIL, firstMaster);	assertEquals(true, firstMaster.isStopped());	
wait the store to abort 

} catch (RuntimeException e) {	}	masterStoreAbort.await();	MasterProcedureTestingUtility.waitBackupMaster(UTIL, firstMaster);	assertEquals(true, firstMaster.isStopped());	backupStore3.getStoreTracker().setDeleted(1, false);	try {	backupStore3.delete(1);	fail("expected RuntimeException 'sync aborted'");	} catch (RuntimeException e) {	
got 

public void testWALfencing(boolean walRolls) throws IOException {	final ProcedureStore procStore = getMasterProcedureExecutor().getStore();	assertTrue("expected WALStore for this test", procStore instanceof WALProcedureStore);	HMaster firstMaster = UTIL.getHBaseCluster().getMaster();	firstMaster.getConfiguration().setLong(WALProcedureStore.ROLL_THRESHOLD_CONF_KEY, 1);	HMaster backupMaster3 = Mockito.mock(HMaster.class);	Mockito.doReturn(firstMaster.getConfiguration()).when(backupMaster3).getConfiguration();	Mockito.doReturn(true).when(backupMaster3).isActiveMaster();	final WALProcedureStore procStore2 = new WALProcedureStore(firstMaster.getConfiguration(), ((WALProcedureStore)procStore).getWALDir(), null, new MasterProcedureEnv.WALStoreLeaseRecovery(backupMaster3));	
starting new walprocedurestore 

assertTrue("expected WALStore for this test", procStore instanceof WALProcedureStore);	HMaster firstMaster = UTIL.getHBaseCluster().getMaster();	firstMaster.getConfiguration().setLong(WALProcedureStore.ROLL_THRESHOLD_CONF_KEY, 1);	HMaster backupMaster3 = Mockito.mock(HMaster.class);	Mockito.doReturn(firstMaster.getConfiguration()).when(backupMaster3).getConfiguration();	Mockito.doReturn(true).when(backupMaster3).isActiveMaster();	final WALProcedureStore procStore2 = new WALProcedureStore(firstMaster.getConfiguration(), ((WALProcedureStore)procStore).getWALDir(), null, new MasterProcedureEnv.WALStoreLeaseRecovery(backupMaster3));	procStore2.start(1);	procStore2.recoverLease();	if (walRolls) {	
inserting into second walprocedurestore causing wal rolls 

final WALProcedureStore procStore2 = new WALProcedureStore(firstMaster.getConfiguration(), ((WALProcedureStore)procStore).getWALDir(), null, new MasterProcedureEnv.WALStoreLeaseRecovery(backupMaster3));	procStore2.start(1);	procStore2.recoverLease();	if (walRolls) {	for (int i = 0; i < 512; i++) {	Procedure proc2 = new TestProcedure(i);	procStore2.insert(proc2, null);	procStore2.delete(proc2.getProcId());	}	}	
inserting into first walprocedurestore 

for (int i = 0; i < 512; i++) {	Procedure proc2 = new TestProcedure(i);	procStore2.insert(proc2, null);	procStore2.delete(proc2.getProcId());	}	}	try {	procStore.insert(new TestProcedure(11), null);	fail("Inserting into Procedure Store should have failed");	} catch (Exception ex) {	
received expected exception 

========================= hbase sample_1826 =========================

public void testFullBackupMultipleCommand() throws Exception {	
test full backup on a multiple tables with data command line 

int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	List<BackupInfo> backups = table.getBackupHistory();	int after = table.getBackupHistory().size();	assertTrue(after == before + 1);	for (BackupInfo data : backups) {	String backupId = data.getBackupId();	assertTrue(checkSucceeded(backupId));	}	}	
backup complete 

========================= hbase sample_557 =========================

private RegionInfo getAndCheckSingleTableRegion(final List<HRegion> regions) throws IOException, InterruptedException {	assertEquals(1, regions.size());	RegionInfo hri = regions.get(0).getRegionInfo();	try {	cluster.getMaster().getAssignmentManager().waitForAssignment(hri, 600000);	} catch (NoSuchProcedureException e) {	
presume the procedure has been cleaned up so just proceed 

t.close();	this.admin.setBalancerRunning(false, true);	master.setCatalogJanitorEnabled(false);	final HRegion region = findSplittableRegion(regions);	assertTrue("not able to find a splittable region", region != null);	master.getMasterCoprocessorHost().load( FailingSplitMasterObserver.class, Coprocessor.PRIORITY_USER, master.getConfiguration());	this.admin.splitRegion(region.getRegionInfo().getRegionName(), new byte[] {42});	FailingSplitMasterObserver observer = master.getMasterCoprocessorHost().findCoprocessor(FailingSplitMasterObserver.class);	assertNotNull(observer);	observer.latch.await();	
waiting for region to come out of rit 

cluster.getMaster().setCatalogJanitorEnabled(false);	try {	TESTING_UTIL.loadTable(t, HConstants.CATALOG_FAMILY);	HRegionServer server = cluster.getRegionServer(tableRegionIndex);	printOutRegions(server, "Initial regions: ");	int regionCount = cluster.getRegions(hri.getTable()).size();	split(hri, server, regionCount);	List<HRegion> daughters = checkAndGetDaughters(tableName);	regionCount = cluster.getRegions(hri.getTable()).size();	RegionInfo daughter = daughters.get(0).getRegionInfo();	
daughter we are going to split 

split(hri, server, regionCount);	List<HRegion> daughters = checkAndGetDaughters(tableName);	regionCount = cluster.getRegions(hri.getTable()).size();	RegionInfo daughter = daughters.get(0).getRegionInfo();	this.admin.compactRegion(daughter.getRegionName());	daughters = cluster.getRegions(tableName);	HRegion daughterRegion = null;	for (HRegion r: daughters) {	if (RegionInfo.COMPARATOR.compare(r.getRegionInfo(), daughter) == 0) {	daughterRegion = r;	
found matching hri 

daughterRegion = r;	break;	}	}	assertTrue(daughterRegion != null);	for (int i=0; i<100; i++) {	if (!daughterRegion.hasReferences()) break;	Threads.sleep(100);	}	assertFalse("Waiting for reference to be compacted", daughterRegion.hasReferences());	
daughter hri before split has been compacted 

}	assertTrue(daughterRegion != null);	for (int i=0; i<100; i++) {	if (!daughterRegion.hasReferences()) break;	Threads.sleep(100);	}	assertFalse("Waiting for reference to be compacted", daughterRegion.hasReferences());	split(daughter, server, regionCount);	daughters = cluster.getRegions(tableName);	for (HRegion d: daughters) {	
regions before crash 

assertFalse("Waiting for reference to be compacted", daughterRegion.hasReferences());	split(daughter, server, regionCount);	daughters = cluster.getRegions(tableName);	for (HRegion d: daughters) {	}	cluster.abortRegionServer(tableRegionIndex);	waitUntilRegionServerDead();	awaitDaughters(tableName, daughters.size());	regions = cluster.getRegions(tableName);	for (HRegion d: daughters) {	
regions after crash 

}	if (daughters.size() != regions.size()) {	LOG.info("Daughters=" + daughters.size() + ", regions=" + regions.size());	}	assertEquals(daughters.size(), regions.size());	for (HRegion r: regions) {	LOG.info("Regions post crash " + r + ", contains=" + daughters.contains(r));	assertTrue("Missing region post crash " + r, daughters.contains(r));	}	} finally {	
EXITING 

table.put(p);	p = new Put("row8".getBytes());	p.addColumn("col".getBytes(), "ql".getBytes(), "val".getBytes());	table.put(p);	admin.flush(userTableName);	admin.splitRegion(hRegionInfo.getRegionName(), "row7".getBytes());	regionsOfTable = cluster.getMaster() .getAssignmentManager().getRegionStates() .getRegionsOfTable(userTableName);	while (regionsOfTable.size() != 2) {	Thread.sleep(1000);	regionsOfTable = cluster.getMaster() .getAssignmentManager().getRegionStates() .getRegionsOfTable(userTableName);	
waiting regions to be available got 

final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor htd = TESTING_UTIL.createTableDescriptor(name.getMethodName());	htd.setRegionReplication(2);	htd.addCoprocessor(SlowMeCopro.class.getName());	Table t = TESTING_UTIL.createTable(htd, new byte[][]{Bytes.toBytes("cf")}, null);	List<HRegion> oldRegions;	do {	oldRegions = cluster.getRegions(tableName);	Thread.sleep(10);	} while (oldRegions.size() != 2);	
oldregion 

assertTrue("not able to find a splittable region", region != null);	try {	requestSplitRegion(regionServer, region, Bytes.toBytes("row2"));	} catch (IOException e) {	e.printStackTrace();	fail("Split execution should have succeeded with no exceptions thrown " + e);	}	List<HRegion> newRegions;	do {	newRegions = cluster.getRegions(tableName);	
newregion 

newRegions = cluster.getRegions(tableName);	Thread.sleep(1000);	} while ((newRegions.contains(oldRegions.get(0)) || newRegions.contains(oldRegions.get(1))) || newRegions.size() != 4);	tableExists = MetaTableAccessor.tableExists(regionServer.getConnection(), tableName);	assertEquals("The specified table should be present.", true, tableExists);	byte[] b1 = "row1".getBytes();	Get g = new Get(b1);	g.setConsistency(Consistency.STRONG);	Result r = t.get(g);	Assert.assertFalse(r.isStale());	
exists stale after flush done 

List<HRegion> daughters = cluster.getRegions(tableName);	assertEquals(2, daughters.size());	HBaseFsck.debugLsr(conf, new Path("/"));	Map<String, Path> storefilesAfter = FSUtils.getTableStoreFilePathMap(null, fs, rootDir, tableName);	assertEquals("Expected nothing but found " + storefilesAfter.toString(), storefilesAfter.size(), 0);	hri = region.getRegionInfo();	AssignmentManager am = cluster.getMaster().getAssignmentManager();	RegionStates regionStates = am.getRegionStates();	long start = EnvironmentEdgeManager.currentTime();	while (!regionStates.isRegionInState(hri, State.SPLIT)) {	
waiting for split state on 

private void split(final RegionInfo hri, final HRegionServer server, final int regionCount) throws IOException, InterruptedException {	admin.splitRegion(hri.getRegionName());	for (int i = 0; cluster.getRegions(hri.getTable()).size() <= regionCount && i < 60; i++) {	
waiting on region to split 

private void waitUntilRegionServerDead() throws InterruptedException, IOException {	for (int i=0; (cluster.getMaster().getClusterMetrics() .getLiveServerMetrics().size() > NB_SERVERS || cluster.getLiveRegionServerThreads().size() > NB_SERVERS) && i<100; i++) {	
waiting on server to go down 

private void awaitDaughters(TableName tableName, int numDaughters) throws InterruptedException {	for (int i = 0; cluster.getRegions(tableName).size() < numDaughters && i < 60; i++) {	
waiting for repair to happen 

========================= hbase sample_1719 =========================

protected void chore() {	try {	balancer.setClusterMetrics(master.getClusterMetricsWithoutCoprocessor());	} catch (InterruptedIOException e) {	
ignoring interruption 

========================= hbase sample_2837 =========================

public void testFromClientSideWhileSplitting() throws Throwable {	
starting testfromclientsidewhilesplitting 

========================= hbase sample_1718 =========================

final WALFactory walfactory = new WALFactory(conf, null, getName());	WAL log = walfactory.getWAL(info);	long ts = System.currentTimeMillis();	WALEdit edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("1"), ts, value));	log.append(info, getWalKeyImpl(ts, scopes), edit, true);	edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("2"), ts+1, value));	log.append(info, getWalKeyImpl(ts+1, scopes), edit, true);	log.sync();	
before wal roll 

WAL log = walfactory.getWAL(info);	long ts = System.currentTimeMillis();	WALEdit edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("1"), ts, value));	log.append(info, getWalKeyImpl(ts, scopes), edit, true);	edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("2"), ts+1, value));	log.append(info, getWalKeyImpl(ts+1, scopes), edit, true);	log.sync();	log.rollWriter();	
past wal roll 

long ts1 = System.currentTimeMillis();	edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("3"), ts1+1, value));	log.append(info, getWalKeyImpl(ts1+1, scopes), edit, true);	edit = new WALEdit();	edit.add(new KeyValue(rowName, family, Bytes.toBytes("4"), ts1+2, value));	log.append(info, getWalKeyImpl(ts1+2, scopes), edit, true);	log.sync();	log.shutdown();	walfactory.shutdown();	
closed wal 

========================= hbase sample_3375 =========================

public void run() {	if (!sleep()) {	
interrupted while sleeping for expected sleep time ms 

========================= hbase sample_385 =========================

public static WALKeyImpl writeCompactionMarker(WAL wal, NavigableMap<byte[], Integer> replicationScope, RegionInfo hri, final CompactionDescriptor c, MultiVersionConcurrencyControl mvcc) throws IOException {	WALKeyImpl walKey = writeMarker(wal, replicationScope, hri, WALEdit.createCompaction(hri, c), mvcc);	if (LOG.isTraceEnabled()) {	
appended compaction marker 

public static WALKeyImpl writeFlushMarker(WAL wal, NavigableMap<byte[], Integer> replicationScope, RegionInfo hri, final FlushDescriptor f, boolean sync, MultiVersionConcurrencyControl mvcc) throws IOException {	WALKeyImpl walKey = doFullAppendTransaction(wal, replicationScope, hri, WALEdit.createFlushWALEdit(hri, f), mvcc, sync);	if (LOG.isTraceEnabled()) {	
appended flush marker 

public static WALKeyImpl writeRegionEventMarker(WAL wal, NavigableMap<byte[], Integer> replicationScope, RegionInfo hri, final RegionEventDescriptor r, final MultiVersionConcurrencyControl mvcc) throws IOException {	WALKeyImpl walKey = writeMarker(wal, replicationScope, hri, WALEdit.createRegionEventWALEdit(hri, r), mvcc);	if (LOG.isTraceEnabled()) {	
appended region event marker 

public static WALKeyImpl writeBulkLoadMarkerAndSync(final WAL wal, final NavigableMap<byte[], Integer> replicationScope, final RegionInfo hri, final WALProtos.BulkLoadDescriptor desc, final MultiVersionConcurrencyControl mvcc) throws IOException {	WALKeyImpl walKey = writeMarker(wal, replicationScope, hri, WALEdit.createBulkLoadEvent(hri, desc), mvcc);	if (LOG.isTraceEnabled()) {	
appended bulk load marker 

========================= hbase sample_2564 =========================

protected abstract void execute(Table table) throws IOException;	public void testRpcTimeout() throws IOException {	Configuration c = new Configuration(TEST_UTIL.getConfiguration());	try (Table table = TEST_UTIL.getConnection().getTableBuilder(tableName, null) .setRpcTimeout(SleepCoprocessor.SLEEP_TIME / 2) .setReadRpcTimeout(SleepCoprocessor.SLEEP_TIME / 2) .setWriteRpcTimeout(SleepCoprocessor.SLEEP_TIME / 2) .setOperationTimeout(SleepCoprocessor.SLEEP_TIME * 100).build()) {	execute(table);	fail("Get should not have succeeded");	} catch (RetriesExhaustedException e) {	
we received an exception as expected 

}	c.setInt(HConstants.HBASE_RPC_TIMEOUT_KEY, SleepCoprocessor.SLEEP_TIME / 2);	c.setInt(HConstants.HBASE_RPC_READ_TIMEOUT_KEY, SleepCoprocessor.SLEEP_TIME / 2);	c.setInt(HConstants.HBASE_RPC_WRITE_TIMEOUT_KEY, SleepCoprocessor.SLEEP_TIME / 2);	c.setInt(HConstants.HBASE_CLIENT_OPERATION_TIMEOUT, SleepCoprocessor.SLEEP_TIME * 100);	try (Connection conn = ConnectionFactory.createConnection(c)) {	try (Table table = conn.getTable(tableName)) {	execute(table);	fail("Get should not have succeeded");	} catch (RetriesExhaustedException e) {	
we received an exception as expected 

========================= hbase sample_2071 =========================

protected void reconnect(KeeperException ke) {	if (ke instanceof ConnectionLossException || ke instanceof SessionExpiredException || ke instanceof AuthFailedException) {	String clusterKey = ctx.getPeerConfig().getClusterKey();	
lost the zookeeper connection for peer 

protected void reconnect(KeeperException ke) {	if (ke instanceof ConnectionLossException || ke instanceof SessionExpiredException || ke instanceof AuthFailedException) {	String clusterKey = ctx.getPeerConfig().getClusterKey();	try {	reloadZkWatcher();	} catch (IOException io) {	
creation of zookeeperwatcher failed for peer 

public void abort(String why, Throwable e) {	
the hbasereplicationendpoint corresponding to peer was aborted for the following reason s 

public synchronized List<ServerName> getRegionServers() {	try {	setRegionServers(fetchSlavesAddresses(this.getZkw()));	} catch (KeeperException ke) {	if (LOG.isDebugEnabled()) {	
fetch slaves addresses failed 

public synchronized void nodeChildrenChanged(String path) {	if (path.equals(regionServerListNode)) {	try {	
detected change to peer region servers fetching updated list 

public synchronized void nodeChildrenChanged(String path) {	if (path.equals(regionServerListNode)) {	try {	replicationEndpoint.setRegionServers(fetchSlavesAddresses(replicationEndpoint.getZkw()));	} catch (KeeperException e) {	
error reading slave addresses 

========================= hbase sample_2972 =========================

scanner = heap.poll();	if (scanner == null) {	current = null;	}	}	} catch (Exception e) {	if (scanner != null) {	try {	scanner.close();	} catch (Exception ce) {	
close keyvaluescanner error 

========================= hbase sample_2708 =========================

public synchronized void threadFailed(Throwable t) {	if (err == null) err = t;	
failed 

========================= hbase sample_1574 =========================

if (destination == this) {	throw new IllegalArgumentException( "A BlockingQueue cannot drain to itself.");	}	List<Call> drained = new ArrayList<>();	underlyingQueue.drainTo(drained, maxElements);	for (Call r : drained) {	updateMetrics(r);	}	destination.addAll(drained);	int sz = drained.size();	
elements drained 

========================= hbase sample_805 =========================

if (nsLimiter) {	isBypass &= quotaCache.getNamespaceLimiter(table.getNamespaceAsString()).isBypass();	}	if (isBypass != bypass) {	envEdge.incValue(100);	isUpdated = false;	break;	}	}	}	
QuotaCache 

========================= hbase sample_1431 =========================

MultiRowRangeFilter filter1 = new MultiRowRangeFilter(ranges1);	List<RowRange> ranges2 = new ArrayList<>();	ranges2.add(new RowRange(Bytes.toBytes(15), true, Bytes.toBytes(20), false));	ranges2.add(new RowRange(Bytes.toBytes(9985), true, Bytes.toBytes(9990), false));	MultiRowRangeFilter filter2 = new MultiRowRangeFilter(ranges2);	FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);	filterList.addFilter(filter1);	filterList.addFilter(filter2);	scan.setFilter(filterList);	int resultsSize = getResultsSize(ht, scan);	
found results 

FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);	filterList.addFilter(filter1);	filterList.addFilter(filter2);	scan.setFilter(filterList);	int resultsSize = getResultsSize(ht, scan);	List<Cell> results1 = getScanResult(Bytes.toBytes(10), Bytes.toBytes(20), ht);	List<Cell> results2 = getScanResult(Bytes.toBytes(9980), Bytes.toBytes(9990), ht);	assertEquals(results1.size() + results2.size(), resultsSize);	long blocksEnd = getBlkAccessCount();	long diff = blocksEnd - blocksStart;	
diff in number of blocks 

========================= hbase sample_1962 =========================

public void testIncBackupRestore() throws Exception {	int ADD_ROWS = 99;	
create full backup image for all tables 

Connection conn = ConnectionFactory.createConnection(conf1);	int NB_ROWS_FAM3 = 6;	insertIntoTable(conn, table1, fam3Name, 3, NB_ROWS_FAM3).close();	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	
writing rows to 

insertIntoTable(conn, table1, fam3Name, 3, NB_ROWS_FAM3).close();	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH + ADD_ROWS + NB_ROWS_FAM3);	t1.close();	
written rows to 

t1.close();	HTable t2 = (HTable) conn.getTable(table2);	Put p2;	for (int i = 0; i < 5; i++) {	p2 = new Put(Bytes.toBytes("row-t2" + i));	p2.addColumn(famName, qualName, Bytes.toBytes("val" + i));	t2.put(p2);	}	Assert.assertEquals(TEST_UTIL.countRows(t2), NB_ROWS_IN_BATCH + 5);	t2.close();	
written rows to 

private void incrementalBackupWithFailures() throws Exception {	conf1.set(TableBackupClient.BACKUP_CLIENT_IMPL_CLASS, IncrementalTableBackupClientForTest.class.getName());	int maxStage = Stage.values().length -1;	for (int stage = 0; stage <= maxStage; stage++) {	
running stage 

========================= hbase sample_556 =========================

Admin admin = util.getAdmin();	boolean major = RandomUtils.nextInt(0, 100) < majorRatio;	LOG.info("Performing action: Compact table " + tableName + ", major=" + major);	try {	if (major) {	admin.majorCompact(tableName);	} else {	admin.compact(tableName);	}	} catch (Exception ex) {	
compaction failed might be caused by other chaos 

========================= hbase sample_3322 =========================

protected void chore() {	try {	master.normalizeRegions();	} catch (IOException e) {	
failed to normalize regions 

========================= hbase sample_2860 =========================

if (cellBlock != null) {	for (int i = 0; i < cellBlockBufferSize; i++) {	responseBufs[i + 1] = cellBlock.get(i);	}	}	bc = new BufferChain(responseBufs);	if (connection.useWrap) {	bc = wrapWithSasl(bc);	}	} catch (IOException e) {	
exception while creating response 

if (connection.useWrap) {	bc = wrapWithSasl(bc);	}	} catch (IOException e) {	}	this.response = bc;	if (this.rpcCallback != null) {	try {	this.rpcCallback.run();	} catch (Exception e) {	
exception while running the rpc callback 

if (connection.useCryptoAesWrap) {	synchronized (connection.cryptoAES) {	token = connection.cryptoAES.wrap(responseBytes, 0, responseBytes.length);	}	} else {	synchronized (connection.saslServer) {	token = connection.saslServer.wrap(responseBytes, 0, responseBytes.length);	}	}	if (RpcServer.LOG.isTraceEnabled()) {	
adding saslserver wrapped token of size as call response 

========================= hbase sample_2925 =========================

for (byte invalidVersion : new byte[] { HFile.MIN_FORMAT_VERSION - 1, HFile.MAX_FORMAT_VERSION + 1}) {	bytes[bytes.length - 1] = invalidVersion;	writeTrailer(trailerPath, null, bytes);	try {	readTrailer(trailerPath);	fail("Exception expected");	} catch (IllegalArgumentException ex) {	String msg = ex.getMessage();	String cleanMsg = msg.replaceAll( "^(java(\\.[a-zA-Z]+)+:\\s+)?|\\s+\\(.*\\)\\s*$", "");	assertEquals("Actual exception message is \"" + msg + "\".\n" + "Cleaned-up message", "Invalid HFile version: " + invalidVersion, cleanMsg);	
got an expected exception 

========================= hbase sample_1489 =========================

public int run(String[] args) throws InterruptedException, ExecutionException, TimeoutException {	final BufferedMutator.ExceptionListener listener = new BufferedMutator.ExceptionListener() {	public void onException(RetriesExhaustedWithDetailsException e, BufferedMutator mutator) {	for (int i = 0; i < e.getNumExceptions(); i++) {	
failed to sent put 

mutator.mutate(p);	return null;	}	}));	}	for (Future<Void> f : futures) {	f.get(5, TimeUnit.MINUTES);	}	workerPool.shutdown();	} catch (IOException e) {	
exception while creating destroying connection or bufferedmutator 

========================= hbase sample_1173 =========================

public HTableDescriptor[] deleteTables(Pattern pattern) throws IOException {	List<HTableDescriptor> failed = new LinkedList<>();	for (HTableDescriptor table : listTables(pattern)) {	try {	deleteTable(table.getTableName());	} catch (IOException ex) {	
failed to delete table 

public Future<Void> truncateTableAsync(final TableName tableName, final boolean preserveSplits) throws IOException {	TruncateTableResponse response = executeCallable(new MasterCallable<TruncateTableResponse>(getConnection(), getRpcControllerFactory()) {	protected TruncateTableResponse rpcCall() throws Exception {	setPriority(tableName);	
started truncating 

public Future<Void> enableTableAsync(final TableName tableName) throws IOException {	TableName.isLegalFullyQualifiedTableName(tableName.getName());	EnableTableResponse response = executeCallable( new MasterCallable<EnableTableResponse>(getConnection(), getRpcControllerFactory()) {	protected EnableTableResponse rpcCall() throws Exception {	setPriority(tableName);	
started enable of 

public HTableDescriptor[] enableTables(Pattern pattern) throws IOException {	List<HTableDescriptor> failed = new LinkedList<>();	for (HTableDescriptor table : listTables(pattern)) {	if (isTableDisabled(table.getTableName())) {	try {	enableTable(table.getTableName());	} catch (IOException ex) {	
failed to enable table 

public Future<Void> disableTableAsync(final TableName tableName) throws IOException {	TableName.isLegalFullyQualifiedTableName(tableName.getName());	DisableTableResponse response = executeCallable( new MasterCallable<DisableTableResponse>(getConnection(), getRpcControllerFactory()) {	protected DisableTableResponse rpcCall() throws Exception {	setPriority(tableName);	
started disable of 

public HTableDescriptor[] disableTables(Pattern pattern) throws IOException {	List<HTableDescriptor> failed = new LinkedList<>();	for (HTableDescriptor table : listTables(pattern)) {	if (isTableEnabled(table.getTableName())) {	try {	disableTable(table.getTableName());	} catch (IOException ex) {	
failed to disable table 

public void flush(final TableName tableName) throws IOException {	checkTableExists(tableName);	if (isTableDisabled(tableName)) {	
table is disabled 

case NORMAL: checkTableExists(tableName);	for (HRegionLocation loc :connection.locateRegions(tableName, false, false)) {	ServerName sn = loc.getServerName();	if (sn == null) {	continue;	}	try {	compact(this.connection.getAdmin(sn), loc.getRegion(), major, columnFamily);	} catch (NotServingRegionException e) {	if (LOG.isDebugEnabled()) {	
trying to major compact 

public CacheEvictionStats clearBlockCache(final TableName tableName) throws IOException {	checkTableExists(tableName);	CacheEvictionStatsBuilder cacheEvictionStats = CacheEvictionStats.builder();	List<Pair<RegionInfo, ServerName>> pairs = MetaTableAccessor.getTableRegionsAndLocations(connection, tableName);	Map<ServerName, List<RegionInfo>> regionInfoByServerName = pairs.stream() .filter(pair -> !(pair.getFirst().isOffline())) .filter(pair -> pair.getSecond() != null) .collect(Collectors.groupingBy(pair -> pair.getSecond(), Collectors.mapping(pair -> pair.getFirst(), Collectors.toList())));	for (Map.Entry<ServerName, List<RegionInfo>> entry : regionInfoByServerName.entrySet()) {	CacheEvictionStats stats = clearBlockCache(entry.getKey(), entry.getValue());	cacheEvictionStats = cacheEvictionStats.append(stats);	if (stats.getExceptionCount() > 0) {	for (Map.Entry<byte[], Throwable> exception : stats.getExceptions().entrySet()) {	
failed to clear block cache for on 

public boolean visit(Result data) throws IOException {	RegionInfo info = MetaTableAccessor.getRegionInfo(data);	if (info == null) {	
no serialized hregioninfo in 

public void snapshot(SnapshotDescription snapshotDesc) throws IOException, SnapshotCreationException, IllegalArgumentException {	SnapshotProtos.SnapshotDescription snapshot = ProtobufUtil.createHBaseProtosSnapshotDesc(snapshotDesc);	SnapshotResponse response = asyncSnapshot(snapshot);	final IsSnapshotDoneRequest request = IsSnapshotDoneRequest.newBuilder().setSnapshot(snapshot).build();	IsSnapshotDoneResponse done = null;	long start = EnvironmentEdgeManager.currentTime();	long max = response.getExpectedTimeout();	long maxPauseTime = max / this.numRetries;	int tries = 0;	
waiting a max of ms for snapshot to complete max ms per retry 

final IsSnapshotDoneRequest request = IsSnapshotDoneRequest.newBuilder().setSnapshot(snapshot).build();	IsSnapshotDoneResponse done = null;	long start = EnvironmentEdgeManager.currentTime();	long max = response.getExpectedTimeout();	long maxPauseTime = max / this.numRetries;	int tries = 0;	while (tries == 0 || ((EnvironmentEdgeManager.currentTime() - start) < max && !done.getDone())) {	try {	long sleep = getPauseTime(tries++);	sleep = sleep > maxPauseTime ? maxPauseTime : sleep;	
sleeping ms while waiting for snapshot completion 

long maxPauseTime = max / this.numRetries;	int tries = 0;	while (tries == 0 || ((EnvironmentEdgeManager.currentTime() - start) < max && !done.getDone())) {	try {	long sleep = getPauseTime(tries++);	sleep = sleep > maxPauseTime ? maxPauseTime : sleep;	Thread.sleep(sleep);	} catch (InterruptedException e) {	throw (InterruptedIOException)new InterruptedIOException("Interrupted").initCause(e);	}	
getting current status of snapshot from master 

cloneSnapshot(snapshotName, tableName, restoreAcl);	return;	}	if (!isTableDisabled(tableName)) {	throw new TableNotDisabledException(tableName);	}	String failSafeSnapshotSnapshotName = null;	if (takeFailSafeSnapshot) {	failSafeSnapshotSnapshotName = conf.get("hbase.snapshot.restore.failsafe.name", "hbase-failsafe-{snapshot.name}-{restore.timestamp}");	failSafeSnapshotSnapshotName = failSafeSnapshotSnapshotName .replace("{snapshot.name}", snapshotName) .replace("{table.name}", tableName.toString().replace(TableName.NAMESPACE_DELIM, '.')) .replace("{restore.timestamp}", String.valueOf(EnvironmentEdgeManager.currentTime()));	
taking restore failsafe snapshot 

String msg = "Failed to restore and rollback to snapshot=" + failSafeSnapshotSnapshotName;	LOG.error(msg, ex);	throw new RestoreSnapshotException(msg, e);	}	} else {	throw new RestoreSnapshotException("Failed to restore snapshot=" + snapshotName, e);	}	}	if (takeFailSafeSnapshot) {	try {	
deleting restore failsafe snapshot 

throw new RestoreSnapshotException(msg, e);	}	} else {	throw new RestoreSnapshotException("Failed to restore snapshot=" + snapshotName, e);	}	}	if (takeFailSafeSnapshot) {	try {	deleteSnapshot(failSafeSnapshotSnapshotName);	} catch (IOException e) {	
unable to remove the failsafe snapshot 

final ExecProcedureRequest request = ExecProcedureRequest.newBuilder().setProcedure(desc).build();	ExecProcedureResponse response = executeCallable(new MasterCallable<ExecProcedureResponse>( getConnection(), getRpcControllerFactory()) {	protected ExecProcedureResponse rpcCall() throws Exception {	return master.execProcedure(getRpcController(), request);	}	});	long start = EnvironmentEdgeManager.currentTime();	long max = response.getExpectedTimeout();	long maxPauseTime = max / this.numRetries;	int tries = 0;	
waiting a max of ms for procedure to complete max ms per retry 

});	long start = EnvironmentEdgeManager.currentTime();	long max = response.getExpectedTimeout();	long maxPauseTime = max / this.numRetries;	int tries = 0;	boolean done = false;	while (tries == 0 || ((EnvironmentEdgeManager.currentTime() - start) < max && !done)) {	try {	long sleep = getPauseTime(tries++);	sleep = sleep > maxPauseTime ? maxPauseTime : sleep;	
sleeping ms while waiting for procedure completion 

int tries = 0;	boolean done = false;	while (tries == 0 || ((EnvironmentEdgeManager.currentTime() - start) < max && !done)) {	try {	long sleep = getPauseTime(tries++);	sleep = sleep > maxPauseTime ? maxPauseTime : sleep;	Thread.sleep(sleep);	} catch (InterruptedException e) {	throw (InterruptedIOException)new InterruptedIOException("Interrupted").initCause(e);	}	
getting current status of procedure from master 

public void deleteSnapshots(final Pattern pattern) throws IOException {	List<SnapshotDescription> snapshots = listSnapshots(pattern);	for (final SnapshotDescription snapshot : snapshots) {	try {	internalDeleteSnapshot(snapshot);	} catch (IOException ex) {	
failed to delete snapshot for table 

public void deleteTableSnapshots(Pattern tableNamePattern, Pattern snapshotNamePattern) throws IOException {	List<SnapshotDescription> snapshots = listTableSnapshots(tableNamePattern, snapshotNamePattern);	for (SnapshotDescription snapshot : snapshots) {	try {	internalDeleteSnapshot(snapshot);	
successfully deleted snapshot 

public void deleteTableSnapshots(Pattern tableNamePattern, Pattern snapshotNamePattern) throws IOException {	List<SnapshotDescription> snapshots = listTableSnapshots(tableNamePattern, snapshotNamePattern);	for (SnapshotDescription snapshot : snapshots) {	try {	internalDeleteSnapshot(snapshot);	} catch (IOException e) {	
failed to delete snapshot 

public CoprocessorRpcChannel coprocessorService() {	return new SyncCoprocessorRpcChannel() {	protected Message callExecService(final RpcController controller, final Descriptors.MethodDescriptor method, final Message request, final Message responsePrototype) throws IOException {	if (LOG.isTraceEnabled()) {	
call 

public CoprocessorRpcChannel coprocessorService(final ServerName serverName) {	return new SyncCoprocessorRpcChannel() {	protected Message callExecService(RpcController controller, Descriptors.MethodDescriptor method, Message request, Message responsePrototype) throws IOException {	if (LOG.isTraceEnabled()) {	
call 

state = AdminProtos.GetRegionInfoResponse.CompactionState.MAJOR;	break;	case MINOR: if (state == AdminProtos.GetRegionInfoResponse.CompactionState.MAJOR) {	return CompactionState.MAJOR_AND_MINOR;	}	state = AdminProtos.GetRegionInfoResponse.CompactionState.MINOR;	break;	case NONE: default: }	} catch (NotServingRegionException e) {	if (LOG.isDebugEnabled()) {	
trying to get compaction state of 

}	state = AdminProtos.GetRegionInfoResponse.CompactionState.MINOR;	break;	case NONE: default: }	} catch (NotServingRegionException e) {	if (LOG.isDebugEnabled()) {	}	} catch (RemoteException e) {	if (e.getMessage().indexOf(NotServingRegionException.class.getName()) >= 0) {	if (LOG.isDebugEnabled()) {	
trying to get compaction state of 

int tries = 0;	IOException serviceEx = null;	while (EnvironmentEdgeManager.currentTime() < deadlineTs) {	GetProcedureResultResponse response = null;	try {	response = getProcedureResult(request);	} catch (IOException e) {	serviceEx = unwrapException(e);	LOG.warn("failed to get the procedure result procId=" + procId, serviceEx);	if (serviceEx instanceof DoNotRetryIOException) {	
proc is unsupported on this master 

protected V postOperationResult(final V result, final long deadlineTs) throws IOException, TimeoutException {	
completed 

protected V postOperationFailure(final IOException exception, final long deadlineTs) throws IOException, TimeoutException {	
failed with 

protected void waitForAllRegionsOnline(final long deadlineTs, final byte[][] splitKeys) throws IOException, TimeoutException {	final TableDescriptor desc = getTableDescriptor();	final AtomicInteger actualRegCount = new AtomicInteger(0);	final MetaTableAccessor.Visitor visitor = new MetaTableAccessor.Visitor() {	public boolean visit(Result rowResult) throws IOException {	RegionLocations list = MetaTableAccessor.getRegionLocations(rowResult);	if (list == null) {	
no serialized hregioninfo in 

========================= hbase sample_501 =========================

conf1.setLong(HConstants.THREAD_WAKE_FREQUENCY, 100);	conf1.setInt("replication.stats.thread.period.seconds", 5);	conf1.setBoolean("hbase.tests.use.shortcircuit.reads", false);	conf1.setStrings(HConstants.REPLICATION_CODEC_CONF_KEY, KeyValueCodecWithTags.class.getName());	conf1.setStrings(CoprocessorHost.USER_REGION_COPROCESSOR_CONF_KEY, TestCoprocessorForTagsAtSource.class.getName());	utility1 = new HBaseTestingUtility(conf1);	utility1.startMiniZKCluster();	MiniZooKeeperCluster miniZK = utility1.getZkCluster();	conf1 = utility1.getConfiguration();	replicationAdmin = new ReplicationAdmin(conf1);	
setup first zk 

replicationAdmin = new ReplicationAdmin(conf1);	conf2 = HBaseConfiguration.create(conf1);	conf2.setInt("hfile.format.version", 3);	conf2.set(HConstants.ZOOKEEPER_ZNODE_PARENT, "/2");	conf2.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 6);	conf2.setBoolean("hbase.tests.use.shortcircuit.reads", false);	conf2.setStrings(HConstants.REPLICATION_CODEC_CONF_KEY, KeyValueCodecWithTags.class.getName());	conf2.setStrings(CoprocessorHost.USER_REGION_COPROCESSOR_CONF_KEY, TestCoprocessorForTagsAtSink.class.getName());	utility2 = new HBaseTestingUtility(conf2);	utility2.setZkCluster(miniZK);	
setup second zk 

public void testReplicationWithCellTags() throws Exception {	
testSimplePutDelete 

htable1 = utility1.getConnection().getTable(TABLE_NAME);	htable1.put(put);	Get get = new Get(ROW);	try {	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

========================= hbase sample_1935 =========================

public void perform() throws Exception {	
performing action restart random rs holding table 

========================= hbase sample_3334 =========================

initBlockCache();	initMobFileCache();	this.period = regionServer.conf.getLong(HConstants.REGIONSERVER_METRICS_PERIOD, HConstants.DEFAULT_REGIONSERVER_METRICS_PERIOD);	this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();	this.runnable = new RegionServerMetricsWrapperRunnable();	this.executor.scheduleWithFixedDelay(this.runnable, this.period, this.period, TimeUnit.MILLISECONDS);	this.metricsWALSource = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);	try {	this.dfsHedgedReadMetrics = FSUtils.getDFSHedgedReadMetrics(regionServer.getConfiguration());	} catch (IOException e) {	
failed to get hedged metrics 

this.period = regionServer.conf.getLong(HConstants.REGIONSERVER_METRICS_PERIOD, HConstants.DEFAULT_REGIONSERVER_METRICS_PERIOD);	this.executor = CompatibilitySingletonFactory.getInstance(MetricsExecutor.class).getExecutor();	this.runnable = new RegionServerMetricsWrapperRunnable();	this.executor.scheduleWithFixedDelay(this.runnable, this.period, this.period, TimeUnit.MILLISECONDS);	this.metricsWALSource = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);	try {	this.dfsHedgedReadMetrics = FSUtils.getDFSHedgedReadMetrics(regionServer.getConfiguration());	} catch (IOException e) {	}	if (LOG.isInfoEnabled()) {	
computing regionserver metrics every milliseconds 

========================= hbase sample_2525 =========================

public void setConf(Configuration conf) {	
ignoring setconf call 

protected void doLoadIncrementalHFiles(Path hfiles, TableName tableName) throws Exception {	String[] args = { hfiles.toString(), tableName.getNameAsString() };	
running loadincrememntalhfiles with args s 

========================= hbase sample_3271 =========================

return HConstants.NORMAL_QOS;	}	if (param instanceof ScanRequest) {	ScanRequest request = (ScanRequest)param;	if (!request.hasScannerId()) {	return HConstants.NORMAL_QOS;	}	RegionScanner scanner = rpcServices.getScanner(request.getScannerId());	if (scanner != null && scanner.getRegionInfo().getTable().isSystemTable()) {	if (LOG.isTraceEnabled()) {	
high priority scanner request 

========================= hbase sample_2749 =========================

byte[] b = new byte[10];	ThreadLocalRandom.current().nextBytes(b);	out.write(b, 0, b.length);	out.flush(false).get();	TEST_UTIL.getDFSCluster().restartDataNode(0);	out.write(b, 0, b.length);	try {	out.flush(false).get();	fail("flush should fail");	} catch (ExecutionException e) {	
expected exception caught 

public void testCreateParentFailed() throws IOException {	Path f = new Path("/" + name.getMethodName() + "/test");	EventLoop eventLoop = EVENT_LOOP_GROUP.next();	try {	FanOutOneBlockAsyncDFSOutputHelper.createOutput(FS, f, true, false, (short) 3, FS.getDefaultBlockSize(), eventLoop, CHANNEL_CLASS);	fail("should fail with parent does not exist");	} catch (RemoteException e) {	
expected exception caught 

========================= hbase sample_1470 =========================

for (Map.Entry<ServerName, List<RegionInfo>> entry : serverToRegionMap.entrySet()) {	if (entry.getKey().equals(util.getHBaseCluster().getMaster().getServerName())) {	continue;	}	List<RegionInfo> regions = entry.getValue();	Set<byte[]> setOfStartKeys = new HashSet<>();	for (RegionInfo region : regions) {	byte[] startKey = region.getStartKey();	if (region.getTable().equals(table)) {	setOfStartKeys.add(startKey);	
startkey 

========================= hbase sample_1889 =========================

public long trailerSize() {	if (trailerPresent) {	final long calculatedSize = PB_WAL_COMPLETE_MAGIC.length + Bytes.SIZEOF_INT + trailer.getSerializedSize();	final long expectedSize = fileLength - walEditsStopOffset;	if (expectedSize != calculatedSize) {	
after parsing the trailer we expect the total footer to be bytes but we calculate it as being 

WALProtos.WALHeader header = builder.build();	this.hasCompression = header.hasHasCompression() && header.getHasCompression();	this.hasTagCompression = header.hasHasTagCompression() && header.getHasTagCompression();	}	this.inputStream = stream;	this.walEditsStopOffset = this.fileLength;	long currentPosition = stream.getPos();	trailerPresent = setTrailerIfPresent();	this.seekOnFs(currentPosition);	if (LOG.isTraceEnabled()) {	
after reading the trailer waleditsstopoffset filelength trailerpresent true size false currentposition 

private boolean setTrailerIfPresent() {	try {	long trailerSizeOffset = this.fileLength - (PB_WAL_COMPLETE_MAGIC.length + Bytes.SIZEOF_INT);	if (trailerSizeOffset <= 0) return false;	this.seekOnFs(trailerSizeOffset);	int trailerSize = this.inputStream.readInt();	ByteBuffer buf = ByteBuffer.allocate(ProtobufLogReader.PB_WAL_COMPLETE_MAGIC.length);	this.inputStream.readFully(buf.array(), buf.arrayOffset(), buf.capacity());	if (!Arrays.equals(buf.array(), PB_WAL_COMPLETE_MAGIC)) {	
no trailer found 

long trailerSizeOffset = this.fileLength - (PB_WAL_COMPLETE_MAGIC.length + Bytes.SIZEOF_INT);	if (trailerSizeOffset <= 0) return false;	this.seekOnFs(trailerSizeOffset);	int trailerSize = this.inputStream.readInt();	ByteBuffer buf = ByteBuffer.allocate(ProtobufLogReader.PB_WAL_COMPLETE_MAGIC.length);	this.inputStream.readFully(buf.array(), buf.arrayOffset(), buf.capacity());	if (!Arrays.equals(buf.array(), PB_WAL_COMPLETE_MAGIC)) {	return false;	}	if (trailerSize < 0) {	
invalid trailer size ignoring the trailer 

this.seekOnFs(trailerSizeOffset);	int trailerSize = this.inputStream.readInt();	ByteBuffer buf = ByteBuffer.allocate(ProtobufLogReader.PB_WAL_COMPLETE_MAGIC.length);	this.inputStream.readFully(buf.array(), buf.arrayOffset(), buf.capacity());	if (!Arrays.equals(buf.array(), PB_WAL_COMPLETE_MAGIC)) {	return false;	}	if (trailerSize < 0) {	return false;	} else if (trailerSize > this.trailerWarnSize) {	
please investigate waltrailer usage trailer size maximum configured size 

} else if (trailerSize > this.trailerWarnSize) {	}	long positionOfTrailer = trailerSizeOffset - trailerSize;	this.seekOnFs(positionOfTrailer);	buf = ByteBuffer.allocate(trailerSize);	this.inputStream.readFully(buf.array(), buf.arrayOffset(), buf.capacity());	trailer = WALTrailer.parseFrom(buf.array());	this.walEditsStopOffset = positionOfTrailer;	return true;	} catch (IOException ioe) {	
got ioe while reading the trailer continuing as if no trailer is present 

protected boolean readNext(Entry entry) throws IOException {	while (true) {	long originalPosition = this.inputStream.getPos();	if (trailerPresent && originalPosition > 0 && originalPosition == this.walEditsStopOffset) {	if (LOG.isTraceEnabled()) {	
reached end of expected edits area at offset 

int actualCells = entry.getEdit().readFromCells(cellDecoder, expectedCells);	if (expectedCells != actualCells) {	throw new EOFException("Only read " + actualCells);	}	} catch (Exception ex) {	String posAfterStr = "<unknown>";	try {	posAfterStr = this.inputStream.getPos() + "";	} catch (Throwable t) {	if (LOG.isTraceEnabled()) {	
error getting pos for error message ignoring 

posAfterStr = this.inputStream.getPos() + "";	} catch (Throwable t) {	if (LOG.isTraceEnabled()) {	}	}	String message = " while reading " + expectedCells + " WAL KVs; started reading at " + posBefore + " and read up to " + posAfterStr;	IOException realEofEx = extractHiddenEof(ex);	throw (EOFException) new EOFException("EOF " + message). initCause(realEofEx != null ? realEofEx : ex);	}	if (trailerPresent && this.inputStream.getPos() > this.walEditsStopOffset) {	
read waltrailer while reading waledits wal inputstream getpos waleditsstopoffset 

throw new EOFException("Read WALTrailer while reading WALEdits");	}	} catch (EOFException eof) {	if (originalPosition < 0) {	if (LOG.isTraceEnabled()) {	LOG.trace("Encountered a malformed edit, but can't seek back to last good position because originalPosition is negative. last offset=" + this.inputStream.getPos(), eof);	}	throw eof;	}	if (LOG.isTraceEnabled()) {	
encountered a malformed edit seeking back to last good position in file from to 

========================= hbase sample_2572 =========================

public boolean removeObjectName(final String name) {	if (removeObjectMethod != null) {	try {	removeObjectMethod.invoke(DefaultMetricsSystem.INSTANCE, name);	return true;	} catch (Exception e) {	if (LOG.isTraceEnabled()) {	
unable to remove object name from cache 

return;	}	try {	Object sourceNames = sourceNamesField.get(DefaultMetricsSystem.INSTANCE);	HashMap map = (HashMap) mapField.get(sourceNames);	synchronized (sourceNames) {	map.remove(name);	}	} catch (Exception ex) {	if (LOG.isTraceEnabled()) {	
received exception while trying to access hadoop metrics classes via reflection 

========================= hbase sample_669 =========================

static String getUsernameFromConf(Configuration conf) {	String oldStyleUgi = conf.get(DEPRECATED_UGI_KEY);	if (oldStyleUgi != null) {	
should not be used instead use 

========================= hbase sample_3226 =========================

public Configuration getConf(Configuration sinkConf, String replicationClusterId) throws IOException {	if (sourceClustersConfs.get(replicationClusterId) == null) {	synchronized (this.sourceClustersConfs) {	if (sourceClustersConfs.get(replicationClusterId) == null) {	
loading source cluster fs client conf for cluster 

public Configuration getConf(Configuration sinkConf, String replicationClusterId) throws IOException {	if (sourceClustersConfs.get(replicationClusterId) == null) {	synchronized (this.sourceClustersConfs) {	if (sourceClustersConfs.get(replicationClusterId) == null) {	Configuration sourceClusterConf = new Configuration(false);	String replicationConfDir = sinkConf.get(HConstants.REPLICATION_CONF_DIR);	if (replicationConfDir == null) {	
is not configured 

String replicationConfDir = sinkConf.get(HConstants.REPLICATION_CONF_DIR);	if (replicationConfDir == null) {	URL resource = HBaseConfiguration.class.getClassLoader().getResource("hbase-site.xml");	if (resource != null) {	String path = resource.getPath();	replicationConfDir = path.substring(0, path.lastIndexOf("/"));	} else {	replicationConfDir = System.getenv("HBASE_CONF_DIR");	}	}	
loading source cluster file system configurations from xml files under directory 

========================= hbase sample_2964 =========================

public Optional<Cell> getLastKey() {	if (top) {	return super.getLastKey();	}	HFileScanner scanner = getScanner(true, true);	try {	if (scanner.seekBefore(this.splitCell)) {	return Optional.ofNullable(scanner.getKey());	}	} catch (IOException e) {	
failed seekbefore 

public Optional<Cell> getFirstKey() {	if (!firstKeySeeked) {	HFileScanner scanner = getScanner(true, true, false);	try {	if (scanner.seekTo()) {	this.firstKey = Optional.ofNullable(scanner.getKey());	}	firstKeySeeked = true;	} catch (IOException e) {	
failed seekto first kv in the file 

========================= hbase sample_2437 =========================

public MetricsTableSourceImpl(String tblName, MetricsTableAggregateSourceImpl aggregate, MetricsTableWrapperAggregate tblWrapperAgg) {	
creating new metricstablesourceimpl for table 

public void close() {	boolean wasClosed = closed.getAndSet(true);	if (wasClosed) {	return;	}	agg.deregister(tableName.getNameAsString());	synchronized (this) {	if (LOG.isTraceEnabled()) {	
removing table metrics for table 

========================= hbase sample_686 =========================

final TableName tableName = TableName.valueOf(name.getMethodName());	Table t = TEST_UTIL.createTable(tableName, Bytes.toBytes("f"), splitKeys);	TEST_UTIL.waitUntilAllRegionsAssigned(tableName);	final int numberOfRegions = admin.getTableRegions(t.getName()).size();	checkIfFavoredNodeInformationIsCorrect(tableName);	byte[] splitPoint = Bytes.toBytes(0);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	HRegionInfo parent = locator.getRegionLocation(splitPoint).getRegionInfo();	List<ServerName> parentFN = fnm.getFavoredNodes(parent);	assertNotNull("FN should not be null for region: " + parent, parentFN);	
splitting table 

TEST_UTIL.waitUntilAllRegionsAssigned(tableName);	final int numberOfRegions = admin.getTableRegions(t.getName()).size();	checkIfFavoredNodeInformationIsCorrect(tableName);	byte[] splitPoint = Bytes.toBytes(0);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	HRegionInfo parent = locator.getRegionLocation(splitPoint).getRegionInfo();	List<ServerName> parentFN = fnm.getFavoredNodes(parent);	assertNotNull("FN should not be null for region: " + parent, parentFN);	admin.split(tableName, splitPoint);	TEST_UTIL.waitUntilNoRegionsInTransition(WAIT_TIMEOUT);	
finished waiting on rit 

assertEquals("Daughter's PRIMARY FN should be PRIMARY of parent", parentFN.get(PRIMARY.ordinal()), daughter1FN.get(PRIMARY.ordinal()));	assertEquals("Daughter's SECONDARY FN should be SECONDARY of parent", parentFN.get(SECONDARY.ordinal()), daughter1FN.get(SECONDARY.ordinal()));	assertEquals("Daughter's PRIMARY FN should be PRIMARY of parent", parentFN.get(PRIMARY.ordinal()), daughter2FN.get(PRIMARY.ordinal()));	assertEquals("Daughter's SECONDARY FN should be TERTIARY of parent", parentFN.get(TERTIARY.ordinal()), daughter2FN.get(SECONDARY.ordinal()));	TEST_UTIL.getMiniHBaseCluster().compact(tableName, true);	admin.runCatalogScan();	ProcedureTestingUtility.waitAllProcedures( TEST_UTIL.getMiniHBaseCluster().getMaster().getMasterProcedureExecutor());	assertNull("Parent FN should be null", fnm.getFavoredNodes(parent));	List<HRegionInfo> regions = admin.getTableRegions(tableName);	Threads.sleep(2000);	
starting delete 

public void testMergeTable() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	TEST_UTIL.createTable(tableName, Bytes.toBytes("f"), splitKeys);	TEST_UTIL.waitUntilAllRegionsAssigned(tableName);	checkIfFavoredNodeInformationIsCorrect(tableName);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	HRegionInfo regionA = locator.getRegionLocation(HConstants.EMPTY_START_ROW).getRegionInfo();	HRegionInfo regionB = locator.getRegionLocation(splitKeys[0]).getRegionInfo();	List<ServerName> regionAFN = fnm.getFavoredNodes(regionA);	
regiona with fn 

public void testMergeTable() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	TEST_UTIL.createTable(tableName, Bytes.toBytes("f"), splitKeys);	TEST_UTIL.waitUntilAllRegionsAssigned(tableName);	checkIfFavoredNodeInformationIsCorrect(tableName);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	HRegionInfo regionA = locator.getRegionLocation(HConstants.EMPTY_START_ROW).getRegionInfo();	HRegionInfo regionB = locator.getRegionLocation(splitKeys[0]).getRegionInfo();	List<ServerName> regionAFN = fnm.getFavoredNodes(regionA);	
regionb with fn 

private void checkNoFNForDeletedTable(List<HRegionInfo> regions) {	for (HRegionInfo region : regions) {	
testing if fn data for 

========================= hbase sample_2067 =========================

Future<Pair<Result[], ScannerCallable>> f = cs.poll(timeBeforeReplicas, TimeUnit.MICROSECONDS);	if (f != null) {	Pair<Result[], ScannerCallable> r = f.get();	if (r != null && r.getSecond() != null) {	updateCurrentlyServingReplica(r.getSecond(), r.getFirst(), done, pool);	}	return r == null ? null : r.getFirst();	}	} catch (ExecutionException e) {	if (LOG.isDebugEnabled()) {	
scan with primary region returns 

return r == null ? null : r.getFirst();	} catch (ExecutionException e) {	RpcRetryingCallerWithReadReplicas.throwEnrichedException(e, retries);	} catch (CancellationException e) {	throw new InterruptedIOException(e.getMessage());	} catch (InterruptedException e) {	throw new InterruptedIOException(e.getMessage());	} finally {	cs.cancelAll();	}	
imposible arrive at an unreachable line 

========================= hbase sample_405 =========================

public void testMRegions() throws Exception {	final byte[][] splitKeys = new byte[500][];	for (int i = 0; i < splitKeys.length; ++i) {	splitKeys[i] = Bytes.toBytes(String.format("%08d", i));	}	final TableDescriptor htd = MasterProcedureTestingUtility.createHTD( TableName.valueOf("TestMRegions"), F1, F2);	UTIL.getAdmin().createTableAsync(htd, splitKeys) .get(10, java.util.concurrent.TimeUnit.HOURS);	
table created 

========================= hbase sample_1831 =========================

public void TestIncBackupDeleteTable() throws Exception {	String testName = "TestIncBackupDeleteTable";	
create full backup image for all tables 

HTable t1 = (HTable) conn.getTable(table1);	Put p1;	for (int i = 0; i < NB_ROWS_IN_BATCH; i++) {	p1 = new Put(Bytes.toBytes("row-t1" + i));	p1.addColumn(famName, qualName, Bytes.toBytes("val" + i));	t1.put(p1);	}	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH * 2);	t1.close();	int NB_ROWS2 = 20;	
bulk loading into 

}	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH * 2);	t1.close();	int NB_ROWS2 = 20;	int actual = TestLoadIncrementalHFiles.loadHFiles(testName, table1Desc, TEST_UTIL, famName, qualName, false, null, new byte[][][] {	new byte[][]{ Bytes.toBytes("aaaa"), Bytes.toBytes("cccc") }, new byte[][]{ Bytes.toBytes("ddd"), Bytes.toBytes("ooo") }, }, true, false, true, NB_ROWS_IN_BATCH*2, NB_ROWS2);	tables = Lists.newArrayList(table1);	request = createBackupRequest(BackupType.INCREMENTAL, tables, BACKUP_ROOT_DIR);	String backupIdIncMultiple = client.backupTables(request);	assertTrue(checkSucceeded(backupIdIncMultiple));	
bulk loading into 

========================= hbase sample_540 =========================

long timeBeforeScan = System.currentTimeMillis();	int found = 0;	while (scanner.next(results)) {	found += results.size();	results.clear();	}	found += results.size();	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("\nscan time = " + scanTime + "ms");	
found results 

buf.putShort((short) 2);	buf.putInt(i1);	buf.putInt(i2);	for (int c = 0; c < 5; c++) {	byte[] cq = new byte[4];	Bytes.putBytes(cq, 0, Bytes.toBytes(c), 0, 4);	Put p = new Put(rk);	p.setDurability(Durability.SKIP_WAL);	p.addColumn(cf.getBytes(), cq, Bytes.toBytes(c));	ht.put(p);	
inserting rk cq 

Scan scan = new Scan();	scan.addFamily(cf.getBytes());	FilterList filterList = new FilterList(Operator.MUST_PASS_ALL, filter1, filter2);	scan.setFilter(filterList);	ResultScanner scanner = hTable.getScanner(scan);	List<Cell> results = new ArrayList<>();	Result result;	long timeBeforeScan = System.currentTimeMillis();	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	
got rk cq 

Result result;	long timeBeforeScan = System.currentTimeMillis();	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	results.add(kv);	}	}	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("scan time = " + scanTime + "ms");	
found results 

========================= hbase sample_1974 =========================

public static void sleep(Configuration conf, long time) {	try {	Thread.sleep((long) (getWaitForRatio(conf) * time));	} catch (InterruptedException ex) {	
sleep interrupted 

sleepInterval = (remainderWait > interval) ? interval : remainderWait;	Thread.sleep(sleepInterval);	} catch (InterruptedException e) {	eval = predicate.evaluate();	interrupted = true;	break;	}	}	if (!eval) {	if (interrupted) {	
waiting interrupted after msec 

break;	}	}	if (!eval) {	if (interrupted) {	} else if (failIfTimeout) {	String msg = getExplanation(predicate);	fail(MessageFormat .format("Waiting timed out after [{0}] msec", adjustedTimeout) + msg);	} else {	String msg = getExplanation(predicate);	
waiting timed out after msec 

public static String getExplanation(Predicate<?> explain) {	if (explain instanceof ExplainingPredicate) {	try {	return " " + ((ExplainingPredicate<?>) explain).explainFailure();	} catch (Exception e) {	
failed to get explanation 

========================= hbase sample_813 =========================

private void mimicSyncUpAfterBulkLoad(Iterator<String> randomHFileRangeListIterator) throws Exception {	
mimicSyncUpAfterBulkLoad 

assertEquals("@Peer1 t2_syncup should still have 200 rows", 200, rowCount_ht2TargetAtPeer1);	syncUp(utility1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 200 || rowCount_ht2TargetAtPeer1 != 400) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	
syncup should have rows at source and it is 

syncUp(utility1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 200 || rowCount_ht2TargetAtPeer1 != 400) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	rowCount_ht2Source = utility1.countRows(ht2Source);	
syncup should have rows at source and it is 

private void loadAndReplicateHFiles(boolean verifyReplicationOnSlave, Iterator<String> randomHFileRangeListIterator) throws Exception {	
loadAndReplicateHFiles 

========================= hbase sample_1260 =========================

private void startCmdLineThread(final String[] args) {	
starting hbase thrift server with command line 

Class<? extends TServer> expectedClass = implType != null ? implType.serverClass : TBoundedThreadPoolServer.class;	assertEquals(expectedClass, thriftServer.serverRunner.tserver.getClass());	try {	talkToThriftServer();	} catch (Exception ex) {	clientSideException = ex;	} finally {	stopCmdLineThread();	}	if (clientSideException != null) {	
thrift client threw an exception parameters 

private void stopCmdLineThread() throws Exception {	
stopping thrift server 

private void stopCmdLineThread() throws Exception {	thriftServer.stop();	cmdLineThread.join();	if (cmdLineException != null) {	
command line invocation of hbase thrift server threw an exception 

========================= hbase sample_757 =========================

protected void handleException(Throwable t) {	if (t instanceof InterruptedIOException || t instanceof InterruptedException) {	
caught throwable while processing event 

========================= hbase sample_2509 =========================

public void removeWAL(ServerName serverName, String queueId, String fileName) throws ReplicationException {	String fileNode = getFileNode(serverName, queueId, fileName);	try {	ZKUtil.deleteNode(zookeeper, fileNode);	} catch (NoNodeException e) {	
has already been deleted when removing log 

public Pair<String, SortedSet<String>> claimQueue(ServerName sourceServerName, String queueId, ServerName destServerName) throws ReplicationException {	
atomically moving s wals to 

ZKUtil.createWithParents(zookeeper, getRsNode(destServerName));	} catch (KeeperException e) {	throw new ReplicationException( "Claim queue queueId=" + queueId + " from " + sourceServerName + " to " + destServerName + " failed when creating the node for " + destServerName, e);	}	try {	String oldQueueNode = getQueueNode(sourceServerName, queueId);	List<String> wals = ZKUtil.listChildrenNoWatch(zookeeper, oldQueueNode);	String newQueueId = queueId + "-" + sourceServerName;	if (CollectionUtils.isEmpty(wals)) {	ZKUtil.deleteNodeFailSilent(zookeeper, oldQueueNode);	
removed since it s empty 

return new Pair<>(newQueueId, Collections.emptySortedSet());	}	String newQueueNode = getQueueNode(destServerName, newQueueId);	List<ZKUtilOp> listOfOps = new ArrayList<>();	SortedSet<String> logQueue = new TreeSet<>();	listOfOps.add(ZKUtilOp.createAndFailSilent(newQueueNode, HConstants.EMPTY_BYTE_ARRAY));	for (String wal : wals) {	String oldWalNode = getFileNode(oldQueueNode, wal);	byte[] logOffset = ZKUtil.getData(this.zookeeper, oldWalNode);	if (LOG.isDebugEnabled()) {	
creating with data 

byte[] logOffset = ZKUtil.getData(this.zookeeper, oldWalNode);	if (LOG.isDebugEnabled()) {	}	String newWalNode = getFileNode(newQueueNode, wal);	listOfOps.add(ZKUtilOp.createAndFailSilent(newWalNode, logOffset));	listOfOps.add(ZKUtilOp.deleteNodeFailSilent(oldWalNode));	logQueue.add(wal);	}	listOfOps.add(ZKUtilOp.deleteNodeFailSilent(oldQueueNode));	if (LOG.isTraceEnabled()) {	
the multi list size is 

}	String newWalNode = getFileNode(newQueueNode, wal);	listOfOps.add(ZKUtilOp.createAndFailSilent(newWalNode, logOffset));	listOfOps.add(ZKUtilOp.deleteNodeFailSilent(oldWalNode));	logQueue.add(wal);	}	listOfOps.add(ZKUtilOp.deleteNodeFailSilent(oldQueueNode));	if (LOG.isTraceEnabled()) {	}	ZKUtil.multiOrSequential(zookeeper, listOfOps, false);	
atomically moved s wals to 

public Set<String> getAllWALs() throws ReplicationException {	try {	for (int retry = 0;; retry++) {	int v0 = getQueuesZNodeCversion();	List<ServerName> rss = getListOfReplicators0();	if (rss.isEmpty()) {	
didn t find any region server that replicates won t prevent any deletions 

public void addPeerToHFileRefs(String peerId) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	try {	if (ZKUtil.checkExists(zookeeper, peerNode) == -1) {	
adding peer to hfile reference queue 

public void removePeerFromHFileRefs(String peerId) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	try {	if (ZKUtil.checkExists(zookeeper, peerNode) == -1) {	if (LOG.isDebugEnabled()) {	
peer not found in hfile reference queue 

public void removePeerFromHFileRefs(String peerId) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	try {	if (ZKUtil.checkExists(zookeeper, peerNode) == -1) {	if (LOG.isDebugEnabled()) {	}	} else {	
removing peer from hfile reference queue 

public void addHFileRefs(String peerId, List<Pair<Path, Path>> pairs) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	boolean debugEnabled = LOG.isDebugEnabled();	if (debugEnabled) {	
adding hfile references in queue 

public void addHFileRefs(String peerId, List<Pair<Path, Path>> pairs) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	boolean debugEnabled = LOG.isDebugEnabled();	if (debugEnabled) {	}	List<ZKUtilOp> listOfOps = pairs.stream().map(p -> p.getSecond().getName()) .map(n -> getHFileNode(peerNode, n)) .map(f -> ZKUtilOp.createAndFailSilent(f, HConstants.EMPTY_BYTE_ARRAY)).collect(toList());	if (debugEnabled) {	
the multi list size for adding hfile references in zk for node is 

public void removeHFileRefs(String peerId, List<String> files) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	boolean debugEnabled = LOG.isDebugEnabled();	if (debugEnabled) {	
removing hfile references from queue 

public void removeHFileRefs(String peerId, List<String> files) throws ReplicationException {	String peerNode = getHFileRefsPeerNode(peerId);	boolean debugEnabled = LOG.isDebugEnabled();	if (debugEnabled) {	}	List<ZKUtilOp> listOfOps = files.stream().map(n -> getHFileNode(peerNode, n)) .map(ZKUtilOp::deleteNodeFailSilent).collect(toList());	if (debugEnabled) {	
the multi list size for removing hfile references in zk for node is 

public Set<String> getAllHFileRefs() throws ReplicationException {	try {	for (int retry = 0;; retry++) {	int v0 = getHFileRefsZNodeCversion();	List<String> peers = getAllPeersFromHFileRefsQueue();	if (peers.isEmpty()) {	
didn t find any peers with hfile references won t prevent any deletions 

========================= hbase sample_612 =========================

public void perform() throws Exception {	
performing action restart active master 

========================= hbase sample_3318 =========================

public RpcRetryingCallerFactory(Configuration conf, RetryingCallerInterceptor interceptor) {	this.conf = conf;	pause = conf.getLong(HConstants.HBASE_CLIENT_PAUSE, HConstants.DEFAULT_HBASE_CLIENT_PAUSE);	long configuredPauseForCQTBE = conf.getLong(HConstants.HBASE_CLIENT_PAUSE_FOR_CQTBE, pause);	if (configuredPauseForCQTBE < pause) {	
the setting is smaller than will use instead 

========================= hbase sample_491 =========================

public void run(Context context) throws IOException, InterruptedException {	outer = context;	int numberOfThreads = getNumberOfThreads(context);	mapClass = getMapperClass(context);	if (LOG.isDebugEnabled()) {	
configuring multithread runner to use threads 

public void run() {	try {	mapper.run(subcontext);	} catch (Throwable ie) {	
problem in running map 

========================= hbase sample_3461 =========================

public void publishReadFailure(String table, String server) {	incReadFailureCount();	
read from table s on region server s 

public void publishReadTiming(String table, String server, long msTime) {	
read from table s on region server s in dms 

public void publishReadFailure(String zNode, String server) {	incReadFailureCount();	
read from znode s on zookeeper instance s 

public void publishReadTiming(String znode, String server, long msTime) {	
read from znode s on zookeeper instance s in dms 

public void publishReadFailure(ServerName serverName, RegionInfo region, Exception e) {	incReadFailureCount();	
read from region s on regionserver s failed 

public void publishReadFailure(ServerName serverName, RegionInfo region, ColumnFamilyDescriptor column, Exception e) {	incReadFailureCount();	
read from region s on regionserver s column family s failed 

public void publishReadTiming(ServerName serverName, RegionInfo region, ColumnFamilyDescriptor column, long msTime) {	
read from region s on regionserver s column family s in dms 

public void publishWriteFailure(ServerName serverName, RegionInfo region, Exception e) {	incWriteFailureCount();	
write to region s on regionserver s failed 

public void publishWriteFailure(ServerName serverName, RegionInfo region, ColumnFamilyDescriptor column, Exception e) {	incWriteFailureCount();	
write to region s on regionserver s column family s failed 

public void publishWriteTiming(ServerName serverName, RegionInfo region, ColumnFamilyDescriptor column, long msTime) {	
write to region s on regionserver s column family s in dms 

public Void read() {	Table table = null;	TableDescriptor tableDesc = null;	try {	if (LOG.isDebugEnabled()) {	
reading table descriptor for table s 

public Void read() {	Table table = null;	TableDescriptor tableDesc = null;	try {	if (LOG.isDebugEnabled()) {	}	table = connection.getTable(region.getTable());	tableDesc = table.getDescriptor();	} catch (IOException e) {	
sniffregion failed 

if (LOG.isDebugEnabled()) {	}	table = connection.getTable(region.getTable());	tableDesc = table.getDescriptor();	} catch (IOException e) {	sink.publishReadFailure(serverName, region, e);	if (table != null) {	try {	table.close();	} catch (IOException ioe) {	
close table failed 

stopWatch.reset();	startKey = region.getStartKey();	if (startKey.length > 0) {	get = new Get(startKey);	get.setCacheBlocks(false);	get.setFilter(new FirstKeyOnlyFilter());	get.addFamily(column.getName());	} else {	scan = new Scan();	if (LOG.isDebugEnabled()) {	
rawscan s for table s 

}	scan.setRaw(rawScanEnabled);	scan.setCaching(1);	scan.setCacheBlocks(false);	scan.setFilter(new FirstKeyOnlyFilter());	scan.addFamily(column.getName());	scan.setMaxResultSize(1L);	scan.setOneRowLimit();	}	if (LOG.isDebugEnabled()) {	
reading from table s region s column family s and key s 

if (rs != null) {	rs.close();	}	scan = null;	get = null;	}	}	try {	table.close();	} catch (IOException e) {	
close table failed 

if (rowToCheck.length == 0) {	rowToCheck = new byte[]{0x0};	}	int writeValueSize = connection.getConfiguration().getInt(HConstants.HBASE_CANARY_WRITE_VALUE_SIZE_KEY, 10);	for (ColumnFamilyDescriptor column : tableDesc.getColumnFamilies()) {	Put put = new Put(rowToCheck);	byte[] value = new byte[writeValueSize];	Bytes.random(value);	put.addColumn(column.getName(), HConstants.EMPTY_BYTE_ARRAY, value);	if (LOG.isDebugEnabled()) {	
writing to table s region s column family s and key s 

Get get = null;	byte[] startKey = null;	Scan scan = null;	StopWatch stopWatch = new StopWatch();	stopWatch.reset();	try {	tableName = region.getTable();	table = connection.getTable(tableName);	startKey = region.getStartKey();	if (LOG.isDebugEnabled()) {	
reading from region server s table s region s and key s 

scan.setOneRowLimit();	stopWatch.start();	ResultScanner s = table.getScanner(scan);	s.next();	s.close();	stopWatch.stop();	}	successes.incrementAndGet();	sink.publishReadTiming(tableName.getNameAsString(), serverName, stopWatch.getTime());	} catch (TableNotFoundException tnfe) {	
table may be deleted 

ResultScanner s = table.getScanner(scan);	s.next();	s.close();	stopWatch.stop();	}	successes.incrementAndGet();	sink.publishReadTiming(tableName.getNameAsString(), serverName, stopWatch.getTime());	} catch (TableNotFoundException tnfe) {	} catch (TableNotEnabledException tnee) {	successes.incrementAndGet();	
the targeted table was disabled assuming success 

} catch (DoNotRetryIOException dnrioe) {	sink.publishReadFailure(tableName.getNameAsString(), serverName);	LOG.error(dnrioe.toString(), dnrioe);	} catch (IOException e) {	sink.publishReadFailure(tableName.getNameAsString(), serverName);	LOG.error(e.toString(), e);	} finally {	if (table != null) {	try {	table.close();	
close table failed 

if (this.failOnError && monitor.hasError()) {	monitorThread.interrupt();	if (monitor.initialized) {	return monitor.errorCode;	} else {	return INIT_ERROR_EXIT_CODE;	}	}	currentTimeLength = System.currentTimeMillis() - startTime;	if (currentTimeLength > this.timeout) {	
the monitor is running too long after timeout limit will be killed itself 

public abstract void run();	protected boolean initAdmin() {	if (null == this.admin) {	try {	this.admin = this.connection.getAdmin();	} catch (Exception e) {	
initial hbaseadmin failed 

public abstract void run();	protected boolean initAdmin() {	if (null == this.admin) {	try {	this.admin = this.connection.getAdmin();	} catch (Exception e) {	this.errorCode = INIT_ERROR_EXIT_CODE;	}	} else if (admin.isAborted()) {	
hbaseadmin aborted 

public void run() {	if (this.initAdmin()) {	try {	List<Future<Void>> taskFutures = new LinkedList<>();	RegionStdOutSink regionSink = this.getSink();	if (this.targets != null && this.targets.length > 0) {	String[] tables = generateMonitorTables(this.targets);	if (! new HashSet<>(Arrays.asList(tables)).containsAll(this.configuredReadTableTimeouts.keySet())) {	
readtabletimeouts can only specify read timeouts for monitor targets passed via command line 

taskFutures.addAll(Canary.sniff(admin, regionSink, table, executor, TaskType.READ, this.rawScanEnabled, readLatency));	}	} else {	taskFutures.addAll(sniff(TaskType.READ, regionSink));	}	if (writeSniffing) {	if (EnvironmentEdgeManager.currentTime() - lastCheckTime > checkPeriod) {	try {	checkWriteTableDistribution();	} catch (IOException e) {	
check canary table distribution failed 

lastCheckTime = EnvironmentEdgeManager.currentTime();	}	regionSink.initializeWriteLatency();	LongAdder writeTableLatency = regionSink.getWriteLatency();	taskFutures.addAll(Canary.sniff(admin, regionSink, admin.getTableDescriptor(writeTableName), executor, TaskType.WRITE, this.rawScanEnabled, writeTableLatency));	}	for (Future<Void> future : taskFutures) {	try {	future.get();	} catch (ExecutionException e) {	
sniff region failed 

future.get();	} catch (ExecutionException e) {	}	}	Map<String, LongAdder> actualReadTableLatency = regionSink.getReadLatencyMap();	for (Map.Entry<String, Long> entry : configuredReadTableTimeouts.entrySet()) {	String tableName = entry.getKey();	if (actualReadTableLatency.containsKey(tableName)) {	Long actual = actualReadTableLatency.get(tableName).longValue();	Long configured = entry.getValue();	
read operation for took ms the configured read timeout was ms 

} catch (ExecutionException e) {	}	}	Map<String, LongAdder> actualReadTableLatency = regionSink.getReadLatencyMap();	for (Map.Entry<String, Long> entry : configuredReadTableTimeouts.entrySet()) {	String tableName = entry.getKey();	if (actualReadTableLatency.containsKey(tableName)) {	Long actual = actualReadTableLatency.get(tableName).longValue();	Long configured = entry.getValue();	if (actual > configured) {	
read operation for exceeded the configured read timeout 

}	Map<String, LongAdder> actualReadTableLatency = regionSink.getReadLatencyMap();	for (Map.Entry<String, Long> entry : configuredReadTableTimeouts.entrySet()) {	String tableName = entry.getKey();	if (actualReadTableLatency.containsKey(tableName)) {	Long actual = actualReadTableLatency.get(tableName).longValue();	Long configured = entry.getValue();	if (actual > configured) {	}	} else {	
read operation for failed 

Long actual = actualReadTableLatency.get(tableName).longValue();	Long configured = entry.getValue();	if (actual > configured) {	}	} else {	}	}	if (this.writeSniffing) {	String writeTableStringName = this.writeTableName.getNameAsString();	long actualWriteLatency = regionSink.getWriteLatency().longValue();	
write operation for took ms the configured write timeout was ms 

Long configured = entry.getValue();	if (actual > configured) {	}	} else {	}	}	if (this.writeSniffing) {	String writeTableStringName = this.writeTableName.getNameAsString();	long actualWriteLatency = regionSink.getWriteLatency().longValue();	if (actualWriteLatency > this.configuredWriteTableTimeout) {	
write operation for exceeded the configured write timeout 

} else {	}	}	if (this.writeSniffing) {	String writeTableStringName = this.writeTableName.getNameAsString();	long actualWriteLatency = regionSink.getWriteLatency().longValue();	if (actualWriteLatency > this.configuredWriteTableTimeout) {	}	}	} catch (Exception e) {	
run regionmonitor failed 

private String[] generateMonitorTables(String[] monitorTargets) throws IOException {	String[] returnTables = null;	if (this.useRegExp) {	Pattern pattern = null;	HTableDescriptor[] tds = null;	Set<String> tmpTables = new TreeSet<>();	try {	if (LOG.isDebugEnabled()) {	
reading list of tables 

}	for (String monitorTarget : monitorTargets) {	pattern = Pattern.compile(monitorTarget);	for (HTableDescriptor td : tds) {	if (pattern.matcher(td.getNameAsString()).matches()) {	tmpTables.add(td.getNameAsString());	}	}	}	} catch (IOException e) {	
communicate with admin failed 

private List<Future<Void>> sniff(TaskType taskType, RegionStdOutSink regionSink) throws Exception {	if (LOG.isDebugEnabled()) {	
reading list of tables 

private void createWriteTable(int numberOfServers) throws IOException {	int numberOfRegions = (int)(numberOfServers * regionsLowerLimit);	
number of live regionservers pre splitting the canary table into regions current lower limit of regions per server is and you can change it by config 

private static List<Future<Void>> sniff(final Admin admin, final Sink sink, String tableName, ExecutorService executor, TaskType taskType, boolean rawScanEnabled, LongAdder readLatency) throws Exception {	if (LOG.isDebugEnabled()) {	
checking table is enabled and getting table descriptor for table s 

private static List<Future<Void>> sniff(final Admin admin, final Sink sink, String tableName, ExecutorService executor, TaskType taskType, boolean rawScanEnabled, LongAdder readLatency) throws Exception {	if (LOG.isDebugEnabled()) {	}	if (admin.isTableEnabled(TableName.valueOf(tableName))) {	return Canary.sniff(admin, sink, admin.getTableDescriptor(TableName.valueOf(tableName)), executor, taskType, rawScanEnabled, readLatency);	} else {	
table s is not enabled 

private static List<Future<Void>> sniff(final Admin admin, final Sink sink, HTableDescriptor tableDesc, ExecutorService executor, TaskType taskType, boolean rawScanEnabled, LongAdder rwLatency) throws Exception {	if (LOG.isDebugEnabled()) {	
reading list of regions for table s 

public void run() {	if (this.initAdmin() && this.checkNoTableNames()) {	RegionServerStdOutSink regionServerSink = null;	try {	regionServerSink = this.getSink();	} catch (RuntimeException e) {	
run regionservermonitor failed 

private boolean checkNoTableNames() {	List<String> foundTableNames = new ArrayList<>();	TableName[] tableNames = null;	if (LOG.isDebugEnabled()) {	
reading list of tables 

private boolean checkNoTableNames() {	List<String> foundTableNames = new ArrayList<>();	TableName[] tableNames = null;	if (LOG.isDebugEnabled()) {	}	try {	tableNames = this.admin.listTableNames();	} catch (IOException e) {	
get listtablenames failed 

private void monitorRegionServers(Map<String, List<RegionInfo>> rsAndRMap, RegionServerStdOutSink regionServerSink) {	List<RegionServerTask> tasks = new ArrayList<>();	Map<String, AtomicLong> successMap = new HashMap<>();	Random rand = new Random();	for (Map.Entry<String, List<RegionInfo>> entry : rsAndRMap.entrySet()) {	String serverName = entry.getKey();	AtomicLong successes = new AtomicLong(0);	successMap.put(serverName, successes);	if (entry.getValue().isEmpty()) {	
regionserver not serving any regions s 

} else {	RegionInfo region = entry.getValue().get(rand.nextInt(entry.getValue().size()));	tasks.add(new RegionServerTask(this.connection, serverName, region, regionServerSink, successes));	}	}	try {	for (Future<Void> future : this.executor.invokeAll(tasks)) {	try {	future.get();	} catch (ExecutionException e) {	
sniff regionserver failed 

for (Future<Void> future : this.executor.invokeAll(tasks)) {	try {	future.get();	} catch (ExecutionException e) {	this.errorCode = ERROR_EXIT_CODE;	}	}	if (this.allRegions) {	for (Map.Entry<String, List<RegionInfo>> entry : rsAndRMap.entrySet()) {	String serverName = entry.getKey();	
successfully read regions out of on regionserver 

this.errorCode = ERROR_EXIT_CODE;	}	}	if (this.allRegions) {	for (Map.Entry<String, List<RegionInfo>> entry : rsAndRMap.entrySet()) {	String serverName = entry.getKey();	}	}	} catch (InterruptedException e) {	this.errorCode = ERROR_EXIT_CODE;	
sniff regionserver interrupted 

private Map<String, List<RegionInfo>> getAllRegionServerByName() {	Map<String, List<RegionInfo>> rsAndRMap = new HashMap<>();	Table table = null;	RegionLocator regionLocator = null;	try {	if (LOG.isDebugEnabled()) {	
reading list of tables and locations 

}	} catch (IOException e) {	String msg = "Get HTables info failed";	LOG.error(msg, e);	this.errorCode = INIT_ERROR_EXIT_CODE;	} finally {	if (table != null) {	try {	table.close();	} catch (IOException e) {	
close table failed 

regExpFound = false;	pattern = Pattern.compile(rsName);	for (Map.Entry<String, List<RegionInfo>> entry : fullRsAndRMap.entrySet()) {	matcher = pattern.matcher(entry.getKey());	if (matcher.matches()) {	filteredRsAndRMap.put(entry.getKey(), entry.getValue());	regExpFound = true;	}	}	if (!regExpFound) {	
no regionserverinfo found regionserverpattern 

filteredRsAndRMap.put(entry.getKey(), entry.getValue());	regExpFound = true;	}	}	if (!regExpFound) {	}	} else {	if (fullRsAndRMap.containsKey(rsName)) {	filteredRsAndRMap.put(rsName, fullRsAndRMap.get(rsName));	} else {	
no regionserverinfo found regionservername 

public static void main(String[] args) throws Exception {	final Configuration conf = HBaseConfiguration.create();	new GenericOptionsParser(conf, args);	int numThreads = conf.getInt("hbase.canary.threads.num", MAX_THREADS_NUM);	
number of execution threads 

========================= hbase sample_3031 =========================

}	setLeftoverRegions(null);	long regionSizesCalculated = 0L;	long offlineRegionsSkipped = 0L;	long skippedSplitParents = 0L;	long skippedRegionReplicas = 0L;	final long start = EnvironmentEdgeManager.currentTime();	while (iterator.hasNext()) {	long timeRunning = EnvironmentEdgeManager.currentTime() - start;	if (timeRunning > maxIterationMillis) {	
preempting execution of filesystemutilizationchore because it exceeds the maximum iteration configuration value will process remaining iterators on a subsequent invocation 

}	if (RegionInfo.DEFAULT_REPLICA_ID != region.getRegionInfo().getReplicaId()) {	skippedRegionReplicas++;	continue;	}	final long sizeInBytes = computeSize(region);	onlineRegionSizes.put(region.getRegionInfo(), sizeInBytes);	regionSizesCalculated++;	}	if (LOG.isTraceEnabled()) {	
computed the size of regions skipped computation of regions due to not being online on this rs regions due to being the parent of a split and regions due to being region replicas 

========================= hbase sample_2335 =========================

public void start() throws IOException {	if (!MetaTableAccessor.tableExists(masterServices.getConnection(), TableName.NAMESPACE_TABLE_NAME)) {	
namespace table not found creating 

byte[] val =  CellUtil.cloneValue(result.getColumnLatestCell( HTableDescriptor.NAMESPACE_FAMILY_INFO_BYTES, HTableDescriptor.NAMESPACE_COL_DESC_BYTES));	NamespaceDescriptor ns = ProtobufUtil.toNamespaceDescriptor( HBaseProtos.NamespaceDescriptor.parseFrom(val));	zkNamespaceManager.update(ns);	}	} finally {	scanner.close();	}	initialized = true;	return true;	} catch (IOException ie) {	
caught exception in initializing namespace table manager 

public void stop(String why) {	if (this.stopped) {	return;	}	try {	this.zkNamespaceManager.stop();	} catch (IOException ioe) {	
failed namespacemanager close 

if (this.stopped) {	return;	}	try {	this.zkNamespaceManager.stop();	} catch (IOException ioe) {	}	try {	this.nsTable.close();	} catch (IOException ioe) {	
failed namespace table close 

========================= hbase sample_2765 =========================

scanner.seekTo();	assertTrue(scanner.next());	faultyfs.startFaults();	try {	int scanned=0;	while (scanner.next()) {	scanned++;	}	fail("Scanner didn't throw after faults injected");	} catch (IOException ioe) {	
got expected exception 

scanner.seek(KeyValue.LOWESTKEY);	assertNotNull(scanner.next());	faultyfs.startFaults();	try {	int scanned=0;	while (scanner.next() != null) {	scanned++;	}	fail("Scanner didn't throw after faults injected");	} catch (IOException ioe) {	
got expected exception 

admin.createTable(desc);	try (Table table = util.getConnection().getTable(tableName)) {	util.loadTable(table, fam, false);	util.flush();	util.countRows(table);	util.getDFSCluster().shutdownDataNodes();	try {	util.countRows(table);	fail("Did not fail to count after removing data");	} catch (Exception e) {	
got expected error 

========================= hbase sample_1667 =========================

protected void doStart() {	try {	connection = (ClusterConnection) ConnectionFactory.createConnection(this.conf);	this.pool = getDefaultThreadPool(conf);	outputSink = new RegionReplicaOutputSink(controller, tableDescriptors, entryBuffers, connection, pool, numWriterThreads, operationTimeout);	outputSink.startWriterThreads();	super.doStart();	} catch (IOException ex) {	
received exception while creating connection 

protected void doStop() {	if (outputSink != null) {	try {	outputSink.finishWritingAndClose();	} catch (IOException ex) {	
got exception while trying to close outputsink 

try {	outputSink.finishWritingAndClose();	} catch (IOException ex) {	}	}	if (this.pool != null) {	this.pool.shutdownNow();	try {	boolean shutdown = this.pool.awaitTermination(10000, TimeUnit.MILLISECONDS);	if (!shutdown) {	
failed to shutdown the thread pool after seconds 

} catch (IOException ex) {	}	}	if (this.pool != null) {	this.pool.shutdownNow();	try {	boolean shutdown = this.pool.awaitTermination(10000, TimeUnit.MILLISECONDS);	if (!shutdown) {	}	} catch (InterruptedException e) {	
got interrupted while waiting for the thread pool to shut down 

boolean shutdown = this.pool.awaitTermination(10000, TimeUnit.MILLISECONDS);	if (!shutdown) {	}	} catch (InterruptedException e) {	}	}	if (connection != null) {	try {	connection.close();	} catch (IOException ex) {	
got exception closing connection 

for (Entry entry: replicateContext.getEntries()) {	entryBuffers.appendEntry(entry);	}	outputSink.flush();	ctx.getMetrics().incrLogEditsFiltered( outputSink.getSkippedEditsCounter().getAndSet(0));	return true;	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	return false;	} catch (IOException e) {	
received ioexception while trying to replicate 

public void append(TableName tableName, byte[] encodedRegionName, byte[] row, List<Entry> entries) throws IOException {	if (disabledAndDroppedTables.getIfPresent(tableName) != null) {	if (LOG.isTraceEnabled()) {	
skipping entries because table is cached as a disabled or dropped table 

public void append(TableName tableName, byte[] encodedRegionName, byte[] row, List<Entry> entries) throws IOException {	if (disabledAndDroppedTables.getIfPresent(tableName) != null) {	if (LOG.isTraceEnabled()) {	for (Entry entry : entries) {	
skipping 

RegionLocations locations = null;	boolean useCache = true;	while (true) {	try {	locations = RegionReplicaReplayCallable .getRegionLocations(connection, tableName, row, useCache, 0);	if (locations == null) {	throw new HBaseIOException("Cannot locate locations for " + tableName + ", row:" + Bytes.toStringBinary(row));	}	} catch (TableNotFoundException e) {	if (LOG.isTraceEnabled()) {	
skipping entries because table is dropped adding table to cache 

boolean useCache = true;	while (true) {	try {	locations = RegionReplicaReplayCallable .getRegionLocations(connection, tableName, row, useCache, 0);	if (locations == null) {	throw new HBaseIOException("Cannot locate locations for " + tableName + ", row:" + Bytes.toStringBinary(row));	}	} catch (TableNotFoundException e) {	if (LOG.isTraceEnabled()) {	for (Entry entry : entries) {	
skipping 

sink.getSkippedEditsCounter().addAndGet(entries.size());	return;	}	HRegionLocation primaryLocation = locations.getDefaultRegionLocation();	if (!Bytes.equals(primaryLocation.getRegionInfo().getEncodedNameAsBytes(), encodedRegionName)) {	if (useCache) {	useCache = false;	continue;	}	if (LOG.isTraceEnabled()) {	
skipping entries in table because located region is different than the original region from waledit 

return;	}	HRegionLocation primaryLocation = locations.getDefaultRegionLocation();	if (!Bytes.equals(primaryLocation.getRegionInfo().getEncodedNameAsBytes(), encodedRegionName)) {	if (useCache) {	useCache = false;	continue;	}	if (LOG.isTraceEnabled()) {	for (Entry entry : entries) {	
skipping 

for (Future<ReplicateWALEntryResponse> task : tasks) {	try {	task.get();	} catch (InterruptedException e) {	throw new InterruptedIOException(e.getMessage());	} catch (ExecutionException e) {	Throwable cause = e.getCause();	if (cause instanceof IOException) {	if (cause instanceof TableNotFoundException || connection.isTableDisabled(tableName)) {	if (LOG.isTraceEnabled()) {	
skipping entries in table because received exception for dropped or disabled table 

try {	task.get();	} catch (InterruptedException e) {	throw new InterruptedIOException(e.getMessage());	} catch (ExecutionException e) {	Throwable cause = e.getCause();	if (cause instanceof IOException) {	if (cause instanceof TableNotFoundException || connection.isTableDisabled(tableName)) {	if (LOG.isTraceEnabled()) {	for (Entry entry : entries) {	
skipping 

}	if (!this.entries.isEmpty() && !skip) {	Entry[] entriesArray = new Entry[this.entries.size()];	entriesArray = this.entries.toArray(entriesArray);	Pair<AdminProtos.ReplicateWALEntryRequest, CellScanner> p = ReplicationProtbufUtil.buildReplicateWALEntryRequest(entriesArray, location .getRegionInfo().getEncodedNameAsBytes(), null, null, null);	controller.setCellScanner(p.getSecond());	return stub.replay(controller, p.getFirst());	}	if (skip) {	if (LOG.isTraceEnabled()) {	
skipping entries in table because located region is different than the original region from waledit 

if (!this.entries.isEmpty() && !skip) {	Entry[] entriesArray = new Entry[this.entries.size()];	entriesArray = this.entries.toArray(entriesArray);	Pair<AdminProtos.ReplicateWALEntryRequest, CellScanner> p = ReplicationProtbufUtil.buildReplicateWALEntryRequest(entriesArray, location .getRegionInfo().getEncodedNameAsBytes(), null, null, null);	controller.setCellScanner(p.getSecond());	return stub.replay(controller, p.getFirst());	}	if (skip) {	if (LOG.isTraceEnabled()) {	for (Entry entry : entries) {	
skipping 

========================= hbase sample_2948 =========================

private void loadProcedure(final ProcedureWALEntry entry, final ProcedureProtos.Procedure proc) {	maxProcId = Math.max(maxProcId, proc.getProcId());	if (isRequired(proc.getProcId())) {	if (LOG.isTraceEnabled()) {	
read entry 

private void deleteEntry(final long procId) {	if (LOG.isTraceEnabled()) {	
delete entry 

private boolean checkReadyToRun(Entry rootEntry) {	assert !rootEntry.hasParent() : "expected root procedure, got " + rootEntry;	if (rootEntry.isFinished()) {	if (rootEntry.childHead != null) {	
unexpected active children for root procedure 

private boolean checkReadyToRun(Entry rootEntry) {	assert !rootEntry.hasParent() : "expected root procedure, got " + rootEntry;	if (rootEntry.isFinished()) {	if (rootEntry.childHead != null) {	for (Entry p = rootEntry.childHead; p != null; p = p.linkNext) {	
unexpected active children 

========================= hbase sample_1237 =========================

public void put(String qual, long ts) {	if (!putTimestamps.contains(ts)) {	put.addColumn(FAMILY_BYTES, Bytes.toBytes(qual), ts, createValue(ts));	putTimestamps.add(ts);	}	if (VERBOSE) {	
put row cf qualifier ts 

========================= hbase sample_1688 =========================

initialize(context);	}	try {	if (getTable() == null) {	throw new IOException(INITIALIZATION_ERROR);	}	} catch (IllegalStateException exception) {	throw new IOException(INITIALIZATION_ERROR, exception);	}	TableSplit tSplit = (TableSplit) split;	
input split length bytes 

continue;	}	byte[] startRow = scan.getStartRow();	byte[] stopRow = scan.getStopRow();	if ((startRow.length == 0 || keys.getSecond()[i].length == 0 || Bytes.compareTo(startRow, keys.getSecond()[i]) < 0) && (stopRow.length == 0 || Bytes.compareTo(stopRow, keys.getFirst()[i]) > 0)) {	byte[] splitStart = startRow.length == 0 || Bytes.compareTo(keys.getFirst()[i], startRow) >= 0 ? keys.getFirst()[i] : startRow;	byte[] splitStop = (stopRow.length == 0 || Bytes.compareTo(keys.getSecond()[i], stopRow) <= 0) && keys.getSecond()[i].length > 0 ? keys.getSecond()[i] : stopRow;	HRegionLocation location = getRegionLocator().getRegionLocation(keys.getFirst()[i], false);	InetSocketAddress isa = new InetSocketAddress(location.getHostname(), location.getPort());	if (isa.isUnresolved()) {	
failed resolve 

}	InetAddress regionAddress = isa.getAddress();	String regionLocation;	regionLocation = reverseDNS(regionAddress);	byte[] regionName = location.getRegionInfo().getRegionName();	String encodedRegionName = location.getRegionInfo().getEncodedName();	long regionSize = sizeCalculator.getRegionSize(regionName);	TableSplit split = new TableSplit(tableName, scan, splitStart, splitStop, regionLocation, encodedRegionName, regionSize);	splits.add(split);	if (LOG.isDebugEnabled()) {	
getsplits split 

return splits;	}	List<InputSplit> resultList = new ArrayList<>();	long totalRegionSize = 0;	for (int i = 0; i < splits.size(); i++) {	TableSplit ts = (TableSplit) splits.get(i);	totalRegionSize += ts.getLength();	}	long averageRegionSize = totalRegionSize / splits.size();	if (averageRegionSize <= 0) {	
the averageregionsize is not positive set it to long max value 

protected void initializeTable(Connection connection, TableName tableName) throws IOException {	if (this.table != null || this.connection != null) {	
initializetable called multiple times overwriting connection and table reference tableinputformatbase will not close these old references when done 

========================= hbase sample_3436 =========================

htable1.put(put);	Thread.sleep(SLEEP_TIME * NB_RETRIES);	admin.disablePeer("2");	utility2.startMiniHBaseCluster(1, 2);	Get get = new Get(rowkey);	for (int i = 0; i < NB_RETRIES; i++) {	Result res = htable2.get(get);	if (res.size() >= 1) {	fail("Replication wasn't disabled");	} else {	
row not replicated let s wait a bit more 

fail("Replication wasn't disabled");	} else {	Thread.sleep(SLEEP_TIME);	}	}	admin.enablePeer("2");	Thread.sleep(SLEEP_TIME * NB_RETRIES);	for (int i = 0; i < NB_RETRIES; i++) {	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

========================= hbase sample_1958 =========================

assert fs != null;	assert initialPath != null;	assert conf != null;	this.fs = fs;	this.conf = conf;	this.initialPath = initialPath;	Path p = initialPath;	if (HFileLink.isHFileLink(p)) {	this.reference = null;	this.link = HFileLink.buildFromHFileLinkPattern(conf, p);	
is a link 

this.reference = null;	this.link = HFileLink.buildFromHFileLinkPattern(conf, p);	} else if (isReference(p)) {	this.reference = Reference.read(fs, p);	Path referencePath = getReferredToFile(p);	if (HFileLink.isHFileLink(referencePath)) {	this.link = HFileLink.buildFromHFileLinkPattern(conf, referencePath);	} else {	this.link = null;	}	
is a reference to 

public static Path getReferredToFile(final Path p) {	Matcher m = REF_NAME_PATTERN.matcher(p.getName());	if (m == null || !m.matches()) {	
failed match of store file name 

public static boolean isValid(final FileStatus fileStatus) throws IOException {	final Path p = fileStatus.getPath();	if (fileStatus.isDirectory()) return false;	if (!HFileLink.isHFileLink(p) && fileStatus.getLen() <= 0) {	
skipping because it is empty hbase data loss 

========================= hbase sample_2732 =========================

public boolean waitForOutstandingTasks() throws ForeignException {	
waiting for backup procedure to finish 

public void abort(String why, Throwable e) {	if (this.aborted) {	return;	}	this.aborted = true;	
aborting because 

========================= hbase sample_583 =========================

private void initialize(Cluster cluster, boolean sslEnabled) {	this.cluster = cluster;	this.sslEnabled = sslEnabled;	extraHeaders = new ConcurrentHashMap<>();	String clspath = System.getProperty("java.class.path");	
classpath 

if (headers != null) {	for (Header header: headers) {	method.addHeader(header);	}	}	long startTime = System.currentTimeMillis();	if (resp != null) EntityUtils.consumeQuietly(resp.getEntity());	resp = httpClient.execute(method);	long endTime = System.currentTimeMillis();	if (LOG.isTraceEnabled()) {	
in ms 

========================= hbase sample_3123 =========================

tableScan.setTimeRange(startTime, endTime);	if (!startRow.isEmpty()) {	tableScan.setStartRow(Bytes.toBytes(startRow));	}	tableScan.setStopRow(Bytes.toBytes(endRow));	for (String csplit : column) {	String[] familysplit = csplit.trim().split(":");	if (familysplit.length == 2) {	if (familysplit[1].length() > 0) {	if (LOG.isTraceEnabled()) {	
scan family and column 

for (String csplit : column) {	String[] familysplit = csplit.trim().split(":");	if (familysplit.length == 2) {	if (familysplit[1].length() > 0) {	if (LOG.isTraceEnabled()) {	}	tableScan.addColumn(Bytes.toBytes(familysplit[0]), Bytes.toBytes(familysplit[1]));	} else {	tableScan.addFamily(Bytes.toBytes(familysplit[0]));	if (LOG.isTraceEnabled()) {	
scan family and empty qualifier 

}	tableScan.addColumn(Bytes.toBytes(familysplit[0]), Bytes.toBytes(familysplit[1]));	} else {	tableScan.addFamily(Bytes.toBytes(familysplit[0]));	if (LOG.isTraceEnabled()) {	}	tableScan.addColumn(Bytes.toBytes(familysplit[0]), null);	}	} else if (StringUtils.isNotEmpty(familysplit[0])) {	if (LOG.isTraceEnabled()) {	
scan family 

========================= hbase sample_3089 =========================

byte[][] splitKeys = new byte[3][];	splitKeys[0] = "region1".getBytes();	splitKeys[1] = HConstants.EMPTY_BYTE_ARRAY;	splitKeys[2] = "region2".getBytes();	HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));	desc.addFamily(new HColumnDescriptor("col"));	try {	admin.createTable(desc, splitKeys);	fail("Test case should fail as empty split key is passed.");	} catch (IllegalArgumentException e) {	
expected 

========================= hbase sample_2118 =========================

TableName tableName = TableName.valueOf(opts.tableName);	boolean needsDelete = false, exists = admin.tableExists(tableName);	boolean isReadCmd = opts.cmdName.toLowerCase(Locale.ROOT).contains("read") || opts.cmdName.toLowerCase(Locale.ROOT).contains("scan");	if (!exists && isReadCmd) {	throw new IllegalStateException( "Must specify an existing table for read commands. Run a write command first.");	}	HTableDescriptor desc = exists ? admin.getTableDescriptor(TableName.valueOf(opts.tableName)) : null;	byte[][] splits = getSplits(opts);	if ((exists && opts.presplitRegions != DEFAULT_OPTS.presplitRegions) || (!isReadCmd && desc != null && !StringUtils.equals(desc.getRegionSplitPolicyClassName(), opts.splitPolicy)) || (!isReadCmd && desc != null && desc.getRegionReplication() != opts.replicas)) {	needsDelete = true;	
needsDelete needsDelete isReadCmd exists desc presplit splitPolicy replicas 

if (admin.isTableEnabled(tableName)) {	admin.disableTable(tableName);	}	admin.deleteTable(tableName);	}	if (!exists || needsDelete) {	desc = getTableDescriptor(opts);	if (splits != null) {	if (LOG.isDebugEnabled()) {	for (int i = 0; i < splits.length; i++) {	
split 

}	if (!exists || needsDelete) {	desc = getTableDescriptor(opts);	if (splits != null) {	if (LOG.isDebugEnabled()) {	for (int i = 0; i < splits.length; i++) {	}	}	}	admin.createTable(desc, splits);	
table created 

final int index = i;	threads[i] = pool.submit(new Callable<RunResult>() {	public RunResult call() throws Exception {	TestOptions threadOpts = new TestOptions(opts);	if (threadOpts.startRow == 0) threadOpts.startRow = index * threadOpts.perClientRunRows;	RunResult run = runOneClient(cmd, conf, con, asyncCon, threadOpts, new Status() {	public void setStatus(final String msg) throws IOException {	LOG.info(msg);	}	});	
finished in ms over rows 

}	pool.shutdown();	for (int i = 0; i < threads.length; i++) {	try {	results[i] = threads[i].get();	} catch (ExecutionException e) {	throw new IOException(e.getCause());	}	}	final String test = cmd.getSimpleName();	
summary of timings ms 

} catch (ExecutionException e) {	throw new IOException(e.getCause());	}	}	final String test = cmd.getSimpleName();	Arrays.sort(results);	long total = 0;	for (RunResult result : results) {	total += result.duration;	}	
tmin ms tmax ms tavg ms 

========================= hbase sample_3359 =========================

public static void setUpBeforeClass() throws Exception {	Configuration conf = TEST_UTIL.getConfiguration();	conf.set(HConstants.CRYPTO_KEYPROVIDER_CONF_KEY, KeyProviderForTesting.class.getName());	conf.set(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, "hbase");	
hbase hlog split skip errors 

========================= hbase sample_1364 =========================

public RegionInfo call() throws IOException {	return createRegion(conf, rootDir, tableDescriptor, newRegion, task);	}	});	}	try {	for (int i = 0; i < regionNumber; i++) {	regionInfos.add(completionService.take().get());	}	} catch (InterruptedException e) {	
caught during region creation 

========================= hbase sample_2231 =========================

try {	if (localfs) {	testDir = getUnitTestdir(getName());	if (fs.exists(testDir)) {	fs.delete(testDir, true);	}	} else {	testDir = FSUtils.getRootDir(conf);	}	} catch (Exception e) {	
error during setup 

protected void tearDown() throws Exception {	try {	if (localfs) {	if (this.fs.exists(testDir)) {	this.fs.delete(testDir, true);	}	}	} catch (Exception e) {	
error during tear down 

public static void shutdownDfs(MiniDFSCluster cluster) {	if (cluster != null) {	
shutting down mini dfs 

public static void shutdownDfs(MiniDFSCluster cluster) {	if (cluster != null) {	try {	cluster.shutdown();	} catch (Exception e) {	}	try {	FileSystem fs = cluster.getFileSystem();	if (fs != null) {	
shutting down filesystem 

cluster.shutdown();	} catch (Exception e) {	}	try {	FileSystem fs = cluster.getFileSystem();	if (fs != null) {	fs.close();	}	FileSystem.closeAll();	} catch (IOException e) {	
error closing file system 

========================= hbase sample_1558 =========================

String inputDirs = args[0];	String tabName = args[1];	conf.setStrings(TABLES_KEY, tabName);	conf.set(FileInputFormat.INPUT_DIR, inputDirs);	Job job = Job.getInstance(conf, conf.get(JOB_NAME_CONF_KEY, NAME + "_" + EnvironmentEdgeManager.currentTime()));	job.setJarByClass(MapReduceHFileSplitterJob.class);	job.setInputFormatClass(HFileInputFormat.class);	job.setMapOutputKeyClass(ImmutableBytesWritable.class);	String hfileOutPath = conf.get(BULK_OUTPUT_CONF_KEY);	if (hfileOutPath != null) {	
add incremental job from 

job.setMapperClass(HFileCellMapper.class);	job.setReducerClass(CellSortReducer.class);	Path outputDir = new Path(hfileOutPath);	FileOutputFormat.setOutputPath(job, outputDir);	job.setMapOutputValueClass(MapReduceExtendedCell.class);	try (Connection conn = ConnectionFactory.createConnection(conf);	Table table = conn.getTable(tableName);	RegionLocator regionLocator = conn.getRegionLocator(tableName)) {	HFileOutputFormat2.configureIncrementalLoad(job, table.getDescriptor(), regionLocator);	}	
success configuring load incremental job 

========================= hbase sample_595 =========================

private boolean doInit(Configuration conf) {	boolean tuningEnabled = true;	globalMemStorePercent = MemorySizeUtil.getGlobalMemStoreHeapPercent(conf, false);	blockCachePercent = conf.getFloat(HFILE_BLOCK_CACHE_SIZE_KEY, HConstants.HFILE_BLOCK_CACHE_SIZE_DEFAULT);	MemorySizeUtil.checkForClusterFreeHeapMemoryLimit(conf);	globalMemStorePercentMinRange = conf.getFloat(MEMSTORE_SIZE_MIN_RANGE_KEY, globalMemStorePercent);	globalMemStorePercentMaxRange = conf.getFloat(MEMSTORE_SIZE_MAX_RANGE_KEY, globalMemStorePercent);	if (globalMemStorePercent < globalMemStorePercentMinRange) {	
setting to same value as because supplied value greater than initial memstore size value 

globalMemStorePercent = MemorySizeUtil.getGlobalMemStoreHeapPercent(conf, false);	blockCachePercent = conf.getFloat(HFILE_BLOCK_CACHE_SIZE_KEY, HConstants.HFILE_BLOCK_CACHE_SIZE_DEFAULT);	MemorySizeUtil.checkForClusterFreeHeapMemoryLimit(conf);	globalMemStorePercentMinRange = conf.getFloat(MEMSTORE_SIZE_MIN_RANGE_KEY, globalMemStorePercent);	globalMemStorePercentMaxRange = conf.getFloat(MEMSTORE_SIZE_MAX_RANGE_KEY, globalMemStorePercent);	if (globalMemStorePercent < globalMemStorePercentMinRange) {	globalMemStorePercentMinRange = globalMemStorePercent;	conf.setFloat(MEMSTORE_SIZE_MIN_RANGE_KEY, globalMemStorePercentMinRange);	}	if (globalMemStorePercent > globalMemStorePercentMaxRange) {	
setting to same value as because supplied value less than initial memstore size value 

if (globalMemStorePercent > globalMemStorePercentMaxRange) {	globalMemStorePercentMaxRange = globalMemStorePercent;	conf.setFloat(MEMSTORE_SIZE_MAX_RANGE_KEY, globalMemStorePercentMaxRange);	}	if (globalMemStorePercent == globalMemStorePercentMinRange && globalMemStorePercent == globalMemStorePercentMaxRange) {	tuningEnabled = false;	}	blockCachePercentMinRange = conf.getFloat(BLOCK_CACHE_SIZE_MIN_RANGE_KEY, blockCachePercent);	blockCachePercentMaxRange = conf.getFloat(BLOCK_CACHE_SIZE_MAX_RANGE_KEY, blockCachePercent);	if (blockCachePercent < blockCachePercentMinRange) {	
setting to same value as because supplied value greater than initial block cache size 

if (globalMemStorePercent == globalMemStorePercentMinRange && globalMemStorePercent == globalMemStorePercentMaxRange) {	tuningEnabled = false;	}	blockCachePercentMinRange = conf.getFloat(BLOCK_CACHE_SIZE_MIN_RANGE_KEY, blockCachePercent);	blockCachePercentMaxRange = conf.getFloat(BLOCK_CACHE_SIZE_MAX_RANGE_KEY, blockCachePercent);	if (blockCachePercent < blockCachePercentMinRange) {	blockCachePercentMinRange = blockCachePercent;	conf.setFloat(BLOCK_CACHE_SIZE_MIN_RANGE_KEY, blockCachePercentMinRange);	}	if (blockCachePercent > blockCachePercentMaxRange) {	
setting to same value as because supplied value less than initial block cache size 

public void start(ChoreService service) {	
starting heapmemorytuner chore 

public void stop() {	
stopping heapmemorytuner chore 

protected void chore() {	final MemoryUsage usage = MemorySizeUtil.safeGetHeapMemoryUsage();	if (usage != null) {	heapOccupancyPercent = (float)usage.getUsed() / (float)usage.getCommitted();	} else {	heapOccupancyPercent = Float.MAX_VALUE;	}	if (heapOccupancyPercent >= heapOccupancyLowWatermark) {	if (!alarming) {	
heapoccupancypercent is above heap occupancy alarm watermark 

}	metricsHeapMemoryManager.increaseAboveHeapOccupancyLowWatermarkCounter();	triggerNow();	try {	Thread.sleep(1000);	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	}	} else {	if (alarming) {	
heapoccupancypercent is now below the heap occupancy alarm watermark 

metricsHeapMemoryManager.setCurBlockCacheSizeGauge(blockCache.getCurrentSize());	long globalMemstoreHeapSize = regionServerAccounting.getGlobalMemStoreHeapSize();	tunerContext.setCurMemStoreUsed((float) globalMemstoreHeapSize / maxHeapSize);	metricsHeapMemoryManager.setCurMemStoreSizeGauge(globalMemstoreHeapSize);	tunerContext.setCurBlockCacheSize(blockCachePercent);	tunerContext.setCurMemStoreSize(globalMemStorePercent);	TunerResult result = null;	try {	result = this.heapMemTuner.tune(tunerContext);	} catch (Throwable t) {	
exception thrown from the heapmemorytuner implementation 

tunerContext.setCurBlockCacheSize(blockCachePercent);	tunerContext.setCurMemStoreSize(globalMemStorePercent);	TunerResult result = null;	try {	result = this.heapMemTuner.tune(tunerContext);	} catch (Throwable t) {	}	if (result != null && result.needsTuning()) {	float memstoreSize = result.getMemStoreSize();	float blockCacheSize = result.getBlockCacheSize();	
from heapmemorytuner new memstoresize new blockcachesize 

tunerContext.setCurMemStoreSize(globalMemStorePercent);	TunerResult result = null;	try {	result = this.heapMemTuner.tune(tunerContext);	} catch (Throwable t) {	}	if (result != null && result.needsTuning()) {	float memstoreSize = result.getMemStoreSize();	float blockCacheSize = result.getBlockCacheSize();	if (memstoreSize < globalMemStorePercentMinRange) {	
new memstoresize from heapmemorytuner is below min level resetting memstoresize to min size 

try {	result = this.heapMemTuner.tune(tunerContext);	} catch (Throwable t) {	}	if (result != null && result.needsTuning()) {	float memstoreSize = result.getMemStoreSize();	float blockCacheSize = result.getBlockCacheSize();	if (memstoreSize < globalMemStorePercentMinRange) {	memstoreSize = globalMemStorePercentMinRange;	} else if (memstoreSize > globalMemStorePercentMaxRange) {	
new memstoresize from heapmemorytuner is above max level resetting memstoresize to max size 

}	if (result != null && result.needsTuning()) {	float memstoreSize = result.getMemStoreSize();	float blockCacheSize = result.getBlockCacheSize();	if (memstoreSize < globalMemStorePercentMinRange) {	memstoreSize = globalMemStorePercentMinRange;	} else if (memstoreSize > globalMemStorePercentMaxRange) {	memstoreSize = globalMemStorePercentMaxRange;	}	if (blockCacheSize < blockCachePercentMinRange) {	
new blockcachesize from heapmemorytuner is below min level resetting blockcachesize to min size 

float memstoreSize = result.getMemStoreSize();	float blockCacheSize = result.getBlockCacheSize();	if (memstoreSize < globalMemStorePercentMinRange) {	memstoreSize = globalMemStorePercentMinRange;	} else if (memstoreSize > globalMemStorePercentMaxRange) {	memstoreSize = globalMemStorePercentMaxRange;	}	if (blockCacheSize < blockCachePercentMinRange) {	blockCacheSize = blockCachePercentMinRange;	} else if (blockCacheSize > blockCachePercentMaxRange) {	
new blockcachesize from heapmemorytuner is above max level resetting blockcachesize to min size 

memstoreSize = globalMemStorePercentMaxRange;	}	if (blockCacheSize < blockCachePercentMinRange) {	blockCacheSize = blockCachePercentMinRange;	} else if (blockCacheSize > blockCachePercentMaxRange) {	blockCacheSize = blockCachePercentMaxRange;	}	int gml = (int) (memstoreSize * CONVERT_TO_PERCENTAGE);	int bcul = (int) ((blockCacheSize) * CONVERT_TO_PERCENTAGE);	if (CONVERT_TO_PERCENTAGE - (gml + bcul) < CLUSTER_MINIMUM_MEMORY_THRESHOLD) {	
current heap configuration from heapmemorytuner exceeds the threshold required for successful cluster operation the combined value cannot exceed is and is 

int gml = (int) (memstoreSize * CONVERT_TO_PERCENTAGE);	int bcul = (int) ((blockCacheSize) * CONVERT_TO_PERCENTAGE);	if (CONVERT_TO_PERCENTAGE - (gml + bcul) < CLUSTER_MINIMUM_MEMORY_THRESHOLD) {	} else {	int memStoreDeltaSize = (int) ((memstoreSize - globalMemStorePercent) * CONVERT_TO_PERCENTAGE);	int blockCacheDeltaSize = (int) ((blockCacheSize - blockCachePercent) * CONVERT_TO_PERCENTAGE);	metricsHeapMemoryManager.updateMemStoreDeltaSizeHistogram(memStoreDeltaSize);	metricsHeapMemoryManager.updateBlockCacheDeltaSizeHistogram(blockCacheDeltaSize);	long newBlockCacheSize = (long) (maxHeapSize * blockCacheSize);	long newMemstoreSize = (long) (maxHeapSize * memstoreSize);	
setting block cache heap size to and memstore heap size to 

blockCache.setMaxSize(newBlockCacheSize);	globalMemStorePercent = memstoreSize;	memStoreFlusher.setGlobalMemStoreLimit(newMemstoreSize);	for (HeapMemoryTuneObserver observer : tuneObservers) {	observer.onHeapMemoryTune(newMemstoreSize, newBlockCacheSize);	}	}	} else {	metricsHeapMemoryManager.increaseTunerDoNothingCounter();	if (LOG.isDebugEnabled()) {	
no changes made by heapmemorytuner 

========================= hbase sample_2724 =========================

PendingWatcher pendingWatcher = new PendingWatcher();	this.recoverableZooKeeper = ZKUtil.connect(conf, quorum, pendingWatcher, identifier);	pendingWatcher.prepare(this);	if (canCreateBaseZNode) {	try {	createBaseZNodes();	} catch (ZooKeeperConnectionException zce) {	try {	this.recoverableZooKeeper.close();	} catch (InterruptedException ie) {	
encountered interruptedexception when closing 

public void checkAndSetZNodeAcls() {	if (!ZKUtil.isSecureZooKeeper(getConfiguration())) {	
not a secure deployment proceeding 

public void checkAndSetZNodeAcls() {	if (!ZKUtil.isSecureZooKeeper(getConfiguration())) {	return;	}	try {	List<ACL> actualAcls = recoverableZooKeeper.getAcl(znodePaths.baseZNode, new Stat());	if (!isBaseZnodeAclSetup(actualAcls)) {	
setting znode acls 

try {	List<ACL> actualAcls = recoverableZooKeeper.getAcl(znodePaths.baseZNode, new Stat());	if (!isBaseZnodeAclSetup(actualAcls)) {	setZnodeAclsRecursive(znodePaths.baseZNode);	}	} catch(KeeperException.NoNodeException nne) {	return;	} catch(InterruptedException ie) {	interruptedExceptionNoThrow(ie, false);	} catch (IOException|KeeperException e) {	
received exception while checking and setting zookeeper acls 

private void setZnodeAclsRecursive(String znode) throws KeeperException, InterruptedException {	List<String> children = recoverableZooKeeper.getChildren(znode, false);	for (String child : children) {	setZnodeAclsRecursive(ZNodePaths.joinZNode(znode, child));	}	List<ACL> acls = ZKUtil.createACL(this, znode, true);	
setting acls for znode acl 

private boolean isBaseZnodeAclSetup(List<ACL> acls) throws IOException {	if (LOG.isDebugEnabled()) {	
checking znode acls 

private boolean isBaseZnodeAclSetup(List<ACL> acls) throws IOException {	if (LOG.isDebugEnabled()) {	}	String[] superUsers = conf.getStrings(Superusers.SUPERUSER_CONF_KEY);	if (superUsers != null && !checkACLForSuperUsers(superUsers, acls)) {	return false;	}	String hbaseUser = UserGroupInformation.getCurrentUser().getShortUserName();	if (acls.isEmpty()) {	if (LOG.isDebugEnabled()) {	
acl is empty 

if (LOG.isDebugEnabled()) {	}	return false;	}	for (ACL acl : acls) {	int perms = acl.getPerms();	Id id = acl.getId();	if (Ids.ANYONE_ID_UNSAFE.equals(id)) {	if (perms != Perms.READ) {	if (LOG.isDebugEnabled()) {	
permissions for s are not correct have x want x 

Id id = acl.getId();	if (Ids.ANYONE_ID_UNSAFE.equals(id)) {	if (perms != Perms.READ) {	if (LOG.isDebugEnabled()) {	}	return false;	}	} else if (superUsers != null && isSuperUserId(superUsers, id)) {	if (perms != Perms.ALL) {	if (LOG.isDebugEnabled()) {	
permissions for s are not correct have x want x 

}	} else if ("sasl".equals(id.getScheme())) {	String name = id.getId();	Matcher match = NAME_PATTERN.matcher(name);	if (match.matches()) {	name = match.group(1);	}	if (name.equals(hbaseUser)) {	if (perms != Perms.ALL) {	if (LOG.isDebugEnabled()) {	
permissions for s are not correct have x want x 

name = match.group(1);	}	if (name.equals(hbaseUser)) {	if (perms != Perms.ALL) {	if (LOG.isDebugEnabled()) {	}	return false;	}	} else {	if (LOG.isDebugEnabled()) {	
unexpected shortname in sasl acl 

}	return false;	}	} else {	if (LOG.isDebugEnabled()) {	}	return false;	}	} else {	if (LOG.isDebugEnabled()) {	
unexpected acl id 

private boolean checkACLForSuperUsers(String[] superUsers, List<ACL> acls) {	for (String user : superUsers) {	boolean hasAccess = false;	if (!AuthUtil.isGroupPrincipal(user)) {	for (ACL acl : acls) {	if (user.equals(acl.getId().getId())) {	if (acl.getPerms() == Perms.ALL) {	hasAccess = true;	} else {	if (LOG.isDebugEnabled()) {	
superuser s does not have correct permissions have x want x 

private void connectionEvent(WatchedEvent event) {	switch(event.getState()) {	case SyncConnected: this.identifier = this.prefix + "-0x" + Long.toHexString(this.recoverableZooKeeper.getSessionId());	
connected 

private void connectionEvent(WatchedEvent event) {	switch(event.getState()) {	case SyncConnected: this.identifier = this.prefix + "-0x" + Long.toHexString(this.recoverableZooKeeper.getSessionId());	break;	
received disconnected from zookeeper ignoring 

public void keeperException(KeeperException ke) throws KeeperException {	
received unexpected keeperexception re throwing exception 

public void interruptedExceptionNoThrow(InterruptedException ie, boolean throwLater) {	
received interruptedexception will interrupt current thread and rethrow a systemerrorexception 

========================= hbase sample_741 =========================

TEST_UTIL.getConfiguration().setInt("dfs.datanode.max.xceivers", 9192);	TEST_UTIL.startMiniCluster(3);	conf = TEST_UTIL.getConfiguration();	this.connection = ConnectionFactory.createConnection(conf);	assertEquals(0, TEST_UTIL.getAdmin().listTables().length);	table = TableName.valueOf(TABLE_BASE + "-" + tableIdx);	tableIdx++;	htbl = setupTable(table);	populateTable(htbl);	assertEquals(5, scanMeta());	
table has entries 

protected void deleteRegion(Configuration conf, final Table tbl, byte[] startKey, byte[] endKey) throws IOException {	
before delete 

HTableDescriptor htd = tbl.getTableDescriptor();	dumpMeta(htd);	List<HRegionLocation> regions;	try(RegionLocator rl = connection.getRegionLocator(tbl.getName())) {	regions = rl.getAllRegionLocations();	}	for (HRegionLocation e : regions) {	RegionInfo hri = e.getRegionInfo();	ServerName hsa = e.getServerName();	if (Bytes.compareTo(hri.getStartKey(), startKey) == 0 && Bytes.compareTo(hri.getEndKey(), endKey) == 0) {	
regionname 

List<HRegionLocation> regions;	try(RegionLocator rl = connection.getRegionLocator(tbl.getName())) {	regions = rl.getAllRegionLocations();	}	for (HRegionLocation e : regions) {	RegionInfo hri = e.getRegionInfo();	ServerName hsa = e.getServerName();	if (Bytes.compareTo(hri.getStartKey(), startKey) == 0 && Bytes.compareTo(hri.getEndKey(), endKey) == 0) {	byte[] deleteRow = hri.getRegionName();	TEST_UTIL.getAdmin().unassign(deleteRow, true);	
deleting hdfs data 

Path p = new Path(FSUtils.getTableDir(rootDir, htd.getTableName()), hri.getEncodedName());	fs.delete(p, true);	try (Table meta = this.connection.getTable(TableName.META_TABLE_NAME)) {	Delete delete = new Delete(deleteRow);	meta.delete(delete);	}	}	LOG.info(hri.toString() + hsa.toString());	}	TEST_UTIL.getMetaTableRows(htd.getTableName());	
after delete 

protected RegionInfo createRegion(Configuration conf, final Table htbl, byte[] startKey, byte[] endKey) throws IOException {	Table meta = TEST_UTIL.getConnection().getTable(TableName.META_TABLE_NAME);	HTableDescriptor htd = htbl.getTableDescriptor();	RegionInfo hri = RegionInfoBuilder.newBuilder(htbl.getName()) .setStartKey(startKey) .setEndKey(endKey) .build();	
manually adding regioninfo and hdfs data 

protected int scanMeta() throws IOException {	
scanning meta 

========================= hbase sample_1299 =========================

public void testReadingInvalidDirectoryFromFS() throws IOException {	FileSystem fs = FileSystem.get(UTIL.getConfiguration());	try {	new FSTableDescriptors(UTIL.getConfiguration(), fs, FSUtils.getRootDir(UTIL.getConfiguration())) .get(TableName.valueOf(HConstants.HBASE_TEMP_DIRECTORY));	fail("Shouldn't be able to read a table descriptor for the archive directory.");	} catch (Exception e) {	
correctly got error when reading a table descriptor from the archive directory 

========================= hbase sample_1333 =========================

}	MobUtils.doMobCompaction(master.getConfiguration(), master.getFileSystem(), htd.getTableName(), hcd, pool, false, lock);	}	} finally {	if (reported) {	master.reportMobCompactionEnd(htd.getTableName());	}	}	}	} catch (Exception e) {	
failed to compact mob files 

========================= hbase sample_2773 =========================

public void start(CoprocessorEnvironment env) throws IOException {	this.conf = env.getConfiguration();	authorizationEnabled = AccessChecker.isAuthorizationSupported(conf);	if (!authorizationEnabled) {	
the visibilitycontroller has been loaded with authorization checks disabled 

private void initVisibilityLabelService(RegionCoprocessorEnvironment env) {	try {	this.visibilityLabelService.init(env);	this.initialized = true;	} catch (IOException ioe) {	
error while initializing visibilitylabelservice 

if (status.getOperationStatusCode() != SUCCESS) {	RegionActionResult.Builder failureResultBuilder = RegionActionResult.newBuilder();	failureResultBuilder.setException(buildException(new DoNotRetryIOException( status.getExceptionMsg())));	response.setResult(i, failureResultBuilder.build());	}	i++;	}	}	} catch (AccessDeniedException e) {	logResult(false, "addLabels", e.getMessage(), null, labels, null);	
user is not having required permissions to add labels 

if (status.getOperationStatusCode() == SUCCESS) {	response.addResult(successResult);	} else {	RegionActionResult.Builder failureResultBuilder = RegionActionResult.newBuilder();	failureResultBuilder.setException(buildException(new DoNotRetryIOException( status.getExceptionMsg())));	response.addResult(failureResultBuilder.build());	}	}	} catch (AccessDeniedException e) {	logResult(false, "setAuths", e.getMessage(), user, labelAuths, null);	
user is not having required permissions to set authorization 

if (status.getOperationStatusCode() == SUCCESS) {	response.addResult(successResult);	} else {	RegionActionResult.Builder failureResultBuilder = RegionActionResult.newBuilder();	failureResultBuilder.setException(buildException(new DoNotRetryIOException( status.getExceptionMsg())));	response.addResult(failureResultBuilder.build());	}	}	} catch (AccessDeniedException e) {	logResult(false, "clearAuths", e.getMessage(), requestUser, labelAuths, null);	
user is not having required permissions to clear authorization 

========================= hbase sample_2289 =========================

public List<RegionPlan> balanceCluster(Map<ServerName, List<RegionInfo>> clusterState)  {	List<RegionPlan> plans = new ArrayList<>();	SnapshotOfRegionAssignmentFromMeta snaphotOfRegionAssignment = new SnapshotOfRegionAssignmentFromMeta(super.services.getConnection());	try {	snaphotOfRegionAssignment.initialize();	} catch (IOException ie) {	
not running balancer since exception was thrown 

if (!assignmentHelper.canPlaceFavoredNodes()) {	return super.roundRobinAssignment(regions, servers);	}	Pair<Map<ServerName,List<RegionInfo>>, List<RegionInfo>> segregatedRegions = segregateRegionsAndAssignRegionsWithFavoredNodes(regions, servers);	Map<ServerName,List<RegionInfo>> regionsWithFavoredNodesMap = segregatedRegions.getFirst();	List<RegionInfo> regionsWithNoFavoredNodes = segregatedRegions.getSecond();	assignmentMap = new HashMap<>();	roundRobinAssignmentImpl(assignmentHelper, assignmentMap, regionsWithNoFavoredNodes, servers);	assignmentMap.putAll(regionsWithFavoredNodesMap);	} catch (Exception ex) {	
encountered exception while doing favored nodes assignment falling back to regular assignment 

}	}	}	List<RegionInfo> regions = new ArrayList<>(1);	regions.add(regionInfo);	Map<RegionInfo, ServerName> primaryRSMap = new HashMap<>(1);	primaryRSMap.put(regionInfo, primary);	assignSecondaryAndTertiaryNodesForRegion(assignmentHelper, regions, primaryRSMap);	return primary;	} catch (Exception ex) {	
encountered exception while doing favored nodes random assignment falling back to regular assignment 

public void generateFavoredNodesForDaughter(List<ServerName> servers, RegionInfo parent, RegionInfo regionA, RegionInfo regionB) throws IOException {	Map<RegionInfo, List<ServerName>> result = new HashMap<>();	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(servers, rackManager);	helper.initialize();	List<ServerName> parentFavoredNodes = getFavoredNodes(parent);	if (parentFavoredNodes == null) {	
unable to find favored nodes for parent generating new favored nodes for daughter 

========================= hbase sample_2323 =========================

private void stopPrefetch(ScanController controller) {	if (LOG.isDebugEnabled()) {	
x stop prefetching when scanning as the cache size is greater than the maxcachesize 

private void resumePrefetch() {	if (LOG.isDebugEnabled()) {	
x resume prefetching 

========================= hbase sample_468 =========================

public static ScheduledChore getAuthChore(Configuration conf) throws IOException {	UserProvider userProvider = UserProvider.instantiate(conf);	boolean securityEnabled = userProvider.isHadoopSecurityEnabled() && userProvider.isHBaseSecurityEnabled();	if (!securityEnabled) return null;	String host = null;	try {	host = Strings.domainNamePointerToHostName(DNS.getDefaultHost( conf.get("hbase.client.dns.interface", "default"), conf.get("hbase.client.dns.nameserver", "default")));	userProvider.login("hbase.client.keytab.file", "hbase.client.kerberos.principal", host);	} catch (UnknownHostException e) {	
error resolving host name 

UserProvider userProvider = UserProvider.instantiate(conf);	boolean securityEnabled = userProvider.isHadoopSecurityEnabled() && userProvider.isHBaseSecurityEnabled();	if (!securityEnabled) return null;	String host = null;	try {	host = Strings.domainNamePointerToHostName(DNS.getDefaultHost( conf.get("hbase.client.dns.interface", "default"), conf.get("hbase.client.dns.nameserver", "default")));	userProvider.login("hbase.client.keytab.file", "hbase.client.kerberos.principal", host);	} catch (UnknownHostException e) {	throw e;	} catch (IOException e) {	
error while trying to perform the initial login 

public boolean isStopped() {	return isStopped;	}	};	final int CHECK_TGT_INTERVAL = 30 * 1000;	ScheduledChore refreshCredentials = new ScheduledChore("RefreshCredentials", stoppable, CHECK_TGT_INTERVAL) {	protected void chore() {	try {	ugi.checkTGTAndReloginFromKeytab();	} catch (IOException e) {	
got exception while trying to refresh credentials 

========================= hbase sample_1128 =========================

public void serve() {	try {	serverTransport_.listen();	} catch (TTransportException ttx) {	
error occurred during listening 

TBoundedThreadPoolServer.this.stop();	}	});	stopped = false;	while (!stopped && !Thread.interrupted()) {	TTransport client = null;	try {	client = serverTransport_.accept();	} catch (TTransportException ttx) {	if (!stopped) {	
transport error when accepting message 

continue;	} else {	break;	}	}	ClientConnnection command = new ClientConnnection(client);	try {	executorService.execute(command);	} catch (RejectedExecutionException rex) {	if (client.getClass() == TSocket.class) {	
from 

private void shutdownServer() {	executorService.shutdown();	long msLeftToWait = serverOptions.stopTimeoutUnit.toMillis(serverOptions.stopTimeoutVal);	long timeMillis = System.currentTimeMillis();	
waiting for up to ms to finish processing pending requests 

try {	executorService.awaitTermination(msLeftToWait, TimeUnit.MILLISECONDS);	break;	} catch (InterruptedException ix) {	long timePassed = System.currentTimeMillis() - timeMillis;	msLeftToWait -= timePassed;	timeMillis += timePassed;	interrupted = true;	}	}	
interrupting all worker threads and waiting for ms longer 

msLeftToWait -= timePassed;	timeMillis += timePassed;	interrupted = true;	}	}	executorService.shutdownNow();	Threads.sleepWithoutInterrupt(TIME_TO_WAIT_AFTER_SHUTDOWN_MS);	if (interrupted) {	Thread.currentThread().interrupt();	}	
thrift server shutdown complete 

TProtocol outputProtocol = null;	try {	processor = processorFactory_.getProcessor(client);	inputTransport = inputTransportFactory_.getTransport(client);	outputTransport = outputTransportFactory_.getTransport(client);	inputProtocol = inputProtocolFactory_.getProtocol(inputTransport);	outputProtocol = outputProtocolFactory_.getProtocol(outputTransport);	while (!stopped && processor.process(inputProtocol, outputProtocol)) {}	} catch (TTransportException ttx) {	} catch (TException tx) {	
thrift error occurred during processing of message 

try {	processor = processorFactory_.getProcessor(client);	inputTransport = inputTransportFactory_.getTransport(client);	outputTransport = outputTransportFactory_.getTransport(client);	inputProtocol = inputProtocolFactory_.getProtocol(inputTransport);	outputProtocol = outputProtocolFactory_.getProtocol(outputTransport);	while (!stopped && processor.process(inputProtocol, outputProtocol)) {}	} catch (TTransportException ttx) {	} catch (TException tx) {	} catch (Exception x) {	
error occurred during processing of message 

========================= hbase sample_809 =========================

public void testAdvanceTwiceOnEmptyCell() throws IOException {	Result r = Result.create(new Cell[0]);	assertFalse(r.advance());	try {	r.advance();	fail("NoSuchElementException should have been thrown!");	} catch (NoSuchElementException ex) {	
as expected 

public void testEmptyResultIsReadonly() {	Result emptyResult = Result.EMPTY_RESULT;	Result otherResult = new Result();	try {	emptyResult.copyFrom(otherResult);	fail("UnsupportedOperationException should have been thrown!");	} catch (UnsupportedOperationException ex) {	
as expected 

Result otherResult = new Result();	try {	emptyResult.copyFrom(otherResult);	fail("UnsupportedOperationException should have been thrown!");	} catch (UnsupportedOperationException ex) {	}	try {	emptyResult.setExists(true);	fail("UnsupportedOperationException should have been thrown!");	} catch (UnsupportedOperationException ex) {	
as expected 

public static void main(String[] args) {	TestResult testResult = new TestResult();	try {	testResult.doReadBenchmark();	} catch (Exception e) {	
unexpected exception 

========================= hbase sample_2138 =========================

public HFileArchiveManager disableHFileBackup() throws IOException {	
disabling backups on all tables 

private void enable(ZKWatcher zooKeeper, byte[] table) throws KeeperException {	
ensuring archiving znode exists 

private void enable(ZKWatcher zooKeeper, byte[] table) throws KeeperException {	ZKUtil.createAndFailSilent(zooKeeper, archiveZnode);	String tableNode = this.getTableNode(table);	
creating data 

private void disable(ZKWatcher zooKeeper, byte[] table) throws KeeperException {	zooKeeper.sync(archiveZnode);	if (ZKUtil.checkExists(zooKeeper, archiveZnode) < 0) {	return;	}	String tableNode = this.getTableNode(table);	zooKeeper.sync(tableNode);	
attempting to delete table node 

public void stop() {	if (!this.stopped) {	this.stopped = true;	
stopping hfilearchivemanager 

========================= hbase sample_2991 =========================

protected synchronized ZooKeeper checkZk() throws KeeperException {	if (this.zk == null) {	try {	this.zk = new ZooKeeper(quorumServers, sessionTimeout, watcher);	} catch (IOException ex) {	
unable to create zookeeper connection 

public synchronized void reconnectAfterExpiration() throws IOException, KeeperException, InterruptedException {	if (zk != null) {	
closing dead zookeeper connection session was 

public synchronized void reconnectAfterExpiration() throws IOException, KeeperException, InterruptedException {	if (zk != null) {	zk.close();	zk = null;	}	checkZk();	
recreated a zookeeper session is 

RetryCounter retryCounter = retryCounterFactory.create();	boolean isRetry = false;	while (true) {	try {	long startTime = EnvironmentEdgeManager.currentTime();	checkZk().delete(path, version);	return;	} catch (KeeperException e) {	switch (e.code()) {	case NONODE: if (isRetry) {	
node already deleted assuming a previous attempt succeeded 

private void retryOrThrow(RetryCounter retryCounter, KeeperException e, String opName) throws KeeperException {	if (!retryCounter.shouldRetry()) {	
zookeeper failed after attempts 

String nodePath = checkZk().create(path, data, acl, createMode);	return nodePath;	} catch (KeeperException e) {	switch (e.code()) {	case NODEEXISTS: if (isRetry) {	startTime = EnvironmentEdgeManager.currentTime();	byte[] currentData = checkZk().getData(path, false, null);	if (currentData != null && Bytes.compareTo(currentData, data) == 0) {	return path;	}	
node already exists with could not write 

} catch (KeeperException e) {	switch (e.code()) {	case NODEEXISTS: if (isRetry) {	startTime = EnvironmentEdgeManager.currentTime();	byte[] currentData = checkZk().getData(path, false, null);	if (currentData != null && Bytes.compareTo(currentData, data) == 0) {	return path;	}	throw e;	}	
node already exists 

========================= hbase sample_736 =========================

private int start() throws Exception {	Configuration conf = getConf();	TraceUtil.initTracer(conf);	try {	if (LocalHBaseCluster.isLocal(conf)) {	
not starting a distinct region server because is false 

} else {	logProcessInfo(getConf());	HRegionServer hrs = HRegionServer.constructRegionServer(regionServerClass, conf);	hrs.start();	hrs.join();	if (hrs.isAborted()) {	throw new RuntimeException("HRegionServer Aborted");	}	}	} catch (Throwable t) {	
region server exiting 

========================= hbase sample_2587 =========================

public List<String> getLabels(User user, Authorizations authorizations) {	String userName = user.getShortName();	if (authorizations != null) {	
dropping authorizations requested by user 

========================= hbase sample_2303 =========================

protected abstract boolean setNewStartKey();	protected abstract ScannerCallable createScannerCallable();	protected boolean moveToNextRegion() {	try {	closeScanner();	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
close scanner for failed 

} catch (IOException e) {	if (LOG.isDebugEnabled()) {	}	}	if (currentRegion != null) {	if (!setNewStartKey()) {	return false;	}	scan.resetMvccReadPoint();	if (LOG.isTraceEnabled()) {	
finished 

}	if (currentRegion != null) {	if (!setNewStartKey()) {	return false;	}	scan.resetMvccReadPoint();	if (LOG.isTraceEnabled()) {	}	}	if (LOG.isDebugEnabled() && this.currentRegion != null) {	
advancing internal scanner to startkey at inclusive exclusive 

scan.setLimit(newLimit);	}	if (scan.getLimit() == 0 || scanExhausted(values)) {	closeScanner();	closed = true;	break;	}	boolean regionExhausted = regionExhausted(values);	if (callable.isHeartbeatMessage()) {	if (!cache.isEmpty()) {	
heartbeat message received and cache contains results breaking out of scan loop 

public void close() {	if (!scanMetricsPublished) writeScanMetrics();	if (callable != null) {	callable.setClose();	try {	call(callable, caller, scannerTimeout, false);	} catch (UnknownScannerException e) {	
scanner failed to close 

public void close() {	if (!scanMetricsPublished) writeScanMetrics();	if (callable != null) {	callable.setClose();	try {	call(callable, caller, scannerTimeout, false);	} catch (UnknownScannerException e) {	} catch (IOException e) {	
scanner failed to close 

public boolean renewLease() {	if (callable == null) {	return false;	}	callable.setRenew(true);	try {	this.caller.callWithoutRetries(callable, this.scannerTimeout);	return true;	} catch (Exception e) {	
scanner failed to renew lease 

========================= hbase sample_448 =========================

public Cacheable deserialize(ByteBuff b) throws IOException {	
deserialized 

public void serialize(ByteBuffer destination) {	
serialized to 

========================= hbase sample_1485 =========================

public void cleanExpiredMobFiles(String tableName, ColumnFamilyDescriptor family) throws IOException {	Configuration conf = getConf();	TableName tn = TableName.valueOf(tableName);	FileSystem fs = FileSystem.get(conf);	
cleaning the expired mob files of in 

}	if (family.getMinVersions() > 0) {	throw new IOException( "The minVersions of the column family is not 0, could not be handled by this cleaner");	}	cleanExpiredMobFiles(tableName, family);	return 0;	} finally {	try {	admin.close();	} catch (IOException e) {	
failed to close the hbaseadmin 

cleanExpiredMobFiles(tableName, family);	return 0;	} finally {	try {	admin.close();	} catch (IOException e) {	}	try {	connection.close();	} catch (IOException e) {	
failed to close the connection 

========================= hbase sample_3007 =========================

protected StateMachineProcedure.Flow executeFromState(TestProcEnv env, State state) throws InterruptedException {	final long ts = env.nextTimestamp();	LOG.info(getProcId() + " execute step " + state + " ts=" + ts);	executionInfo.add(new ExecutionInfo(ts, state, false));	Thread.sleep(150);	if (throwInterruptOnceOnEachStep && ((executionInfo.size() - 1) % 2) == 0) {	
throw interrupt 

protected void rollbackState(TestProcEnv env, final State state) throws InterruptedException {	final long ts = env.nextTimestamp();	LOG.debug(getProcId() + " rollback state " + state + " ts=" + ts);	executionInfo.add(new ExecutionInfo(ts, state, true));	Thread.sleep(150);	if (throwInterruptOnceOnEachStep && ((executionInfo.size() - 1) % 2) == 0) {	
throw interrupt 

protected Procedure[] execute(final TestProcEnv env) throws ProcedureYieldException {	
execute step 

========================= hbase sample_1190 =========================

public RecordReader<ImmutableBytesWritable, Result> createRecordReader( InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {	TableSplit tSplit = (TableSplit) split;	
input split length bytes 

byte[] splitStart = startRow.length == 0 || Bytes.compareTo(keys.getFirst()[i], startRow) >= 0 ? keys.getFirst()[i] : startRow;	byte[] splitStop = (stopRow.length == 0 || Bytes.compareTo(keys.getSecond()[i], stopRow) <= 0) && keys.getSecond()[i].length > 0 ? keys.getSecond()[i] : stopRow;	HRegionLocation hregionLocation = regionLocator.getRegionLocation( keys.getFirst()[i], false);	String regionHostname = hregionLocation.getHostname();	HRegionInfo regionInfo = hregionLocation.getRegionInfo();	String encodedRegionName = regionInfo.getEncodedName();	long regionSize = sizeCalculator.getRegionSize( regionInfo.getRegionName());	TableSplit split = new TableSplit(table.getName(), scan, splitStart, splitStop, regionHostname, encodedRegionName, regionSize);	splits.add(split);	if (LOG.isDebugEnabled()) {	
getsplits split 

========================= hbase sample_3457 =========================

public void testCyclicReplication1() throws Exception {	
testSimplePutDelete 

public void testLoopedReplication() throws Exception {	
testLoopedReplication 

public void testHFileCyclicReplication() throws Exception {	
testHFileCyclicReplication 

public void testCyclicReplication2() throws Exception {	
testCyclicReplication2 

public void testHFileMultiSlaveReplication() throws Exception {	
testHFileMultiSlaveReplication 

public void testHFileReplicationForConfiguredTableCfs() throws Exception {	
testHFileReplicationForConfiguredTableCfs 

public void testCyclicReplication3() throws Exception {	
testCyclicReplication2 

private void close(Closeable... closeables) {	try {	if (closeables != null) {	for (Closeable closeable : closeables) {	closeable.close();	}	}	} catch (Exception e) {	
exception occurred while closing the object 

private void wait(int slaveNumber, Table target, int expectedCount) throws IOException, InterruptedException {	int count = 0;	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for bulkloaded data replication. Current count=" + count + ", expected count=" + expectedCount);	}	count = utilities[slaveNumber].countRows(target);	if (count != expectedCount) {	
waiting more time for bulkloaded data replication 

private void wait(byte[] row, Table target, boolean isDeleted) throws Exception {	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for replication. Row:" + Bytes.toString(row) + ". IsDeleteReplication:" + isDeleted);	}	Result res = target.get(get);	boolean sleep = isDeleted ? res.size() > 0 : res.isEmpty();	if (sleep) {	
waiting for more time for replication row isdeletereplication 

fail("Waited too much time for replication. Row:" + Bytes.toString(row) + ". IsDeleteReplication:" + isDeleted);	}	Result res = target.get(get);	boolean sleep = isDeleted ? res.size() > 0 : res.isEmpty();	if (sleep) {	Thread.sleep(SLEEP_TIME);	} else {	if (!isDeleted) {	assertArrayEquals(res.value(), row);	}	
obtained row isdeletereplication 

final WALActionsListener listener = new WALActionsListener() {	public void postLogRoll(final Path oldPath, final Path newPath) throws IOException {	latch.countDown();	}	};	region.getWAL().registerWALActionsListener(listener);	admin.rollWALWriter(cluster.getServerHoldingRegion(region.getTableDescriptor().getTableName(), region.getRegionInfo().getRegionName()));	try {	latch.await();	} catch (InterruptedException exception) {	
interrupted while waiting for the wal of to roll if later replication tests fail it s probably because we should still be waiting 

========================= hbase sample_1939 =========================

while (System.currentTimeMillis() < endTime) {	long id = rand.nextInt(NUM_IDS);	boolean readLock = rand.nextBoolean();	ReentrantReadWriteLock readWriteLock = idLock.getLock(id);	Lock lock = readLock ? readWriteLock.readLock() : readWriteLock.writeLock();	try {	lock.lock();	int sleepMs = 1 + rand.nextInt(4);	String owner = idOwner.get(id);	if (owner != null && LOG.isDebugEnabled()) {	
Read Write lock of id already taken by we are 

int sleepMs = 1 + rand.nextInt(4);	String owner = idOwner.get(id);	if (owner != null && LOG.isDebugEnabled()) {	}	idOwner.put(id, clientId);	Thread.sleep(sleepMs);	idOwner.remove(id);	} finally {	lock.unlock();	if (LOG.isDebugEnabled()) {	
release Read Write lock of id we are 

public void testMultipleClients() throws Exception {	ExecutorService exec = Executors.newFixedThreadPool(NUM_THREADS);	try {	ExecutorCompletionService<Boolean> ecs = new ExecutorCompletionService<>(exec);	for (int i = 0; i < NUM_THREADS; ++i) ecs.submit(new IdLockTestThread("client_" + i));	for (int i = 0; i < NUM_THREADS; ++i) {	Future<Boolean> result = ecs.take();	assertTrue(result.get());	}	int entryPoolSize = idLock.purgeAndGetEntryPoolSize();	
size of entry pool after gc and purge 

========================= hbase sample_1313 =========================

String[] defaultProcClasses = conf.getStrings(confKey);	if (defaultProcClasses == null || defaultProcClasses.length == 0) return;	List<E> configured = new ArrayList<>();	for (String className : defaultProcClasses) {	className = className.trim();	ClassLoader cl = this.getClass().getClassLoader();	Thread.currentThread().setContextClassLoader(cl);	try {	implClass = cl.loadClass(className);	configured.add(loadInstance(implClass));	
user procedure was loaded successfully 

if (defaultProcClasses == null || defaultProcClasses.length == 0) return;	List<E> configured = new ArrayList<>();	for (String className : defaultProcClasses) {	className = className.trim();	ClassLoader cl = this.getClass().getClassLoader();	Thread.currentThread().setContextClassLoader(cl);	try {	implClass = cl.loadClass(className);	configured.add(loadInstance(implClass));	} catch (ClassNotFoundException e) {	
class cannot be found 

List<E> configured = new ArrayList<>();	for (String className : defaultProcClasses) {	className = className.trim();	ClassLoader cl = this.getClass().getClassLoader();	Thread.currentThread().setContextClassLoader(cl);	try {	implClass = cl.loadClass(className);	configured.add(loadInstance(implClass));	} catch (ClassNotFoundException e) {	} catch (IOException e) {	
load procedure failed 

========================= hbase sample_2495 =========================

static List<SnapshotRegionManifest> loadRegionManifests(final Configuration conf, final Executor executor,final FileSystem fs, final Path snapshotDir, final SnapshotDescription desc) throws IOException {	FileStatus[] regions = FSUtils.listStatus(fs, snapshotDir, new FSUtils.RegionDirFilter(fs));	if (regions == null) {	
no regions under directory 

static SnapshotRegionManifest buildManifestFromDisk(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = HRegionFileSystem.openRegionFromFileSystem(conf, fs, tableDir, regionInfo, true);	SnapshotRegionManifest.Builder manifest = SnapshotRegionManifest.newBuilder();	
storing region info for snapshot 

static SnapshotRegionManifest buildManifestFromDisk(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = HRegionFileSystem.openRegionFromFileSystem(conf, fs, tableDir, regionInfo, true);	SnapshotRegionManifest.Builder manifest = SnapshotRegionManifest.newBuilder();	manifest.setRegionInfo(ProtobufUtil.toRegionInfo(regionInfo));	
creating references for hfiles 

static SnapshotRegionManifest buildManifestFromDisk(final Configuration conf, final FileSystem fs, final Path tableDir, final RegionInfo regionInfo) throws IOException {	HRegionFileSystem regionFs = HRegionFileSystem.openRegionFromFileSystem(conf, fs, tableDir, regionInfo, true);	SnapshotRegionManifest.Builder manifest = SnapshotRegionManifest.newBuilder();	manifest.setRegionInfo(ProtobufUtil.toRegionInfo(regionInfo));	Collection<String> familyNames = regionFs.getFamilies();	if (familyNames != null) {	for (String familyName: familyNames) {	Collection<StoreFileInfo> storeFiles = regionFs.getStoreFiles(familyName, false);	if (storeFiles == null) {	
no files under family 

Collection<String> familyNames = regionFs.getFamilies();	if (familyNames != null) {	for (String familyName: familyNames) {	Collection<StoreFileInfo> storeFiles = regionFs.getStoreFiles(familyName, false);	if (storeFiles == null) {	continue;	}	SnapshotRegionManifest.FamilyFiles.Builder family = SnapshotRegionManifest.FamilyFiles.newBuilder();	family.setFamilyName(UnsafeByteOperations.unsafeWrap(Bytes.toBytes(familyName)));	if (LOG.isDebugEnabled()) {	
adding snapshot references for hfiles 

if (storeFiles == null) {	continue;	}	SnapshotRegionManifest.FamilyFiles.Builder family = SnapshotRegionManifest.FamilyFiles.newBuilder();	family.setFamilyName(UnsafeByteOperations.unsafeWrap(Bytes.toBytes(familyName)));	if (LOG.isDebugEnabled()) {	}	int i = 0;	int sz = storeFiles.size();	for (StoreFileInfo storeFile: storeFiles) {	
adding reference for file 

========================= hbase sample_2180 =========================

byte[] fam = Bytes.toBytes(family(i));	createHFile(fs, hfile, fam, QUAL, val, 1000);	famPaths.add(new Pair<>(fam, hfile.toString()));	}	final ClusterConnection conn = (ClusterConnection) UTIL.getAdmin().getConnection();	Table table = conn.getTable(tableName);	final String bulkToken = new SecureBulkLoadEndpointClient(table).prepareBulkLoad(tableName);	RpcControllerFactory rpcControllerFactory = new RpcControllerFactory(UTIL.getConfiguration());	ClientServiceCallable<Void> callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), rpcControllerFactory.newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
going to connect to server for row 

}	return null;	}	};	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(conf);	RpcRetryingCaller<Void> caller = factory.<Void> newCaller();	caller.callWithRetries(callable, Integer.MAX_VALUE);	if (numBulkLoads.get() % 5 == 0) {	callable = new ClientServiceCallable<Void>(conn, tableName, Bytes.toBytes("aaa"), rpcControllerFactory.newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
compacting for row 

========================= hbase sample_1256 =========================

public void testMultiIndexLevelRandomHFileWithBlooms() throws IOException {	conf = TEST_UTIL.getConfiguration();	for (int hfileVersion = HFile.MIN_FORMAT_VERSION_WITH_TAGS;	hfileVersion <= HFile.MAX_FORMAT_VERSION; hfileVersion++) {	conf.setInt(HFile.FORMAT_VERSION_KEY, hfileVersion);	fs = HFileSystem.get(conf);	for (BloomType bloomType : BloomType.values()) {	for (int testI = 0; testI < INDEX_CHUNK_SIZES.length; testI++) {	int indexBlockSize = INDEX_CHUNK_SIZES[testI];	int expectedNumLevels = EXPECTED_NUM_LEVELS[testI];	
testing hfileversion s bloomtype s index levels s 

========================= hbase sample_1493 =========================

public synchronized void receive(ForeignException e) {	if (exception != null) return;	
accepting received exception 

========================= hbase sample_2315 =========================

public static FSUtils getInstance(FileSystem fs, Configuration conf) {	String scheme = fs.getUri().getScheme();	if (scheme == null) {	
could not find scheme for uri default to hdfs 

public static FSDataOutputStream create(Configuration conf, FileSystem fs, Path path, FsPermission perm, InetSocketAddress[] favoredNodes) throws IOException {	if (fs instanceof HFileSystem) {	FileSystem backingFs = ((HFileSystem)fs).getBackingFs();	if (backingFs instanceof DistributedFileSystem) {	short replication = Short.parseShort(conf.get(HColumnDescriptor.DFS_REPLICATION, String.valueOf(HColumnDescriptor.DEFAULT_DFS_REPLICATION)));	try {	return (FSDataOutputStream) (DistributedFileSystem.class.getDeclaredMethod("create", Path.class, FsPermission.class, boolean.class, int.class, short.class, long.class, Progressable.class, InetSocketAddress[].class).invoke(backingFs, path, perm, true, getDefaultBufferSize(backingFs), replication > 0 ? replication : getDefaultReplication(backingFs, path), getDefaultBlockSize(backingFs, path), null, favoredNodes));	} catch (InvocationTargetException ite) {	throw new IOException(ite.getCause());	} catch (NoSuchMethodException e) {	
dfs client does not support most favored nodes create using default create 

public static FSDataOutputStream create(Configuration conf, FileSystem fs, Path path, FsPermission perm, InetSocketAddress[] favoredNodes) throws IOException {	if (fs instanceof HFileSystem) {	FileSystem backingFs = ((HFileSystem)fs).getBackingFs();	if (backingFs instanceof DistributedFileSystem) {	short replication = Short.parseShort(conf.get(HColumnDescriptor.DFS_REPLICATION, String.valueOf(HColumnDescriptor.DEFAULT_DFS_REPLICATION)));	try {	return (FSDataOutputStream) (DistributedFileSystem.class.getDeclaredMethod("create", Path.class, FsPermission.class, boolean.class, int.class, short.class, long.class, Progressable.class, InetSocketAddress[].class).invoke(backingFs, path, perm, true, getDefaultBufferSize(backingFs), replication > 0 ? replication : getDefaultReplication(backingFs, path), getDefaultBlockSize(backingFs, path), null, favoredNodes));	} catch (InvocationTargetException ite) {	throw new IOException(ite.getCause());	} catch (NoSuchMethodException e) {	
ignoring use default create 

if (fs instanceof HFileSystem) {	FileSystem backingFs = ((HFileSystem)fs).getBackingFs();	if (backingFs instanceof DistributedFileSystem) {	short replication = Short.parseShort(conf.get(HColumnDescriptor.DFS_REPLICATION, String.valueOf(HColumnDescriptor.DEFAULT_DFS_REPLICATION)));	try {	return (FSDataOutputStream) (DistributedFileSystem.class.getDeclaredMethod("create", Path.class, FsPermission.class, boolean.class, int.class, short.class, long.class, Progressable.class, InetSocketAddress[].class).invoke(backingFs, path, perm, true, getDefaultBufferSize(backingFs), replication > 0 ? replication : getDefaultReplication(backingFs, path), getDefaultBlockSize(backingFs, path), null, favoredNodes));	} catch (InvocationTargetException ite) {	throw new IOException(ite.getCause());	} catch (NoSuchMethodException e) {	} catch (IllegalArgumentException e) {	
ignoring most likely reflection related exception 

FileSystem backingFs = ((HFileSystem)fs).getBackingFs();	if (backingFs instanceof DistributedFileSystem) {	short replication = Short.parseShort(conf.get(HColumnDescriptor.DFS_REPLICATION, String.valueOf(HColumnDescriptor.DEFAULT_DFS_REPLICATION)));	try {	return (FSDataOutputStream) (DistributedFileSystem.class.getDeclaredMethod("create", Path.class, FsPermission.class, boolean.class, int.class, short.class, long.class, Progressable.class, InetSocketAddress[].class).invoke(backingFs, path, perm, true, getDefaultBufferSize(backingFs), replication > 0 ? replication : getDefaultReplication(backingFs, path), getDefaultBlockSize(backingFs, path), null, favoredNodes));	} catch (InvocationTargetException ite) {	throw new IOException(ite.getCause());	} catch (NoSuchMethodException e) {	} catch (IllegalArgumentException e) {	} catch (SecurityException e) {	
ignoring most likely reflection related exception 

if (backingFs instanceof DistributedFileSystem) {	short replication = Short.parseShort(conf.get(HColumnDescriptor.DFS_REPLICATION, String.valueOf(HColumnDescriptor.DEFAULT_DFS_REPLICATION)));	try {	return (FSDataOutputStream) (DistributedFileSystem.class.getDeclaredMethod("create", Path.class, FsPermission.class, boolean.class, int.class, short.class, long.class, Progressable.class, InetSocketAddress[].class).invoke(backingFs, path, perm, true, getDefaultBufferSize(backingFs), replication > 0 ? replication : getDefaultReplication(backingFs, path), getDefaultBlockSize(backingFs, path), null, favoredNodes));	} catch (InvocationTargetException ite) {	throw new IOException(ite.getCause());	} catch (NoSuchMethodException e) {	} catch (IllegalArgumentException e) {	} catch (SecurityException e) {	} catch (IllegalAccessException e) {	
ignoring most likely reflection related exception 

try {	if (dfs.exists(new Path("/"))) {	return;	}	} catch (IOException e) {	exception = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	}	try {	fs.close();	} catch (Exception e) {	
file system close failed 

} else {	InputStream is = new ByteArrayInputStream(content);	DataInputStream dis = new DataInputStream(is);	try {	version = dis.readUTF();	} finally {	dis.close();	}	}	} catch (EOFException eof) {	
version file was empty odd will try to set it 

}	} finally {	try {	if (s != null) s.close();	} catch (IOException ignore) { }	}	LOG.info("Created version file at " + rootdir.toString() + " with version=" + version);	return;	} catch (IOException e) {	if (retries > 0) {	
unable to create version file at retrying 

public static boolean checkClusterIdExists(FileSystem fs, Path rootdir, int wait) throws IOException {	while (true) {	try {	Path filePath = new Path(rootdir, HConstants.CLUSTER_ID_FILE_NAME);	return fs.exists(filePath);	} catch (IOException ioe) {	if (wait > 0) {	
unable to check cluster id file in retrying in msec 

Path idPath = new Path(rootdir, HConstants.CLUSTER_ID_FILE_NAME);	ClusterId clusterId = null;	FileStatus status = fs.exists(idPath)? fs.getFileStatus(idPath):  null;	if (status != null) {	int len = Ints.checkedCast(status.getLen());	byte [] content = new byte[len];	FSDataInputStream in = fs.open(idPath);	try {	in.readFully(content);	} catch (EOFException eof) {	
cluster id file was empty 

} catch (DeserializationException e) {	throw new IOException("content=" + Bytes.toString(content), e);	}	if (!ProtobufUtil.isPBMagicPrefix(content)) {	String cid = null;	in = fs.open(idPath);	try {	cid = in.readUTF();	clusterId = new ClusterId(cid);	} catch (EOFException eof) {	
cluster id file was empty 

cid = in.readUTF();	clusterId = new ClusterId(cid);	} catch (EOFException eof) {	} finally {	in.close();	}	rewriteAsPb(fs, rootdir, idPath, clusterId);	}	return clusterId;	} else {	
cluster id file does not exist at 

private static void rewriteAsPb(final FileSystem fs, final Path rootdir, final Path p, final ClusterId cid) throws IOException {	Path movedAsideName = new Path(p + "." + System.currentTimeMillis());	if (!fs.rename(p, movedAsideName)) throw new IOException("Failed rename of " + p);	setClusterId(fs, rootdir, cid, 100);	if (!fs.delete(movedAsideName, false)) {	throw new IOException("Failed delete of " + movedAsideName);	}	
rewrote the hbase id file as pb 

s = null;	if (!fs.rename(tempIdFile, idFile)) {	throw new IOException("Unable to move temp version file to " + idFile);	}	} finally {	try {	if (s != null) s.close();	} catch (IOException ignore) { }	}	if (LOG.isDebugEnabled()) {	
created cluster id file at with id 

} finally {	try {	if (s != null) s.close();	} catch (IOException ignore) { }	}	if (LOG.isDebugEnabled()) {	}	return;	} catch (IOException ioe) {	if (wait > 0) {	
unable to create cluster id file in retrying in msec 

public static void waitOnSafeMode(final Configuration conf, final long wait) throws IOException {	FileSystem fs = FileSystem.get(conf);	if (!(fs instanceof DistributedFileSystem)) return;	DistributedFileSystem dfs = (DistributedFileSystem)fs;	while (isInSafeMode(dfs)) {	
waiting for dfs to exit safe mode 

protected boolean accept(Path p, @CheckForNull Boolean isDir) {	if (!isValidName(p.getName())) {	return false;	}	try {	return isDirectory(fs, isDir, p);	} catch (IOException e) {	
an error occurred while verifying if is a valid directory returning not valid and continuing 

protected boolean isValidName(final String name) {	if (!super.isValidName(name)) return false;	try {	TableName.isLegalTableQualifierName(Bytes.toBytes(name));	} catch (IllegalArgumentException e) {	
invalid name 

protected boolean accept(Path p, @CheckForNull Boolean isDir) {	if (!regionDirPattern.matcher(p.getName()).matches()) {	return false;	}	try {	return isDirectory(fs, isDir, p);	} catch (IOException ioe) {	
skipping file due to ioexception 

protected boolean accept(Path p, @CheckForNull Boolean isDir) {	try {	HColumnDescriptor.isLegalFamilyName(Bytes.toBytes(p.getName()));	} catch (IllegalArgumentException iae) {	return false;	}	try {	return isDirectory(fs, isDir, p);	} catch (IOException ioe) {	
skipping file due to ioexception 

protected boolean accept(Path p, @CheckForNull Boolean isDir) {	if (!StoreFileInfo.isHFile(p)) {	return false;	}	try {	return isFile(fs, isDir, p);	} catch (IOException ioe) {	
skipping file due to ioexception 

protected boolean accept(Path p, @CheckForNull Boolean isDir) {	if (!StoreFileInfo.isReference(p)) {	return false;	}	try {	return isFile(fs, isDir, p);	} catch (IOException ioe) {	
skipping file due to ioexception 

if (!exceptions.isEmpty()) {	break;	}	Runnable getRegionStoreFileMapCall = new Runnable() {	public void run() {	try {	HashMap<String,Path> regionStoreFileMap = new HashMap<>();	List<FileStatus> familyDirs = FSUtils.listStatusWithStatusFilter(fs, dd, familyFilter);	if (familyDirs == null) {	if (!fs.exists(dd)) {	
skipping region because it no longer exists 

break;	}	Runnable getRegionStoreFileMapCall = new Runnable() {	public void run() {	try {	HashMap<String,Path> regionStoreFileMap = new HashMap<>();	List<FileStatus> familyDirs = FSUtils.listStatusWithStatusFilter(fs, dd, familyFilter);	if (familyDirs == null) {	if (!fs.exists(dd)) {	} else {	
skipping region because it has no family dirs 

errors.progress();	}	Path sf = sfStatus.getPath();	if (sfFilter == null || sfFilter.accept(sf)) {	regionStoreFileMap.put( sf.getName(), sf);	}	}	}	finalResultMap.putAll(regionStoreFileMap);	} catch (Exception e) {	
could not get region store file map for region 

futures.add(future);	}	}	for (Future<?> f : futures) {	if (!exceptions.isEmpty()) {	break;	}	try {	f.get();	} catch (ExecutionException e) {	
unexpected exec exception should ve been caught already bug 

for (Future<?> f : futures) {	if (!exceptions.isEmpty()) {	break;	}	try {	f.get();	} catch (ExecutionException e) {	}	}	} catch (IOException e) {	
cannot execute gettablestorefilepathmap for 

public static int getRegionReferenceFileCount(final FileSystem fs, final Path p) {	int result = 0;	try {	for (Path familyDir:getFamilyDirs(fs, p)){	result += getReferenceFilePaths(fs, familyDir).size();	}	} catch (IOException e) {	
error counting reference files 

public static List<FileStatus> listStatusWithStatusFilter(final FileSystem fs, final Path dir, final FileStatusFilter filter) throws IOException {	FileStatus [] status = null;	try {	status = fs.listStatus(dir);	} catch (FileNotFoundException fnfe) {	if (LOG.isTraceEnabled()) {	
doesn t exist 

if (!regionName.toLowerCase(Locale.ROOT).matches("[0-9a-f]+")) {	return false;	}	return true;	}	};	FileStatus[] statusList = fs.globStatus(queryPath, pathFilter);	if (null == statusList) {	return;	} else {	
query path list of files 

if (null == regionPath) {	continue;	}	tpe.execute(new FSRegionScanner(fs, regionPath, regionToBestLocalityRSMapping, regionDegreeLocalityMapping));	}	} finally {	tpe.shutdown();	int threadWakeFrequency = conf.getInt(HConstants.THREAD_WAKE_FREQUENCY, 60 * 1000);	try {	while (!tpe.awaitTermination(threadWakeFrequency, TimeUnit.MILLISECONDS)) {	
locality checking is underway scanned regions 

public static void setupShortCircuitRead(final Configuration conf) {	boolean shortCircuitSkipChecksum = conf.getBoolean("dfs.client.read.shortcircuit.skip.checksum", false);	boolean useHBaseChecksum = conf.getBoolean(HConstants.HBASE_CHECKSUM_VERIFICATION, true);	if (shortCircuitSkipChecksum) {	
configuration should not be set to true hbase checksum doesn t require it see https assert shortcircuitskipchecksum 

public static DFSHedgedReadMetrics getDFSHedgedReadMetrics(final Configuration c) throws IOException {	if (!isHDFS(c)) return null;	final String name = "getHedgedReadMetrics";	DFSClient dfsclient = ((DistributedFileSystem)FileSystem.get(c)).getClient();	Method m;	try {	m = dfsclient.getClass().getDeclaredMethod(name);	} catch (NoSuchMethodException e) {	
failed find method in dfsclient no hedged read metrics 

public static DFSHedgedReadMetrics getDFSHedgedReadMetrics(final Configuration c) throws IOException {	if (!isHDFS(c)) return null;	final String name = "getHedgedReadMetrics";	DFSClient dfsclient = ((DistributedFileSystem)FileSystem.get(c)).getClient();	Method m;	try {	m = dfsclient.getClass().getDeclaredMethod(name);	} catch (NoSuchMethodException e) {	return null;	} catch (SecurityException e) {	
failed find method in dfsclient no hedged read metrics 

m = dfsclient.getClass().getDeclaredMethod(name);	} catch (NoSuchMethodException e) {	return null;	} catch (SecurityException e) {	return null;	}	m.setAccessible(true);	try {	return (DFSHedgedReadMetrics)m.invoke(dfsclient);	} catch (IllegalAccessException e) {	
failed invoking method on dfsclient no hedged read metrics 

return null;	} catch (SecurityException e) {	return null;	}	m.setAccessible(true);	try {	return (DFSHedgedReadMetrics)m.invoke(dfsclient);	} catch (IllegalAccessException e) {	return null;	} catch (IllegalArgumentException e) {	
failed invoking method on dfsclient no hedged read metrics 

return null;	}	m.setAccessible(true);	try {	return (DFSHedgedReadMetrics)m.invoke(dfsclient);	} catch (IllegalAccessException e) {	return null;	} catch (IllegalArgumentException e) {	return null;	} catch (InvocationTargetException e) {	
failed invoking method on dfsclient no hedged read metrics 

========================= hbase sample_2250 =========================

final CatalogJanitor janitor = TEST_UTIL.getHBaseCluster().getMaster().getCatalogJanitor();	Admin admin = TEST_UTIL.getAdmin();	admin.enableCatalogJanitor(false);	final TableName tableName = TableName.valueOf(name.getMethodName());	Table t = TEST_UTIL.createTable(tableName, FAMILY);	int rowCount = TEST_UTIL.loadTable(t, FAMILY, false);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	List<HRegionLocation> allRegionLocations = locator.getAllRegionLocations();	HRegionLocation parent = allRegionLocations.get(0);	List<HRegionLocation> daughters = splitRegion(parent.getRegionInfo());	
parent region 

final CatalogJanitor janitor = TEST_UTIL.getHBaseCluster().getMaster().getCatalogJanitor();	Admin admin = TEST_UTIL.getAdmin();	admin.enableCatalogJanitor(false);	final TableName tableName = TableName.valueOf(name.getMethodName());	Table t = TEST_UTIL.createTable(tableName, FAMILY);	int rowCount = TEST_UTIL.loadTable(t, FAMILY, false);	RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName);	List<HRegionLocation> allRegionLocations = locator.getAllRegionLocations();	HRegionLocation parent = allRegionLocations.get(0);	List<HRegionLocation> daughters = splitRegion(parent.getRegionInfo());	
daughter regions 

Table metaTable = conn.getTable(TableName.META_TABLE_NAME)) {	Result result = null;	RegionInfo region = null;	while ((System.currentTimeMillis() - start) < 60000) {	result = metaTable.get(new Get(r.getRegionName()));	if (result == null) {	break;	}	region = MetaTableAccessor.getRegionInfo(result);	if (region.isSplitParent()) {	
is a parent 

========================= hbase sample_1885 =========================

public void restoreSnapshots(Configuration conf, Map<String, Path> snapshotToDir, FileSystem fs) throws IOException {	Path rootDir = FSUtils.getRootDir(conf);	for (Map.Entry<String, Path> entry : snapshotToDir.entrySet()) {	String snapshotName = entry.getKey();	Path restoreDir = entry.getValue();	
restoring snapshot into for multitablesnapshotinputformat 

========================= hbase sample_3441 =========================

Semaphore latch1 = new Semaphore(2);	latch1.acquire(2);	BusyWaitProcedure busyProc1 = new BusyWaitProcedure(latch1);	Semaphore latch2 = new Semaphore(2);	latch2.acquire(2);	BusyWaitProcedure busyProc2 = new BusyWaitProcedure(latch2);	long busyProcId1 = procExecutor.submitProcedure(busyProc1);	long busyProcId2 = procExecutor.submitProcedure(busyProc2);	long otherProcId = procExecutor.submitProcedure(new NoopProcedure());	int threads1 = waitThreadCount(NUM_THREADS + 1);	
new threads got created 

int threads1 = waitThreadCount(NUM_THREADS + 1);	assertEquals(NUM_THREADS + 1, threads1);	ProcedureTestingUtility.waitProcedure(procExecutor, otherProcId);	assertEquals(true, procExecutor.isFinished(otherProcId));	ProcedureTestingUtility.assertProcNotFailed(procExecutor, otherProcId);	assertEquals(true, procExecutor.isRunning());	assertEquals(false, procExecutor.isFinished(busyProcId1));	assertEquals(false, procExecutor.isFinished(busyProcId2));	latch1.release();	latch2.release();	
set keep alive and wait threads being removed 

ProcedureTestingUtility.waitProcedure(procExecutor, otherProcId);	assertEquals(true, procExecutor.isFinished(otherProcId));	ProcedureTestingUtility.assertProcNotFailed(procExecutor, otherProcId);	assertEquals(true, procExecutor.isRunning());	assertEquals(false, procExecutor.isFinished(busyProcId1));	assertEquals(false, procExecutor.isFinished(busyProcId2));	latch1.release();	latch2.release();	procExecutor.setKeepAliveTime(500L, TimeUnit.MILLISECONDS);	int threads2 = waitThreadCount(NUM_THREADS);	
threads got removed 

protected Procedure[] execute(final TestProcEnv env) {	try {	
worker started 

protected Procedure[] execute(final TestProcEnv env) {	try {	if (!latch.tryAcquire(1, 30, TimeUnit.SECONDS)) {	throw new Exception("waited too long");	}	
worker step 

protected Procedure[] execute(final TestProcEnv env) {	try {	if (!latch.tryAcquire(1, 30, TimeUnit.SECONDS)) {	throw new Exception("waited too long");	}	if (!latch.tryAcquire(1, 30, TimeUnit.SECONDS)) {	throw new Exception("waited too long");	}	} catch (Exception e) {	
got unexpected exception 

========================= hbase sample_1186 =========================

public void run() {	try {	if (shouldAuthenticateOverKrb()) {	relogin();	}	} catch (IOException e) {	
relogin failed 

private void connect() {	if (LOG.isDebugEnabled()) {	
connecting to 

========================= hbase sample_262 =========================

public Void call() throws Exception {	
starting region operation on 

public Void call() throws Exception {	region.startRegionOperation();	try {	
flush region started 

public Void call() throws Exception {	region.startRegionOperation();	try {	region.flush(true);	} finally {	
closing region operation on 

return;	}	monitor.rethrowException();	if (taskManager.hasTasks()) {	throw new IllegalStateException("Attempting to flush " + table + " but we currently have outstanding tasks");	}	for (HRegion region : regions) {	taskManager.submitTask(new RegionFlushTask(region));	monitor.rethrowException();	}	
flush region tasks submitted for regions 

public void cleanup(Exception e) {	
aborting all flush region subprocedure task threads for due to error 

========================= hbase sample_2483 =========================

public void afterMethod() throws Exception {	deleteTableIfNecessary();	deleteNamespaceIfNecessary();	deleteGroups();	int missing = NUM_SLAVES_BASE - getNumServers();	
restoring servers 

deleteGroups();	int missing = NUM_SLAVES_BASE - getNumServers();	for(int i=0; i<missing; i++) {	((MiniHBaseCluster)cluster).startRegionServer();	}	rsGroupAdmin.addRSGroup("master");	ServerName masterServerName = ((MiniHBaseCluster)cluster).getMaster().getServerName();	try {	rsGroupAdmin.moveServers(Sets.newHashSet(masterServerName.getAddress()), "master");	} catch (Exception ex) {	
got this on setup fyi 

((MiniHBaseCluster)cluster).startRegionServer();	}	rsGroupAdmin.addRSGroup("master");	ServerName masterServerName = ((MiniHBaseCluster)cluster).getMaster().getServerName();	try {	rsGroupAdmin.moveServers(Sets.newHashSet(masterServerName.getAddress()), "master");	} catch (Exception ex) {	}	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	
waiting for cleanup to finish 

public void testNamespaceCreateAndAssign() throws Exception {	
testNamespaceCreateAndAssign 

public void testDefaultNamespaceCreateAndAssign() throws Exception {	
testDefaultNamespaceCreateAndAssign 

public void testNamespaceConstraint() throws Exception {	String nsName = tablePrefix+"_foo";	String groupName = tablePrefix+"_foo";	
testNamespaceConstraint 

public void testMisplacedRegions() throws Exception {	final TableName tableName = TableName.valueOf(tablePrefix+"_testMisplacedRegions");	
testMisplacedRegions 

========================= hbase sample_3338 =========================

protected int doWork() throws Exception {	ProcessBasedLocalHBaseCluster hbaseCluster = new ProcessBasedLocalHBaseCluster(conf, NUM_DATANODES, numRegionServers);	hbaseCluster.startMiniDFS();	hbaseCluster.startHBase();	HBaseTestingUtility.createPreSplitLoadTestTable(conf, TABLE_NAME, HFileTestUtil.DEFAULT_COLUMN_FAMILY, Compression.Algorithm.NONE, DataBlockEncoding.NONE);	
loading data 

protected int doWork() throws Exception {	ProcessBasedLocalHBaseCluster hbaseCluster = new ProcessBasedLocalHBaseCluster(conf, NUM_DATANODES, numRegionServers);	hbaseCluster.startMiniDFS();	hbaseCluster.startHBase();	HBaseTestingUtility.createPreSplitLoadTestTable(conf, TABLE_NAME, HFileTestUtil.DEFAULT_COLUMN_FAMILY, Compression.Algorithm.NONE, DataBlockEncoding.NONE);	loadData();	
sleeping for seconds 

protected int doWork() throws Exception {	ProcessBasedLocalHBaseCluster hbaseCluster = new ProcessBasedLocalHBaseCluster(conf, NUM_DATANODES, numRegionServers);	hbaseCluster.startMiniDFS();	hbaseCluster.startHBase();	HBaseTestingUtility.createPreSplitLoadTestTable(conf, TABLE_NAME, HFileTestUtil.DEFAULT_COLUMN_FAMILY, Compression.Algorithm.NONE, DataBlockEncoding.NONE);	loadData();	Threads.sleep(5 * SLEEP_SEC_AFTER_DATA_LOAD);	Connection connection = ConnectionFactory.createConnection(conf);	int metaRSPort = HBaseTestingUtility.getMetaRSPort(connection);	
killing hbase meta region server running on port 

ProcessBasedLocalHBaseCluster hbaseCluster = new ProcessBasedLocalHBaseCluster(conf, NUM_DATANODES, numRegionServers);	hbaseCluster.startMiniDFS();	hbaseCluster.startHBase();	HBaseTestingUtility.createPreSplitLoadTestTable(conf, TABLE_NAME, HFileTestUtil.DEFAULT_COLUMN_FAMILY, Compression.Algorithm.NONE, DataBlockEncoding.NONE);	loadData();	Threads.sleep(5 * SLEEP_SEC_AFTER_DATA_LOAD);	Connection connection = ConnectionFactory.createConnection(conf);	int metaRSPort = HBaseTestingUtility.getMetaRSPort(connection);	hbaseCluster.killRegionServer(metaRSPort);	Threads.sleep(2000);	
restarting region server running on port metarsport 

hbaseCluster.startHBase();	HBaseTestingUtility.createPreSplitLoadTestTable(conf, TABLE_NAME, HFileTestUtil.DEFAULT_COLUMN_FAMILY, Compression.Algorithm.NONE, DataBlockEncoding.NONE);	loadData();	Threads.sleep(5 * SLEEP_SEC_AFTER_DATA_LOAD);	Connection connection = ConnectionFactory.createConnection(conf);	int metaRSPort = HBaseTestingUtility.getMetaRSPort(connection);	hbaseCluster.killRegionServer(metaRSPort);	Threads.sleep(2000);	hbaseCluster.startRegionServer(metaRSPort);	Threads.sleep(2000);	
trying to scan meta 

========================= hbase sample_1305 =========================

public void tearDown() throws Exception {	EnvironmentEdgeManagerTestHelper.reset();	
cleaning test directory 

HRegion region = null;	try {	region = initHRegion(tableName, null, null, false, Durability.SYNC_WAL, wal, COLUMN_FAMILY_BYTES);	long size = region.getMemStoreSize();	Assert.assertEquals(0, size);	Put p1 = new Put(row);	p1.add(new KeyValue(row, COLUMN_FAMILY_BYTES, qual1, 1, (byte[]) null));	region.put(p1);	final long sizeOfOnePut = region.getMemStoreSize();	try {	
Flushing 

HStore store = region.getStore(COLUMN_FAMILY_BYTES);	StoreFlushContext storeFlushCtx = store.createFlushContext(12345, FlushLifeCycleTracker.DUMMY);	storeFlushCtx.prepare();	Put p2 = new Put(row);	p2.add(new KeyValue(row, COLUMN_FAMILY_BYTES, qual2, 2, (byte[])null));	p2.add(new KeyValue(row, COLUMN_FAMILY_BYTES, qual3, 3, (byte[])null));	region.put(p2);	region.close();	fail();	} catch (DroppedSnapshotException dse) {	
expected droppedsnapshotexception 

WALProvider.Writer writer = wals.createRecoveredEditsWriter(fs, recoveredEdits);	for (WAL.Entry entry : flushDescriptors) {	writer.append(entry);	}	writer.close();	} finally {	if (null != reader) {	try {	reader.close();	} catch (IOException exception) {	
problem closing wal 

WALProvider.Writer writer = wals.createRecoveredEditsWriter(fs, recoveredEdits);	for (WAL.Entry entry : flushDescriptors) {	writer.append(entry);	}	writer.close();	} finally {	if (null != reader) {	try {	reader.close();	} catch (IOException exception) {	
exception details 

final Put[] puts = new Put[10];	MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);	try {	long syncs = prepareRegionForBachPut(puts, source, false);	OperationStatus[] codes = this.region.batchMutate(puts);	assertEquals(10, codes.length);	for (int i = 0; i < 10; i++) {	assertEquals(OperationStatusCode.SUCCESS, codes[i].getOperationStatusCode());	}	metricsAssertHelper.assertCounter("syncTimeNumOps", syncs + 1, source);	
next a batch put with one invalid family 

public void testBatchPut_whileMultipleRowLocksHeld() throws Exception {	final Put[] puts = new Put[10];	MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);	try {	long syncs = prepareRegionForBachPut(puts, source, false);	puts[5].addColumn(Bytes.toBytes("BAD_CF"), qual, value);	
batchput will have to break into four batches to avoid row locks 

MultithreadedTestUtil.TestContext ctx = new MultithreadedTestUtil.TestContext(CONF);	final AtomicReference<OperationStatus[]> retFromThread = new AtomicReference<>();	final CountDownLatch startingPuts = new CountDownLatch(1);	final CountDownLatch startingClose = new CountDownLatch(1);	TestThread putter = new TestThread(ctx) {	public void doWork() throws IOException {	startingPuts.countDown();	retFromThread.set(region.batchMutate(puts));	}	};	
starting put thread while holding locks 

throw new RuntimeException(e);	} catch (InterruptedException e) {	throw new RuntimeException(e);	}	}	};	regionCloseThread.start();	startingClose.await();	startingPuts.await();	Thread.sleep(100);	
releasing row lock which should let put thread continue 

}	};	regionCloseThread.start();	startingClose.await();	startingPuts.await();	Thread.sleep(100);	rowLock1.release();	rowLock2.release();	rowLock3.release();	waitForCounter(source, "syncTimeNumOps", syncs + 1);	
joining on put thread 

RowLock lock = region.getRowLock(Bytes.toBytes("row_" + 3));	MultithreadedTestUtil.TestContext ctx = new MultithreadedTestUtil.TestContext(CONF);	final AtomicReference<IOException> retFromThread = new AtomicReference<>();	final CountDownLatch finishedPuts = new CountDownLatch(1);	final MutationBatchOperation finalBatchOp = new MutationBatchOperation(region, puts, true, HConstants .NO_NONCE, HConstants.NO_NONCE);	TestThread putter = new TestThread(ctx) {	public void doWork() throws IOException {	try {	region.batchMutate(finalBatchOp);	} catch (IOException ioe) {	
test failed 

TestThread putter = new TestThread(ctx) {	public void doWork() throws IOException {	try {	region.batchMutate(finalBatchOp);	} catch (IOException ioe) {	retFromThread.set(ioe);	}	finishedPuts.countDown();	}	};	
starting put thread while holding locks 

try {	region.batchMutate(finalBatchOp);	} catch (IOException ioe) {	retFromThread.set(ioe);	}	finishedPuts.countDown();	}	};	ctx.addThread(putter);	ctx.startThreads();	
waiting for batch puts while holding locks 

retFromThread.set(ioe);	}	finishedPuts.countDown();	}	};	ctx.addThread(putter);	ctx.startThreads();	try {	finishedPuts.await();	} catch (InterruptedException e) {	
interrupted 

try {	finishedPuts.await();	} catch (InterruptedException e) {	} finally {	if (lock != null) {	lock.release();	}	}	assertNotNull(retFromThread.get());	metricsAssertHelper.assertCounter("syncTimeNumOps", syncs + 1, source);	
next a batch put with one invalid family 

private long prepareRegionForBachPut(final Put[] puts, final MetricsWALSource source, boolean slop) throws IOException {	this.region = initHRegion(tableName, method, CONF, COLUMN_FAMILY_BYTES);	
first a batch put with all valid puts 

try {	byte[] row = Bytes.toBytes("row1");	byte[] qual = Bytes.toBytes("qual");	Put put = new Put(row);	put.addColumn(fam, qual, HConstants.LATEST_TIMESTAMP, Bytes.toBytes("value"));	region.put(put);	Get get = new Get(row).addColumn(fam, qual);	Result result = region.get(get);	assertEquals(1, result.size());	Cell kv = result.rawCells()[0];	
got 

Cell kv = result.rawCells()[0];	assertTrue("LATEST_TIMESTAMP was not replaced with real timestamp", kv.getTimestamp() != HConstants.LATEST_TIMESTAMP);	row = Bytes.toBytes("row2");	put = new Put(row);	put.addColumn(fam, qual, HConstants.LATEST_TIMESTAMP, Bytes.toBytes("value"));	region.put(put);	get = new Get(row).addColumn(fam, qual);	result = region.get(get);	assertEquals(1, result.size());	kv = result.rawCells()[0];	
got 

byte[][] families = { fam };	CONF.setInt("hbase.hregion.keyvalue.timestamp.slop.millisecs", 1000);	this.region = initHRegion(tableName, method, CONF, families);	boolean caughtExcep = false;	try {	try {	region.put(new Put(row).addColumn(fam, Bytes.toBytes("qual"), Bytes.toBytes("value")));	region.put(new Put(row).addColumn(fam, Bytes.toBytes("qual"), System.currentTimeMillis() + 2000, Bytes.toBytes("value")));	fail("Expected IOE for TS out of configured timerange");	} catch (FailedSanityCheckException ioe) {	
received expected exception 

public void testDataInMemoryWithoutWAL() throws IOException {	FileSystem fs = FileSystem.get(CONF);	Path rootDir = new Path(dir + "testDataInMemoryWithoutWAL");	FSHLog hLog = new FSHLog(fs, rootDir, "testDataInMemoryWithoutWAL", CONF);	ChunkCreator.initialize(MemStoreLABImpl.CHUNK_SIZE_DEFAULT, false, 0, 0, 0, null);	HRegion region = initHRegion(tableName, null, null, false, Durability.SYNC_WAL, hLog, COLUMN_FAMILY_BYTES);	Cell originalCell = CellUtil.createCell(row, COLUMN_FAMILY_BYTES, qual1, System.currentTimeMillis(), KeyValue.Type.Put.getCode(), value1);	final long originalSize = KeyValueUtil.length(originalCell);	Cell addCell = CellUtil.createCell(row, COLUMN_FAMILY_BYTES, qual1, System.currentTimeMillis(), KeyValue.Type.Put.getCode(), Bytes.toBytes("xxxxxxxxxx"));	final long addSize = KeyValueUtil.length(addCell);	
originalsize addsize 

assertEquals("toggle="+toggle+"i=" + i + " ts="+System.currentTimeMillis(), expectedCount, res.size());	toggle = !toggle;	}	}	} finally {	try {	flushThread.done();	flushThread.join();	flushThread.checkNoError();	} catch (InterruptedException ie) {	
caught exception when joining with flushthread 

} catch (InterruptedException ignored) {	if (done) {	break;	}	}	}	try {	region.flush(true);	} catch (IOException e) {	if (!done) {	
error while flushing cache 

}	}	try {	region.flush(true);	} catch (IOException e) {	if (!done) {	error = e;	}	break;	} catch (Throwable t) {	
uncaught exception 

putThread.done();	region.flush(true);	} finally {	try {	flushThread.done();	flushThread.join();	flushThread.checkNoError();	putThread.join();	putThread.checkNoError();	} catch (InterruptedException ie) {	
caught exception when joining with flushthread 

region.put(put);	numPutsFinished++;	if (numPutsFinished > 0 && numPutsFinished % 47 == 0) {	System.out.println("put iteration = " + numPutsFinished);	Delete delete = new Delete(row, (long) numPutsFinished - 30);	region.delete(delete);	}	numPutsFinished++;	}	} catch (InterruptedIOException e) {	
Interrupted 

numPutsFinished++;	if (numPutsFinished > 0 && numPutsFinished % 47 == 0) {	System.out.println("put iteration = " + numPutsFinished);	Delete delete = new Delete(row, (long) numPutsFinished - 30);	region.delete(delete);	}	numPutsFinished++;	}	} catch (InterruptedIOException e) {	} catch (IOException e) {	
error while putting records 

store.closeAndArchiveCompactedFiles();	}	}	});	ctx.startThreads();	Get get = new Get(Bytes.toBytes("row0"));	Result result = null;	int expectedCount = numFamilies * numQualifiers;	long prevTimestamp = 0L;	for (int i = 0; i < testCount; i++) {	
testwriteswhilegetting verify turn 

timestamp = kv.getTimestamp();	}	}	assertTrue(timestamp >= prevTimestamp);	prevTimestamp = timestamp;	Cell previousKV = null;	for (Cell kv : result.rawCells()) {	byte[] thisValue = CellUtil.cloneValue(kv);	if (previousKV != null) {	if (Bytes.compareTo(CellUtil.cloneValue(previousKV), thisValue) != 0) {	
these two kv should have the same value previous kv memstorets new kv memstorets 

when(rss.getWAL((HRegionInfo) any())).thenReturn(wal);	try {	region = HRegion.openHRegion(hri, htd, rss.getWAL(hri), TEST_UTIL.getConfiguration(), rss, null);	verify(wal, times(1)).append((HRegionInfo)any(), (WALKeyImpl)any() , editCaptor.capture(), anyBoolean());	WALEdit edit = editCaptor.getValue();	assertNotNull(edit);	assertNotNull(edit.getCells());	assertEquals(1, edit.getCells().size());	RegionEventDescriptor desc = WALEdit.getRegionEventDescriptor(edit.getCells().get(0));	assertNotNull(desc);	
regioneventdescriptor from wal 

region = HRegion.createHRegion(hri, rootDir, TEST_UTIL.getConfiguration(), htd, rss.getWAL(hri));	region = HRegion.openHRegion(hri, htd, rss.getWAL(hri), TEST_UTIL.getConfiguration(), rss, null);	region.close(false);	verify(wal, times(2)).append((HRegionInfo)any(), (WALKeyImpl)any(), editCaptor.capture(), anyBoolean());	WALEdit edit = editCaptor.getAllValues().get(1);	assertNotNull(edit);	assertNotNull(edit.getCells());	assertEquals(1, edit.getCells().size());	RegionEventDescriptor desc = WALEdit.getRegionEventDescriptor(edit.getCells().get(0));	assertNotNull(desc);	
regioneventdescriptor from wal 

Mutation[] mutations = new Mutation[] {	new Put(a) .add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY) .setRow(a) .setFamily(fam1) .setTimestamp(HConstants.LATEST_TIMESTAMP) .setType(Cell.Type.Put) .build()), new Put(c).add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY) .setRow(c) .setFamily(fam1) .setTimestamp(HConstants.LATEST_TIMESTAMP) .setType(Type.Put) .build()), new Put(b).add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY) .setRow(b) .setFamily(fam1) .setTimestamp(HConstants.LATEST_TIMESTAMP) .setType(Cell.Type.Put) .build()) };	OperationStatus[] status = region.batchMutate(mutations);	assertEquals(status[0].getOperationStatusCode(), OperationStatusCode.SUCCESS);	assertEquals(status[1].getOperationStatusCode(), OperationStatusCode.SANITY_CHECK_FAILURE);	assertEquals(status[2].getOperationStatusCode(), OperationStatusCode.SUCCESS);	final CountDownLatch obtainedRowLock = new CountDownLatch(1);	ExecutorService exec = Executors.newFixedThreadPool(2);	Future<Void> f1 = exec.submit(new Callable<Void>() {	public Void call() throws Exception {	
acquiring row lock 

OperationStatus[] status = region.batchMutate(mutations);	assertEquals(status[0].getOperationStatusCode(), OperationStatusCode.SUCCESS);	assertEquals(status[1].getOperationStatusCode(), OperationStatusCode.SANITY_CHECK_FAILURE);	assertEquals(status[2].getOperationStatusCode(), OperationStatusCode.SUCCESS);	final CountDownLatch obtainedRowLock = new CountDownLatch(1);	ExecutorService exec = Executors.newFixedThreadPool(2);	Future<Void> f1 = exec.submit(new Callable<Void>() {	public Void call() throws Exception {	RowLock rl = region.getRowLock(b);	obtainedRowLock.countDown();	
waiting for seconds before releasing lock 

assertEquals(status[0].getOperationStatusCode(), OperationStatusCode.SUCCESS);	assertEquals(status[1].getOperationStatusCode(), OperationStatusCode.SANITY_CHECK_FAILURE);	assertEquals(status[2].getOperationStatusCode(), OperationStatusCode.SUCCESS);	final CountDownLatch obtainedRowLock = new CountDownLatch(1);	ExecutorService exec = Executors.newFixedThreadPool(2);	Future<Void> f1 = exec.submit(new Callable<Void>() {	public Void call() throws Exception {	RowLock rl = region.getRowLock(b);	obtainedRowLock.countDown();	Threads.sleep(5000);	
releasing row lock 

edge.setValue(1);	p = new Put(row);	p.setDurability(Durability.SKIP_WAL);	p.addColumn(fam1, qual1, qual2);	RowMutations rm = new RowMutations(row);	rm.add(p);	assertTrue(region.checkAndRowMutate(row, fam1, qual1, CompareOperator.EQUAL, new BinaryComparator(qual1), rm, false));	result = region.get(new Get(row));	c = result.getColumnLatestCell(fam1, qual1);	assertEquals(c.getTimestamp(), 10L);	
c value 

protected List<HStoreFile> doCompaction(CompactionRequestImpl cr, Collection<HStoreFile> filesToCompact, User user, long compactionStartTime, List<Path> newFiles) throws IOException {	if (!this.conf.getBoolean("hbase.hstore.compaction.complete", true)) {	
hbase hstore compaction complete is set to false 

========================= hbase sample_1755 =========================

public void run() {	try {	doRunLoop();	} finally {	try {	readSelector.close();	} catch (IOException ioe) {	
error closing read selector in 

iter.remove();	if (key.isValid()) {	if (key.isReadable()) {	doRead(key);	}	}	key = null;	}	} catch (InterruptedException e) {	if (running) {	
unexpectedly interrupted 

if (key.isReadable()) {	doRead(key);	}	}	key = null;	}	} catch (InterruptedException e) {	if (running) {	}	} catch (CancelledKeyException e) {	
cancelledkeyexception in reader 

doRead(key);	}	}	key = null;	}	} catch (InterruptedException e) {	if (running) {	}	} catch (CancelledKeyException e) {	} catch (IOException ex) {	
ioexception in reader 

public void run() {	
starting 

selector.select();	Iterator<SelectionKey> iter = selector.selectedKeys().iterator();	while (iter.hasNext()) {	key = iter.next();	iter.remove();	try {	if (key.isValid()) {	if (key.isAcceptable()) doAccept(key);	}	} catch (IOException ignored) {	
ignored 

if (key.isValid()) {	if (key.isAcceptable()) doAccept(key);	}	} catch (IOException ignored) {	}	key = null;	}	} catch (OutOfMemoryError e) {	if (errorHandler != null) {	if (errorHandler.checkOOME(e)) {	
exiting on outofmemoryerror 

key = null;	}	} catch (OutOfMemoryError e) {	if (errorHandler != null) {	if (errorHandler.checkOOME(e)) {	closeCurrentConnection(key, e);	connectionManager.closeIdle(true);	return;	}	} else {	
outofmemoryerror in server select 

closeCurrentConnection(key, e);	connectionManager.closeIdle(true);	return;	}	} else {	closeCurrentConnection(key, e);	connectionManager.closeIdle(true);	try {	Thread.sleep(60000);	} catch (InterruptedException ex) {	
interrupted while sleeping 

connectionManager.closeIdle(true);	try {	Thread.sleep(60000);	} catch (InterruptedException ex) {	}	}	} catch (Exception e) {	closeCurrentConnection(key, e);	}	}	
stopping 

}	} catch (Exception e) {	closeCurrentConnection(key, e);	}	}	synchronized (this) {	try {	acceptChannel.close();	selector.close();	} catch (IOException ignored) {	
ignored 

public synchronized void stop() {	
stopping server on 

private void scheduleIdleScanTask() {	if (!running) {	return;	}	TimerTask idleScanTask = new TimerTask(){	public void run() {	if (!running) {	return;	}	if (LOG.isTraceEnabled()) {	
running 

========================= hbase sample_2895 =========================

private MasterAddressTracker setupMasterTracker(final ServerName sn, final int infoPort) throws Exception {	ZKWatcher zk = new ZKWatcher(TEST_UTIL.getConfiguration(), name.getMethodName(), null);	ZKUtil.createAndFailSilent(zk, zk.znodePaths.baseZNode);	MasterAddressTracker addressTracker = new MasterAddressTracker(zk, null);	addressTracker.start();	assertFalse(addressTracker.hasMaster());	zk.registerListener(addressTracker);	NodeCreationListener listener = new NodeCreationListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	if (sn != null) {	
creating master node 

ZKWatcher zk = new ZKWatcher(TEST_UTIL.getConfiguration(), name.getMethodName(), null);	ZKUtil.createAndFailSilent(zk, zk.znodePaths.baseZNode);	MasterAddressTracker addressTracker = new MasterAddressTracker(zk, null);	addressTracker.start();	assertFalse(addressTracker.hasMaster());	zk.registerListener(addressTracker);	NodeCreationListener listener = new NodeCreationListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	if (sn != null) {	MasterAddressTracker.setMasterAddress(zk, zk.znodePaths.masterAddressZNode, sn, infoPort);	
waiting for master address manager to be notified 

ZKUtil.createAndFailSilent(zk, zk.znodePaths.baseZNode);	MasterAddressTracker addressTracker = new MasterAddressTracker(zk, null);	addressTracker.start();	assertFalse(addressTracker.hasMaster());	zk.registerListener(addressTracker);	NodeCreationListener listener = new NodeCreationListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	if (sn != null) {	MasterAddressTracker.setMasterAddress(zk, zk.znodePaths.masterAddressZNode, sn, infoPort);	listener.waitForCreation();	
master node created 

public void nodeCreated(String path) {	if(path.equals(node)) {	
nodecreated 

========================= hbase sample_1610 =========================

codecIterators.add(codec.getIterator(HFileBlock.headerSize(useHBaseChecksum)));	}	int j = 0;	while ((currentKv = KeyValueUtil.ensureKeyValue(scanner.next())) != null && j < kvLimit) {	++j;	for (Iterator<Cell> it : codecIterators) {	Cell c = it.next();	KeyValue codecKv = KeyValueUtil.ensureKeyValue(c);	if (codecKv == null || 0 != Bytes.compareTo( codecKv.getBuffer(), codecKv.getOffset(), codecKv.getLength(), currentKv.getBuffer(), currentKv.getOffset(), currentKv.getLength())) {	if (codecKv == null) {	
there is a bug in codec it returned null keyvalue 

Cell c = it.next();	KeyValue codecKv = KeyValueUtil.ensureKeyValue(c);	if (codecKv == null || 0 != Bytes.compareTo( codecKv.getBuffer(), codecKv.getOffset(), codecKv.getLength(), currentKv.getBuffer(), currentKv.getOffset(), currentKv.getLength())) {	if (codecKv == null) {	} else {	int prefix = 0;	int limitLength = 2 * Bytes.SIZEOF_INT + Math.min(codecKv.getLength(), currentKv.getLength());	while (prefix < limitLength && codecKv.getBuffer()[prefix + codecKv.getOffset()] == currentKv.getBuffer()[prefix + currentKv.getOffset()]) {	prefix++;	}	
there is bug in codec on element codeckv getkeylength codeckv getvaluelength codeckv getlength currentkv getkeylength currentkv getvaluelength codeckv getlength currentkv rowlength familyname qualifier prefix codeckv diff currentkv diff 

int prefix = 0;	int limitLength = 2 * Bytes.SIZEOF_INT + Math.min(codecKv.getLength(), currentKv.getLength());	while (prefix < limitLength && codecKv.getBuffer()[prefix + codecKv.getOffset()] == currentKv.getBuffer()[prefix + currentKv.getOffset()]) {	prefix++;	}	}	return false;	}	}	}	
verification was successful 

public void benchmarkCodecs() throws IOException {	
starting a throughput benchmark for data block encoding codecs 

} catch (ParseException e) {	System.err.println("Could not parse arguments!");	System.exit(-1);	return;	}	int kvLimit = Integer.MAX_VALUE;	if (cmd.hasOption(OPT_KV_LIMIT)) {	kvLimit = Integer.parseInt(cmd.getOptionValue(OPT_KV_LIMIT));	}	if (!cmd.hasOption(OPT_HFILE_NAME)) {	
please specify hfile name using the option 

}	boolean doBenchmark = cmd.hasOption(OPT_MEASURE_THROUGHPUT);	boolean doVerify = !cmd.hasOption(OPT_OMIT_CORRECTNESS_TEST);	if (cmd.hasOption(OPT_BENCHMARK_N_TIMES)) {	benchmarkNTimes = Integer.valueOf(cmd.getOptionValue( OPT_BENCHMARK_N_TIMES));	}	if (cmd.hasOption(OPT_BENCHMARK_N_OMIT)) {	benchmarkNOmit = Integer.valueOf(cmd.getOptionValue(OPT_BENCHMARK_N_OMIT));	}	if (benchmarkNTimes < benchmarkNOmit) {	
the number of times to run each benchmark must be greater than the number of benchmark runs to exclude from statistics 

boolean doVerify = !cmd.hasOption(OPT_OMIT_CORRECTNESS_TEST);	if (cmd.hasOption(OPT_BENCHMARK_N_TIMES)) {	benchmarkNTimes = Integer.valueOf(cmd.getOptionValue( OPT_BENCHMARK_N_TIMES));	}	if (cmd.hasOption(OPT_BENCHMARK_N_OMIT)) {	benchmarkNOmit = Integer.valueOf(cmd.getOptionValue(OPT_BENCHMARK_N_OMIT));	}	if (benchmarkNTimes < benchmarkNOmit) {	System.exit(1);	}	
running benchmark times excluding the first times from statistics 

========================= hbase sample_1581 =========================

public RegionServerCoprocessorHost(RegionServerServices rsServices, Configuration conf) {	super(rsServices);	this.rsServices = rsServices;	this.conf = conf;	boolean coprocessorsEnabled = conf.getBoolean(COPROCESSORS_ENABLED_CONF_KEY, DEFAULT_COPROCESSORS_ENABLED);	boolean tableCoprocessorsEnabled = conf.getBoolean(USER_COPROCESSORS_ENABLED_CONF_KEY, DEFAULT_USER_COPROCESSORS_ENABLED);	
system coprocessor loading is enabled disabled 

public RegionServerCoprocessorHost(RegionServerServices rsServices, Configuration conf) {	super(rsServices);	this.rsServices = rsServices;	this.conf = conf;	boolean coprocessorsEnabled = conf.getBoolean(COPROCESSORS_ENABLED_CONF_KEY, DEFAULT_COPROCESSORS_ENABLED);	boolean tableCoprocessorsEnabled = conf.getBoolean(USER_COPROCESSORS_ENABLED_CONF_KEY, DEFAULT_USER_COPROCESSORS_ENABLED);	
table coprocessor loading is enabled disabled 

public RegionServerCoprocessor checkAndGetInstance(Class<?> implClass) throws InstantiationException, IllegalAccessException {	if (RegionServerCoprocessor.class.isAssignableFrom(implClass)) {	return (RegionServerCoprocessor)implClass.newInstance();	} else if (SingletonCoprocessorService.class.isAssignableFrom(implClass)) {	return new CoprocessorServiceBackwardCompatiblity.RegionServerCoprocessorService( (SingletonCoprocessorService)implClass.newInstance());	} else {	
is not of type regionservercoprocessor check the configuration 

========================= hbase sample_2657 =========================

private Set<String> getUndeletedHFileRefsPeers() throws ReplicationException {	Set<String> undeletedHFileRefsPeerIds = new HashSet<>(queueStorage.getAllPeersFromHFileRefsQueue());	Set<String> peerIds = new HashSet<>(peerStorage.listPeerIds());	undeletedHFileRefsPeerIds.removeAll(peerIds);	if (LOG.isDebugEnabled()) {	for (String peerId : undeletedHFileRefsPeerIds) {	
undeleted replication hfile refs queue for removed peer found 

========================= hbase sample_2207 =========================

String snapshotString = "offlineTableSnapshot";	try {	Table table = TEST_UTIL.createTable(tableName, Bytes.toBytes("cf"));	for (int i = 0; i < 100; i++) {	Put put = new Put(Bytes.toBytes(i)).addColumn(Bytes.toBytes("cf"), null, Bytes.toBytes(i));	table.put(put);	}	Map<String, String> props = new HashMap<>();	props.put("table", tableName.getNameAsString());	admin.execProcedure(SnapshotManager.ONLINE_SNAPSHOT_CONTROLLER_DESCRIPTION, snapshotString, props).get();	
snapshot completed 

========================= hbase sample_2084 =========================

public void abort(String why, Throwable e) {	aborted = true;	
aborting during test 

public void testLeaderSelection() throws Exception {	MockLeader currentLeader = getCurrentLeader();	assertNotNull("Leader should exist", currentLeader);	
current leader index is 

public void testLeaderSelection() throws Exception {	MockLeader currentLeader = getCurrentLeader();	assertNotNull("Leader should exist", currentLeader);	byte[] znodeData = ZKUtil.getData(currentLeader.getWatcher(), LEADER_ZNODE);	assertNotNull("Leader znode should contain leader index", znodeData);	assertTrue("Leader znode should not be empty", znodeData.length > 0);	int storedIndex = Bytes.toInt(znodeData);	
stored leader index in zk is 

MockLeader currentLeader = getCurrentLeader();	assertNotNull("Leader should exist", currentLeader);	byte[] znodeData = ZKUtil.getData(currentLeader.getWatcher(), LEADER_ZNODE);	assertNotNull("Leader znode should contain leader index", znodeData);	assertTrue("Leader znode should not be empty", znodeData.length > 0);	int storedIndex = Bytes.toInt(znodeData);	assertEquals("Leader znode should match leader index", currentLeader.getIndex(), storedIndex);	currentLeader.abdicate();	currentLeader = getCurrentLeader();	assertNotNull("New leader should exist after abdication", currentLeader);	
new leader index is 

assertTrue("Leader znode should not be empty", znodeData.length > 0);	int storedIndex = Bytes.toInt(znodeData);	assertEquals("Leader znode should match leader index", currentLeader.getIndex(), storedIndex);	currentLeader.abdicate();	currentLeader = getCurrentLeader();	assertNotNull("New leader should exist after abdication", currentLeader);	znodeData = ZKUtil.getData(currentLeader.getWatcher(), LEADER_ZNODE);	assertNotNull("Leader znode should contain leader index", znodeData);	assertTrue("Leader znode should not be empty", znodeData.length > 0);	storedIndex = Bytes.toInt(znodeData);	
stored leader index in zk is 

currentLeader = getCurrentLeader();	assertNotNull("New leader should exist after abdication", currentLeader);	znodeData = ZKUtil.getData(currentLeader.getWatcher(), LEADER_ZNODE);	assertNotNull("Leader znode should contain leader index", znodeData);	assertTrue("Leader znode should not be empty", znodeData.length > 0);	storedIndex = Bytes.toInt(znodeData);	assertEquals("Leader znode should match leader index", currentLeader.getIndex(), storedIndex);	currentLeader.stop("Stopping for test");	currentLeader = getCurrentLeader();	assertNotNull("New leader should exist after stop", currentLeader);	
new leader index is 

assertTrue("Leader znode should not be empty", znodeData.length > 0);	storedIndex = Bytes.toInt(znodeData);	assertEquals("Leader znode should match leader index", currentLeader.getIndex(), storedIndex);	currentLeader.stop("Stopping for test");	currentLeader = getCurrentLeader();	assertNotNull("New leader should exist after stop", currentLeader);	znodeData = ZKUtil.getData(currentLeader.getWatcher(), LEADER_ZNODE);	assertNotNull("Leader znode should contain leader index", znodeData);	assertTrue("Leader znode should not be empty", znodeData.length > 0);	storedIndex = Bytes.toInt(znodeData);	
stored leader index in zk is 

========================= hbase sample_720 =========================

public boolean copyTableCFs(String peerId) throws ReplicationException {	String tableCFsNode = getTableCFsNode(peerId);	try {	if (ZKUtil.checkExists(zookeeper, tableCFsNode) != -1) {	ReplicationPeerConfig rpc = peerStorage.getPeerConfig(peerId);	if (rpc.getTableCFsMap() == null || rpc.getTableCFsMap().isEmpty()) {	
copy tablecfs into peernode 

try {	if (ZKUtil.checkExists(zookeeper, tableCFsNode) != -1) {	ReplicationPeerConfig rpc = peerStorage.getPeerConfig(peerId);	if (rpc.getTableCFsMap() == null || rpc.getTableCFsMap().isEmpty()) {	ReplicationProtos.TableCF[] tableCFs = ReplicationPeerConfigUtil.parseTableCFs(ZKUtil.getData(this.zookeeper, tableCFsNode));	if (tableCFs != null && tableCFs.length > 0) {	rpc.setTableCFsMap(ReplicationPeerConfigUtil.convert2Map(tableCFs));	peerStorage.updatePeerConfig(peerId, rpc);	}	} else {	
no tablecfs in peernode 

========================= hbase sample_2968 =========================

private void runTestOnTable(Table table) throws IOException, InterruptedException, ClassNotFoundException {	Job job = null;	try {	
before map reduce startup 

try {	job = new Job(table.getConfiguration(), "process column contents");	job.setNumReduceTasks(1);	Scan scan = new Scan();	scan.addFamily(INPUT_FAMILY);	TableMapReduceUtil.initTableMapperJob( table.getName(), scan, MultithreadedTableMapper.class, ImmutableBytesWritable.class, Put.class, job);	MultithreadedTableMapper.setMapperClass(job, ProcessContentsMapper.class);	MultithreadedTableMapper.setNumberOfThreads(job, NUMBER_OF_THREADS);	TableMapReduceUtil.initTableReducerJob( table.getName().getNameAsString(), IdentityTableReducer.class, job);	FileOutputFormat.setOutputPath(job, new Path("test"));	
started 

job = new Job(table.getConfiguration(), "process column contents");	job.setNumReduceTasks(1);	Scan scan = new Scan();	scan.addFamily(INPUT_FAMILY);	TableMapReduceUtil.initTableMapperJob( table.getName(), scan, MultithreadedTableMapper.class, ImmutableBytesWritable.class, Put.class, job);	MultithreadedTableMapper.setMapperClass(job, ProcessContentsMapper.class);	MultithreadedTableMapper.setNumberOfThreads(job, NUMBER_OF_THREADS);	TableMapReduceUtil.initTableReducerJob( table.getName().getNameAsString(), IdentityTableReducer.class, job);	FileOutputFormat.setOutputPath(job, new Path("test"));	assertTrue(job.waitForCompletion(true));	
after map reduce completion 

private void verify(TableName tableName) throws IOException {	Table table = UTIL.getConnection().getTable(tableName);	boolean verified = false;	long pause = UTIL.getConfiguration().getLong("hbase.client.pause", 5 * 1000);	int numRetries = UTIL.getConfiguration().getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	
verification attempt 

Table table = UTIL.getConnection().getTable(tableName);	boolean verified = false;	long pause = UTIL.getConfiguration().getLong("hbase.client.pause", 5 * 1000);	int numRetries = UTIL.getConfiguration().getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	verifyAttempt(table);	verified = true;	break;	} catch (NullPointerException e) {	
verification attempt failed 

========================= hbase sample_3380 =========================

public void testMissingServerResource() throws Throwable {	try {	HttpServer server = createServer("NoSuchWebapp");	String serverDescription = server.toString();	stop(server);	fail("Expected an exception, got " + serverDescription);	} catch (FileNotFoundException expected) {	
expected exception 

========================= hbase sample_3197 =========================

Field ExecutorField = scheduler.getClass().getDeclaredField("executor");	ExecutorField.setAccessible(true);	scheduler.start();	rpcExecutor = (ThreadPoolExecutor) ExecutorField.get(scheduler);	rpcExecutor.setMaximumPoolSize(1);	rpcExecutor.allowCoreThreadTimeOut(true);	rpcExecutor.setCorePoolSize(0);	rpcExecutor.setKeepAliveTime(1, TimeUnit.MICROSECONDS);	Thread.sleep(2000);	} catch (NoSuchFieldException e) {	
no such field exception 

ExecutorField.setAccessible(true);	scheduler.start();	rpcExecutor = (ThreadPoolExecutor) ExecutorField.get(scheduler);	rpcExecutor.setMaximumPoolSize(1);	rpcExecutor.allowCoreThreadTimeOut(true);	rpcExecutor.setCorePoolSize(0);	rpcExecutor.setKeepAliveTime(1, TimeUnit.MICROSECONDS);	Thread.sleep(2000);	} catch (NoSuchFieldException e) {	} catch (IllegalAccessException e) {	
illegal access exception 

scheduler.start();	rpcExecutor = (ThreadPoolExecutor) ExecutorField.get(scheduler);	rpcExecutor.setMaximumPoolSize(1);	rpcExecutor.allowCoreThreadTimeOut(true);	rpcExecutor.setCorePoolSize(0);	rpcExecutor.setKeepAliveTime(1, TimeUnit.MICROSECONDS);	Thread.sleep(2000);	} catch (NoSuchFieldException e) {	} catch (IllegalAccessException e) {	} catch (InterruptedException e) {	
interrupted exception 

========================= hbase sample_1903 =========================

public void testFullRestoreSingle() throws Exception {	
test full restore on a single table empty table 

public void testFullRestoreSingle() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

public void testFullRestoreSingleCommand() throws Exception {	
test full restore on a single table empty table command line 

public void testFullRestoreSingleCommand() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	
backup complete 

public void testFullRestoreCheckCommand() throws Exception {	
test full restore on a single table command line check only 

public void testFullRestoreCheckCommand() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	
backup complete 

public void testFullRestoreMultiple() throws Exception {	
create full backup image on multiple tables 

public void testFullRestoreMultipleCommand() throws Exception {	
create full backup image on multiple tables command line 

public void testFullRestoreSingleOverwrite() throws Exception {	
test full restore on a single table empty table 

public void testFullRestoreSingleOverwrite() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

public void testFullRestoreSingleOverwriteCommand() throws Exception {	
test full restore on a single table empty table command line 

public void testFullRestoreSingleOverwriteCommand() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

public void testFullRestoreMultipleOverwrite() throws Exception {	
create full backup image on multiple tables 

public void testFullRestoreMultipleOverwriteCommand() throws Exception {	
create full backup image on multiple tables command line 

public void testFullRestoreSingleDNE() throws Exception {	
test restore fails on a single table that does not exist 

public void testFullRestoreSingleDNE() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

public void testFullRestoreSingleDNECommand() throws Exception {	
test restore fails on a single table that does not exist command line 

public void testFullRestoreSingleDNECommand() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

public void testFullRestoreMultipleDNE() throws Exception {	
test restore fails on multiple tables that do not exist 

public void testFullRestoreMultipleDNECommand() throws Exception {	
test restore fails on multiple tables that do not exist command line 

========================= hbase sample_537 =========================

public void postSync() {}	public void abortProcess() {	
abort the procedure store 

public void tearDown() throws Exception {	store.stop(false);	UTIL.getDFSCluster().getFileSystem().delete(store.getWALDir(), true);	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testWalAbortOnLowReplication() throws Exception {	setupDFS();	assertEquals(3, UTIL.getDFSCluster().getDataNodes().size());	
stop datanode 

store.registerListener(new ProcedureStore.ProcedureStoreListener() {	public void postSync() { Threads.sleepWithoutInterrupt(2000); }	public void abortProcess() {}	});	final AtomicInteger reCount = new AtomicInteger(0);	Thread[] thread = new Thread[store.getNumThreads() * 2 + 1];	for (int i = 0; i < thread.length; ++i) {	final long procId = i + 1;	thread[i] = new Thread(() -> {	try {	
s insert 

public void postSync() { Threads.sleepWithoutInterrupt(2000); }	public void abortProcess() {}	});	final AtomicInteger reCount = new AtomicInteger(0);	Thread[] thread = new Thread[store.getNumThreads() * 2 + 1];	for (int i = 0; i < thread.length; ++i) {	final long procId = i + 1;	thread[i] = new Thread(() -> {	try {	store.insert(new TestProcedure(procId, -1), null);	
e insert 

});	final AtomicInteger reCount = new AtomicInteger(0);	Thread[] thread = new Thread[store.getNumThreads() * 2 + 1];	for (int i = 0; i < thread.length; ++i) {	final long procId = i + 1;	thread[i] = new Thread(() -> {	try {	store.insert(new TestProcedure(procId, -1), null);	} catch (RuntimeException e) {	reCount.incrementAndGet();	
f insert 

thread[i] = new Thread(() -> {	try {	store.insert(new TestProcedure(procId, -1), null);	} catch (RuntimeException e) {	reCount.incrementAndGet();	}	});	thread[i].start();	}	Thread.sleep(1000);	
stop datanode 

UTIL.getConfiguration().setInt("dfs.namenode.replication.min", 1);	setupDFS();	int dnCount = 0;	store.insert(new TestProcedure(1, -1), null);	UTIL.getDFSCluster().restartDataNode(dnCount);	for (long i = 2; i < 100; ++i) {	store.insert(new TestProcedure(i, -1), null);	waitForNumReplicas(3);	Thread.sleep(100);	if ((i % 30) == 0) {	
restart data node 

========================= hbase sample_1846 =========================

public MultiTableRecordWriter(Configuration conf, boolean useWriteAheadLogging) throws IOException {	
created new multitablerecordreader with wal on off 

========================= hbase sample_3482 =========================

public List<JVMClusterUtil.RegionServerThread> getLiveRegionServers() {	List<JVMClusterUtil.RegionServerThread> liveServers = new ArrayList<>();	List<RegionServerThread> list = getRegionServers();	for (JVMClusterUtil.RegionServerThread rst: list) {	if (rst.isAlive()) liveServers.add(rst);	
not alive 

public String waitOnRegionServer(JVMClusterUtil.RegionServerThread rst) {	while (rst.isAlive()) {	try {	
waiting on 

public String waitOnMaster(JVMClusterUtil.MasterThread masterThread) {	while (masterThread.isAlive()) {	try {	
waiting on 

public void join() {	if (this.regionThreads != null) {	for(Thread t: this.regionThreads) {	if (t.isAlive()) {	try {	Threads.threadDumpingIsAlive(t);	} catch (InterruptedException e) {	
Interrupted 

}	}	}	}	if (this.masterThreads != null) {	for (Thread t : this.masterThreads) {	if (t.isAlive()) {	try {	Threads.threadDumpingIsAlive(t);	} catch (InterruptedException e) {	
Interrupted 

========================= hbase sample_2440 =========================

public static void startCluster() throws Exception {	
starting cluster 

========================= hbase sample_1796 =========================

for (int i = 0; i < numberOfTests; i++) {	if (columnLists[i].contains(column)) {	kvMaps[i].put(kv.getKeyString(), kv);	}	}	}	}	}	region.put(p);	if (Math.random() < flushPercentage) {	
flushing 

}	}	}	}	}	region.put(p);	if (Math.random() < flushPercentage) {	region.flush(true);	}	if (Math.random() < minorPercentage) {	
minor compacting 

}	}	region.put(p);	if (Math.random() < flushPercentage) {	region.flush(true);	}	if (Math.random() < minorPercentage) {	region.compact(false);	}	if (Math.random() < majorPercentage) {	
major compacting 

for (int i = 0; i < numberOfTests + 1; i++) {	Collection<KeyValue> kvSet;	Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	
explicitcolumns scanner 

for (int i = 0; i < numberOfTests + 1; i++) {	Collection<KeyValue> kvSet;	Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	
columns keys 

Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	} else {	kvSet = allKVMap.values();	
wildcard scanner 

Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	} else {	kvSet = allKVMap.values();	
columns keys 

for (int i = 0; i < numberOfTests; i++) {	if (columnLists[i].contains(column)) {	kvMaps[i].put(kv.getKeyString(), kv);	}	}	}	}	}	region.put(p);	if (Math.random() < flushPercentage) {	
flushing 

}	}	}	}	}	region.put(p);	if (Math.random() < flushPercentage) {	region.flush(true);	}	if (Math.random() < minorPercentage) {	
minor compacting 

}	}	region.put(p);	if (Math.random() < flushPercentage) {	region.flush(true);	}	if (Math.random() < minorPercentage) {	region.compact(false);	}	if (Math.random() < majorPercentage) {	
major compacting 

for (int i = 0; i < numberOfTests + 1; i++) {	Collection<KeyValue> kvSet;	Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	
explicitcolumns scanner 

for (int i = 0; i < numberOfTests + 1; i++) {	Collection<KeyValue> kvSet;	Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	
columns keys 

Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	} else {	kvSet = allKVMap.values();	
wildcard scanner 

Scan scan = new Scan();	scan.setMaxVersions();	if (i < numberOfTests) {	if (columnLists[i].isEmpty()) continue;	kvSet = kvMaps[i].values();	for (String column : columnLists[i]) {	scan.addColumn(familyBytes, Bytes.toBytes(column));	}	} else {	kvSet = allKVMap.values();	
columns keys 

========================= hbase sample_1779 =========================

public void run() {	try {	while (!master.isStopped() && master.isActiveMaster()) {	Thread.sleep(timeout);	if (master.isInitialized()) {	
initialization completed within allotted tolerance monitor exiting 

public void run() {	try {	while (!master.isStopped() && master.isActiveMaster()) {	Thread.sleep(timeout);	if (master.isInitialized()) {	} else {	
master failed to complete initialization after ms please consider submitting a bug report including a thread dump of this process 

public void run() {	try {	while (!master.isStopped() && master.isActiveMaster()) {	Thread.sleep(timeout);	if (master.isInitialized()) {	} else {	if (haltOnTimeout) {	
zombie master exiting thread dump to stdout 

Thread.sleep(timeout);	if (master.isInitialized()) {	} else {	if (haltOnTimeout) {	Threads.printThreadInfo(System.out, "Zombie HMaster");	System.exit(-1);	}	}	}	} catch (InterruptedException ie) {	
initmonitor thread interrupted existing 

public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {	String redirectHost = regionServerHostname;	if(redirectHost == null) {	redirectHost = request.getServerName();	if(!Addressing.isLocalAddress(InetAddress.getByName(redirectHost))) {	
couldn t resolve as an address local to this node and is not set client will get a http response if your hbase deployment relies on client accessible names that the region server process can t resolve locally then you should set the previously mentioned configuration variable to an appropriate hostname 

this.masterCheckCompression = conf.getBoolean("hbase.master.check.compression", true);	this.masterCheckEncryption = conf.getBoolean("hbase.master.check.encryption", true);	this.metricsMaster = new MetricsMaster(new MetricsMasterWrapperImpl(this));	this.preLoadTableDescriptors = conf.getBoolean("hbase.master.preload.tabledescriptors", true);	this.maxBlancingTime = getMaxBalancingTime();	this.maxRitPercent = conf.getDouble(HConstants.HBASE_MASTER_BALANCER_MAX_RIT_PERCENT, HConstants.DEFAULT_HBASE_MASTER_BALANCER_MAX_RIT_PERCENT);	boolean shouldPublish = conf.getBoolean(HConstants.STATUS_PUBLISHED, HConstants.STATUS_PUBLISHED_DEFAULT);	Class<? extends ClusterStatusPublisher.Publisher> publisherClass = conf.getClass(ClusterStatusPublisher.STATUS_PUBLISHER_CLASS, ClusterStatusPublisher.DEFAULT_STATUS_PUBLISHER_CLASS, ClusterStatusPublisher.Publisher.class);	if (shouldPublish) {	if (publisherClass == null) {	
is true but is not set not publishing status 

clusterStatusPublisherChore = new ClusterStatusPublisher(this, conf, publisherClass);	getChoreService().scheduleChore(clusterStatusPublisherChore);	}	}	if (!conf.getBoolean("hbase.testing.nocluster", false)) {	this.activeMasterManager = new ActiveMasterManager(zooKeeper, this.serverName, this);	} else {	this.activeMasterManager = null;	}	} catch (Throwable t) {	
failed construction of master 

}	}	}	super.run();	} finally {	if (this.clusterSchemaService != null) {	this.clusterSchemaService.stopAsync();	try {	this.clusterSchemaService.awaitTerminated( getConfiguration().getInt(HBASE_MASTER_WAIT_ON_SERVICE_IN_SECONDS, DEFAULT_HBASE_MASTER_WAIT_ON_SERVICE_IN_SECONDS), TimeUnit.SECONDS);	} catch (TimeoutException te) {	
failed shutdown of clusterschemaservice 

status.setStatus("Recovering  Meta Region");	MasterMetaBootstrap metaBootstrap = createMetaBootstrap(this, status);	metaBootstrap.recoverMeta();	if (isStopped()) return;	if (favoredNodesManager != null) {	SnapshotOfRegionAssignmentFromMeta snapshotOfRegionAssignment = new SnapshotOfRegionAssignmentFromMeta(getConnection());	snapshotOfRegionAssignment.initialize();	favoredNodesManager.initialize(snapshotOfRegionAssignment);	}	for (Map.Entry<TableName, TableState.State> entry : ZKDataMigrator .queryForTableStates(getZooKeeper()).entrySet()) {	
converting state from zk to new states 

this.normalizerChore = new RegionNormalizerChore(this);	getChoreService().scheduleChore(normalizerChore);	this.catalogJanitorChore = new CatalogJanitor(this);	getChoreService().scheduleChore(catalogJanitorChore);	status.setStatus("Starting cluster schema service");	initClusterSchemaService();	if (this.cpHost != null) {	try {	this.cpHost.preMasterInitialization();	} catch (IOException e) {	
coprocessor premasterinitialization hook failed 

getChoreService().scheduleChore(catalogJanitorChore);	status.setStatus("Starting cluster schema service");	initClusterSchemaService();	if (this.cpHost != null) {	try {	this.cpHost.preMasterInitialization();	} catch (IOException e) {	}	}	status.markComplete("Initialization successful");	
master has completed initialization 

this.serverManager.clearDeadServersWithSameHostNameAndPortOfOnlineServer();	status.setStatus("Checking ZNode ACLs");	zooKeeper.checkAndSetZNodeAcls();	status.setStatus("Initializing MOB Cleaner");	initMobCleaner();	status.setStatus("Calling postStartMaster coprocessors");	if (this.cpHost != null) {	try {	this.cpHost.postStartMaster();	} catch (IOException ioe) {	
coprocessor poststartmaster hook failed 

private void waitForRegionServers(final MonitoredTask status) throws IOException, InterruptedException {	this.serverManager.waitForRegionServers(status);	for (ServerName sn: this.regionServerTracker.getOnlineServers()) {	if (!this.serverManager.isServerOnline(sn) && serverManager.checkAndRecordNewServer(sn, new ServerLoad(ServerMetricsBuilder.of(sn)))) {	
registered server found up in zk but who has not yet reported in 

int cleanerInterval = conf.getInt("hbase.master.cleaner.interval", 60 * 1000);	this.logCleaner = new LogCleaner(cleanerInterval, this, conf, getMasterWalManager().getFileSystem(), getMasterWalManager().getOldLogDir());	getChoreService().scheduleChore(logCleaner);	Path archiveDir = HFileArchiveUtil.getArchivePath(conf);	Map<String, Object> params = new HashMap<>();	params.put(MASTER, this);	this.hfileCleaner = new HFileCleaner(cleanerInterval, this, conf, getMasterFileSystem() .getFileSystem(), archiveDir, params);	getChoreService().scheduleChore(hfileCleaner);	serviceStarted = true;	if (LOG.isTraceEnabled()) {	
started service threads 

protected void stopServiceThreads() {	if (masterJettyServer != null) {	
stopping master jetty server 

protected void stopServiceThreads() {	if (masterJettyServer != null) {	try {	masterJettyServer.stop();	} catch (Exception e) {	
failed to stop master jetty server 

protected void stopServiceThreads() {	if (masterJettyServer != null) {	try {	masterJettyServer.stop();	} catch (Exception e) {	}	}	super.stopServiceThreads();	stopChores();	if (LOG.isDebugEnabled()) {	
stopping service threads 

public boolean balance(boolean force) throws IOException {	if (!isInitialized()) {	
master has not been initialized don t run balancer 

public boolean balance(boolean force) throws IOException {	if (!isInitialized()) {	return false;	}	if (isInMaintenanceMode()) {	
master is in maintenancemode mode don t run balancer 

List<RegionStateNode> regionsInTransition = assignmentManager.getRegionsInTransition();	boolean metaInTransition = assignmentManager.isMetaRegionInTransition();	String prefix = force && !metaInTransition ? "R" : "Not r";	List<RegionStateNode> toPrint = regionsInTransition;	int max = 5;	boolean truncated = false;	if (regionsInTransition.size() > max) {	toPrint = regionsInTransition.subList(0, max);	truncated = true;	}	
unning balancer because region s in transition truncated list 

List<RegionStateNode> toPrint = regionsInTransition;	int max = 5;	boolean truncated = false;	if (regionsInTransition.size() > max) {	toPrint = regionsInTransition.subList(0, max);	truncated = true;	}	if (!force || metaInTransition) return false;	}	if (this.serverManager.areDeadServersInProgress()) {	
not running balancer because processing dead regionserver s 

truncated = true;	}	if (!force || metaInTransition) return false;	}	if (this.serverManager.areDeadServersInProgress()) {	return false;	}	if (this.cpHost != null) {	try {	if (this.cpHost.preBalance()) {	
coprocessor bypassing balancer request 

}	if (this.serverManager.areDeadServersInProgress()) {	return false;	}	if (this.cpHost != null) {	try {	if (this.cpHost.preBalance()) {	return false;	}	} catch (IOException ioe) {	
error invoking master coprocessor prebalance 

}	for (Entry<TableName, Map<ServerName, List<RegionInfo>>> e : assignmentsByTable.entrySet()) {	List<RegionPlan> partialPlans = this.balancer.balanceCluster(e.getKey(), e.getValue());	if (partialPlans != null) plans.addAll(partialPlans);	}	long balanceStartTime = System.currentTimeMillis();	long cutoffTime = balanceStartTime + this.maxBlancingTime;	int rpCount = 0;	if (plans != null && !plans.isEmpty()) {	int balanceInterval = this.maxBlancingTime / plans.size();	
balancer plans size is the balance interval is ms and the max number regions in transition is 

for (Entry<TableName, Map<ServerName, List<RegionInfo>>> e : assignmentsByTable.entrySet()) {	List<RegionPlan> partialPlans = this.balancer.balanceCluster(e.getKey(), e.getValue());	if (partialPlans != null) plans.addAll(partialPlans);	}	long balanceStartTime = System.currentTimeMillis();	long cutoffTime = balanceStartTime + this.maxBlancingTime;	int rpCount = 0;	if (plans != null && !plans.isEmpty()) {	int balanceInterval = this.maxBlancingTime / plans.size();	for (RegionPlan plan: plans) {	
balance 

if (rpCount < plans.size() && System.currentTimeMillis() > cutoffTime) {	LOG.debug("No more balancing till next balance run; maxBalanceTime=" + this.maxBlancingTime);	break;	}	}	}	if (this.cpHost != null) {	try {	this.cpHost.postBalance(rpCount < plans.size() ? plans.subList(0, rpCount) : plans);	} catch (IOException ioe) {	
error invoking master coprocessor postbalance 

public boolean normalizeRegions() throws IOException {	if (!isInitialized()) {	
master has not been initialized don t run region normalizer 

public boolean normalizeRegions() throws IOException {	if (!isInitialized()) {	return false;	}	if (isInMaintenanceMode()) {	
master is in maintenance mode don t run region normalizer 

public boolean normalizeRegions() throws IOException {	if (!isInitialized()) {	return false;	}	if (isInMaintenanceMode()) {	return false;	}	if (!this.regionNormalizerTracker.isNormalizerOn()) {	
region normalization is disabled don t run region normalizer 

return false;	}	if (!this.regionNormalizerTracker.isNormalizerOn()) {	return false;	}	synchronized (this.normalizer) {	List<TableName> allEnabledTables = new ArrayList<>( this.tableStateManager.getTablesInStates(TableState.State.ENABLED));	Collections.shuffle(allEnabledTables);	for (TableName table : allEnabledTables) {	if (isInMaintenanceMode()) {	
master is in maintenance mode stop running region normalizer 

}	synchronized (this.normalizer) {	List<TableName> allEnabledTables = new ArrayList<>( this.tableStateManager.getTablesInStates(TableState.State.ENABLED));	Collections.shuffle(allEnabledTables);	for (TableName table : allEnabledTables) {	if (isInMaintenanceMode()) {	return false;	}	TableDescriptor tblDesc = getTableDescriptors().get(table);	if (table.isSystemTable() || (tblDesc != null && !tblDesc.isNormalizationEnabled())) {	
skipping normalization for table as it s either system table or doesn t have auto normalization turned on 

}	if (!tableName.equals(regionsToMerge[1].getTable())) {	throw new IOException ( "Cannot merge regions from two different tables " + regionsToMerge[0].getTable() + " and " + regionsToMerge[1].getTable());	}	if (RegionInfo.COMPARATOR.compare(regionsToMerge[0], regionsToMerge[1]) == 0) {	throw new MergeRegionException( "Cannot merge a region to itself " + regionsToMerge[0] + ", " + regionsToMerge[1]);	}	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preMergeRegions(regionsToMerge);	
merge regions and 

public long splitRegion(final RegionInfo regionInfo, final byte[] splitRow, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preSplitRegion(regionInfo.getTable(), splitRow);	
split 

RegionState regionState = assignmentManager.getRegionStates(). getRegionState(Bytes.toString(encodedRegionName));	RegionInfo hri;	if (regionState != null) {	hri = regionState.getRegion();	} else {	throw new UnknownRegionException(Bytes.toStringBinary(encodedRegionName));	}	ServerName dest;	List<ServerName> exclude = hri.getTable().isSystemTable() ? assignmentManager.getExcludedServersForSystemTable() : new ArrayList<>(1);	if (destServerName != null && exclude.contains(ServerName.valueOf(Bytes.toString(destServerName)))) {	
can not move to because the server is in exclude list 

hri = regionState.getRegion();	} else {	throw new UnknownRegionException(Bytes.toStringBinary(encodedRegionName));	}	ServerName dest;	List<ServerName> exclude = hri.getTable().isSystemTable() ? assignmentManager.getExcludedServersForSystemTable() : new ArrayList<>(1);	if (destServerName != null && exclude.contains(ServerName.valueOf(Bytes.toString(destServerName)))) {	destServerName = null;	}	if (destServerName == null || destServerName.length == 0) {	
passed destination servername is null empty so choosing a server at random 

ServerName dest;	List<ServerName> exclude = hri.getTable().isSystemTable() ? assignmentManager.getExcludedServersForSystemTable() : new ArrayList<>(1);	if (destServerName != null && exclude.contains(ServerName.valueOf(Bytes.toString(destServerName)))) {	destServerName = null;	}	if (destServerName == null || destServerName.length == 0) {	exclude.add(regionState.getServerName());	final List<ServerName> destServers = this.serverManager.createDestinationServersList(exclude);	dest = balancer.randomAssignment(hri, destServers);	if (dest == null) {	
unable to determine a plan to assign 

exclude.add(regionState.getServerName());	final List<ServerName> destServers = this.serverManager.createDestinationServersList(exclude);	dest = balancer.randomAssignment(hri, destServers);	if (dest == null) {	return;	}	} else {	ServerName candidate = ServerName.valueOf(Bytes.toString(destServerName));	dest = balancer.randomAssignment(hri, Lists.newArrayList(candidate));	if (dest == null) {	
unable to determine a plan to assign 

if (dest == null) {	return;	}	} else {	ServerName candidate = ServerName.valueOf(Bytes.toString(destServerName));	dest = balancer.randomAssignment(hri, Lists.newArrayList(candidate));	if (dest == null) {	return;	}	if (dest.equals(serverName) && balancer instanceof BaseLoadBalancer && !((BaseLoadBalancer)balancer).shouldBeOnMaster(hri)) {	
skipping move of region to avoid unnecessary region moving later by load balancer because it should not be on master 

ServerName candidate = ServerName.valueOf(Bytes.toString(destServerName));	dest = balancer.randomAssignment(hri, Lists.newArrayList(candidate));	if (dest == null) {	return;	}	if (dest.equals(serverName) && balancer instanceof BaseLoadBalancer && !((BaseLoadBalancer)balancer).shouldBeOnMaster(hri)) {	return;	}	}	if (dest.equals(regionState.getServerName())) {	
skipping move of region because region already assigned to the same server 

}	RegionPlan rp = new RegionPlan(hri, regionState.getServerName(), dest);	assert rp.getDestination() != null: rp.toString() + " " + dest;	assert rp.getSource() != null: rp.toString();	try {	checkInitialized();	if (this.cpHost != null) {	this.cpHost.preMove(hri, rp.getSource(), rp.getDestination());	}	serverManager.sendRegionWarmup(rp.getDestination(), hri);	
move running balancer 

public long createTable( final TableDescriptor tableDescriptor, final byte [][] splitKeys, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	String namespace = tableDescriptor.getTableName().getNamespaceAsString();	this.clusterSchemaService.getNamespace(namespace);	RegionInfo[] newRegions = ModifyRegionUtils.createRegionInfos(tableDescriptor, splitKeys);	sanityCheckTableDescriptor(tableDescriptor);	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preCreateTable(tableDescriptor, newRegions);	
create 

public long createSystemTable(final TableDescriptor tableDescriptor) throws IOException {	if (isStopped()) {	throw new MasterNotRunningException();	}	TableName tableName = tableDescriptor.getTableName();	if (!(tableName.isSystemTable())) {	throw new IllegalArgumentException( "Only system table creation can use this createSystemTable API");	}	RegionInfo[] newRegions = ModifyRegionUtils.createRegionInfos(tableDescriptor, null);	
create 

private void startActiveMasterManager(int infoPort) throws KeeperException {	String backupZNode = ZNodePaths.joinZNode( zooKeeper.znodePaths.backupMasterAddressesZNode, serverName.toString());	
adding backup master znode 

private void startActiveMasterManager(int infoPort) throws KeeperException {	String backupZNode = ZNodePaths.joinZNode( zooKeeper.znodePaths.backupMasterAddressesZNode, serverName.toString());	if (!MasterAddressTracker.setMasterAddress(zooKeeper, backupZNode, serverName, infoPort)) {	
failed create of by 

private void startActiveMasterManager(int infoPort) throws KeeperException {	String backupZNode = ZNodePaths.joinZNode( zooKeeper.znodePaths.backupMasterAddressesZNode, serverName.toString());	if (!MasterAddressTracker.setMasterAddress(zooKeeper, backupZNode, serverName, infoPort)) {	}	this.activeMasterManager.setInfoPort(infoPort);	int timeout = conf.getInt(HConstants.ZK_SESSION_TIMEOUT, HConstants.DEFAULT_ZK_SESSION_TIMEOUT);	if (conf.getBoolean(HConstants.MASTER_TYPE_BACKUP, HConstants.DEFAULT_MASTER_TYPE_BACKUP)) {	
hmaster started in backup mode stalling until master znode is written 

private void startActiveMasterManager(int infoPort) throws KeeperException {	String backupZNode = ZNodePaths.joinZNode( zooKeeper.znodePaths.backupMasterAddressesZNode, serverName.toString());	if (!MasterAddressTracker.setMasterAddress(zooKeeper, backupZNode, serverName, infoPort)) {	}	this.activeMasterManager.setInfoPort(infoPort);	int timeout = conf.getInt(HConstants.ZK_SESSION_TIMEOUT, HConstants.DEFAULT_ZK_SESSION_TIMEOUT);	if (conf.getBoolean(HConstants.MASTER_TYPE_BACKUP, HConstants.DEFAULT_MASTER_TYPE_BACKUP)) {	while (!activeMasterManager.hasActiveMaster()) {	
waiting for master address and cluster state znode to be written 

}	}	MonitoredTask status = TaskMonitor.get().createStatus("Master startup");	status.setDescription("Master startup");	try {	if (activeMasterManager.blockUntilBecomingActiveMaster(timeout, status)) {	finishActiveMasterInitialization(status);	}	} catch (Throwable t) {	status.setStatus("Failed to become active: " + t.getMessage());	
failed to become active master 

public long deleteTable( final TableName tableName, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preDeleteTable(tableName);	
delete 

public long truncateTable( final TableName tableName, final boolean preserveSplits, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preTruncateTable(tableName);	
truncate 

if (quotaManager != null) {	if (quotaManager.isQuotaInitialized()) {	Quotas quotaForTable = QuotaUtil.getTableQuota(getConnection(), tableName);	if (quotaForTable != null && quotaForTable.hasSpace()) {	SpaceViolationPolicy policy = quotaForTable.getSpace().getViolationPolicy();	if (SpaceViolationPolicy.DISABLE == policy) {	throw new AccessDeniedException("Enabling the table '" + tableName + "' is disallowed due to a violated space quota.");	}	}	} else if (LOG.isTraceEnabled()) {	
unable to check for space quotas as the masterquotamanager is not enabled 

Quotas quotaForTable = QuotaUtil.getTableQuota(getConnection(), tableName);	if (quotaForTable != null && quotaForTable.hasSpace()) {	SpaceViolationPolicy policy = quotaForTable.getSpace().getViolationPolicy();	if (SpaceViolationPolicy.DISABLE == policy) {	throw new AccessDeniedException("Enabling the table '" + tableName + "' is disallowed due to a violated space quota.");	}	}	} else if (LOG.isTraceEnabled()) {	}	}	
enable 

public long disableTable(final TableName tableName, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preDisableTable(tableName);	
disable 

public long modifyTable(final TableName tableName, final TableDescriptor descriptor, final long nonceGroup, final long nonce) throws IOException {	checkInitialized();	sanityCheckTableDescriptor(descriptor);	return MasterProcedureUtil.submitProcedure( new MasterProcedureUtil.NonceProcedureRunnable(this, nonceGroup, nonce) {	protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preModifyTable(tableName, descriptor);	
modify 

private List<ServerName> getBackupMasters() throws InterruptedIOException {	List<String> backupMasterStrings;	try {	backupMasterStrings = ZKUtil.listChildrenNoWatch(this.zooKeeper, this.zooKeeper.znodePaths.backupMasterAddressesZNode);	} catch (KeeperException e) {	
unable to list backup servers 

try {	bytes = ZKUtil.getData(this.zooKeeper, ZNodePaths.joinZNode( this.zooKeeper.znodePaths.backupMasterAddressesZNode, s));	} catch (InterruptedException e) {	throw new InterruptedIOException();	}	if (bytes != null) {	ServerName sn;	try {	sn = ProtobufUtil.parseServerNameFrom(bytes);	} catch (DeserializationException e) {	
failed parse skipping registering backup server 

if (bytes != null) {	ServerName sn;	try {	sn = ProtobufUtil.parseServerNameFrom(bytes);	} catch (DeserializationException e) {	continue;	}	backupMasters.add(sn);	}	} catch (KeeperException e) {	
unable to get information about backup servers 

public void abort(final String msg, final Throwable t) {	if (isAborted() || isStopped()) {	return;	}	if (cpHost != null) {	
master server abort loaded coprocessors are 

if (cpHost != null) {	}	if (t != null) {	LOG.error(HBaseMarkers.FATAL, msg, t);	} else {	LOG.error(HBaseMarkers.FATAL, msg);	}	try {	stopMaster();	} catch (IOException e) {	
exception occurred while stopping master 

if (cpHost != null) {	cpHost.preShutdown();	}	if (this.serverManager != null) {	this.serverManager.shutdownCluster();	}	if (this.clusterStatusTracker != null){	try {	this.clusterStatusTracker.setClusterDown();	} catch (KeeperException e) {	
zookeeper exception trying to set cluster as down in zk 

public boolean registerService(Service instance) {	Descriptors.ServiceDescriptor serviceDesc = instance.getDescriptorForType();	String serviceName = CoprocessorRpcUtils.getServiceName(serviceDesc);	if (coprocessorServiceHandlers.containsKey(serviceName)) {	
coprocessor service already registered rejecting request from 

public static void main(String [] args) {	
starting service 

protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preCreateNamespace(namespaceDescriptor);	
creating 

protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preModifyNamespace(namespaceDescriptor);	
modify 

protected void run() throws IOException {	getMaster().getMasterCoprocessorHost().preDeleteNamespace(name);	
delete 

this.serverManager.removeServerFromDrainList(server);	if (encodedRegionNames == null || encodedRegionNames.isEmpty()) {	return;	}	if (!this.serverManager.isServerOnline(server)) {	return;	}	for (byte[] encodedRegionName : encodedRegionNames) {	RegionState regionState = assignmentManager.getRegionStates().getRegionState(Bytes.toString(encodedRegionName));	if (regionState == null) {	
unknown region 

if (!this.serverManager.isServerOnline(server)) {	return;	}	for (byte[] encodedRegionName : encodedRegionNames) {	RegionState regionState = assignmentManager.getRegionStates().getRegionState(Bytes.toString(encodedRegionName));	if (regionState == null) {	continue;	}	RegionInfo hri = regionState.getRegion();	if (server.equals(regionState.getServerName())) {	
skipping move of region because region already assigned to the same server 

public boolean recoverMeta() throws IOException {	ProcedurePrepareLatch latch = ProcedurePrepareLatch.createLatch(2, 0);	
running recovermetaprocedure to ensure proper hbase meta deploy 

========================= hbase sample_2856 =========================

public void testLoadWithAck() throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	int noRegions = regionServer.getNumberOfOnlineRegions();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true).maxthreads(8);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	
unloading 

HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	int noRegions = regionServer.getNumberOfOnlineRegions();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true).maxthreads(8);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	rm.unload();	assertEquals(0, regionServer.getNumberOfOnlineRegions());	
successfully unloaded now loading 

public void testLoadWithoutAck() throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	final HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	int noRegions = regionServer.getNumberOfOnlineRegions();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	
unloading 

final HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	int noRegions = regionServer.getNumberOfOnlineRegions();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	rm.unload();	assertEquals(0, regionServer.getNumberOfOnlineRegions());	
successfully unloaded now loading 

public void testUnloadWithoutAck() throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	final HRegionServer regionServer = cluster.getRegionServer(0);	final int noRegions = regionServer.getNumberOfOnlineRegions();	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(false);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	
unloading 

public void testUnloadWithAck() throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true);	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	rm.unload();	
unloading 

fos.write(excludeServerName);	fos.close();	HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true).excludeFile(excludeFile.getCanonicalPath());	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	rm.unload();	
unloading 

HRegionServer regionServer = cluster.getRegionServer(0);	String rsName = regionServer.getServerName().getHostname();	int port = regionServer.getServerName().getPort();	String rs = rsName + ":" + Integer.toString(port);	RegionMoverBuilder rmBuilder = new RegionMoverBuilder(rs).ack(true).excludeFile(excludeFile.getCanonicalPath());	RegionMover rm = rmBuilder.build();	rm.setConf(TEST_UTIL.getConfiguration());	rm.unload();	assertEquals(0, regionServer.getNumberOfOnlineRegions());	assertEquals(regionsExcludeServer, cluster.getRegionServer(1).getNumberOfOnlineRegions());	
before after 

========================= hbase sample_1329 =========================

public void process() {	try {	String name = regionInfo.getRegionNameAsString();	
processing close of 

public void process() {	try {	String name = regionInfo.getRegionNameAsString();	String encodedRegionName = regionInfo.getEncodedName();	HRegion region = (HRegion)rsServices.getRegion(encodedRegionName);	if (region == null) {	
received close for region but currently not serving ignoring 

public void process() {	try {	String name = regionInfo.getRegionNameAsString();	String encodedRegionName = regionInfo.getEncodedName();	HRegion region = (HRegion)rsServices.getRegion(encodedRegionName);	if (region == null) {	return;	}	try {	if (region.close(abort) == null) {	
can t close region was already closed during close 

try {	if (region.close(abort) == null) {	return;	}	} catch (IOException ioe) {	server.abort("Unrecoverable exception while closing region " + regionInfo.getRegionNameAsString() + ", still finishing close", ioe);	throw new RuntimeException(ioe);	}	this.rsServices.removeRegion(region, destination);	rsServices.reportRegionStateTransition(new RegionStateTransitionContext(TransitionCode.CLOSED, HConstants.NO_SEQNUM, -1, regionInfo));	
closed 

========================= hbase sample_2505 =========================

public void testFullRestoreSingleEmpty() throws Exception {	
test full restore on a single table empty table 

public void testFullRestoreSingleEmpty() throws Exception {	String backupId = fullTableBackup(toList(table1.getNameAsString()));	
backup complete 

public void testFullRestoreMultipleEmpty() throws Exception {	
create full backup image on multiple tables 

========================= hbase sample_560 =========================

public void stop(String why) {	
stopping because 

========================= hbase sample_1954 =========================

try {	classLoader.loadClass(className);	fail("Should not be able to load class " + className);	} catch (ClassNotFoundException cnfe) {	}	try {	String folder = TEST_UTIL.getDataTestDir().toString();	ClassLoaderTestHelper.buildJar( folder, className, null, ClassLoaderTestHelper.localDirPath(conf));	classLoader.loadClass(className);	} catch (ClassNotFoundException cnfe) {	
should be able to load class 

try {	classLoader.loadClass(className);	fail("Should not be able to load class " + className);	} catch (ClassNotFoundException cnfe) {	}	try {	String folder = TEST_UTIL.getDataTestDir().toString();	ClassLoaderTestHelper.buildJar(folder, className, null);	classLoader.loadClass(className);	} catch (ClassNotFoundException cnfe) {	
should be able to load class 

========================= hbase sample_833 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3085 =========================

UTIL.waitUntilAllRegionsAssigned(tableName);	List<HRegionLocation> regions = r.getAllRegionLocations();	HRegionLocation firstGoodPair = null;	for (HRegionLocation e: regions) {	if (e.getServerName() != null) {	firstGoodPair = e;	break;	}	}	assertNotNull("Found a non-null entry", firstGoodPair);	
found 

boolean found = false;	for (ServerName info : servers) {	LOG.info("ServerName=" + info);	if (!serverNameForFirstRegion.equals(info.getServerName()) && !masterServerName.equals(info)) {	destName = info.toString();	found = true;	break;	}	}	assertTrue("Found server", found);	
found 

========================= hbase sample_1542 =========================

public CompactionRequestImpl selectCompaction(Collection<HStoreFile> candidateFiles, List<HStoreFile> filesCompacting, boolean isUserCompaction, boolean mayUseOffPeak, boolean forceMajor) throws IOException {	ArrayList<HStoreFile> candidateSelection = new ArrayList<>(candidateFiles);	int futureFiles = filesCompacting.isEmpty() ? 0 : 1;	boolean mayBeStuck = (candidateFiles.size() - filesCompacting.size() + futureFiles) >= storeConfigInfo.getBlockingFileCount();	candidateSelection = getCurrentEligibleFiles(candidateSelection, filesCompacting);	
selecting compaction from store files compacting eligible blocking 

protected ArrayList<HStoreFile> skipLargeFiles(ArrayList<HStoreFile> candidates, boolean mayUseOffpeak) {	int pos = 0;	while (pos < candidates.size() && !candidates.get(pos).isReference() && (candidates.get(pos).getReader().length() > comConf.getMaxCompactSize(mayUseOffpeak))) {	++pos;	}	if (pos > 0) {	
some files are too large excluding files from compaction candidates 

protected void removeExcessFiles(ArrayList<HStoreFile> candidates, boolean isUserCompaction, boolean isMajorCompaction) {	int excess = candidates.size() - comConf.getMaxFilesToCompact();	if (excess > 0) {	if (isMajorCompaction && isUserCompaction) {	
warning compacting more than files because of a user requested major compaction 

protected void removeExcessFiles(ArrayList<HStoreFile> candidates, boolean isUserCompaction, boolean isMajorCompaction) {	int excess = candidates.size() - comConf.getMaxFilesToCompact();	if (excess > 0) {	if (isMajorCompaction && isUserCompaction) {	} else {	
too many admissible files excluding files from compaction candidates 

protected ArrayList<HStoreFile> checkMinFilesCriteria(ArrayList<HStoreFile> candidates, int minFiles) {	if (candidates.size() < minFiles) {	if (LOG.isDebugEnabled()) {	
not compacting files because we only have files ready for compaction need to initiate 

========================= hbase sample_2694 =========================

public static void stopRs(final HBaseTestingUtility util, final ServerName serverName) throws Exception {	
stop region server 

public static void killRs(final HBaseTestingUtility util, final ServerName serverName) throws Exception {	
kill region server 

========================= hbase sample_1811 =========================

protected void tryStartNewShipper(String walGroupId, PriorityBlockingQueue<Path> queue) {	final RecoveredReplicationSourceShipper worker = new RecoveredReplicationSourceShipper(conf, walGroupId, queue, this, this.queueStorage);	ReplicationSourceShipper extant = workerThreads.putIfAbsent(walGroupId, worker);	if (extant != null) {	
someone has beat us to start a worker thread for wal group 

protected void tryStartNewShipper(String walGroupId, PriorityBlockingQueue<Path> queue) {	final RecoveredReplicationSourceShipper worker = new RecoveredReplicationSourceShipper(conf, walGroupId, queue, this, this.queueStorage);	ReplicationSourceShipper extant = workerThreads.putIfAbsent(walGroupId, worker);	if (extant != null) {	} else {	
starting up worker for wal group 

newPaths.add(path);	continue;	}	hasPathChanged = true;	if (server instanceof ReplicationSyncUp.DummyServer) {	Path newPath = getReplSyncUpPath(path);	newPaths.add(newPath);	continue;	} else {	List<ServerName> deadRegionServers = this.replicationQueueInfo.getDeadRegionServers();	
nb dead servers 

Path newPath = getReplSyncUpPath(path);	newPaths.add(newPath);	continue;	} else {	List<ServerName> deadRegionServers = this.replicationQueueInfo.getDeadRegionServers();	final Path walDir = FSUtils.getWALRootDir(conf);	for (ServerName curDeadServerName : deadRegionServers) {	final Path deadRsDirectory = new Path(walDir, AbstractFSWALProvider.getWALDirectoryName(curDeadServerName .getServerName()));	Path[] locs = new Path[] { new Path(deadRsDirectory, path.getName()), new Path( deadRsDirectory.suffix(AbstractFSWALProvider.SPLITTING_EXT), path.getName()) };	for (Path possibleLogLocation : locs) {	
possible location 

newPaths.add(newPath);	continue;	} else {	List<ServerName> deadRegionServers = this.replicationQueueInfo.getDeadRegionServers();	final Path walDir = FSUtils.getWALRootDir(conf);	for (ServerName curDeadServerName : deadRegionServers) {	final Path deadRsDirectory = new Path(walDir, AbstractFSWALProvider.getWALDirectoryName(curDeadServerName .getServerName()));	Path[] locs = new Path[] { new Path(deadRsDirectory, path.getName()), new Path( deadRsDirectory.suffix(AbstractFSWALProvider.SPLITTING_EXT), path.getName()) };	for (Path possibleLogLocation : locs) {	if (manager.getFs().exists(possibleLogLocation)) {	
log still exists at 

for (ServerName curDeadServerName : deadRegionServers) {	final Path deadRsDirectory = new Path(walDir, AbstractFSWALProvider.getWALDirectoryName(curDeadServerName .getServerName()));	Path[] locs = new Path[] { new Path(deadRsDirectory, path.getName()), new Path( deadRsDirectory.suffix(AbstractFSWALProvider.SPLITTING_EXT), path.getName()) };	for (Path possibleLogLocation : locs) {	if (manager.getFs().exists(possibleLogLocation)) {	newPaths.add(possibleLogLocation);	continue pathsLoop;	}	}	}	
wal path s doesn t exist and couldn t find its new location 

newPaths.add(possibleLogLocation);	continue pathsLoop;	}	}	}	newPaths.add(path);	}	}	if (hasPathChanged) {	if (newPaths.size() != queue.size()) {	
recovery queue size is incorrect 

private Path getReplSyncUpPath(Path path) throws IOException {	FileStatus[] rss = fs.listStatus(manager.getLogDir());	for (FileStatus rs : rss) {	Path p = rs.getPath();	FileStatus[] logs = fs.listStatus(p);	for (FileStatus log : logs) {	p = new Path(p, log.getPath().getName());	if (p.getName().equals(path.getName())) {	
log found at 

for (FileStatus rs : rss) {	Path p = rs.getPath();	FileStatus[] logs = fs.listStatus(p);	for (FileStatus log : logs) {	p = new Path(p, log.getPath().getName());	if (p.getName().equals(path.getName())) {	return p;	}	}	}	
didn t find path for 

Threads.sleep(100);	boolean allTasksDone = true;	for (ReplicationSourceShipper worker : workerThreads.values()) {	if (!worker.isFinished()) {	allTasksDone = false;	break;	}	}	if (allTasksDone) {	manager.removeRecoveredSource(this);	
finished recovering queue with the following stats 

========================= hbase sample_2944 =========================

}	Decryptor d = cipher.getDecryptor();	d.setKey(key);	d.setIv(iv);	try {	decrypt(out, in, outLen, d);	} catch (IOException e) {	String alternateAlgorithm = conf.get(HConstants.CRYPTO_ALTERNATE_KEY_ALGORITHM_CONF_KEY);	if (alternateAlgorithm != null) {	if (LOG.isDebugEnabled()) {	
unable to decrypt data with current cipher algorithm trying with the alternate cipher algorithm configured 

String providerParameters = conf.get(HConstants.CRYPTO_KEYPROVIDER_PARAMETERS_KEY, "");	try {	Pair<String,String> providerCacheKey = new Pair<>(providerClassName, providerParameters);	KeyProvider provider = keyProviderCache.get(providerCacheKey);	if (provider != null) {	return provider;	}	provider = (KeyProvider) ReflectionUtils.newInstance( getClassLoaderForClass(KeyProvider.class).loadClass(providerClassName), conf);	provider.init(providerParameters);	if (LOG.isDebugEnabled()) {	
installed into key provider cache 

========================= hbase sample_1041 =========================

public void testGetCurrent() throws Exception {	User user1 = User.getCurrent();	assertNotNull(user1.ugi);	
is 

========================= hbase sample_1411 =========================

public void cacheBlock(BlockCacheKey cacheKey, Cacheable buf, boolean inMemory) {	if (buf.heapSize() > maxBlockSize) {	if (stats.failInsert() % 50 == 0) {	
trying to cache too large a block is which is larger than 

msg += ". This is harmless and can happen in rare cases (see HBASE-8547)";	LOG.warn(msg);	return;	}	long currentSize = size.get();	long currentAcceptableSize = acceptableSize();	long hardLimitSize = (long) (hardCapacityLimitFactor * currentAcceptableSize);	if (currentSize >= hardLimitSize) {	stats.failInsert();	if (LOG.isTraceEnabled()) {	
lrublockcache current size has exceeded acceptable size the hard limit size is failed to put cachekey into lrublockcache 

public long free(long toFree) {	if (LOG.isTraceEnabled()) {	
freeing from 

}	LruCachedBlock cb;	long freedBytes = 0;	while ((cb = queue.pollLast()) != null) {	freedBytes += evictBlock(cb, true);	if (freedBytes >= toFree) {	return freedBytes;	}	}	if (LOG.isTraceEnabled()) {	
freed from 

public void run() {	enteringRun = true;	while (this.go) {	synchronized (this) {	try {	this.wait(1000 * 10/*Don't wait for ever*/);	} catch (InterruptedException e) {	
interrupted eviction thread 

public void shutdown() {	if (victimHandler != null) {	victimHandler.shutdown();	}	this.scheduleThreadPool.shutdown();	for (int i = 0; i < 10; i++) {	if (!this.scheduleThreadPool.isShutdown()) {	try {	Thread.sleep(10);	} catch (InterruptedException e) {	
interrupted while sleeping 

try {	Thread.sleep(10);	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	break;	}	}	}	if (!this.scheduleThreadPool.isShutdown()) {	List<Runnable> runnables = this.scheduleThreadPool.shutdownNow();	
still running 

========================= hbase sample_2397 =========================

fail("Waited too much time for truncate");	}	ResultScanner scanner = htable2.getScanner(scan);	Result[] res = scanner.next(rowCount);	scanner.close();	if (res.length != 0) {	if (res.length < lastCount) {	i--;	}	lastCount = res.length;	
still got rows 

private void verifyReplicationProceeded(byte[] rowkey) throws Exception {	Get get = new Get(rowkey);	for (int i = 0; i < NB_RETRIES; i++) {	if (i==NB_RETRIES-1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.size() == 0) {	
row not available 

private void verifyReplicationStuck(byte[] rowkey) throws Exception {	Get get = new Get(rowkey);	for (int i = 0; i < NB_RETRIES; i++) {	Result res = htable2.get(get);	if (res.size() >= 1) {	fail("Edit should have been stuck behind dropped tables");	} else {	
row not replicated let s wait a bit more 

========================= hbase sample_1942 =========================

protected void configureForRegion(final HRegion region) {	super.configureForRegion(region);	this.region = region;	Configuration conf = getConf();	maxBlockedRequests = conf.getFloat("hbase.busy.policy.blockedRequests", DEFAULT_MAX_BLOCKED_REQUESTS);	minAge = conf.getLong("hbase.busy.policy.minAge", DEFAULT_MIN_AGE_MS);	aggregationWindow = conf.getLong("hbase.busy.policy.aggWindow", DEFAULT_AGGREGATION_WINDOW);	if (maxBlockedRequests < 0.00001f || maxBlockedRequests > 0.99999f) {	
threshold for maximum blocked requests is set too low or too high resetting to default of 

super.configureForRegion(region);	this.region = region;	Configuration conf = getConf();	maxBlockedRequests = conf.getFloat("hbase.busy.policy.blockedRequests", DEFAULT_MAX_BLOCKED_REQUESTS);	minAge = conf.getLong("hbase.busy.policy.minAge", DEFAULT_MIN_AGE_MS);	aggregationWindow = conf.getLong("hbase.busy.policy.aggWindow", DEFAULT_AGGREGATION_WINDOW);	if (maxBlockedRequests < 0.00001f || maxBlockedRequests > 0.99999f) {	maxBlockedRequests = DEFAULT_MAX_BLOCKED_REQUESTS;	}	if (aggregationWindow <= 0) {	
aggregation window size is too low resetting it to default of 

if (EnvironmentEdgeManager.currentTime() <  startTime + minAge) {	return false;	}	for (HStore store: region.getStores()) {	if (!store.canSplit()) {	return false;	}	}	if (blockedReqRate >= maxBlockedRequests) {	if (LOG.isDebugEnabled()) {	
going to split region because it s too busy blocked request rate 

========================= hbase sample_2728 =========================

private static PBHelper createPBHelper() throws NoSuchMethodException {	Class<?> helperClass;	try {	helperClass = Class.forName("org.apache.hadoop.hdfs.protocolPB.PBHelperClient");	} catch (ClassNotFoundException e) {	
no pbhelperclient class found should be hadoop 

========================= hbase sample_2378 =========================

updateServerSideMetrics(scanMetrics, resp);	boolean isHeartbeatMessage = resp.hasHeartbeatMessage() && resp.getHeartbeatMessage();	Result[] rawResults;	Result[] results;	int numberOfCompleteRowsBefore = resultCache.numberOfCompleteRows();	try {	rawResults = ResponseConverter.getResults(controller.cellScanner(), resp);	updateResultsMetrics(scanMetrics, rawResults, isHeartbeatMessage);	results = resultCache.addAndGet( Optional.ofNullable(rawResults).orElse(ScanResultCache.EMPTY_RESULT_ARRAY), isHeartbeatMessage);	} catch (IOException e) {	
decode scan response failed 

========================= hbase sample_433 =========================

}	++optsInRatio;	if (isBetterSelection(bestSelection, bestSize, potentialMatchFiles, size, mightBeStuck)) {	bestSelection = potentialMatchFiles;	bestSize = size;	bestStart = start;	}	}	}	if (bestSelection.isEmpty() && mightBeStuck) {	
exploring compaction algorithm has selected files of size because the store might be stuck 

if (isBetterSelection(bestSelection, bestSize, potentialMatchFiles, size, mightBeStuck)) {	bestSelection = potentialMatchFiles;	bestSize = size;	bestStart = start;	}	}	}	if (bestSelection.isEmpty() && mightBeStuck) {	return new ArrayList<>(smallest);	}	
exploring compaction algorithm has selected files of size starting at candidate after considering permutations with in ratio 

========================= hbase sample_2682 =========================

public Object answer(InvocationOnMock invocation) throws Throwable {	
delayanswer firing firelatch 

public Object answer(InvocationOnMock invocation) throws Throwable {	fireCounter.getAndIncrement();	fireLatch.countDown();	try {	
delayanswer waiting on waitlatch 

public Object answer(InvocationOnMock invocation) throws Throwable {	fireCounter.getAndIncrement();	fireLatch.countDown();	try {	waitLatch.await();	
delayanswer delay complete 

public Object answer(InvocationOnMock invocation) throws Throwable {	try {	if (log != null) {	
call to on TRACE 

========================= hbase sample_1554 =========================

public void tearDown() throws Exception {	try {	TEST_UTIL.deleteTable(TEST_TABLE.getTableName());	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1387 =========================

List<RegionInfo> regionsOfTable = env.getAssignmentManager().getRegionStates().getRegionsOfTable(tableName, true);	if (regionReplicaCount > 1) {	int currentMaxReplica = 0;	for (RegionInfo regionInfo : regionsOfTable) {	if (regionInfo.getReplicaId() > currentMaxReplica) {	currentMaxReplica = regionInfo.getReplicaId();	}	}	int replicasFound = getNumberOfReplicasFromMeta(connection, regionReplicaCount, regionsOfTable);	assert regionReplicaCount - 1 == replicasFound;	
meta entries added for the given regionreplicacount for the table 

int currentMaxReplica = 0;	for (RegionInfo regionInfo : regionsOfTable) {	if (regionInfo.getReplicaId() > currentMaxReplica) {	currentMaxReplica = regionInfo.getReplicaId();	}	}	int replicasFound = getNumberOfReplicasFromMeta(connection, regionReplicaCount, regionsOfTable);	assert regionReplicaCount - 1 == replicasFound;	if (currentMaxReplica == (regionReplicaCount - 1)) {	if (LOG.isDebugEnabled()) {	
there is no change to the number of region replicas assigning the available regions current and previous replica count is 

if (regionInfo.getReplicaId() > currentMaxReplica) {	currentMaxReplica = regionInfo.getReplicaId();	}	}	int replicasFound = getNumberOfReplicasFromMeta(connection, regionReplicaCount, regionsOfTable);	assert regionReplicaCount - 1 == replicasFound;	if (currentMaxReplica == (regionReplicaCount - 1)) {	if (LOG.isDebugEnabled()) {	}	} else if (currentMaxReplica > (regionReplicaCount - 1)) {	
the number of replicas is more than the region replica count 

int replicasFound = getNumberOfReplicasFromMeta(connection, regionReplicaCount, regionsOfTable);	assert regionReplicaCount - 1 == replicasFound;	if (currentMaxReplica == (regionReplicaCount - 1)) {	if (LOG.isDebugEnabled()) {	}	} else if (currentMaxReplica > (regionReplicaCount - 1)) {	List<RegionInfo> copyOfRegions = new ArrayList<RegionInfo>(regionsOfTable);	for (RegionInfo regionInfo : copyOfRegions) {	if (regionInfo.getReplicaId() > (regionReplicaCount - 1)) {	env.getAssignmentManager().getRegionStates().deleteRegion(regionInfo);	
the regioninfo being removed is 

}	} else if (currentMaxReplica > (regionReplicaCount - 1)) {	List<RegionInfo> copyOfRegions = new ArrayList<RegionInfo>(regionsOfTable);	for (RegionInfo regionInfo : copyOfRegions) {	if (regionInfo.getReplicaId() > (regionReplicaCount - 1)) {	env.getAssignmentManager().getRegionStates().deleteRegion(regionInfo);	regionsOfTable.remove(regionInfo);	}	}	} else {	
the number of replicas has been changed increased lets assign the new region replicas the previous replica count was the current replica count is 

private boolean prepareEnable(final MasterProcedureEnv env) throws IOException {	boolean canTableBeEnabled = true;	if (!MetaTableAccessor.tableExists(env.getMasterServices().getConnection(), tableName)) {	setFailure("master-enable-table", new TableNotFoundException(tableName));	canTableBeEnabled = false;	} else if (!skipTableStateCheck) {	TableStateManager tsm = env.getMasterServices().getTableStateManager();	TableState.State state = tsm.getTableState(tableName);	if(!state.equals(TableState.State.DISABLED)){	
table isn t disabled is skipping enable 

protected static void setTableStateToEnabling( final MasterProcedureEnv env, final TableName tableName) throws IOException {	
attempting to enable the table 

protected static void setTableStateToEnabled( final MasterProcedureEnv env, final TableName tableName) throws IOException {	env.getMasterServices().getTableStateManager().setTableState( tableName, TableState.State.ENABLED);	
table was successfully enabled 

========================= hbase sample_2817 =========================

public void testRefresStoreFiles() throws Exception {	final int refreshPeriod = 2000;	HTU.getConfiguration().setInt("hbase.hstore.compactionThreshold", 100);	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, refreshPeriod);	restartRegionServer();	try {	
opening the secondary region 

public void testRefresStoreFiles() throws Exception {	final int refreshPeriod = 2000;	HTU.getConfiguration().setInt("hbase.hstore.compactionThreshold", 100);	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, refreshPeriod);	restartRegionServer();	try {	openRegion(HTU, getRS(), hriSecondary);	
loading data to primary region 

public void testRefresStoreFiles() throws Exception {	final int refreshPeriod = 2000;	HTU.getConfiguration().setInt("hbase.hstore.compactionThreshold", 100);	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, refreshPeriod);	restartRegionServer();	try {	openRegion(HTU, getRS(), hriSecondary);	HTU.loadNumericRows(table, f, 0, 1000);	Assert.assertEquals(1000, HTU.countRows(table));	
flushing primary region 

HTU.getConfiguration().setInt("hbase.hstore.compactionThreshold", 100);	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, refreshPeriod);	restartRegionServer();	try {	openRegion(HTU, getRS(), hriSecondary);	HTU.loadNumericRows(table, f, 0, 1000);	Assert.assertEquals(1000, HTU.countRows(table));	HRegion region = getRS().getRegionByEncodedName(hriPrimary.getEncodedName());	region.flush(true);	HRegion primaryRegion = region;	
sleeping for 

HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, refreshPeriod);	restartRegionServer();	try {	openRegion(HTU, getRS(), hriSecondary);	HTU.loadNumericRows(table, f, 0, 1000);	Assert.assertEquals(1000, HTU.countRows(table));	HRegion region = getRS().getRegionByEncodedName(hriPrimary.getEncodedName());	region.flush(true);	HRegion primaryRegion = region;	Threads.sleep(4 * refreshPeriod);	
checking results from secondary region replica 

};	Runnable reader = new Runnable() {	Random random = new Random();	public void run() {	try {	while (running.get()) {	if (random.nextInt(10) == 0) {	try {	closeRegion(HTU, getRS(), hriSecondary);	} catch (Exception ex) {	
failed closing the region 

while (running.get()) {	if (random.nextInt(10) == 0) {	try {	closeRegion(HTU, getRS(), hriSecondary);	} catch (Exception ex) {	exceptions[2].compareAndSet(null, ex);	}	try {	openRegion(HTU, getRS(), hriSecondary);	} catch (Exception ex) {	
failed opening the region 

try {	openRegion(HTU, getRS(), hriSecondary);	} catch (Exception ex) {	exceptions[2].compareAndSet(null, ex);	}	}	int key = random.nextInt(endKey - startKey) + startKey;	assertGetRpc(hriSecondary, key, true);	}	} catch (Exception ex) {	
failed getting the value in the region 

}	}	int key = random.nextInt(endKey - startKey) + startKey;	assertGetRpc(hriSecondary, key, true);	}	} catch (Exception ex) {	exceptions[2].compareAndSet(null, ex);	}	}	};	
starting writer and reader 

public void testVerifySecondaryAbilityToReadWithOnFiles() throws Exception {	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, 0);	restartRegionServer();	try {	
opening the secondary region 

public void testVerifySecondaryAbilityToReadWithOnFiles() throws Exception {	HTU.getConfiguration().setInt(StorefileRefresherChore.REGIONSERVER_STOREFILE_REFRESH_PERIOD, 0);	restartRegionServer();	try {	openRegion(HTU, getRS(), hriSecondary);	
loading data to primary region 

for (int i = 0; i < 3; ++i) {	HTU.loadNumericRows(table, f, i * 1000, (i + 1) * 1000);	HRegion region = getRS().getRegionByEncodedName(hriPrimary.getEncodedName());	region.flush(true);	}	HRegion primaryRegion = getRS().getRegion(hriPrimary.getEncodedName());	Assert.assertEquals(3, primaryRegion.getStore(f).getStorefilesCount());	Region secondaryRegion = getRS().getRegion(hriSecondary.getEncodedName());	secondaryRegion.getStore(f).refreshStoreFiles();	Assert.assertEquals(3, secondaryRegion.getStore(f).getStorefilesCount());	
force major compaction on primary region 

========================= hbase sample_1692 =========================

public static Class<? extends ThroughputController> getThroughputControllerClass( Configuration conf) {	String className = conf.get(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, DEFAULT_FLUSH_THROUGHPUT_CONTROLLER_CLASS.getName());	try {	return Class.forName(className).asSubclass(ThroughputController.class);	} catch (Exception e) {	
unable to load configured flush throughput controller load default throughput controller instead 

========================= hbase sample_2544 =========================

public void start() throws IOException {	if (!running.compareAndSet(false, true)) {	return;	}	
starting assignment manager 

public void stop() {	if (!running.compareAndSet(true, false)) {	return;	}	
stopping assignment manager 

public void assignMeta(final RegionInfo metaRegionInfo, final ServerName serverName) throws IOException {	assert isMetaRegion(metaRegionInfo) : "unexpected non-meta region " + metaRegionInfo;	AssignProcedure proc;	if (serverName != null) {	
try assigning meta to 

public void assignMeta(final RegionInfo metaRegionInfo, final ServerName serverName) throws IOException {	assert isMetaRegion(metaRegionInfo) : "unexpected non-meta region " + metaRegionInfo;	AssignProcedure proc;	if (serverName != null) {	proc = createAssignProcedure(metaRegionInfo, serverName);	} else {	
assigning 

public boolean waitForAssignment(final RegionInfo regionInfo, final long timeout) throws IOException {	RegionStateNode node = null;	long startTime = System.currentTimeMillis();	long endTime = startTime + 10000;	while ((node = regionStates.getRegionStateNode(regionInfo)) == null && isRunning() && System.currentTimeMillis() < endTime) {	
waiting on to be added to regionstatemap 

public AssignProcedure[] createRoundRobinAssignProcedures(final List<RegionInfo> hris) {	if (hris.isEmpty()) {	return null;	}	try {	Map<ServerName, List<RegionInfo>> assignments = getBalancer().roundRobinAssignment(hris, this.master.getServerManager().createDestinationServersList(null));	return createAssignProcedures(assignments, hris.size());	} catch (HBaseIOException hioe) {	
failed roundrobinassignment 

public MoveRegionProcedure createMoveRegionProcedure(final RegionPlan plan) {	if (plan.getRegionInfo().getTable().isSystemTable()) {	List<ServerName> exclude = getExcludedServersForSystemTable();	if (plan.getDestination() != null && exclude.contains(plan.getDestination())) {	try {	
can not move to because the server is not with highest version 

break;	case READY_TO_MERGE: case MERGED: case MERGE_REVERTED: assert transition.getRegionInfoCount() == 3 : transition;	final RegionInfo merged = ProtobufUtil.toRegionInfo(transition.getRegionInfo(0));	final RegionInfo mergeA = ProtobufUtil.toRegionInfo(transition.getRegionInfo(1));	final RegionInfo mergeB = ProtobufUtil.toRegionInfo(transition.getRegionInfo(2));	updateRegionMergeTransition(serverName, transition.getTransitionCode(), merged, mergeA, mergeB);	break;	}	}	} catch (PleaseHoldException e) {	
failed transition 

final RegionInfo merged = ProtobufUtil.toRegionInfo(transition.getRegionInfo(0));	final RegionInfo mergeA = ProtobufUtil.toRegionInfo(transition.getRegionInfo(1));	final RegionInfo mergeB = ProtobufUtil.toRegionInfo(transition.getRegionInfo(2));	updateRegionMergeTransition(serverName, transition.getTransitionCode(), merged, mergeA, mergeB);	break;	}	}	} catch (PleaseHoldException e) {	throw e;	} catch (UnsupportedOperationException|IOException e) {	
failed transition 

public void reportOnlineRegions(final ServerName serverName, final int versionNumber, final Set<byte[]> regionNames) throws YouAreDeadException {	if (!isRunning()) return;	if (LOG.isTraceEnabled()) {	LOG.trace("ReportOnlineRegions " + serverName + " regionCount=" + regionNames.size() + ", metaLoaded=" + isMetaLoaded() + " " + regionNames.stream().map(element -> Bytes.toStringBinary(element)). collect(Collectors.toList()));	}	final ServerStateNode serverNode = regionStates.getOrCreateServer(serverName);	synchronized (serverNode) {	serverNode.setVersionNumber(versionNumber);	if (serverNode.isInState(ServerState.SPLITTING, ServerState.OFFLINE)) {	
got a report from a server result in state 

LOG.trace("ReportOnlineRegions " + serverName + " regionCount=" + regionNames.size() + ", metaLoaded=" + isMetaLoaded() + " " + regionNames.stream().map(element -> Bytes.toStringBinary(element)). collect(Collectors.toList()));	}	final ServerStateNode serverNode = regionStates.getOrCreateServer(serverName);	synchronized (serverNode) {	serverNode.setVersionNumber(versionNumber);	if (serverNode.isInState(ServerState.SPLITTING, ServerState.OFFLINE)) {	return;	}	}	if (regionNames.isEmpty()) {	
no online region found on 

private void handleRegionOverStuckWarningThreshold(final RegionInfo regionInfo) {	final RegionStateNode regionNode = regionStates.getRegionStateNode(regionInfo);	
todo handle stuck in transition 

public void joinCluster() throws IOException {	final long startTime = System.currentTimeMillis();	
joining cluster loading hbase meta content 

private void stopAssignmentThread() {	assignQueueSignal();	try {	while (assignThread.isAlive()) {	assignQueueSignal();	assignThread.join(250);	}	} catch (InterruptedException e) {	
join interrupted 

assignQueueFullCond.await();	}	if (!isRunning()) return null;	assignQueueFullCond.await(assignDispatchWaitMillis, TimeUnit.MILLISECONDS);	regions = new HashMap<RegionInfo, RegionStateNode>(pendingAssignQueue.size());	for (RegionStateNode regionNode: pendingAssignQueue) {	regions.put(regionNode.getRegionInfo(), regionNode);	}	pendingAssignQueue.clear();	} catch (InterruptedException e) {	
got interrupted 

final List<RegionInfo> rrList = sysTable ? sysRRList : userRRList;	if (regionNode.getRegionLocation() != null) {	retainMap.put(regionNode.getRegionInfo(), regionNode.getRegionLocation());	} else {	rrList.add(regionNode.getRegionInfo());	}	}	List<ServerName> servers = master.getServerManager().createDestinationServersList();	for (int i = 0; servers.size() < 1; ++i) {	if (i % 4 == 0) {	
no server available unable to find a location for unassigned regions waiting 

retainMap.put(regionNode.getRegionInfo(), regionNode.getRegionLocation());	} else {	rrList.add(regionNode.getRegionInfo());	}	}	List<ServerName> servers = master.getServerManager().createDestinationServersList();	for (int i = 0; servers.size() < 1; ++i) {	if (i % 4 == 0) {	}	if (!isRunning()) {	
aborting assignment queue with not assigned 

if (!isRunning()) {	return;	}	Threads.sleep(250);	servers = master.getServerManager().createDestinationServersList();	}	if (!sysRRList.isEmpty()) {	final List<ServerName> excludeServers = getExcludedServersForSystemTable();	List<ServerName> serversForSysTables = servers.stream() .filter(s -> !excludeServers.contains(s)).collect(Collectors.toList());	if (serversForSysTables.isEmpty()) {	
no servers available for system table regions considering all servers 

LOG.trace("available servers count=" + servers.size() + ": " + servers);	}	final LoadBalancer balancer = getBalancer();	if (retainMap != null && !retainMap.isEmpty()) {	if (isTraceEnabled) {	LOG.trace("retain assign regions=" + retainMap);	}	try {	acceptPlan(regions, balancer.retainAssignment(retainMap, servers));	} catch (HBaseIOException e) {	
unable to retain assignment 

}	}	if (!rrList.isEmpty()) {	Collections.sort(rrList, RegionInfo.COMPARATOR);	if (isTraceEnabled) {	LOG.trace("round robin regions=" + rrList);	}	try {	acceptPlan(regions, balancer.roundRobinAssignment(rrList, servers));	} catch (HBaseIOException e) {	
unable to round robin assignment 

final ServerName server = entry.getKey();	for (RegionInfo hri: entry.getValue()) {	final RegionStateNode regionNode = regions.get(hri);	regionNode.setRegionLocation(server);	events[evcount++] = regionNode.getProcedureEvent();	}	}	ProcedureEvent.wakeEvents(getProcedureScheduler(), events);	final long et = System.currentTimeMillis();	if (LOG.isTraceEnabled()) {	
assign accept 

public void handleMetaRITOnCrashedServer(ServerName serverName) {	RegionInfo hri = RegionReplicaUtil .getRegionInfoForReplica(RegionInfoBuilder.FIRST_META_REGIONINFO, RegionInfo.DEFAULT_REPLICA_ID);	RegionState regionStateNode = getRegionStates().getRegionState(hri);	if (!regionStateNode.getServerName().equals(serverName)) {	return;	}	
meta assigned to crashed reassigning 

public void handleMetaRITOnCrashedServer(ServerName serverName) {	RegionInfo hri = RegionReplicaUtil .getRegionInfoForReplica(RegionInfoBuilder.FIRST_META_REGIONINFO, RegionInfo.DEFAULT_REPLICA_ID);	RegionState regionStateNode = getRegionStates().getRegionState(hri);	if (!regionStateNode.getServerName().equals(serverName)) {	return;	}	RegionTransitionProcedure rtp = getRegionStates().getRegionTransitionProcedure(hri);	if (rtp != null && rtp.isMeta() && rtp.getTransitionState() == RegionTransitionState.REGION_TRANSITION_DISPATCH) {	
failing 

========================= hbase sample_2790 =========================

Executor executor = executorService.getExecutor(ExecutorType.MASTER_SERVER_OPERATIONS);	ThreadPoolExecutor pool = executor.threadPoolExecutor;	assertEquals(0, pool.getPoolSize());	AtomicBoolean lock = new AtomicBoolean(true);	AtomicInteger counter = new AtomicInteger(0);	for (int i = 0; i < maxThreads; i++) {	executorService.submit( new TestEventHandler(mockedServer, EventType.M_SERVER_SHUTDOWN, lock, counter));	}	int tries = 0;	while (counter.get() < maxThreads && tries < maxTries) {	
waiting for all event handlers to start 

private void checkStatusDump(ExecutorStatus status) throws IOException {	StringWriter sw = new StringWriter();	status.dumpTo(sw, "");	String dump = sw.toString();	
got status dump 

========================= hbase sample_1915 =========================

public void testNoEnableAfterDisablePolicy() throws Exception {	Put p = new Put(Bytes.toBytes("to_reject"));	p.addColumn( Bytes.toBytes(SpaceQuotaHelperForTests.F1), Bytes.toBytes("to"), Bytes.toBytes("reject"));	final TableName tn = writeUntilViolation(SpaceViolationPolicy.DISABLE);	final Admin admin = TEST_UTIL.getAdmin();	for (int i = 0; i < NUM_RETRIES * 2; i++) {	if (admin.isTableEnabled(tn)) {	
is still enabled expecting it to be disabled will wait and re check 

Put p = new Put(Bytes.toBytes("to_reject"));	p.addColumn( Bytes.toBytes(SpaceQuotaHelperForTests.F1), Bytes.toBytes("to"), Bytes.toBytes("reject"));	TableName tableName = writeUntilViolationAndVerifyViolation(SpaceViolationPolicy.NO_WRITES, p);	ClientServiceCallable<Void> callable = generateFileToLoad(tableName, 1, 50);	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(TEST_UTIL.getConfiguration());	RpcRetryingCaller<Void> caller = factory.<Void> newCaller();	try {	caller.callWithRetries(callable, Integer.MAX_VALUE);	fail("Expected the bulk load call to fail!");	} catch (SpaceLimitingException e) {	
caught expected exception 

TEST_UTIL.getAdmin().setQuota(settings);	HRegionServer rs = TEST_UTIL.getMiniHBaseCluster().getRegionServer(0);	RegionServerSpaceQuotaManager spaceQuotaManager = rs.getRegionServerSpaceQuotaManager();	Map<TableName,SpaceQuotaSnapshot> snapshots = spaceQuotaManager.copyQuotaSnapshots();	Map<RegionInfo,Long> regionSizes = getReportedSizesForTable(tn);	while (true) {	SpaceQuotaSnapshot snapshot = snapshots.get(tn);	if (snapshot != null && snapshot.getLimit() > 0) {	break;	}	
snapshot does not yet realize quota limit regionsizes 

assertEquals(0L, snapshot.getUsage());	assertEquals(sizeLimit, snapshot.getLimit());	ActivePolicyEnforcement activePolicies = spaceQuotaManager.getActiveEnforcements();	SpaceViolationPolicyEnforcement enforcement = activePolicies.getPolicyEnforcement(tn);	assertTrue( "Expected to find Noop policy, but got " + enforcement.getClass().getSimpleName(), enforcement instanceof DefaultViolationPolicyEnforcement);	ClientServiceCallable<Void> callable = generateFileToLoad(tn, 2, 500);	FileSystem fs = TEST_UTIL.getTestFileSystem();	FileStatus[] files = fs.listStatus( new Path(fs.getHomeDirectory(), testName.getMethodName() + "_files"));	for (FileStatus file : files) {	assertTrue( "Expected the file, " + file.getPath() + ",  length to be larger than 25KB, but was " + file.getLen(), file.getLen() > 25 * SpaceQuotaHelperForTests.ONE_KILOBYTE);	
B 

FileStatus[] files = fs.listStatus( new Path(fs.getHomeDirectory(), testName.getMethodName() + "_files"));	for (FileStatus file : files) {	assertTrue( "Expected the file, " + file.getPath() + ",  length to be larger than 25KB, but was " + file.getLen(), file.getLen() > 25 * SpaceQuotaHelperForTests.ONE_KILOBYTE);	}	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(TEST_UTIL.getConfiguration());	RpcRetryingCaller<Void> caller = factory.<Void> newCaller();	try {	caller.callWithRetries(callable, Integer.MAX_VALUE);	fail("Expected the bulk load call to fail!");	} catch (SpaceLimitingException e) {	
caught expected exception 

table.put((Put) m);	} else if (m instanceof Delete) {	table.delete((Delete) m);	} else if (m instanceof Append) {	table.append((Append) m);	} else if (m instanceof Increment) {	table.increment((Increment) m);	} else {	fail( "Failed to apply " + m.getClass().getSimpleName() + " to the table. Programming error");	}	
did not reject the will sleep and retry 

} catch (Exception e) {	String msg = StringUtils.stringifyException(e);	assertTrue("Expected exception message to contain the word '" + policyToViolate.name() + "', but was " + msg, msg.contains(policyToViolate.name()));	sawError = true;	}	}	if (!sawError) {	try (Table quotaTable = TEST_UTIL.getConnection().getTable(QuotaUtil.QUOTA_TABLE_NAME)) {	ResultScanner scanner = quotaTable.getScanner(new Scan());	Result result = null;	
dumping contents of hbase quota table 

========================= hbase sample_1446 =========================

private void handleDeprecation(String key) {	String oldKey = "hbase." + key;	String newKey = KEY_PREFIX + key;	String oldValue = conf.get(oldKey);	if (oldValue != null) {	
warning using deprecated configuration key please use instead 

private void handleDeprecation(String key) {	String oldKey = "hbase." + key;	String newKey = KEY_PREFIX + key;	String oldValue = conf.get(oldKey);	if (oldValue != null) {	String newValue = conf.get(newKey);	if (newValue == null) {	conf.set(newKey, oldValue);	} else {	
conflicting values for and using 

========================= hbase sample_937 =========================

static void updateCachedLocation(HRegionLocation loc, Throwable exception, Function<HRegionLocation, HRegionLocation> cachedLocationSupplier, Consumer<HRegionLocation> addToCache, Consumer<HRegionLocation> removeFromCache) {	HRegionLocation oldLoc = cachedLocationSupplier.apply(loc);	if (LOG.isDebugEnabled()) {	
try updating the old value is 

static void updateCachedLocation(HRegionLocation loc, Throwable exception, Function<HRegionLocation, HRegionLocation> cachedLocationSupplier, Consumer<HRegionLocation> addToCache, Consumer<HRegionLocation> removeFromCache) {	HRegionLocation oldLoc = cachedLocationSupplier.apply(loc);	if (LOG.isDebugEnabled()) {	}	if (!canUpdate(loc, oldLoc)) {	return;	}	Throwable cause = findException(exception);	if (LOG.isDebugEnabled()) {	
the actual exception when updating 

if (LOG.isDebugEnabled()) {	}	if (!canUpdate(loc, oldLoc)) {	return;	}	Throwable cause = findException(exception);	if (LOG.isDebugEnabled()) {	}	if (cause == null || !isMetaClearingException(cause)) {	if (LOG.isDebugEnabled()) {	
will not update because the exception is null or not the one we care about 

}	if (cause == null || !isMetaClearingException(cause)) {	if (LOG.isDebugEnabled()) {	}	return;	}	if (cause instanceof RegionMovedException) {	RegionMovedException rme = (RegionMovedException) cause;	HRegionLocation newLoc = new HRegionLocation(loc.getRegionInfo(), rme.getServerName(), rme.getLocationSeqNum());	if (LOG.isDebugEnabled()) {	
try updating with the new location constructed by 

return;	}	if (cause instanceof RegionMovedException) {	RegionMovedException rme = (RegionMovedException) cause;	HRegionLocation newLoc = new HRegionLocation(loc.getRegionInfo(), rme.getServerName(), rme.getLocationSeqNum());	if (LOG.isDebugEnabled()) {	}	addToCache.accept(newLoc);	} else {	if (LOG.isDebugEnabled()) {	
try removing from cache 

========================= hbase sample_464 =========================

private void killRandomServerAndVerifyAssignment() throws IOException, InterruptedException, KeeperException {	ServerName serverToKill = null;	int killIndex = 0;	Random random = new Random(System.currentTimeMillis());	ServerName metaServer = TEST_UTIL.getHBaseCluster().getServerHoldingMeta();	
server holding meta 

serverToKill = TEST_UTIL.getHBaseCluster().getRegionServer(killIndex).getServerName();	Collection<HRegion> regs = TEST_UTIL.getHBaseCluster().getRegionServer(killIndex).getOnlineRegionsLocalContext();	isNamespaceServer = false;	for (HRegion r : regs) {	if (r.getRegionInfo().getTable().getNamespaceAsString() .equals(NamespaceDescriptor.SYSTEM_NAMESPACE_NAME_STR)) {	isNamespaceServer = true;	break;	}	}	} while (ServerName.isSameAddress(metaServer, serverToKill) || isNamespaceServer || TEST_UTIL.getHBaseCluster().getRegionServer(killIndex).getNumberOfOnlineRegions() == 0);	
stopping rs 

isNamespaceServer = true;	break;	}	}	} while (ServerName.isSameAddress(metaServer, serverToKill) || isNamespaceServer || TEST_UTIL.getHBaseCluster().getRegionServer(killIndex).getNumberOfOnlineRegions() == 0);	Map<RegionInfo, Pair<ServerName, ServerName>> regionsToVerify = new HashMap<>();	for (Map.Entry<RegionInfo, ServerName[]> entry : favoredNodesAssignmentPlan.entrySet()) {	ServerName s = entry.getValue()[0];	if (ServerName.isSameAddress(s, serverToKill)) {	regionsToVerify.put(entry.getKey(), new Pair<>(entry.getValue()[1], entry.getValue()[2]));	
adding with sedcondary tertiary 

ServerName s = entry.getValue()[0];	if (ServerName.isSameAddress(s, serverToKill)) {	regionsToVerify.put(entry.getKey(), new Pair<>(entry.getValue()[1], entry.getValue()[2]));	}	}	int orig = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getNumRegionsOpened();	TEST_UTIL.getHBaseCluster().stopRegionServer(serverToKill);	TEST_UTIL.getHBaseCluster().waitForRegionServerToStop(serverToKill, 60000);	int curr = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getNumRegionsOpened();	while (curr - orig < regionsToVerify.size()) {	
waiting for to come online current regions original regions 

TEST_UTIL.getHBaseCluster().stopRegionServer(serverToKill);	TEST_UTIL.getHBaseCluster().waitForRegionServerToStop(serverToKill, 60000);	int curr = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getNumRegionsOpened();	while (curr - orig < regionsToVerify.size()) {	Thread.sleep(200);	curr = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getNumRegionsOpened();	}	for (Map.Entry<RegionInfo, Pair<ServerName, ServerName>> entry : regionsToVerify.entrySet()) {	ServerName newDestination = TEST_UTIL.getHBaseCluster().getMaster() .getAssignmentManager().getRegionStates().getRegionServerOfRegion(entry.getKey());	Pair<ServerName, ServerName> secondaryTertiaryServers = entry.getValue();	
new destination for region secondary tertiary are 

HMaster m = cluster.getMaster();	int lastRegionOpenedCount = m.getAssignmentManager().getNumRegionsOpened();	m.balance();	int retry = 10;	long sleep = 3000;	int attempt = 0;	int currentRegionOpened, regionMovement;	do {	currentRegionOpened = m.getAssignmentManager().getNumRegionsOpened();	regionMovement= currentRegionOpened - lastRegionOpenedCount;	
there are regions moved after attempts 

private int getNumRegionisOnPrimaryRS() throws IOException {	final AtomicInteger regionOnPrimaryNum = new AtomicInteger(0);	final AtomicInteger totalRegionNum = new AtomicInteger(0);	
the start of region placement verification 

String placement = "[NOT FAVORED NODE]";	for (int i = 0; i < favoredServerList.length; i++) {	if (favoredServerList[i].equals(serverName)) {	placement = positions[i].toString();	if (i == Position.PRIMARY.ordinal()) {	regionOnPrimaryNum.incrementAndGet();	}	break;	}	}	
on 

for (int i = 0; i < favoredServerList.length; i++) {	if (favoredServerList[i].equals(serverName)) {	placement = positions[i].toString();	if (i == Position.PRIMARY.ordinal()) {	regionOnPrimaryNum.incrementAndGet();	}	break;	}	}	} else {	
running on but there is no favored region server 

placement = positions[i].toString();	if (i == Position.PRIMARY.ordinal()) {	regionOnPrimaryNum.incrementAndGet();	}	break;	}	}	} else {	}	} else {	
not assigned to any server 

}	}	return true;	} catch (RuntimeException e) {	LOG.error("Result=" + result);	throw e;	}	}	};	MetaTableAccessor.fullScanRegions(CONNECTION, visitor);	
there are out of regions running on the primary region servers 

========================= hbase sample_1850 =========================

assert !gotOriginalRow;	gotOriginalRow = true;	} else {	refCount++;	}	}	refsChecked.increment(refCount);	if (!gotOriginalRow) {	String parsedRow = makeRowReadable(referredRow.getBytes(), referredRow.getLength());	String binRow = Bytes.toStringBinary(referredRow.getBytes(), 0, referredRow.getLength());	
reference error row 

protected Job doLoad(Configuration conf, HTableDescriptor htd) throws Exception {	Path outputDir = getTestDir(TEST_NAME, "load-output");	
load output dir 

protected void doVerify(Configuration conf, HTableDescriptor htd) throws Exception {	Path outputDir = getTestDir(TEST_NAME, "verify-output");	
verify output dir 

try (InputStream in = fs.open(keyFileStatus.getPath());	BufferedReader reader = new BufferedReader(new InputStreamReader(in))) {	String line;	while ((line = reader.readLine()) != null) {	if (line.isEmpty()) continue;	String[] parts = line.split("\\s+");	if (parts.length >= 1) {	String key = parts[0];	result.add(Bytes.toBytesBinary(key));	} else {	
cannot parse key from 

private int doSearch(Configuration conf, String keysDir) throws Exception {	Path inputDir = new Path(keysDir);	getConf().set(SEARCHER_INPUTDIR_KEY, inputDir.toString());	SortedSet<byte []> keys = readKeysToSearch(getConf());	if (keys.isEmpty()) throw new RuntimeException("No keys to find");	
count of keys to find 

private int doSearch(Configuration conf, String keysDir) throws Exception {	Path inputDir = new Path(keysDir);	getConf().set(SEARCHER_INPUTDIR_KEY, inputDir.toString());	SortedSet<byte []> keys = readKeysToSearch(getConf());	if (keys.isEmpty()) throw new RuntimeException("No keys to find");	
key 

========================= hbase sample_3247 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	if (ThreadLocalRandom.current().nextDouble() < (((double) splits) / ((double) maxFullTableSplits)) / ((double) 2)) {	splits++;	
performing action split all regions of 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	if (context.isStopping()) {	return;	}	if (ThreadLocalRandom.current().nextDouble() < (((double) splits) / ((double) maxFullTableSplits)) / ((double) 2)) {	splits++;	admin.split(tableName);	} else {	
skipping split of all regions 

========================= hbase sample_3302 =========================

protected void chore() {	try {	master.balance();	} catch (IOException e) {	
failed to balance 

========================= hbase sample_2840 =========================

public void announce() {	
running 

public void testImport94Table() throws Throwable {	final String name = "exportedTableIn94Format";	URL url = TestImportExport.class.getResource(name);	File f = new File(url.toURI());	if (!f.exists()) {	
failed to find skipping out on test 

========================= hbase sample_3403 =========================

public static boolean testCompression(String codec) {	codec = codec.toLowerCase(Locale.ROOT);	Compression.Algorithm a;	try {	a = Compression.getCompressionAlgorithmByName(codec);	} catch (IllegalArgumentException e) {	
codec type is not known 

Compression.Algorithm a;	try {	a = Compression.getCompressionAlgorithmByName(codec);	} catch (IllegalArgumentException e) {	return false;	}	try {	testCompression(a);	return true;	} catch (IOException ignored) {	
can t instantiate codec 

========================= hbase sample_2212 =========================

public void testBackupHistory() throws Exception {	
test backup history on a single table with data 

public void testBackupHistory() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	
backup complete 

return true;	}	};	history = BackupUtils.getHistory(conf1, 10, new Path(BACKUP_ROOT_DIR), nullFilter);	assertTrue(findBackup(history, backupId));	ByteArrayOutputStream baos = new ByteArrayOutputStream();	System.setOut(new PrintStream(baos));	String[] args = new String[] { "history", "-n", "10", "-p", BACKUP_ROOT_DIR };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	
show history 

String[] args = new String[] { "history", "-n", "10", "-p", BACKUP_ROOT_DIR };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	String output = baos.toString();	LOG.info(output);	baos.close();	assertTrue(output.indexOf(backupId) > 0);	tableList = Lists.newArrayList(table2);	String backupId2 = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId2));	
backup complete 

for (BackupInfo info : history) {	if (!info.getTableNames().contains(table1)) {	success = false;	break;	}	}	assertTrue(success);	args = new String[] { "history", "-n", "10", "-p", BACKUP_ROOT_DIR, "-t", "table1", "-s", "backup" };	ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	
show history 

========================= hbase sample_559 =========================

public void testRestoreSnapshotToDifferentTable() throws Exception {	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	final TableName restoredTableName = TableName.valueOf(name.getMethodName());	final HTableDescriptor newHTD = createHTableDescriptor(restoredTableName, CF1, CF2);	long procId = ProcedureTestingUtility.submitAndWait( procExec, new RestoreSnapshotProcedure(procExec.getEnvironment(), newHTD, snapshot));	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
restore snapshot failed with exception 

public void testRestoreSnapshotToEnabledTable() throws Exception {	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	try {	UTIL.getAdmin().enableTable(snapshotTableName);	long procId = ProcedureTestingUtility.submitAndWait( procExec, new RestoreSnapshotProcedure(procExec.getEnvironment(), snapshotHTD, snapshot));	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
restore snapshot failed with exception 

========================= hbase sample_1828 =========================

int onDiskDataSize = 0;	if (startOffset >= 0) {	onDiskDataSize = out.size() - startOffset;	}	out.writeInt(rowsOffsetBAOS.size() / 4);	if (rowsOffsetBAOS.size() > 0) {	out.write(rowsOffsetBAOS.getBuffer(), 0, rowsOffsetBAOS.size());	}	out.writeInt(onDiskDataSize);	if (LOG.isTraceEnabled()) {	
rownumber ondiskdatasize totalondisksize 

========================= hbase sample_1081 =========================

public ServerNonceManager(Configuration conf) {	deleteNonceGracePeriod = conf.getInt(HASH_NONCE_GRACE_PERIOD_KEY, 30 * 60 * 1000);	if (deleteNonceGracePeriod < 60 * 1000) {	
nonce grace period is less than a minute might be too small to be useful 

public boolean startOperation(long group, long nonce, Stoppable stoppable) throws InterruptedException {	if (nonce == HConstants.NO_NONCE) return true;	NonceKey nk = new NonceKey(group, nonce);	OperationContext ctx = new OperationContext();	while (true) {	OperationContext oldResult = nonces.putIfAbsent(nk, ctx);	if (oldResult == null) return true;	synchronized (oldResult) {	int oldState = oldResult.getState();	
conflict detected by nonce 

synchronized (newResult) {	assert newResult.getState() == OperationContext.WAIT;	newResult.setState(success ? OperationContext.DONT_PROCEED : OperationContext.PROCEED);	if (success) {	newResult.reportActivity();	} else {	OperationContext val = nonces.remove(nk);	assert val == newResult;	}	if (newResult.hasWait()) {	
conflict with running op ended 

public void reportOperationFromWal(long group, long nonce, long writeTime) {	if (nonce == HConstants.NO_NONCE) return;	long now = EnvironmentEdgeManager.currentTime();	if (now > writeTime + (deleteNonceGracePeriod * 1.5)) return;	OperationContext newResult = new OperationContext();	newResult.setState(OperationContext.DONT_PROCEED);	NonceKey nk = new NonceKey(group, nonce);	OperationContext oldResult = nonces.putIfAbsent(nk, newResult);	if (oldResult != null) {	
nonce collision during wal recovery with 

========================= hbase sample_2584 =========================

LOG.debug("TARGET row: " + (targetRow == null ? "null" : Bytes.toInt(targetRow.getRow())) + " cells:" + targetRow);	if (sourceRow == null) {	Assert.fail("Expected " + expectedRows + " source rows but only found " + i);	}	if (targetRow == null) {	Assert.fail("Expected " + expectedRows + " target rows but only found " + i);	}	Cell[] sourceCells = sourceRow.rawCells();	Cell[] targetCells = targetRow.rawCells();	if (sourceCells.length != targetCells.length) {	
source cells 

LOG.debug("TARGET row: " + (targetRow == null ? "null" : Bytes.toInt(targetRow.getRow())) + " cells:" + targetRow);	if (sourceRow == null) {	Assert.fail("Expected " + expectedRows + " source rows but only found " + i);	}	if (targetRow == null) {	Assert.fail("Expected " + expectedRows + " target rows but only found " + i);	}	Cell[] sourceCells = sourceRow.rawCells();	Cell[] targetCells = targetRow.rawCells();	if (sourceCells.length != targetCells.length) {	
target cells 

if (!CellUtil.matchingQualifier(sourceCell, targetCell)) {	Assert.fail("Qualifiers don't match");	}	if (!CellUtil.matchingTimestamp(sourceCell, targetCell)) {	Assert.fail("Timestamps don't match");	}	if (!CellUtil.matchingValue(sourceCell, targetCell)) {	Assert.fail("Values don't match");	}	} catch (Throwable t) {	
source cell target cell 

private Counters syncTables(TableName sourceTableName, TableName targetTableName, Path testDir) throws Exception {	SyncTable syncTable = new SyncTable(TEST_UTIL.getConfiguration());	int code = syncTable.run(new String[] {	testDir.toString(), sourceTableName.getNameAsString(), targetTableName.getNameAsString() });	assertEquals("sync table job failed", 0, code);	
sync tables completed 

HashTable hashTable = new HashTable(TEST_UTIL.getConfiguration());	int code = hashTable.run(new String[] {	"--batchsize=" + batchSize, "--numhashfiles=" + numHashFiles, "--scanbatch=" + scanBatch, sourceTableName.getNameAsString(), testDir.toString()});	assertEquals("hash table job failed", 0, code);	FileSystem fs = TEST_UTIL.getTestFileSystem();	HashTable.TableHash tableHash = HashTable.TableHash.read(fs.getConf(), testDir);	assertEquals(sourceTableName.getNameAsString(), tableHash.tableName);	assertEquals(batchSize, tableHash.batchSize);	assertEquals(numHashFiles, tableHash.numHashFiles);	assertEquals(numHashFiles - 1, tableHash.partitions.size());	
hash table completed 

========================= hbase sample_3395 =========================

public void testWALComparator() throws Exception {	AbstractFSWAL<?> wal1 = null;	AbstractFSWAL<?> walMeta = null;	try {	wal1 = newWAL(FS, CommonFSUtils.getWALRootDir(CONF), DIR.toString(), HConstants.HREGION_OLDLOGDIR_NAME, CONF, null, true, null, null);	
log obtained is 

public void testFindMemStoresEligibleForFlush() throws Exception {	
testFindMemStoresEligibleForFlush 

final int countPerFamily = 10;	final AtomicBoolean goslow = new AtomicBoolean(false);	NavigableMap<byte[], Integer> scopes = new TreeMap<>(Bytes.BYTES_COMPARATOR);	for (byte[] fam : htd.getFamiliesKeys()) {	scopes.put(fam, 0);	}	AbstractFSWAL<?> wal = newSlowWAL(FS, CommonFSUtils.getWALRootDir(CONF), DIR.toString(), testName, CONF, null, true, null, null, new Runnable() {	public void run() {	if (goslow.get()) {	Threads.sleep(100);	
sleeping before appending 

========================= hbase sample_1652 =========================

try {	if (fStat.isDirectory()) return true;	Path file = fStat.getPath();	FileStatus[] deleteStatus = FSUtils.listStatus(this.fs, file, null);	if (deleteStatus == null) return true;	Path family = file.getParent();	Path region = family.getParent();	Path table = region.getParent();	String tableName = table.getName();	boolean ret = !archiveTracker.keepHFiles(tableName);	
archiver says to delete keep files for table 

Path file = fStat.getPath();	FileStatus[] deleteStatus = FSUtils.listStatus(this.fs, file, null);	if (deleteStatus == null) return true;	Path family = file.getParent();	Path region = family.getParent();	Path table = region.getParent();	String tableName = table.getName();	boolean ret = !archiveTracker.keepHFiles(tableName);	return ret;	} catch (IOException e) {	
failed to lookup status of keeping it just incase 

public void setConf(Configuration config) {	Configuration conf = new Configuration(config);	super.setConf(conf);	try {	this.fs = FileSystem.get(conf);	this.archiveTracker = TableHFileArchiveTracker.create(conf);	this.archiveTracker.start();	} catch (KeeperException e) {	
error while configuring 

public void setConf(Configuration config) {	Configuration conf = new Configuration(config);	super.setConf(conf);	try {	this.fs = FileSystem.get(conf);	this.archiveTracker = TableHFileArchiveTracker.create(conf);	this.archiveTracker.start();	} catch (KeeperException e) {	} catch (IOException e) {	
error while configuring 

public void stop(String reason) {	if (this.isStopped()) return;	super.stop(reason);	if (this.archiveTracker != null) {	
stopping 

========================= hbase sample_2992 =========================

public void testCompactionConfigurationOnlineChange() throws IOException {	String strPrefix = "hbase.hstore.compaction.";	Store s = r1.getStore(COLUMN_FAMILY1);	if (!(s instanceof HStore)) {	
can t test the compaction configuration of hstore class got a different implementation other than hstore 

========================= hbase sample_1717 =========================

c2.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);	c2.setInt(RpcClient.IDLE_TIME, idleTime);	Connection connection = ConnectionFactory.createConnection(c2);	final Table table = connection.getTable(tableName);	Put put = new Put(ROW);	put.addColumn(FAM_NAM, ROW, ROW);	table.put(put);	ManualEnvironmentEdge mee = new ManualEnvironmentEdge();	mee.setValue(System.currentTimeMillis());	EnvironmentEdgeManager.injectEdge(mee);	
first get 

c2.setInt(RpcClient.IDLE_TIME, idleTime);	Connection connection = ConnectionFactory.createConnection(c2);	final Table table = connection.getTable(tableName);	Put put = new Put(ROW);	put.addColumn(FAM_NAM, ROW, ROW);	table.put(put);	ManualEnvironmentEdge mee = new ManualEnvironmentEdge();	mee.setValue(System.currentTimeMillis());	EnvironmentEdgeManager.injectEdge(mee);	table.get(new Get(ROW));	
first get changing the time sleeping 

final Table table = connection.getTable(tableName);	Put put = new Put(ROW);	put.addColumn(FAM_NAM, ROW, ROW);	table.put(put);	ManualEnvironmentEdge mee = new ManualEnvironmentEdge();	mee.setValue(System.currentTimeMillis());	EnvironmentEdgeManager.injectEdge(mee);	table.get(new Get(ROW));	mee.incValue(idleTime + 1000);	Thread.sleep(1500);	
second get connection has been marked idle in the middle 

put.addColumn(FAM_NAM, ROW, ROW);	table.put(put);	ManualEnvironmentEdge mee = new ManualEnvironmentEdge();	mee.setValue(System.currentTimeMillis());	EnvironmentEdgeManager.injectEdge(mee);	table.get(new Get(ROW));	mee.incValue(idleTime + 1000);	Thread.sleep(1500);	table.get(new Get(ROW));	mee.incValue(idleTime + 1000);	
third get connection is idle but the reader doesn t know yet 

table.put(put);	ManualEnvironmentEdge mee = new ManualEnvironmentEdge();	mee.setValue(System.currentTimeMillis());	EnvironmentEdgeManager.injectEdge(mee);	table.get(new Get(ROW));	mee.incValue(idleTime + 1000);	Thread.sleep(1500);	table.get(new Get(ROW));	mee.incValue(idleTime + 1000);	table.get(new Get(ROW));	
we re done time will change back 

}	}	hci.clusterStatusListener.deadServerHandler.newDead(loc.getServerName());	}	};	t.start();	try {	table.get(get);	Assert.fail();	} catch (IOException expected) {	
received 

TEST_UTIL.getAdmin().move( toMove.getRegionInfo().getEncodedNameAsBytes(), destServerName.getServerName().getBytes() );	while (destServer.getOnlineRegion(regionName) == null || destServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes) || curServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes) || master.getAssignmentManager().hasRegionsInTransition()) {	Thread.sleep(1);	}	LOG.info("Move finished for region="+toMove.getRegionInfo().getRegionNameAsString());	Assert.assertNull(curServer.getOnlineRegion(regionName));	Assert.assertNotNull(destServer.getOnlineRegion(regionName));	Assert.assertFalse(destServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes));	Assert.assertFalse(curServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes));	Assert.assertFalse( conn.getCachedLocation(TABLE_NAME, ROW).getRegionLocation() .getPort() == destServerName.getPort());	
put starting 

Assert.assertNotNull(destServer.getOnlineRegion(regionName));	Assert.assertFalse(destServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes));	Assert.assertFalse(curServer.getRegionsInTransitionInRS().containsKey(encodedRegionNameBytes));	Assert.assertFalse( conn.getCachedLocation(TABLE_NAME, ROW).getRegionLocation() .getPort() == destServerName.getPort());	Put put3 = new Put(ROW);	put3.addColumn(FAM_NAM, ROW, ROW);	try {	table.put(put3);	Assert.fail("Unreachable point");	} catch (RetriesExhaustedWithDetailsException e) {	
put done exception caught 

table.put(put3);	Assert.fail("Unreachable point");	} catch (RetriesExhaustedWithDetailsException e) {	Assert.assertEquals(1, e.getNumExceptions());	Assert.assertEquals(1, e.getCauses().size());	Assert.assertArrayEquals(e.getRow(0).getRow(), ROW);	Throwable cause = ClientExceptionsUtil.findException(e.getCause(0));	Assert.assertNotNull(cause);	Assert.assertTrue(cause instanceof RegionMovedException);	} catch (RetriesExhaustedException ree) {	
put done exception caught 

Scan sc = new Scan();	sc.setStopRow(ROW);	sc.setStartRow(ROW);	TEST_UTIL.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 1);	try {	ResultScanner rs = table.getScanner(sc);	while (rs.next() != null) {	}	Assert.fail("Unreachable point");	} catch (RetriesExhaustedException e) {	
scan done expected exception caught 

========================= hbase sample_2091 =========================

public MemStoreSnapshot snapshot() {	if (!this.snapshot.isEmpty()) {	
snapshot called again without clearing previous doing nothing another ongoing flush or did we fail last attempt 

memstore1.add(new KeyValue(Bytes.toBytes(i), fam, qf, i, empty), memstoreSizing);	}	LOG.info("memstore1 estimated size (2nd loading of same data)=" + (memstoreSizing.getDataSize() + memstoreSizing.getHeapSize()));	DefaultMemStore memstore2 = new DefaultMemStore();	memstoreSizing = new MemStoreSizing();	for (int i = 0; i < count; i++) {	memstore2.add(new KeyValue(Bytes.toBytes(i), fam, qf, i, new byte[i]), memstoreSizing);	}	LOG.info("memstore2 estimated size=" + (memstoreSizing.getDataSize() + memstoreSizing.getHeapSize()));	final int seconds = 30;	
waiting seconds while heap dump is taken 

memstore1.add(new KeyValue(Bytes.toBytes(i), fam, qf, i, empty), memstoreSizing);	}	LOG.info("memstore1 estimated size (2nd loading of same data)=" + (memstoreSizing.getDataSize() + memstoreSizing.getHeapSize()));	DefaultMemStore memstore2 = new DefaultMemStore();	memstoreSizing = new MemStoreSizing();	for (int i = 0; i < count; i++) {	memstore2.add(new KeyValue(Bytes.toBytes(i), fam, qf, i, new byte[i]), memstoreSizing);	}	LOG.info("memstore2 estimated size=" + (memstoreSizing.getDataSize() + memstoreSizing.getHeapSize()));	final int seconds = 30;	
exiting 

========================= hbase sample_2615 =========================

public void close() {	synchronized (connectionsLock) {	if (connections != null) {	for (Connection conn : connections) {	if (conn != null) {	try {	conn.close();	} catch (IOException e) {	
got exception in closing connection 

========================= hbase sample_2245 =========================

mobStore.commitFile(mobFileWriter.getPath(), targetPath);	mobStore.updateMobFlushCount();	mobStore.updateMobFlushedCellsCount(mobCount);	mobStore.updateMobFlushedCellsSize(mobSize);	} else {	try {	status.setStatus("Flushing mob file " + store + ": no mob cells, closing flushed file");	mobFileWriter.close();	store.getFileSystem().delete(mobFileWriter.getPath(), true);	} catch (IOException e) {	
failed to delete the temp mob file 

========================= hbase sample_3004 =========================

protected void rollback(final TestProcEnv env) {	
rollback 

protected LockState acquireLock(final TestProcEnv env) {	if ((hasLock = lock.compareAndSet(false, true))) {	
acquire lock 

protected void releaseLock(final TestProcEnv env) {	
release lock 

========================= hbase sample_1193 =========================

for (String subDir : protectedSubLogDirs) {	checkSubDir(new Path(this.walRootDir, subDir), perms);	}	checkStagingDir();	if (isSecurityEnabled) {	fs.setPermission(new Path(rootdir, HConstants.VERSION_FILE_NAME), secureRootFilePerms);	fs.setPermission(new Path(rootdir, HConstants.CLUSTER_ID_FILE_NAME), secureRootFilePerms);	}	FsPermission currentRootPerms = fs.getFileStatus(this.rootdir).getPermission();	if (!currentRootPerms.getUserAction().implies(FsAction.EXECUTE) || !currentRootPerms.getGroupAction().implies(FsAction.EXECUTE) || !currentRootPerms.getOtherAction().implies(FsAction.EXECUTE)) {	
rootdir permissions do not contain excute for user group or other automatically adding excute permission for all 

if (!fs.exists(rd)) {	fs.mkdirs(rd);	FSUtils.setVersion(fs, rd, c.getInt(HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000), c.getInt(HConstants.VERSION_FILE_WRITE_ATTEMPTS, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS));	} else {	if (!fs.isDirectory(rd)) {	throw new IllegalArgumentException(rd.toString() + " is not a directory");	}	FSUtils.checkVersion(fs, rd, true, c.getInt(HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000), c.getInt(HConstants.VERSION_FILE_WRITE_ATTEMPTS, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS));	}	} catch (DeserializationException de) {	
please fix invalid configuration for 

if (!fs.isDirectory(rd)) {	throw new IllegalArgumentException(rd.toString() + " is not a directory");	}	FSUtils.checkVersion(fs, rd, true, c.getInt(HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000), c.getInt(HConstants.VERSION_FILE_WRITE_ATTEMPTS, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS));	}	} catch (DeserializationException de) {	IOException ioe = new IOException();	ioe.initCause(de);	throw ioe;	} catch (IllegalArgumentException iae) {	
please fix invalid configuration for 

Path p = new Path(this.rootdir, HConstants.BULKLOAD_STAGING_DIR_NAME);	try {	if (!this.fs.exists(p)) {	if (!this.fs.mkdirs(p, HiddenDirPerms)) {	throw new IOException("Failed to create staging directory " + p.toString());	}	} else {	this.fs.setPermission(p, HiddenDirPerms);	}	} catch (IOException e) {	
failed to create or set permission on staging directory 

private static void bootstrap(final Path rd, final Configuration c) throws IOException {	
bootstrap creating hbase meta region 

private static void bootstrap(final Path rd, final Configuration c) throws IOException {	try {	TableDescriptor metaDescriptor = new FSTableDescriptors(c).get(TableName.META_TABLE_NAME);	HRegion meta = HRegion.createHRegion(RegionInfoBuilder.FIRST_META_REGIONINFO, rd, c, setInfoFamilyCachingForMeta(metaDescriptor, false), null);	meta.close();	} catch (IOException e) {	e = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	
bootstrap 

========================= hbase sample_2750 =========================

hasMore = scanner.next(curVals);	for (Cell kv : curVals) {	if (CellUtil.matchingQualifier(kv, qualifier)) {	sumResult += Bytes.toInt(kv.getValueArray(), kv.getValueOffset());	}	}	} while (hasMore);	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	
setting sum result to to indicate error 

if (scanner != null) {	try {	scanner.close();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	sumResult = -1;	}	}	}	done.run(ColumnAggregationNullResponseSumResponse.newBuilder().setSum(sumResult) .build());	
returning sum for region 

========================= hbase sample_1255 =========================

sshUserName = conf.get("hbase.it.clustermanager.ssh.user", "");	String extraSshOptions = conf.get("hbase.it.clustermanager.ssh.opts", "");	sshOptions = System.getenv("HBASE_SSH_OPTS");	if (!extraSshOptions.isEmpty()) {	sshOptions = StringUtils.join(new Object[] { sshOptions, extraSshOptions }, " ");	}	sshOptions = (sshOptions == null) ? "" : sshOptions;	sshUserName = (sshUserName == null) ? "" : sshUserName;	tunnelCmd = conf.get("hbase.it.clustermanager.ssh.cmd", DEFAULT_TUNNEL_CMD);	if ((sshUserName != null && sshUserName.length() > 0) || (sshOptions != null && sshOptions.length() > 0)) {	
running with ssh user and options 

public String[] getExecString() {	String at = sshUserName.isEmpty() ? "" : "@";	String remoteCmd = StringUtils.join(super.getExecString(), " ");	String cmd = String.format(tunnelCmd, sshOptions, sshUserName, at, hostname, remoteCmd, user);	
executing full command 

private Pair<Integer, String> exec(String hostname, ServiceType service, String... cmd) throws IOException {	
executing remote command hostname 

private Pair<Integer, String> exec(String hostname, ServiceType service, String... cmd) throws IOException {	RemoteShell shell = new RemoteShell(hostname, getServiceUser(service), cmd);	try {	shell.execute();	} catch (Shell.ExitCodeException ex) {	String output = shell.getOutput();	throw new Shell.ExitCodeException(ex.getExitCode(), "stderr: " + ex.getMessage() + ", stdout: " + output);	}	
executed remote command exit code output 

RetryCounter retryCounter = retryCounterFactory.create();	while (true) {	try {	return exec(hostname, service, cmd);	} catch (IOException e) {	retryOrThrow(retryCounter, e, hostname, cmd);	}	try {	retryCounter.sleepUntilNextRetry();	} catch (InterruptedException ex) {	
sleep interrupted 

private <E extends Exception> void retryOrThrow(RetryCounter retryCounter, E ex, String hostname, String[] cmd) throws E {	if (retryCounter.shouldRetry()) {	
remote command hostname failed at attempt retrying until maxattempts exception 

========================= hbase sample_3268 =========================

for (Entry<byte[], RegionLoad> entry : regionsLoad.entrySet()) {	byte[] encodedRegionName = Bytes.toBytes(RegionInfo.encodeRegionName(entry.getKey()));	Long existingValue = flushedSequenceIdByRegion.get(encodedRegionName);	long l = entry.getValue().getCompleteSequenceId();	if (LOG.isTraceEnabled()) {	LOG.trace(Bytes.toString(encodedRegionName) + ", existingValue=" + existingValue + ", completeSequenceId=" + l);	}	if (existingValue == null || (l != HConstants.NO_SEQNUM && l > existingValue)) {	flushedSequenceIdByRegion.put(encodedRegionName, l);	} else if (l != HConstants.NO_SEQNUM && l < existingValue) {	
regionserver indicates a last flushed sequence id that is less than the previous last flushed sequence id for region ignoring 

public void regionServerReport(ServerName sn, ServerLoad sl) throws YouAreDeadException {	checkIsDead(sn, "REPORT");	if (null == this.onlineServers.replace(sn, sl)) {	if (!checkAndRecordNewServer(sn, sl)) {	
regionserverreport ignored could not record the server 

private void checkIsDead(final ServerName serverName, final String what) throws YouAreDeadException {	if (this.deadservers.isDeadServer(serverName)) {	String message = "Server " + what + " rejected; currently processing " + serverName + " as dead server";	LOG.debug(message);	throw new YouAreDeadException(message);	}	if ((this.master == null || this.master.isInitialized()) && this.deadservers.cleanPreviousInstance(serverName)) {	
server came back up removed it from the dead servers list 

public synchronized void expireServer(final ServerName serverName) {	if (serverName.equals(master.getServerName())) {	if (!(master.isAborted() || master.isStopped())) {	master.stop("We lost our znode?");	}	return;	}	if (!master.isServerCrashProcessingEnabled()) {	
master doesn t enable servershutdownhandler during initialization delay expiring server 

master.stop("We lost our znode?");	}	return;	}	if (!master.isServerCrashProcessingEnabled()) {	master.getAssignmentManager().handleMetaRITOnCrashedServer(serverName);	this.queuedDeadServers.add(serverName);	return;	}	if (this.deadservers.isDeadServer(serverName)) {	
expiration of but server shutdown already in progress 

return;	}	moveFromOnlineToDeadServers(serverName);	if (this.clusterShutdown.get()) {	LOG.info("Cluster shutdown set; " + serverName + " expired; onlineServers=" + this.onlineServers.size());	if (this.onlineServers.isEmpty()) {	master.stop("Cluster shutdown set; onlineServer=0");	}	return;	}	
processing expiration of on 

public void moveFromOnlineToDeadServers(final ServerName sn) {	synchronized (onlineServers) {	if (!this.onlineServers.containsKey(sn)) {	
expiration of but server not online 

public synchronized boolean removeServerFromDrainList(final ServerName sn) {	if (!this.isServerOnline(sn)) {	
server is not currently online removing from draining list anyway as requested 

public synchronized boolean addServerToDrainList(final ServerName sn) {	if (!this.isServerOnline(sn)) {	
server is not currently online ignoring request to add it to draining list 

public synchronized boolean addServerToDrainList(final ServerName sn) {	if (!this.isServerOnline(sn)) {	return false;	}	if (this.drainingServers.contains(sn)) {	
server is already in the draining server list ignoring request to add it again 

public synchronized boolean addServerToDrainList(final ServerName sn) {	if (!this.isServerOnline(sn)) {	return false;	}	if (this.drainingServers.contains(sn)) {	return true;	}	
server added to draining server list 

public void sendRegionWarmup(ServerName server, RegionInfo region) {	if (server == null) return;	try {	AdminService.BlockingInterface admin = getRsAdmin(server);	HBaseRpcController controller = newRpcController();	ProtobufUtil.warmupRegion(controller, admin, region);	} catch (IOException e) {	
received exception in rpc for warmup server region exception 

public static void closeRegionSilentlyAndWait(ClusterConnection connection, ServerName server, RegionInfo region, long timeout) throws IOException, InterruptedException {	AdminService.BlockingInterface rs = connection.getAdmin(server);	HBaseRpcController controller = connection.getRpcControllerFactory().newController();	try {	ProtobufUtil.closeRegion(controller, rs, server, region.getRegionName());	} catch (IOException e) {	
exception when closing region 

} catch (IOException e) {	}	long expiration = timeout + System.currentTimeMillis();	while (System.currentTimeMillis() < expiration) {	controller.reset();	try {	RegionInfo rsRegion = ProtobufUtil.getRegionInfo(controller, rs, region.getRegionName());	if (rsRegion == null) return;	} catch (IOException ioe) {	if (ioe instanceof NotServingRegionException) return;	
exception when retrieving regioninfo from 

public AdminService.BlockingInterface getRsAdmin(final ServerName sn) throws IOException {	AdminService.BlockingInterface admin = this.rsAdmins.get(sn);	if (admin == null) {	
new admin connection to 

public void waitForRegionServers(MonitoredTask status) throws InterruptedException {	final long interval = this.master.getConfiguration(). getLong(WAIT_ON_REGIONSERVERS_INTERVAL, 1500);	final long timeout = this.master.getConfiguration(). getLong(WAIT_ON_REGIONSERVERS_TIMEOUT, 4500);	int minToStart = getMinToStart();	int maxToStart = this.master.getConfiguration(). getInt(WAIT_ON_REGIONSERVERS_MAXTOSTART, Integer.MAX_VALUE);	if (maxToStart < minToStart) {	
the value of s d is set less than s d ignoring 

public void stop() {	if (connection != null) {	try {	connection.close();	} catch (IOException e) {	
attempt to close connection to master failed 

========================= hbase sample_2880 =========================

public static void setUpBeforeClass() throws Exception {	TEST_UTIL.getConfiguration().setInt(HConstants.HBASE_RPC_TIMEOUT_KEY, 60000);	TEST_UTIL.getConfiguration().setInt(HConstants.HBASE_CLIENT_OPERATION_TIMEOUT, 120000);	TEST_UTIL.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 2);	TEST_UTIL.getConfiguration().setInt(START_LOG_ERRORS_AFTER_COUNT_KEY, 0);	TEST_UTIL.startMiniCluster(1);	ASYNC_CONN = ConnectionFactory.createAsyncConnection(TEST_UTIL.getConfiguration()).get();	master = TEST_UTIL.getHBaseCluster().getMaster();	zkNamespaceManager = new ZKNamespaceManager(master.getZooKeeper());	zkNamespaceManager.start();	
done initializing cluster 

private static <V, E> void runWithExpectedException(Callable<V> callable, Class<E> exceptionClass) {	try {	callable.call();	} catch (Exception ex) {	
get exception is 

========================= hbase sample_2029 =========================

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	exists_result result = new exists_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<TResult> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<TResult>() {	public void onComplete(TResult o) {	get_result result = new get_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TResult>>() {	public void onComplete(List<TResult> o) {	getMultiple_result result = new getMultiple_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	put_result result = new put_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	checkAndPut_result result = new checkAndPut_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	putMultiple_result result = new putMultiple_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteSingle_result result = new deleteSingle_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TDelete>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TDelete>>() {	public void onComplete(List<TDelete> o) {	deleteMultiple_result result = new deleteMultiple_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	checkAndDelete_result result = new checkAndDelete_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<TResult> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<TResult>() {	public void onComplete(TResult o) {	increment_result result = new increment_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<TResult> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<TResult>() {	public void onComplete(TResult o) {	append_result result = new append_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	openScanner_result result = new openScanner_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TResult>>() {	public void onComplete(List<TResult> o) {	getScannerRows_result result = new getScannerRows_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	closeScanner_result result = new closeScanner_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	mutateRow_result result = new mutateRow_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TResult>>() {	public void onComplete(List<TResult> o) {	getScannerResults_result result = new getScannerResults_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<THRegionLocation> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<THRegionLocation>() {	public void onComplete(THRegionLocation o) {	getRegionLocation_result result = new getRegionLocation_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<THRegionLocation>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<THRegionLocation>>() {	public void onComplete(List<THRegionLocation> o) {	getAllRegionLocations_result result = new getAllRegionLocations_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	checkAndMutate_result result = new checkAndMutate_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

========================= hbase sample_762 =========================

public boolean submitSubprocedure(Subprocedure subproc) {	if (subproc == null) {	
submitted null subprocedure nothing to run here 

public boolean submitSubprocedure(Subprocedure subproc) {	if (subproc == null) {	return false;	}	String procName = subproc.getName();	if (procName == null || procName.length() == 0) {	
subproc name cannot be null or the empty string 

if (subproc == null) {	return false;	}	String procName = subproc.getName();	if (procName == null || procName.length() == 0) {	return false;	}	Subprocedure rsub = subprocs.get(procName);	if (rsub != null) {	if (!rsub.isComplete()) {	
subproc is already running bailing out 

}	String procName = subproc.getName();	if (procName == null || procName.length() == 0) {	return false;	}	Subprocedure rsub = subprocs.get(procName);	if (rsub != null) {	if (!rsub.isComplete()) {	return false;	}	
a completed old subproc is still present removing 

String procName = subproc.getName();	if (procName == null || procName.length() == 0) {	return false;	}	Subprocedure rsub = subprocs.get(procName);	if (rsub != null) {	if (!rsub.isComplete()) {	return false;	}	if (!subprocs.remove(procName, rsub)) {	
another thread has replaced existing subproc bailing out 

}	Subprocedure rsub = subprocs.get(procName);	if (rsub != null) {	if (!rsub.isComplete()) {	return false;	}	if (!subprocs.remove(procName, rsub)) {	return false;	}	}	
submitting new subprocedure 

}	if (!subprocs.remove(procName, rsub)) {	return false;	}	}	try {	if (subprocs.putIfAbsent(procName, subproc) == null) {	this.pool.submit(subproc);	return true;	} else {	
another thread has submitted subproc bailing out 

this.pool.submit(subproc);	return true;	} else {	return false;	}	} catch (RejectedExecutionException e) {	subprocs.remove(procName, subproc);	String msg = "Subprocedure pool is full!";	subproc.cancel(msg, e.getCause());	}	
failed to start subprocedure 

public void receivedReachedGlobalBarrier(String procName) {	Subprocedure subproc = subprocs.get(procName);	if (subproc == null) {	
unexpected reached globa barrier message for sub procedure 

public void receivedReachedGlobalBarrier(String procName) {	Subprocedure subproc = subprocs.get(procName);	if (subproc == null) {	return;	}	if (LOG.isTraceEnabled()) {	
reached global barrier message for sub procedure 

public void receiveAbortProcedure(String procName, ForeignException ee) {	
request received to abort procedure 

public void receiveAbortProcedure(String procName, ForeignException ee) {	Subprocedure sub = subprocs.get(procName);	if (sub == null) {	
received abort on procedure with no local subprocedure ignoring it 

========================= hbase sample_2479 =========================

protected void addMobRegion(RegionInfo regionInfo, RegionVisitor visitor) throws IOException {	
storing mob region region info for snapshot 

protected void addMobRegion(RegionInfo regionInfo, RegionVisitor visitor) throws IOException {	Object regionData = visitor.regionOpen(regionInfo);	monitor.rethrowException();	
creating references for mob files 

for (ColumnFamilyDescriptor hcd : htd.getColumnFamilies()) {	if (!hcd.isMobEnabled()) {	continue;	}	Object familyData = visitor.familyOpen(regionData, hcd.getName());	monitor.rethrowException();	Path storePath = MobUtils.getMobFamilyPath(mobRegionPath, hcd.getNameAsString());	List<StoreFileInfo> storeFiles = getStoreFiles(storePath);	if (storeFiles == null) {	if (LOG.isDebugEnabled()) {	
no mob files under family 

protected void addRegion(final HRegion region, RegionVisitor visitor) throws IOException {	
storing region info for snapshot 

protected void addRegion(final HRegion region, RegionVisitor visitor) throws IOException {	Object regionData = visitor.regionOpen(region.getRegionInfo());	monitor.rethrowException();	
creating references for hfiles 

protected void addRegion(final HRegion region, RegionVisitor visitor) throws IOException {	Object regionData = visitor.regionOpen(region.getRegionInfo());	monitor.rethrowException();	for (HStore store : region.getStores()) {	Object familyData = visitor.familyOpen(regionData, store.getColumnFamilyDescriptor().getName());	monitor.rethrowException();	List<HStoreFile> storeFiles = new ArrayList<>(store.getStorefiles());	if (LOG.isDebugEnabled()) {	
adding snapshot references for hfiles 

monitor.rethrowException();	for (HStore store : region.getStores()) {	Object familyData = visitor.familyOpen(regionData, store.getColumnFamilyDescriptor().getName());	monitor.rethrowException();	List<HStoreFile> storeFiles = new ArrayList<>(store.getStorefiles());	if (LOG.isDebugEnabled()) {	}	for (int i = 0, sz = storeFiles.size(); i < sz; i++) {	HStoreFile storeFile = storeFiles.get(i);	monitor.rethrowException();	
adding reference for file 

protected void addRegion(final Path tableDir, final RegionInfo regionInfo, RegionVisitor visitor) throws IOException {	boolean isMobRegion = MobUtils.isMobRegionInfo(regionInfo);	try {	Path baseDir = tableDir;	if (isMobRegion) {	baseDir = FSUtils.getTableDir(MobUtils.getMobHome(conf), regionInfo.getTable());	}	HRegionFileSystem regionFs = HRegionFileSystem.openRegionFromFileSystem(conf, fs, baseDir, regionInfo, true);	monitor.rethrowException();	
storing region info for snapshot 

boolean isMobRegion = MobUtils.isMobRegionInfo(regionInfo);	try {	Path baseDir = tableDir;	if (isMobRegion) {	baseDir = FSUtils.getTableDir(MobUtils.getMobHome(conf), regionInfo.getTable());	}	HRegionFileSystem regionFs = HRegionFileSystem.openRegionFromFileSystem(conf, fs, baseDir, regionInfo, true);	monitor.rethrowException();	Object regionData = visitor.regionOpen(regionInfo);	monitor.rethrowException();	
creating references for hfiles 

Object regionData = visitor.regionOpen(regionInfo);	monitor.rethrowException();	Collection<String> familyNames = regionFs.getFamilies();	if (familyNames != null) {	for (String familyName: familyNames) {	Object familyData = visitor.familyOpen(regionData, Bytes.toBytes(familyName));	monitor.rethrowException();	Collection<StoreFileInfo> storeFiles = regionFs.getStoreFiles(familyName);	if (storeFiles == null) {	if (LOG.isDebugEnabled()) {	
no files under family 

private void addReferenceFiles(RegionVisitor visitor, Object regionData, Object familyData, Collection<StoreFileInfo> storeFiles, boolean isMob) throws IOException {	final String fileType = isMob ? "mob file" : "hfile";	if (LOG.isDebugEnabled()) {	
adding snapshot references for s ss 

private void addReferenceFiles(RegionVisitor visitor, Object regionData, Object familyData, Collection<StoreFileInfo> storeFiles, boolean isMob) throws IOException {	final String fileType = isMob ? "mob file" : "hfile";	if (LOG.isDebugEnabled()) {	}	int i = 0;	int sz = storeFiles.size();	for (StoreFileInfo storeFile: storeFiles) {	monitor.rethrowException();	
adding reference for s d d s 

public void consolidate() throws IOException {	if (getSnapshotFormat(desc) == SnapshotManifestV1.DESCRIPTOR_VERSION) {	Path rootDir = FSUtils.getRootDir(conf);	
using old snapshot format 

public void consolidate() throws IOException {	if (getSnapshotFormat(desc) == SnapshotManifestV1.DESCRIPTOR_VERSION) {	Path rootDir = FSUtils.getRootDir(conf);	new FSTableDescriptors(conf, fs, rootDir) .createTableDescriptorForTableDirectory(workingDir, htd, false);	} else {	
convert to single snapshot manifest 

========================= hbase sample_2183 =========================

private ZNodeClearer() {}	public static void writeMyEphemeralNodeOnDisk(String fileContent) {	String fileName = ZNodeClearer.getMyEphemeralNodeFileName();	if (fileName == null) {	
environment variable hbase znode file not set znodes will not be cleared on crash by start scripts longer mttr 

private ZNodeClearer() {}	public static void writeMyEphemeralNodeOnDisk(String fileContent) {	String fileName = ZNodeClearer.getMyEphemeralNodeFileName();	if (fileName == null) {	return;	}	FileWriter fstream;	try {	fstream = new FileWriter(fileName);	} catch (IOException e) {	
can t write znode file 

try {	out.write(fileContent + "\n");	} finally {	try {	out.close();	} finally {	fstream.close();	}	}	} catch (IOException e) {	
can t write znode file 

public static String parseMasterServerName(String rsZnodePath) {	String masterServerName = null;	try {	String[] rsZnodeParts = rsZnodePath.split("/");	masterServerName = rsZnodeParts[rsZnodeParts.length -1];	} catch (IndexOutOfBoundsException e) {	
string has wrong format 

public static boolean clear(Configuration conf) {	Configuration tempConf = new Configuration(conf);	tempConf.setInt("zookeeper.recovery.retry", 0);	ZKWatcher zkw;	try {	zkw = new ZKWatcher(tempConf, "clean znode for master", new Abortable() {	});	} catch (IOException e) {	
can t connect to zookeeper to read the master znode 

String znodeFileContent;	try {	znodeFileContent = ZNodeClearer.readMyEphemeralNodeOnDisk();	if (ZNodeClearer.tablesOnMaster(conf)) {	ZKUtil.deleteNodeFailSilent(zkw, ZNodePaths.joinZNode(zkw.znodePaths.rsZNode, znodeFileContent));	return MasterAddressTracker.deleteIfEquals(zkw, ZNodeClearer.parseMasterServerName(znodeFileContent));	} else {	return MasterAddressTracker.deleteIfEquals(zkw, znodeFileContent);	}	} catch (FileNotFoundException fnfe) {	
can t find the znode file presume non fatal 

znodeFileContent = ZNodeClearer.readMyEphemeralNodeOnDisk();	if (ZNodeClearer.tablesOnMaster(conf)) {	ZKUtil.deleteNodeFailSilent(zkw, ZNodePaths.joinZNode(zkw.znodePaths.rsZNode, znodeFileContent));	return MasterAddressTracker.deleteIfEquals(zkw, ZNodeClearer.parseMasterServerName(znodeFileContent));	} else {	return MasterAddressTracker.deleteIfEquals(zkw, znodeFileContent);	}	} catch (FileNotFoundException fnfe) {	return true;	} catch (IOException e) {	
can t read the content of the znode file 

ZKUtil.deleteNodeFailSilent(zkw, ZNodePaths.joinZNode(zkw.znodePaths.rsZNode, znodeFileContent));	return MasterAddressTracker.deleteIfEquals(zkw, ZNodeClearer.parseMasterServerName(znodeFileContent));	} else {	return MasterAddressTracker.deleteIfEquals(zkw, znodeFileContent);	}	} catch (FileNotFoundException fnfe) {	return true;	} catch (IOException e) {	return false;	} catch (KeeperException e) {	
zookeeper exception deleting znode 

========================= hbase sample_2496 =========================

public void run() {	Thread.currentThread().setName(getClass().getSimpleName());	try {	long expectedKey = startKey;	Queue<Long> sortedKeys = new PriorityQueue<>();	while (expectedKey < endKey) {	Long k;	try {	k = wroteKeys.poll(1, TimeUnit.SECONDS);	} catch (InterruptedException e) {	
inserted key tracker thread interrupted 

sortedKeys.add(k);	}	while (!sortedKeys.isEmpty() && ((k = sortedKeys.peek()) == expectedKey)) {	sortedKeys.poll();	wroteUpToKey.set(k);	++expectedKey;	}	wroteKeyQueueSize.set(wroteKeys.size() + sortedKeys.size());	}	} catch (Exception ex) {	
error in inserted updaed key tracker 

========================= hbase sample_1310 =========================

protected void rollback(Void env) throws IOException {	if (++retries < 3) {	
inject rollback failure 

========================= hbase sample_1185 =========================

public void close() {	try {	compactingScanner.close();	} catch (IOException e) {	
close store scanner failed 

========================= hbase sample_2603 =========================

String encodedName = r.getRegionInfo().getEncodedName();	long time = EnvironmentEdgeManager.currentTime();	if (!lastRefreshTimes.containsKey(encodedName)) {	lastRefreshTimes.put(encodedName, time);	}	try {	for (Store store : r.getStores()) {	store.refreshStoreFiles();	}	} catch (IOException ex) {	
exception while trying to refresh store files for region exception 

========================= hbase sample_2746 =========================

public void run() {	HRegionServer rs = TEST_UTIL.getMiniHBaseCluster().getRegionServer(0);	HRegion region = TEST_UTIL.getMiniHBaseCluster().getRegions(TABLENAME).get(0);	RegionInfo info = region.getRegionInfo();	try {	HTableDescriptor htd = table.getTableDescriptor();	for (int i = 0; i < 10; i++) {	warmupHRegion(info, htd, rs.getWAL(info), rs.getConfiguration(), rs, null);	}	} catch (IOException ie) {	
failed warming up region 

========================= hbase sample_1869 =========================

public void testPut() throws IOException {	
starting testput 

public void testParallelPuts() throws IOException {	
starting testparallelputs 

for (int i = 0; i < THREADS100; i++) {	all[i] = new Putter(region, i, numOps);	}	for (int i = 0; i < THREADS100; i++) {	all[i].start();	}	for (int i = 0; i < THREADS100; i++) {	try {	all[i].join();	} catch (InterruptedException e) {	
testparallelputs encountered interruptedexception ignoring 

}	for (int i = 0; i < THREADS100; i++) {	all[i].start();	}	for (int i = 0; i < THREADS100; i++) {	try {	all[i].join();	} catch (InterruptedException e) {	}	}	
testparallelputs successfully verified put operations 

========================= hbase sample_1613 =========================

public boolean isFileDeletable(FileStatus fStat) {	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	
hfile life ttl current from 

public boolean isFileDeletable(FileStatus fStat) {	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	}	if (life < 0) {	
found a hfile newer than current time probably a clock skew 

========================= hbase sample_2879 =========================

hcBuilder.withBlockSize(2 * 1024);	hcBuilder.withDataBlockEncoding(encoding);	HFileContext hFileContext = hcBuilder.build();	StoreFileWriter writer = new StoreFileWriter.Builder( TEST_UTIL.getConfiguration(), cacheConf, fs).withOutputDir(hfilePath) .withFileContext(hFileContext).build();	writeStoreFile(writer);	HStoreFile sf = new HStoreFile(fs, writer.getPath(), TEST_UTIL.getConfiguration(), cacheConf, BloomType.NONE, true);	List<StoreFileScanner> scanners = StoreFileScanner .getScannersForStoreFiles(Collections.singletonList(sf), false, true, false, false, Long.MAX_VALUE);	StoreFileScanner scanner = scanners.get(0);	seekTestOfReversibleKeyValueScanner(scanner);	for (int readPoint = 0; readPoint < MAXMVCC; readPoint++) {	
setting read point to 

public void testReversibleMemstoreScanner() throws IOException {	MemStore memstore = new DefaultMemStore();	writeMemstore(memstore);	List<KeyValueScanner> scanners = memstore.getScanners(Long.MAX_VALUE);	seekTestOfReversibleKeyValueScanner(scanners.get(0));	for (int readPoint = 0; readPoint < MAXMVCC; readPoint++) {	
setting read point to 

writeMemstoreAndStoreFiles(memstore, new StoreFileWriter[] { writer1, writer2 });	HStoreFile sf1 = new HStoreFile(fs, writer1.getPath(), TEST_UTIL.getConfiguration(), cacheConf, BloomType.NONE, true);	HStoreFile sf2 = new HStoreFile(fs, writer2.getPath(), TEST_UTIL.getConfiguration(), cacheConf, BloomType.NONE, true);	int startRowNum = ROWSIZE / 2;	ReversedKeyValueHeap kvHeap = getReversibleKeyValueHeap(memstore, sf1, sf2, ROWS[startRowNum], MAXMVCC);	internalTestSeekAndNextForReversibleKeyValueHeap(kvHeap, startRowNum);	startRowNum = ROWSIZE - 1;	kvHeap = getReversibleKeyValueHeap(memstore, sf1, sf2, HConstants.EMPTY_START_ROW, MAXMVCC);	internalTestSeekAndNextForReversibleKeyValueHeap(kvHeap, startRowNum);	for (int readPoint = 0; readPoint < MAXMVCC; readPoint++) {	
setting read point to 

byte[] startRow = ROWS[startRowNum];	scan.withStartRow(startRow);	storeScanner = getReversibleStoreScanner(memstore, sf1, sf2, scan, scanInfo, MAXMVCC);	verifyCountAndOrder(storeScanner, QUALSIZE * (startRowNum + 1), startRowNum + 1, false);	assertTrue(QUALSIZE > 2);	scan.addColumn(FAMILYNAME, QUALS[0]);	scan.addColumn(FAMILYNAME, QUALS[2]);	storeScanner = getReversibleStoreScanner(memstore, sf1, sf2, scan, scanInfo, MAXMVCC);	verifyCountAndOrder(storeScanner, 2 * (startRowNum + 1), startRowNum + 1, false);	for (int readPoint = 0; readPoint < MAXMVCC; readPoint++) {	
setting read point to 

========================= hbase sample_1756 =========================

public synchronized void addToFailedServers(InetSocketAddress address, Throwable throwable) {	final long expiry = EnvironmentEdgeManager.currentTime() + recheckServersTimeout;	this.failedServers.put(address.toString(), expiry);	this.latestExpiry = expiry;	if (LOG.isDebugEnabled()) {	
added failed server with address to list caused by 

========================= hbase sample_261 =========================

public void testHBaseSaslRpcClientCreation() throws Exception {	assertFalse(assertSuccessCreationKerberosPrincipal(null));	assertFalse(assertSuccessCreationKerberosPrincipal("DOMAIN.COM"));	assertFalse(assertSuccessCreationKerberosPrincipal("principal/DOMAIN.COM"));	if (!assertSuccessCreationKerberosPrincipal("principal/localhost@DOMAIN.COM")) {	
could not create a sasl client with valid kerberos credential 

========================= hbase sample_41 =========================

public void start() throws IOException {	random = new SecureRandom();	userProvider = UserProvider.instantiate(conf);	fs = FileSystem.get(conf);	baseStagingDir = new Path(FSUtils.getRootDir(conf), HConstants.BULKLOAD_STAGING_DIR_NAME);	if (conf.get("hbase.bulkload.staging.dir") != null) {	
hbase bulkload staging dir is deprecated bulkload staging directory is 

public void cleanupBulkLoad(final HRegion region, final CleanupBulkLoadRequest request) throws IOException {	region.getCoprocessorHost().preCleanupBulkLoad(getActiveUser());	Path path = new Path(request.getBulkToken());	if (!fs.delete(path, true)) {	if (fs.exists(path)) {	throw new IOException("Failed to clean up " + path);	}	}	
cleaned up successfully 

User user = getActiveUser();	final UserGroupInformation ugi = user.getUGI();	if (userProvider.isHadoopSecurityEnabled()) {	try {	Token tok = TokenUtil.obtainToken(conn);	if (tok != null) {	boolean b = ugi.addToken(tok);	LOG.debug("token added " + tok + " for user " + ugi + " return=" + b);	}	} catch (IOException ioe) {	
unable to add token 

fs = FileSystem.get(conf);	for(Pair<byte[], String> el: familyPaths) {	Path stageFamily = new Path(bulkToken, Bytes.toString(el.getFirst()));	if(!fs.exists(stageFamily)) {	fs.mkdirs(stageFamily);	fs.setPermission(stageFamily, PERM_ALL_ACCESS);	}	}	return region.bulkLoadHFiles(familyPaths, true, new SecureBulkLoadListener(fs, bulkToken, conf), request.getCopyFile());	} catch (Exception e) {	
failed to complete bulk load 

public String prepareBulkLoad(final byte[] family, final String srcPath, boolean copyFile) throws IOException {	Path p = new Path(srcPath);	Path stageP = new Path(stagingDir, new Path(Bytes.toString(family), p.getName()));	if (p.equals(stageP)) {	
is already available in staging directory skipping copy or rename 

if (p.equals(stageP)) {	return stageP.toString();	}	if (srcFs == null) {	srcFs = FileSystem.get(p.toUri(), conf);	}	if(!isFile(p)) {	throw new IOException("Path does not reference a file: " + p);	}	if (!FSHDFSUtils.isSameHdfs(conf, srcFs, fs)) {	
bulk load file is on different filesystem than the destination filesystem copying file over to destination staging dir 

}	if (srcFs == null) {	srcFs = FileSystem.get(p.toUri(), conf);	}	if(!isFile(p)) {	throw new IOException("Path does not reference a file: " + p);	}	if (!FSHDFSUtils.isSameHdfs(conf, srcFs, fs)) {	FileUtil.copy(srcFs, p, fs, stageP, false, conf);	} else if (copyFile) {	
bulk load file is copied to destination staging dir 

srcFs = FileSystem.get(p.toUri(), conf);	}	if(!isFile(p)) {	throw new IOException("Path does not reference a file: " + p);	}	if (!FSHDFSUtils.isSameHdfs(conf, srcFs, fs)) {	FileUtil.copy(srcFs, p, fs, stageP, false, conf);	} else if (copyFile) {	FileUtil.copy(srcFs, p, fs, stageP, false, conf);	} else {	
moving to 

public void doneBulkLoad(byte[] family, String srcPath) throws IOException {	
bulk load done for 

public void failedBulkLoad(final byte[] family, final String srcPath) throws IOException {	if (!FSHDFSUtils.isSameHdfs(conf, srcFs, fs)) {	return;	}	Path p = new Path(srcPath);	Path stageP = new Path(stagingDir, new Path(Bytes.toString(family), p.getName()));	if (p.equals(stageP)) {	
is already available in source directory skipping rename 

public void failedBulkLoad(final byte[] family, final String srcPath) throws IOException {	if (!FSHDFSUtils.isSameHdfs(conf, srcFs, fs)) {	return;	}	Path p = new Path(srcPath);	Path stageP = new Path(stagingDir, new Path(Bytes.toString(family), p.getName()));	if (p.equals(stageP)) {	return;	}	
moving back to 

========================= hbase sample_2654 =========================

key = entry.getKey();	break;	}	}	rs.onlineRegions.put(key, spiedRegion);	Connection conn = testUtil.getConnection();	try (Table table = conn.getTable(tableName)) {	table.put(new Put(Bytes.toBytes("row0")) .addColumn(family, qualifier, Bytes.toBytes("val0")));	}	long oldestSeqIdOfStore = region.getOldestSeqIdOfStore(family);	
change oldest 

========================= hbase sample_1582 =========================

OutputStream b64os = null;	ObjectOutputStream oos = null;	try {	b64os = new Base64OutputStream(baos, ENCODE | options);	oos = ((options & GZIP) == GZIP) ? new ObjectOutputStream(new GZIPOutputStream(b64os)) : new ObjectOutputStream(b64os);	oos.writeObject(serializableObject);	return new String(baos.toByteArray(), PREFERRED_ENCODING);	} catch (UnsupportedEncodingException uue) {	return new String(baos.toByteArray(), StandardCharsets.UTF_8);	} catch (IOException e) {	
error encoding object 

return new String(baos.toByteArray(), PREFERRED_ENCODING);	} catch (UnsupportedEncodingException uue) {	return new String(baos.toByteArray(), StandardCharsets.UTF_8);	} catch (IOException e) {	return null;	} finally {	if (oos != null) {	try {	oos.close();	} catch (Exception e) {	
error closing objectoutputstream 

if (oos != null) {	try {	oos.close();	} catch (Exception e) {	}	}	if (b64os != null) {	try {	b64os.close();	} catch (Exception e) {	
error closing 

}	if (b64os != null) {	try {	b64os.close();	} catch (Exception e) {	}	}	try {	baos.close();	} catch (Exception e) {	
error closing bytearrayoutputstream 

GZIPOutputStream gzos = null;	try {	gzos = new GZIPOutputStream(new Base64OutputStream(baos, ENCODE | options));	gzos.write(source, off, len);	gzos.close();	gzos = null;	return new String(baos.toByteArray(), PREFERRED_ENCODING);	} catch (UnsupportedEncodingException uue) {	return new String(baos.toByteArray(), StandardCharsets.UTF_8);	} catch (IOException e) {	
error encoding byte array 

return new String(baos.toByteArray(), PREFERRED_ENCODING);	} catch (UnsupportedEncodingException uue) {	return new String(baos.toByteArray(), StandardCharsets.UTF_8);	} catch (IOException e) {	return null;	} finally {	if (gzos != null) {	try {	gzos.close();	} catch (Exception e) {	
error closing gzipoutputstream 

} finally {	if (gzos != null) {	try {	gzos.close();	} catch (Exception e) {	}	}	try {	baos.close();	} catch (Exception e) {	
error closing bytearrayoutputstream 

destination[destOffset + 1] = (byte) (outBuff >>> 8);	return 2;	} else {	try {	int outBuff = ((DECODABET[source[srcOffset]] & 0xFF) << 18) | ((DECODABET[source[srcOffset + 1]] & 0xFF) << 12) | ((DECODABET[source[srcOffset + 2]] & 0xFF) << 6) | ((DECODABET[source[srcOffset + 3]] & 0xFF));	destination[destOffset] = (byte) (outBuff >> 16);	destination[destOffset + 1] = (byte) (outBuff >> 8);	destination[destOffset + 2] = (byte) (outBuff);	return 3;	} catch (Exception e) {	
error decoding bytes at 

if (sbiDecode >= WHITE_SPACE_ENC) {	if (sbiDecode >= EQUALS_SIGN_ENC) {	b4[b4Posn++] = sbiCrop;	if (b4Posn > 3) {	outBuffPosn += decode4to3(b4, 0, outBuff, outBuffPosn, options);	b4Posn = 0;	if (sbiCrop == EQUALS_SIGN) break;	}	}	} else {	
bad input character at decimal 

byte[] buffer = new byte[2048];	for (int length; (length = gzis.read(buffer)) >= 0; ) {	baos.write(buffer, 0, length);	}	bytes = baos.toByteArray();	} catch (IOException e) {	} finally {	try {	baos.close();	} catch (Exception e) {	
error closing bytearrayoutputstream 

} catch (IOException e) {	} finally {	try {	baos.close();	} catch (Exception e) {	}	if (gzis != null) {	try {	gzis.close();	} catch (Exception e) {	
error closing gzipinputstream 

public static Object decodeToObject(String encodedObject) {	byte[] objBytes = decode(encodedObject);	Object obj = null;	ObjectInputStream ois = null;	try {	ois = new ObjectInputStream(new ByteArrayInputStream(objBytes));	obj = ois.readObject();	} catch (IOException e) {	
error decoding object 

public static Object decodeToObject(String encodedObject) {	byte[] objBytes = decode(encodedObject);	Object obj = null;	ObjectInputStream ois = null;	try {	ois = new ObjectInputStream(new ByteArrayInputStream(objBytes));	obj = ois.readObject();	} catch (IOException e) {	} catch (ClassNotFoundException e) {	
error decoding object 

try {	ois = new ObjectInputStream(new ByteArrayInputStream(objBytes));	obj = ois.readObject();	} catch (IOException e) {	} catch (ClassNotFoundException e) {	} finally {	if (ois != null) {	try {	ois.close();	} catch (Exception e) {	
error closing objectinputstream 

public static boolean encodeToFile(byte[] dataToEncode, String filename) {	boolean success = false;	Base64OutputStream bos = null;	try {	bos = new Base64OutputStream(new FileOutputStream(filename), ENCODE);	bos.write(dataToEncode);	success = true;	} catch (IOException e) {	
error encoding file 

bos = new Base64OutputStream(new FileOutputStream(filename), ENCODE);	bos.write(dataToEncode);	success = true;	} catch (IOException e) {	success = false;	} finally {	if (bos != null) {	try {	bos.close();	} catch (Exception e) {	
error closing 

public static boolean decodeToFile(String dataToDecode, String filename) {	boolean success = false;	Base64OutputStream bos = null;	try {	bos = new Base64OutputStream(new FileOutputStream(filename), DECODE);	bos.write(dataToDecode.getBytes(PREFERRED_ENCODING));	success = true;	} catch (IOException e) {	
error decoding to file 

bos = new Base64OutputStream(new FileOutputStream(filename), DECODE);	bos.write(dataToDecode.getBytes(PREFERRED_ENCODING));	success = true;	} catch (IOException e) {	success = false;	} finally {	if (bos != null) {	try {	bos.close();	} catch (Exception e) {	
error closing 

public static byte[] decodeFromFile(String filename) {	byte[] decodedData = null;	BufferedInputStream bufferedInputStream = null;	FileInputStream fileInputStream = null;	Base64InputStream base64InputStream = null;	try {	File file = new File(filename);	byte[] buffer;	if (file.length() > Integer.MAX_VALUE) {	
file is too big for this convenience method bytes 

fileInputStream = new FileInputStream(file);	bufferedInputStream = new BufferedInputStream(fileInputStream);	base64InputStream = new Base64InputStream(bufferedInputStream, DECODE);	int length = 0;	for (int numBytes; (numBytes = base64InputStream.read(buffer, length, 4096)) >= 0; ) {	length += numBytes;	}	decodedData = new byte[length];	System.arraycopy(buffer, 0, decodedData, 0, length);	} catch (IOException e) {	
error decoding from file 

length += numBytes;	}	decodedData = new byte[length];	System.arraycopy(buffer, 0, decodedData, 0, length);	} catch (IOException e) {	} finally {	if (fileInputStream != null) {	try {	fileInputStream.close();	} catch (Exception e) {	
error closing fileinputstream 

if (fileInputStream != null) {	try {	fileInputStream.close();	} catch (Exception e) {	}	}	if (bufferedInputStream != null) {	try {	bufferedInputStream.close();	} catch (Exception e) {	
error closing bufferedinputstream 

if (bufferedInputStream != null) {	try {	bufferedInputStream.close();	} catch (Exception e) {	}	}	if (base64InputStream != null) {	try {	base64InputStream.close();	} catch (Exception e) {	
error closing 

byte[] buffer = new byte[Math.max((int) (file.length() * 1.4), 40)];	fileInputStream = new FileInputStream(file);	bufferedInputStream = new BufferedInputStream(fileInputStream);	base64InputStream = new Base64InputStream(bufferedInputStream, ENCODE);	int length = 0;	for (int numBytes; (numBytes = base64InputStream.read(buffer, length, 4096)) >= 0; ) {	length += numBytes;	}	encodedData = new String(buffer, 0, length, PREFERRED_ENCODING);	} catch (IOException e) {	
error encoding from file 

for (int numBytes; (numBytes = base64InputStream.read(buffer, length, 4096)) >= 0; ) {	length += numBytes;	}	encodedData = new String(buffer, 0, length, PREFERRED_ENCODING);	} catch (IOException e) {	} finally {	if (fileInputStream != null) {	try {	fileInputStream.close();	} catch (Exception e) {	
error closing fileinputstream 

if (fileInputStream != null) {	try {	fileInputStream.close();	} catch (Exception e) {	}	}	if (bufferedInputStream != null) {	try {	bufferedInputStream.close();	} catch (Exception e) {	
error closing bufferedinputstream 

if (bufferedInputStream != null) {	try {	bufferedInputStream.close();	} catch (Exception e) {	}	}	if (base64InputStream != null) {	try {	base64InputStream.close();	} catch (Exception e) {	
error closing 

public static void encodeFileToFile(String infile, String outfile) {	String encoded = encodeFromFile(infile);	OutputStream out = null;	try {	out = new BufferedOutputStream(new FileOutputStream(outfile));	out.write(encoded.getBytes("US-ASCII"));	} catch (IOException e) {	
error encoding from file to 

OutputStream out = null;	try {	out = new BufferedOutputStream(new FileOutputStream(outfile));	out.write(encoded.getBytes("US-ASCII"));	} catch (IOException e) {	} finally {	if (out != null) {	try {	out.close();	} catch (Exception e) {	
error closing 

public static void decodeFileToFile(String infile, String outfile) {	byte[] decoded = decodeFromFile(infile);	OutputStream out = null;	try {	out = new BufferedOutputStream(new FileOutputStream(outfile));	out.write(decoded);	} catch (IOException e) {	
error decoding from file to 

OutputStream out = null;	try {	out = new BufferedOutputStream(new FileOutputStream(outfile));	out.write(decoded);	} catch (IOException e) {	} finally {	if (out != null) {	try {	out.close();	} catch (Exception e) {	
error closing 

========================= hbase sample_959 =========================

private void runRowCount(String[] args, int expectedCount) throws Exception {	Job job = RowCounter.createSubmittableJob(TEST_UTIL.getConfiguration(), args);	long start = System.currentTimeMillis();	job.waitForCompletion(true);	long duration = System.currentTimeMillis() - start;	
row count duration ms 

========================= hbase sample_3383 =========================

final ServerName originalServer = loc.getServerName();	ServerName newServer = null;	for (int i = 0; i < SLAVES; i++) {	HRegionServer rs = hbaseCluster.getRegionServer(i);	if (!rs.getServerName().equals(originalServer.getServerName())) {	newServer = rs.getServerName();	break;	}	}	assertNotNull("Did not find a new RegionServer to use", newServer);	
moving from to 

========================= hbase sample_2068 =========================

public MetricsRegionSourceImpl(MetricsRegionWrapper regionWrapper, MetricsRegionAggregateSourceImpl aggregate) {	this.regionWrapper = regionWrapper;	agg = aggregate;	hashCode = regionWrapper.getRegionHashCode();	agg.register(this);	
creating new metricsregionsourceimpl for table 

public void close() {	boolean wasClosed = closed.getAndSet(true);	if (wasClosed) {	return;	}	agg.deregister(this);	synchronized (this) {	if (LOG.isTraceEnabled()) {	
removing region metrics 

========================= hbase sample_689 =========================

public void start(long startKey, long endKey, int numThreads) throws IOException {	super.start(startKey, endKey, numThreads);	if (verbose) {	
updating keys 

try {	get = dataGenerator.beforeGet(rowKeyBase, get);	} catch (Exception e) {	LOG.warn("Failed to modify the get from the load generator  = [" + Bytes.toString(get.getRow()) + "], column family = [" + Bytes.toString(cf) + "]", e);	}	Result result = getRow(get, rowKeyBase, cf);	Map<byte[], byte[]> columnValues = result != null ? result.getFamilyMap(cf) : null;	if (columnValues == null) {	int specialPermCellInsertionFactor = Integer.parseInt(dataGenerator.getArgs()[2]);	if (((int) rowKeyBase % specialPermCellInsertionFactor == 0)) {	
null result expected for the rowkey 

protected void closeHTable() {	try {	if (table != null) {	table.close();	}	} catch (IOException e) {	
error closing table 

} else if (m instanceof Put) {	table.checkAndMutate(row, cf).qualifier(q).ifEquals(v).thenPut((Put)m);	} else if (m instanceof Delete) {	table.checkAndMutate(row, cf).qualifier(q).ifEquals(v).thenDelete((Delete)m);	} else {	throw new IllegalArgumentException( "unsupported mutation " + m.getClass().getSimpleName());	}	totalOpTimeMs.addAndGet(System.currentTimeMillis() - start);	} catch (IOException e) {	if (ignoreNonceConflicts) {	
detected nonce conflict ignoring 

return;	}	failedKeySet.add(keyBase);	String exceptionInfo;	if (e instanceof RetriesExhaustedWithDetailsException) {	RetriesExhaustedWithDetailsException aggEx = (RetriesExhaustedWithDetailsException) e;	exceptionInfo = aggEx.getExhaustiveDescription();	} else {	exceptionInfo = StringUtils.stringifyException(e);	}	
failed to mutate after ms region information errors 

if (e instanceof RetriesExhaustedWithDetailsException) {	RetriesExhaustedWithDetailsException aggEx = (RetriesExhaustedWithDetailsException)e;	exceptionInfo = aggEx.getExhaustiveDescription();	} else {	StringWriter stackWriter = new StringWriter();	PrintWriter pw = new PrintWriter(stackWriter);	e.printStackTrace(pw);	pw.flush();	exceptionInfo = StringUtils.stringifyException(e);	}	
failed to mutate after ms region information errors 

========================= hbase sample_1351 =========================

concurrent = concurrentCount.decrementAndGet();	LOG.debug("[E] peerId="+ peerId +" procId="+ procId +" concurrent="+ concurrent);	assertTrue("dec-concurrent=" + concurrent, concurrent < NUM_PEERS);	} finally {	synchronized (concurrentPeers) {	assertTrue(concurrentPeers.remove(peerId));	}	procSet.release(proc);	}	} catch (Throwable e) {	
failed 

concurrent = concurrentCount.decrementAndGet();	LOG.debug("[E] tableId="+ tableId +" procId="+ procId +" concurrent="+ concurrent);	assertTrue("dec-concurrent=" + concurrent, concurrent < NUM_TABLES);	} finally {	synchronized (concurrentTables) {	assertTrue(concurrentTables.remove(tableId));	}	procSet.release(proc);	}	} catch (Throwable e) {	
failed 

========================= hbase sample_1845 =========================

}	} else if (ret > 0) {	deleteCell = null;	visibilityTagsDeleteColumns = null;	visiblityTagsDeleteColumnVersion = null;	} else {	throw new IllegalStateException("isDeleted failed: deleteBuffer=" + Bytes.toStringBinary(deleteCell.getQualifierArray(), deleteCell.getQualifierOffset(), deleteCell.getQualifierLength()) + ", qualifier=" + Bytes.toStringBinary(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength()) + ", timestamp=" + timestamp + ", comparison result: " + ret);	}	}	} catch (IOException e) {	
error in isdeleted check will treat cell as not deleted 

========================= hbase sample_2290 =========================

protected boolean startTransition(final MasterProcedureEnv env, final RegionStateNode regionNode) throws IOException {	if (regionNode.isInState(State.OPEN) && isServerOnline(env, regionNode)) {	
assigned not reassigning 

if (!forceNewPlan) {	if (this.targetServer != null) {	retain = targetServer.equals(lastRegionLocation);	regionNode.setRegionLocation(targetServer);	} else {	if (lastRegionLocation != null) {	retain = true;	regionNode.setRegionLocation(lastRegionLocation);	} else if (regionNode.getLastHost() != null) {	retain = true;	
setting lasthost as the region location 

protected boolean updateTransition(final MasterProcedureEnv env, final RegionStateNode regionNode) throws IOException, ProcedureSuspendedException {	if (LOG.isTraceEnabled()) {	
update 

protected boolean updateTransition(final MasterProcedureEnv env, final RegionStateNode regionNode) throws IOException, ProcedureSuspendedException {	if (LOG.isTraceEnabled()) {	}	if (regionNode.getRegionLocation() == null) {	setTransitionState(RegionTransitionState.REGION_TRANSITION_QUEUE);	return true;	}	if (!isServerOnline(env, regionNode)) {	
server not online re queuing 

}	if (regionNode.getRegionLocation() == null) {	setTransitionState(RegionTransitionState.REGION_TRANSITION_QUEUE);	return true;	}	if (!isServerOnline(env, regionNode)) {	setTransitionState(RegionTransitionState.REGION_TRANSITION_QUEUE);	return true;	}	if (env.getAssignmentManager().waitServerReportEvent(regionNode.getRegionLocation(), this)) {	
early suspend 

return true;	}	if (!isServerOnline(env, regionNode)) {	setTransitionState(RegionTransitionState.REGION_TRANSITION_QUEUE);	return true;	}	if (env.getAssignmentManager().waitServerReportEvent(regionNode.getRegionLocation(), this)) {	throw new ProcedureSuspendedException();	}	if (regionNode.isInState(State.OPEN)) {	
already assigned 

========================= hbase sample_2785 =========================

public void _testBackupRestoreSystemTable() throws Exception {	
test snapshot system table 

========================= hbase sample_534 =========================

protected void postPeerModification(MasterProcedureEnv env) throws IOException {	
successfully disabled peer 

========================= hbase sample_2855 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	
performing action change split policy of table 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	TableDescriptor tableDescriptor = admin.getDescriptor(tableName);	TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(tableDescriptor);	String chosenPolicy = possiblePolicies[random.nextInt(possiblePolicies.length)];	builder.setRegionSplitPolicyClassName(chosenPolicy);	
changing split policy to 

========================= hbase sample_3317 =========================

public PerfEvalCallable(Admin admin, String argv) {	this.admin = admin;	this.argv.addAll(Arrays.asList(argv.split(" ")));	
created performanceevaluationcallable with args 

protected void processOptions(CommandLine cmd) {	tableName = TableName.valueOf(cmd.getOptionValue(TABLE_NAME_KEY, TABLE_NAME_DEFAULT));	sleepTime = Long.parseLong(cmd.getOptionValue(SLEEP_TIME_KEY, SLEEP_TIME_DEFAULT));	replicaCount = Integer.parseInt(cmd.getOptionValue(REPLICA_COUNT_KEY, REPLICA_COUNT_DEFAULT));	primaryTimeout = Integer.parseInt(cmd.getOptionValue(PRIMARY_TIMEOUT_KEY, PRIMARY_TIMEOUT_DEFAULT));	clusterSize = Integer.parseInt(cmd.getOptionValue(NUM_RS_KEY, NUM_RS_DEFAULT));	
parsed options 

public void test() throws Exception {	int maxIters = 3;	String replicas = "--replicas=" + replicaCount;	String splitPolicy = "--splitPolicy=" + DisabledRegionSplitPolicy.class.getName();	String writeOpts = format("%s --nomapred --table=%s --presplit=16 sequentialWrite 4", splitPolicy, tableName);	String readOpts = format("--nomapred --table=%s --latency --sampleRate=0.1 randomRead 4", tableName);	String replicaReadOpts = format("%s %s", replicas, readOpts);	ArrayList<TimingResult> resultsWithoutReplicas = new ArrayList<>(maxIters);	ArrayList<TimingResult> resultsWithReplicas = new ArrayList<>(maxIters);	
populating table 

String splitPolicy = "--splitPolicy=" + DisabledRegionSplitPolicy.class.getName();	String writeOpts = format("%s --nomapred --table=%s --presplit=16 sequentialWrite 4", splitPolicy, tableName);	String readOpts = format("--nomapred --table=%s --latency --sampleRate=0.1 randomRead 4", tableName);	String replicaReadOpts = format("%s %s", replicas, readOpts);	ArrayList<TimingResult> resultsWithoutReplicas = new ArrayList<>(maxIters);	ArrayList<TimingResult> resultsWithReplicas = new ArrayList<>(maxIters);	new PerfEvalCallable(util.getAdmin(), writeOpts).call();	assertEquals("Table must be created with DisabledRegionSplitPolicy. Broken test.", DisabledRegionSplitPolicy.class.getName(), util.getAdmin().getTableDescriptor(tableName).getRegionSplitPolicyClassName());	startMonkey();	for (int i = 0; i < maxIters; i++) {	
launching non replica job 

ArrayList<TimingResult> resultsWithoutReplicas = new ArrayList<>(maxIters);	ArrayList<TimingResult> resultsWithReplicas = new ArrayList<>(maxIters);	new PerfEvalCallable(util.getAdmin(), writeOpts).call();	assertEquals("Table must be created with DisabledRegionSplitPolicy. Broken test.", DisabledRegionSplitPolicy.class.getName(), util.getAdmin().getTableDescriptor(tableName).getRegionSplitPolicyClassName());	startMonkey();	for (int i = 0; i < maxIters; i++) {	resultsWithoutReplicas.add(new PerfEvalCallable(util.getAdmin(), readOpts).call());	Thread.sleep(5000l);	}	cleanUpMonkey("Altering table.");	
altering replica count to 

startMonkey();	for (int i = 0; i < maxIters; i++) {	resultsWithoutReplicas.add(new PerfEvalCallable(util.getAdmin(), readOpts).call());	Thread.sleep(5000l);	}	cleanUpMonkey("Altering table.");	IntegrationTestingUtility.setReplicas(util.getAdmin(), tableName, replicaCount);	setUpMonkey();	startMonkey();	for (int i = 0; i < maxIters; i++) {	
launching replica job 

setUpMonkey();	startMonkey();	for (int i = 0; i < maxIters; i++) {	resultsWithReplicas.add(new PerfEvalCallable(util.getAdmin(), replicaReadOpts).call());	Thread.sleep(5000l);	}	double withoutReplicasStdevMean = calcMean("withoutReplicas", Stat.STDEV, resultsWithoutReplicas);	double withoutReplicas9999Mean = calcMean("withoutReplicas", Stat.FOUR_9S, resultsWithoutReplicas);	double withReplicasStdevMean = calcMean("withReplicas", Stat.STDEV, resultsWithReplicas);	double withReplicas9999Mean = calcMean("withReplicas", Stat.FOUR_9S, resultsWithReplicas);	
withoutReplicas withReplicas withoutReplicasStdevMean withReplicasStdevMean 

========================= hbase sample_3252 =========================

public static Long getPid() {	String name = ManagementFactory.getRuntimeMXBean().getName();	String[] nameParts = name.split("@");	if (nameParts.length == 2) {	try {	return Long.parseLong(nameParts[0]);	} catch (NumberFormatException ex) {	
failed to get pid from 

public static Long getPid() {	String name = ManagementFactory.getRuntimeMXBean().getName();	String[] nameParts = name.split("@");	if (nameParts.length == 2) {	try {	return Long.parseLong(nameParts[0]);	} catch (NumberFormatException ex) {	}	} else {	
don t know how to get pid from 

public static byte[] getIpAddressBytes() {	try {	return Addressing.getIpAddress().getAddress();	} catch (IOException ex) {	
failed to get ip address bytes 

========================= hbase sample_426 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

RegionInfo [] regions = MasterProcedureTestingUtility.createTable( procExec, tableName, null, ColumnFamilyName1, ColumnFamilyName2);	insertData(tableName);	assertTrue("not able to find a splittable region", regions != null);	assertTrue("not able to find a splittable region", regions.length == 1);	collectAssignmentManagerMetrics();	try {	long procId1 = procExec.submitProcedure( new SplitTableRegionProcedure(procExec.getEnvironment(), regions[0], null));	ProcedureTestingUtility.waitProcedure(procExec, procId1);	fail("unexpected procedure start with invalid split-key");	} catch (DoNotRetryIOException e) {	
expected split procedure construction failure 

========================= hbase sample_1812 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3086 =========================

public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {	FileSplit fileSplit = (FileSplit) split;	conf = context.getConfiguration();	Path path = fileSplit.getPath();	FileSystem fs = path.getFileSystem(conf);	
initialize hfilerecordreader for 

public boolean nextKeyValue() throws IOException, InterruptedException {	boolean hasNext;	if (!seeked) {	
seeking to start 

========================= hbase sample_3439 =========================

protected void snapshotCopy(BackupInfo backupInfo) throws Exception {	
snapshot copy is starting 

protected void snapshotCopy(BackupInfo backupInfo) throws Exception {	backupInfo.setPhase(BackupPhase.SNAPSHOTCOPY);	BackupCopyJob copyService = BackupRestoreFactory.getBackupCopyJob(conf);	float numOfSnapshots = backupInfo.getSnapshotNames().size();	
there are snapshots to be copied 

float numOfSnapshots = backupInfo.getSnapshotNames().size();	for (TableName table : backupInfo.getTables()) {	int res = 0;	String[] args = new String[4];	args[0] = "-snapshot";	args[1] = backupInfo.getSnapshotName(table);	args[2] = "-copy-to";	args[3] = backupInfo.getTableBackupDir(table);	String jobname = "Full-Backup_" + backupInfo.getBackupId() + "_" + table.getNameAsString();	if (LOG.isDebugEnabled()) {	
setting snapshot copy job name to 

int res = 0;	String[] args = new String[4];	args[0] = "-snapshot";	args[1] = backupInfo.getSnapshotName(table);	args[2] = "-copy-to";	args[3] = backupInfo.getTableBackupDir(table);	String jobname = "Full-Backup_" + backupInfo.getBackupId() + "_" + table.getNameAsString();	if (LOG.isDebugEnabled()) {	}	conf.set(JOB_NAME_CONF_KEY, jobname);	
copy snapshot to 

args[0] = "-snapshot";	args[1] = backupInfo.getSnapshotName(table);	args[2] = "-copy-to";	args[3] = backupInfo.getTableBackupDir(table);	String jobname = "Full-Backup_" + backupInfo.getBackupId() + "_" + table.getNameAsString();	if (LOG.isDebugEnabled()) {	}	conf.set(JOB_NAME_CONF_KEY, jobname);	res = copyService.copy(backupInfo, backupManager, conf, BackupType.FULL, args);	if (res != 0) {	
exporting snapshot failed with return code 

args[3] = backupInfo.getTableBackupDir(table);	String jobname = "Full-Backup_" + backupInfo.getBackupId() + "_" + table.getNameAsString();	if (LOG.isDebugEnabled()) {	}	conf.set(JOB_NAME_CONF_KEY, jobname);	res = copyService.copy(backupInfo, backupManager, conf, BackupType.FULL, args);	if (res != 0) {	throw new IOException("Failed of exporting snapshot " + args[1] + " to " + args[3] + " with reason code " + res);	}	conf.unset(JOB_NAME_CONF_KEY);	
snapshot copy finished 

public void execute() throws IOException {	try (Admin admin = conn.getAdmin()) {	beginBackup(backupManager, backupInfo);	String savedStartCode = null;	boolean firstBackup = false;	savedStartCode = backupManager.readBackupStartCode();	firstBackup = savedStartCode == null || Long.parseLong(savedStartCode) == 0L;	if (firstBackup) {	backupManager.writeBackupStartCode(0L);	}	
execute roll log procedure for full backup 

if (firstBackup) {	List<String> logFiles = BackupUtils.getWALFilesOlderThan(conf, newTimestamps);	backupManager.recordWALFiles(logFiles);	}	backupInfo.setPhase(BackupPhase.SNAPSHOT);	for (TableName tableName : tableList) {	String snapshotName = "snapshot_" + Long.toString(EnvironmentEdgeManager.currentTime()) + "_" + tableName.getNamespaceAsString() + "_" + tableName.getQualifierAsString();	snapshotTable(admin, tableName, snapshotName);	backupInfo.setSnapshotName(tableName, snapshotName);	}	
snapshot copy for 

protected void snapshotTable(Admin admin, TableName tableName, String snapshotName) throws IOException {	int maxAttempts = conf.getInt(BACKUP_MAX_ATTEMPTS_KEY, DEFAULT_BACKUP_MAX_ATTEMPTS);	int pause = conf.getInt(BACKUP_ATTEMPTS_PAUSE_MS_KEY, DEFAULT_BACKUP_ATTEMPTS_PAUSE_MS);	int attempts = 0;	while (attempts++ < maxAttempts) {	try {	admin.snapshot(snapshotName, tableName);	return;	} catch (IOException ee) {	
snapshot attempt failed for table sleeping for ms 

========================= hbase sample_563 =========================

public List<Path> compact(CompactionRequestImpl request, final int targetCount, final long targetSize, final byte[] left, final byte[] right, byte[] majorRangeFromRow, byte[] majorRangeToRow, ThroughputController throughputController, User user) throws IOException {	if (LOG.isDebugEnabled()) {	
executing compaction with target file size no more than files in range 

========================= hbase sample_2678 =========================

protected void stopServiceThreads() {	
adding a delay to the regionserver shutdown 

protected void stopServiceThreads() {	try {	Thread.sleep(2000);	} catch (InterruptedException ex) {	
interrupted while sleeping 

========================= hbase sample_1957 =========================

try {	for (int i = 0; i < 100; i++) {	byte[] row = Bytes.toBytes("putRow" + i);	Put put = new Put(row);	put.addColumn("cf".getBytes(), Bytes.toBytes(0), Bytes.toBytes(""));	latch.await();	region.batchMutate(new Mutation[] { put });	Thread.sleep(10);	}	} catch (Throwable t) {	
error happend when increment 

try {	for (int i = 0; i < 100; i++) {	byte[] row = Bytes.toBytes("incrementRow" + i);	Increment inc = new Increment(row);	inc.addColumn("cf".getBytes(), Bytes.toBytes(0), 1);	region.increment(inc);	latch.countDown();	Thread.sleep(10);	}	} catch (Throwable t) {	
error happend when put 

========================= hbase sample_1687 =========================

LOG.trace(this + " execute state=" + state);	}	try {	switch (state) {	case DELETE_TABLE_PRE_OPERATION: boolean deletable = prepareDelete(env);	releaseSyncLatch();	if (!deletable) {	assert isFailed() : "the delete should have an exception here";	return Flow.NO_MORE_STATE;	}	
waiting for regions in transition 

if (!deletable) {	assert isFailed() : "the delete should have an exception here";	return Flow.NO_MORE_STATE;	}	regions = env.getAssignmentManager().getRegionStates().getRegionsOfTable(getTableName());	assert regions != null && !regions.isEmpty() : "unexpected 0 regions";	ProcedureSyncWait.waitRegionInTransition(env, regions);	preDelete(env);	setNextState(DeleteTableState.DELETE_TABLE_REMOVE_FROM_META);	break;	
delete regions from meta 

}	regions = env.getAssignmentManager().getRegionStates().getRegionsOfTable(getTableName());	assert regions != null && !regions.isEmpty() : "unexpected 0 regions";	ProcedureSyncWait.waitRegionInTransition(env, regions);	preDelete(env);	setNextState(DeleteTableState.DELETE_TABLE_REMOVE_FROM_META);	break;	DeleteTableProcedure.deleteFromMeta(env, getTableName(), regions);	setNextState(DeleteTableState.DELETE_TABLE_CLEAR_FS_LAYOUT);	break;	
delete from filesystem 

preDelete(env);	setNextState(DeleteTableState.DELETE_TABLE_REMOVE_FROM_META);	break;	DeleteTableProcedure.deleteFromMeta(env, getTableName(), regions);	setNextState(DeleteTableState.DELETE_TABLE_CLEAR_FS_LAYOUT);	break;	DeleteTableProcedure.deleteFromFs(env, getTableName(), regions, true);	setNextState(DeleteTableState.DELETE_TABLE_UPDATE_DESC_CACHE);	regions = null;	break;	
delete descriptor 

DeleteTableProcedure.deleteFromMeta(env, getTableName(), regions);	setNextState(DeleteTableState.DELETE_TABLE_CLEAR_FS_LAYOUT);	break;	DeleteTableProcedure.deleteFromFs(env, getTableName(), regions, true);	setNextState(DeleteTableState.DELETE_TABLE_UPDATE_DESC_CACHE);	regions = null;	break;	DeleteTableProcedure.deleteTableDescriptorCache(env, getTableName());	setNextState(DeleteTableState.DELETE_TABLE_UNASSIGN_REGIONS);	break;	
delete assignment state 

setNextState(DeleteTableState.DELETE_TABLE_UPDATE_DESC_CACHE);	regions = null;	break;	DeleteTableProcedure.deleteTableDescriptorCache(env, getTableName());	setNextState(DeleteTableState.DELETE_TABLE_UNASSIGN_REGIONS);	break;	DeleteTableProcedure.deleteAssignmentState(env, getTableName());	setNextState(DeleteTableState.DELETE_TABLE_POST_OPERATION);	break;	case DELETE_TABLE_POST_OPERATION: postDelete(env);	
delete completed 

HFileArchiver.archiveRegion(fs, mfs.getRootDir(), tempTableDir, files[i].getPath());	}	}	fs.delete(tempdir, true);	}	throw new IOException("Unable to move '" + tableDir + "' to temp '" + tempTableDir + "'");	}	}	if (archive) {	for (RegionInfo hri : regions) {	
archiving region from fs 

}	fs.delete(tempdir, true);	}	throw new IOException("Unable to move '" + tableDir + "' to temp '" + tempTableDir + "'");	}	}	if (archive) {	for (RegionInfo hri : regions) {	HFileArchiver.archiveRegion(fs, mfs.getRootDir(), tempTableDir, HRegion.getRegionDir(tempTableDir, hri.getEncodedName()));	}	
table archived 

Connection connection = env.getMasterServices().getConnection();	Scan tableScan = MetaTableAccessor.getScanForTableName(connection, tableName);	try (Table metaTable = connection.getTable(TableName.META_TABLE_NAME)) {	List<Delete> deletes = new ArrayList<>();	try (ResultScanner resScanner = metaTable.getScanner(tableScan)) {	for (Result result : resScanner) {	deletes.add(new Delete(result.getRow()));	}	}	if (!deletes.isEmpty()) {	
deleting some vestigial rows of from 

protected static void deleteAssignmentState(final MasterProcedureEnv env, final TableName tableName) throws IOException {	
removing from region states 

protected static void deleteAssignmentState(final MasterProcedureEnv env, final TableName tableName) throws IOException {	env.getMasterServices().getAssignmentManager().deleteTable(tableName);	
marking as deleted 

protected static void deleteTableDescriptorCache(final MasterProcedureEnv env, final TableName tableName) throws IOException {	
removing descriptor 

========================= hbase sample_2802 =========================

Set<HStore> specificStoresToFlush = new HashSet<>();	for (HStore store : stores) {	if (shouldFlush(store)) {	specificStoresToFlush.add(store);	}	}	if (!specificStoresToFlush.isEmpty()) {	return specificStoresToFlush;	}	if (LOG.isDebugEnabled()) {	
since none of the cfs were above the size flushing all 

========================= hbase sample_2551 =========================

public FileIOEngine(long capacity, boolean maintainPersistence, String... filePaths) throws IOException {	this.sizePerFile = capacity / filePaths.length;	this.capacity = this.sizePerFile * filePaths.length;	this.filePaths = filePaths;	this.fileChannels = new FileChannel[filePaths.length];	if (!maintainPersistence) {	for (String filePath : filePaths) {	File file = new File(filePath);	if (file.exists()) {	if (LOG.isDebugEnabled()) {	
file already exists deleting 

String filePath = filePaths[i];	try {	rafs[i] = new RandomAccessFile(filePath, "rw");	long totalSpace = new File(filePath).getTotalSpace();	if (totalSpace < sizePerFile) {	String msg = "Only " + StringUtils.byteDesc(totalSpace) + " total space under " + filePath + ", not enough for requested " + StringUtils.byteDesc(sizePerFile);	LOG.warn(msg);	}	rafs[i].setLength(sizePerFile);	fileChannels[i] = rafs[i].getChannel();	
allocating cache on the path 

try {	rafs[i] = new RandomAccessFile(filePath, "rw");	long totalSpace = new File(filePath).getTotalSpace();	if (totalSpace < sizePerFile) {	String msg = "Only " + StringUtils.byteDesc(totalSpace) + " total space under " + filePath + ", not enough for requested " + StringUtils.byteDesc(sizePerFile);	LOG.warn(msg);	}	rafs[i].setLength(sizePerFile);	fileChannels[i] = rafs[i].getChannel();	} catch (IOException fex) {	
failed allocating cache on 

public void sync() throws IOException {	for (int i = 0; i < fileChannels.length; i++) {	try {	if (fileChannels[i] != null) {	fileChannels[i].force(true);	}	} catch (IOException ie) {	
failed syncing data to 

public void shutdown() {	for (int i = 0; i < filePaths.length; i++) {	try {	if (fileChannels[i] != null) {	fileChannels[i].close();	}	if (rafs[i] != null) {	rafs[i].close();	}	} catch (IOException ex) {	
failed closing when shudown the ioengine 

int bufLimit = buffer.limit();	while (true) {	FileChannel fileChannel = fileChannels[accessFileNum];	int accessLen = 0;	if (endFileNum > accessFileNum) {	buffer.limit((int) (buffer.limit() - remainingAccessDataLen + sizePerFile - accessOffset));	}	try {	accessLen = accessor.access(fileChannel, buffer, accessOffset);	} catch (ClosedChannelException e) {	
caught closedchannelexception accessing bucketcache reopening file 

========================= hbase sample_2414 =========================

public void test() throws InterruptedException, ExecutionException, IOException {	
started test 

public void testIndependentZKConnections() throws IOException {	try (ReadOnlyZKClient zk1 = REGISTRY.getZKClient()) {	Configuration otherConf = new Configuration(TEST_UTIL.getConfiguration());	otherConf.set(HConstants.ZOOKEEPER_QUORUM, "127.0.0.1");	try (ZKAsyncRegistry otherRegistry = new ZKAsyncRegistry(otherConf)) {	ReadOnlyZKClient zk2 = otherRegistry.getZKClient();	assertNotSame("Using a different configuration / quorum should result in different " + "backing zk connection.", zk1, zk2);	assertNotEquals( "Using a different configrution / quorum should be reflected in the zk connection.", zk1.getConnectString(), zk2.getConnectString());	}	} finally {	
done 

========================= hbase sample_2044 =========================

public void close() {	if (stream == null) return;	try {	stream.close();	} catch (IOException e) {	
unable to close the wal file 

public void removeFile(final Path walArchiveDir) throws IOException {	close();	boolean archived = false;	if (walArchiveDir != null) {	Path archivedFile = new Path(walArchiveDir, logFile.getName());	
archiving to 

public void removeFile(final Path walArchiveDir) throws IOException {	close();	boolean archived = false;	if (walArchiveDir != null) {	Path archivedFile = new Path(walArchiveDir, logFile.getName());	if (!fs.rename(logFile, archivedFile)) {	
failed archive of deleting 

boolean archived = false;	if (walArchiveDir != null) {	Path archivedFile = new Path(walArchiveDir, logFile.getName());	if (!fs.rename(logFile, archivedFile)) {	} else {	archived = true;	}	}	if (!archived) {	if (!fs.delete(logFile, false)) {	
failed delete of 

========================= hbase sample_1238 =========================

private WALEntrySinkFilter setupWALEntrySinkFilter() throws IOException {	Class<?> walEntryFilterClass = this.conf.getClass(WALEntrySinkFilter.WAL_ENTRY_FILTER_KEY, null);	WALEntrySinkFilter filter = null;	try {	filter = walEntryFilterClass == null? null: (WALEntrySinkFilter)walEntryFilterClass.newInstance();	} catch (Exception e) {	
failed to instantiate 

((Delete) mutation).add(cell);	} else {	((Put) mutation).add(cell);	}	previousCell = cell;	}	}	totalReplicated++;	}	if (!rowMap.isEmpty()) {	
started replicating mutations 

}	previousCell = cell;	}	}	totalReplicated++;	}	if (!rowMap.isEmpty()) {	for (Entry<TableName, Map<List<UUID>, List<Row>>> entry : rowMap.entrySet()) {	batch(entry.getKey(), entry.getValue().values());	}	
finished replicating mutations 

}	}	totalReplicated++;	}	if (!rowMap.isEmpty()) {	for (Entry<TableName, Map<List<UUID>, List<Row>>> entry : rowMap.entrySet()) {	batch(entry.getKey(), entry.getValue().values());	}	}	if (bulkLoadHFileMap != null && !bulkLoadHFileMap.isEmpty()) {	
started replicating bulk loaded data 

totalReplicated++;	}	if (!rowMap.isEmpty()) {	for (Entry<TableName, Map<List<UUID>, List<Row>>> entry : rowMap.entrySet()) {	batch(entry.getKey(), entry.getValue().values());	}	}	if (bulkLoadHFileMap != null && !bulkLoadHFileMap.isEmpty()) {	HFileReplicator hFileReplicator = new HFileReplicator(this.provider.getConf(this.conf, replicationClusterId), sourceBaseNamespaceDirPath, sourceHFileArchiveDirPath, bulkLoadHFileMap, conf, getConnection());	hFileReplicator.replicate();	
finished replicating bulk loaded data 

}	if (bulkLoadHFileMap != null && !bulkLoadHFileMap.isEmpty()) {	HFileReplicator hFileReplicator = new HFileReplicator(this.provider.getConf(this.conf, replicationClusterId), sourceBaseNamespaceDirPath, sourceHFileArchiveDirPath, bulkLoadHFileMap, conf, getConnection());	hFileReplicator.replicate();	}	int size = entries.size();	this.metrics.setAgeOfLastAppliedOp(entries.get(size - 1).getKey().getWriteTime());	this.metrics.applyBatch(size + hfilesReplicated, hfilesReplicated);	this.totalReplicatedEdits.addAndGet(totalReplicated);	} catch (IOException ex) {	
unable to accept edit because 

try {	if (this.sharedHtableCon != null) {	synchronized (sharedHtableConLock) {	if (this.sharedHtableCon != null) {	this.sharedHtableCon.close();	this.sharedHtableCon = null;	}	}	}	} catch (IOException e) {	
ioexception while closing the connection 

========================= hbase sample_2947 =========================

waitOnCrashProcessing();	UTIL.getHBaseCluster().getMaster().balance();	assertRegionsAreBalanced();	LOG.info("Readding third server=" + UTIL.getHBaseCluster().startRegionServer().getRegionServer().getServerName());	LOG.info("Added fourth server=" + UTIL.getHBaseCluster().startRegionServer().getRegionServer().getServerName());	waitOnCrashProcessing();	waitForAllRegionsAssigned();	assert(UTIL.getHBaseCluster().getMaster().balance() == true);	assertRegionsAreBalanced();	for (int i = 0; i < 6; i++){	
adding th region server 

private void waitOnCrashProcessing() {	while (UTIL.getHBaseCluster().getMaster().getServerManager().areDeadServersInProgress()) {	
waiting on processing of crashed server before proceeding 

waitForAllRegionsAssigned();	long regionCount = UTIL.getMiniHBaseCluster().countServedRegions();	List<HRegionServer> servers = getOnlineRegionServers();	double avg = (double)regionCount / (double)servers.size();	int avgLoadPlusSlop = (int)Math.ceil(avg * (1 + slop));	int avgLoadMinusSlop = (int)Math.floor(avg * (1 - slop)) - 1;	if (this.balancerName.contains("StochasticLoadBalancer")) {	avgLoadPlusSlop++;	avgLoadMinusSlop--;	}	
there are servers and regions load average low border up border attempt 

List<HRegionServer> servers = getOnlineRegionServers();	double avg = (double)regionCount / (double)servers.size();	int avgLoadPlusSlop = (int)Math.ceil(avg * (1 + slop));	int avgLoadMinusSlop = (int)Math.floor(avg * (1 - slop)) - 1;	if (this.balancerName.contains("StochasticLoadBalancer")) {	avgLoadPlusSlop++;	avgLoadMinusSlop--;	}	for (HRegionServer server : servers) {	int serverLoad = ProtobufUtil.getOnlineRegions(server.getRSRpcServices()).size();	
avg actual 

avgLoadPlusSlop++;	avgLoadMinusSlop--;	}	for (HRegionServer server : servers) {	int serverLoad = ProtobufUtil.getOnlineRegions(server.getRSRpcServices()).size();	if (!(avg > 2.0 && serverLoad <= avgLoadPlusSlop && serverLoad >= avgLoadMinusSlop)) {	for (RegionInfo hri : ProtobufUtil.getOnlineRegions(server.getRSRpcServices())) {	if (hri.isMetaRegion()) serverLoad--;	}	if (!(serverLoad <= avgLoadPlusSlop && serverLoad >= avgLoadMinusSlop)) {	
isn t balanced avg actual slop 

private void waitForAllRegionsAssigned() throws IOException {	int totalRegions = HBaseTestingUtility.KEYS.length;	try {	Thread.sleep(200);	} catch (InterruptedException e) {	throw new InterruptedIOException();	}	while (UTIL.getMiniHBaseCluster().countServedRegions() < totalRegions) {	
waiting for there to be regions but there are right now 

========================= hbase sample_1557 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

public Response getBinary(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get as 

public Response put(final CellSetModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
put 

public Response putBinary(final byte[] message, final @Context UriInfo uriInfo, final @Context HttpHeaders headers) {	if (LOG.isTraceEnabled()) {	
put as 

public Response post(final CellSetModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
post 

public Response postBinary(final byte[] message, final @Context UriInfo uriInfo, final @Context HttpHeaders headers) {	if (LOG.isTraceEnabled()) {	
post as 

public Response delete(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
delete 

return Response.status(Response.Status.BAD_REQUEST) .type(MIMETYPE_TEXT).entity("Bad request" + CRLF) .build();	}	}	}	Table table = null;	try {	table = servlet.getTable(tableResource.getName());	table.delete(delete);	servlet.getMetrics().incrementSucessfulDeleteRequests(1);	if (LOG.isTraceEnabled()) {	
delete 

servlet.getMetrics().incrementSucessfulDeleteRequests(1);	if (LOG.isTraceEnabled()) {	}	} catch (Exception e) {	servlet.getMetrics().incrementFailedDeleteRequests(1);	return processException(e);	} finally {	if (table != null) try {	table.close();	} catch (IOException ioe) {	
exception received while closing the table 

========================= hbase sample_3090 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

private boolean awaitForLocked(long procId, long timeoutInMs) throws Exception {	long deadline = System.currentTimeMillis() + timeoutInMs;	while (System.currentTimeMillis() < deadline) {	LockHeartbeatResponse response = masterRpcService.lockHeartbeat(null, LockHeartbeatRequest.newBuilder().setProcId(procId).build());	if (response.getLockStatus() == LockHeartbeatResponse.LockStatus.LOCKED) {	assertEquals(response.getTimeoutMs(), HEARTBEAT_TIMEOUT);	
proc id s acquired lock 

private void sendHeartbeatAndCheckLocked(long procId, boolean isLocked) throws ServiceException {	LockHeartbeatResponse response = masterRpcService.lockHeartbeat(null, LockHeartbeatRequest.newBuilder().setProcId(procId).build());	if (isLocked) {	assertEquals(LockHeartbeatResponse.LockStatus.LOCKED, response.getLockStatus());	} else {	assertEquals(LockHeartbeatResponse.LockStatus.UNLOCKED, response.getLockStatus());	}	
proc id s s 

========================= hbase sample_1804 =========================

public boolean needsCompaction(Collection<HStoreFile> storeFiles, List<HStoreFile> filesCompacting) {	ArrayList<HStoreFile> candidates = new ArrayList<>(storeFiles);	try {	return !selectMinorCompaction(candidates, false, true).getFiles().isEmpty();	} catch (Exception e) {	
can not check for compaction 

public boolean shouldPerformMajorCompaction(Collection<HStoreFile> filesToCompact) throws IOException {	long mcTime = getNextMajorCompactTime(filesToCompact);	if (filesToCompact == null || mcTime == 0) {	if (LOG.isDebugEnabled()) {	
filestocompact mctime 

long mcTime = getNextMajorCompactTime(filesToCompact);	if (filesToCompact == null || mcTime == 0) {	if (LOG.isDebugEnabled()) {	}	return false;	}	long lowTimestamp = StoreUtils.getLowestTimestamp(filesToCompact);	long now = EnvironmentEdgeManager.currentTime();	if (lowTimestamp <= 0L || lowTimestamp >= (now - mcTime)) {	if (LOG.isDebugEnabled()) {	
lowtimestamp lowtimestamp now mctime 

return false;	}	long cfTTL = this.storeConfigInfo.getStoreFileTtl();	HDFSBlocksDistribution hdfsBlocksDistribution = new HDFSBlocksDistribution();	List<Long> boundaries = getCompactBoundariesForMajor(filesToCompact, now);	boolean[] filesInWindow = new boolean[boundaries.size()];	for (HStoreFile file: filesToCompact) {	OptionalLong minTimestamp = file.getMinimumTimestamp();	long oldest = minTimestamp.isPresent() ? now - minTimestamp.getAsLong() : Long.MIN_VALUE;	if (cfTTL != Long.MAX_VALUE && oldest >= cfTTL) {	
major compaction triggered on store for ttl maintenance 

HDFSBlocksDistribution hdfsBlocksDistribution = new HDFSBlocksDistribution();	List<Long> boundaries = getCompactBoundariesForMajor(filesToCompact, now);	boolean[] filesInWindow = new boolean[boundaries.size()];	for (HStoreFile file: filesToCompact) {	OptionalLong minTimestamp = file.getMinimumTimestamp();	long oldest = minTimestamp.isPresent() ? now - minTimestamp.getAsLong() : Long.MIN_VALUE;	if (cfTTL != Long.MAX_VALUE && oldest >= cfTTL) {	return true;	}	if (!file.isMajorCompactionResult() || file.isBulkLoadResult()) {	
major compaction triggered on store because there are new files and time since last major compaction ms 

return true;	}	if (!file.isMajorCompactionResult() || file.isBulkLoadResult()) {	return true;	}	int lowerWindowIndex = Collections.binarySearch(boundaries, minTimestamp.orElse(Long.MAX_VALUE));	int upperWindowIndex = Collections.binarySearch(boundaries, file.getMaximumTimestamp().orElse(Long.MAX_VALUE));	lowerWindowIndex = (lowerWindowIndex < 0) ? Math.abs(lowerWindowIndex + 2) : lowerWindowIndex;	upperWindowIndex = (upperWindowIndex < 0) ? Math.abs(upperWindowIndex + 2) : upperWindowIndex;	if (lowerWindowIndex != upperWindowIndex) {	
major compaction triggered on store because file has data with timestamps cross window boundaries 

if (!file.isMajorCompactionResult() || file.isBulkLoadResult()) {	return true;	}	int lowerWindowIndex = Collections.binarySearch(boundaries, minTimestamp.orElse(Long.MAX_VALUE));	int upperWindowIndex = Collections.binarySearch(boundaries, file.getMaximumTimestamp().orElse(Long.MAX_VALUE));	lowerWindowIndex = (lowerWindowIndex < 0) ? Math.abs(lowerWindowIndex + 2) : lowerWindowIndex;	upperWindowIndex = (upperWindowIndex < 0) ? Math.abs(upperWindowIndex + 2) : upperWindowIndex;	if (lowerWindowIndex != upperWindowIndex) {	return true;	} else if (filesInWindow[upperWindowIndex]) {	
major compaction triggered on store because there are more than one file in some windows 

return true;	} else if (filesInWindow[upperWindowIndex]) {	return true;	} else {	filesInWindow[upperWindowIndex] = true;	}	hdfsBlocksDistribution.add(file.getHDFSBlockDistribution());	}	float blockLocalityIndex = hdfsBlocksDistribution .getBlockLocalityIndex(RSRpcServices.getHostname(comConf.conf, false));	if (blockLocalityIndex < comConf.getMinLocalityToForceCompact()) {	
major compaction triggered on store to make hdfs blocks local current blocklocalityindex is min 

return true;	} else {	filesInWindow[upperWindowIndex] = true;	}	hdfsBlocksDistribution.add(file.getHDFSBlockDistribution());	}	float blockLocalityIndex = hdfsBlocksDistribution .getBlockLocalityIndex(RSRpcServices.getHostname(comConf.conf, false));	if (blockLocalityIndex < comConf.getMinLocalityToForceCompact()) {	return true;	}	
skipping major compaction of because the files are already major compacted 

protected CompactionRequestImpl createCompactionRequest(ArrayList<HStoreFile> candidateSelection, boolean tryingMajor, boolean mayUseOffPeak, boolean mayBeStuck) throws IOException {	CompactionRequestImpl result = tryingMajor ? selectMajorCompaction(candidateSelection) : selectMinorCompaction(candidateSelection, mayUseOffPeak, mayBeStuck);	if (LOG.isDebugEnabled()) {	
generated compaction request 

if (compResult > 0) {	window = window.nextEarlierWindow();	minThreshold = comConf.getMinFilesToCompact();	} else {	ArrayList<HStoreFile> fileList = Lists.newArrayList();	while (it.hasNext() && window.compareToTimestamp(it.peek().getSecond()) <= 0) {	fileList.add(it.next().getFirst());	}	if (fileList.size() >= minThreshold) {	if (LOG.isDebugEnabled()) {	
processing files for window 

private static long getOldestToCompact(long maxAgeMillis, long now) {	try {	return LongMath.checkedSubtract(now, maxAgeMillis);	} catch (ArithmeticException ae) {	
value for all the files will be eligible for minor compaction 

========================= hbase sample_2681 =========================

private void writeResponse(ChannelHandlerContext ctx, byte[] response) {	if (LOG.isDebugEnabled()) {	
will send token of size from initsaslcontext 

if (len == SaslUtil.SWITCH_TO_SIMPLE_AUTH) {	saslRpcClient.dispose();	if (saslRpcClient.fallbackAllowed) {	saslPromise.trySuccess(false);	} else {	saslPromise.tryFailure(new FallbackDisallowedException());	}	return;	}	if (LOG.isDebugEnabled()) {	
will read input token of size for processing by initsaslcontext 

========================= hbase sample_125 =========================

return false;	}	String host = parseHostNameFromLogFile(p);	if (host == null) {	return false;	}	Long oldTimestamp = hostTimestampMap.get(host);	Long currentLogTS = BackupUtils.getCreationTime(p);	return currentLogTS <= oldTimestamp;	} catch (Exception e) {	
can not parse 

public static boolean checkPathExist(String backupStr, Configuration conf) throws IOException {	boolean isExist = false;	Path backupPath = new Path(backupStr);	FileSystem fileSys = backupPath.getFileSystem(conf);	String targetFsScheme = fileSys.getUri().getScheme();	if (LOG.isTraceEnabled()) {	
schema of given url is 

String newMsg = null;	if (expMsg.contains("No FileSystem for scheme")) {	newMsg = "Unsupported filesystem scheme found in the backup target url. Error Message: " + newMsg;	LOG.error(newMsg);	throw new IOException(newMsg);	} else {	throw e;	}	}	if (targetExists) {	
using existing backup root dir 

if (expMsg.contains("No FileSystem for scheme")) {	newMsg = "Unsupported filesystem scheme found in the backup target url. Error Message: " + newMsg;	LOG.error(newMsg);	throw new IOException(newMsg);	} else {	throw e;	}	}	if (targetExists) {	} else {	
backup root dir does not exist will be created 

private static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	
trying to cleanup up target dir 

private static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	
no target directory specified for 

private static void cleanupTargetDir(BackupInfo backupInfo, Configuration conf) {	try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	return;	}	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	
cleaning up backup data at done 

try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	return;	}	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	
no data has been found in 

FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	for (TableName table : backupInfo.getTables()) {	Path targetDirPath = new Path(getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	}	Path tableDir = targetDirPath.getParent();	FileStatus[] backups = listStatus(outputFs, tableDir, null);	if (backups == null || backups.length == 0) {	outputFs.delete(tableDir, true);	
is empty remove it 

} else {	}	Path tableDir = targetDirPath.getParent();	FileStatus[] backups = listStatus(outputFs, tableDir, null);	if (backups == null || backups.length == 0) {	outputFs.delete(tableDir, true);	}	}	outputFs.delete(new Path(targetDir, backupInfo.getBackupId()), true);	} catch (IOException e1) {	
cleaning up backup data of at failed due to 

RemoteIterator<LocatedFileStatus> it = fs.listLocatedStatus(backupRootPath);	List<BackupInfo> infos = new ArrayList<BackupInfo>();	while (it.hasNext()) {	LocatedFileStatus lfs = it.next();	if (!lfs.isDirectory()) continue;	String backupId = lfs.getPath().getName();	try {	BackupInfo info = loadBackupInfo(backupRootPath, backupId, fs);	infos.add(info);	} catch (IOException e) {	
can not load backup info from 

public static boolean validate(HashMap<TableName, BackupManifest> backupManifestMap, Configuration conf) throws IOException {	boolean isValid = true;	for (Entry<TableName, BackupManifest> manifestEntry : backupManifestMap.entrySet()) {	TableName table = manifestEntry.getKey();	TreeSet<BackupImage> imageSet = new TreeSet<BackupImage>();	ArrayList<BackupImage> depList = manifestEntry.getValue().getDependentListByTable(table);	if (depList != null && !depList.isEmpty()) {	imageSet.addAll(depList);	}	
dependent image s from old to new 

for (Entry<TableName, BackupManifest> manifestEntry : backupManifestMap.entrySet()) {	TableName table = manifestEntry.getKey();	TreeSet<BackupImage> imageSet = new TreeSet<BackupImage>();	ArrayList<BackupImage> depList = manifestEntry.getValue().getDependentListByTable(table);	if (depList != null && !depList.isEmpty()) {	imageSet.addAll(depList);	}	for (BackupImage image : imageSet) {	String imageDir = HBackupFileSystem.getTableBackupDir(image.getRootDir(), image.getBackupId(), table);	if (!BackupUtils.checkPathExist(imageDir, conf)) {	
error backup image does not exist 

ArrayList<BackupImage> depList = manifestEntry.getValue().getDependentListByTable(table);	if (depList != null && !depList.isEmpty()) {	imageSet.addAll(depList);	}	for (BackupImage image : imageSet) {	String imageDir = HBackupFileSystem.getTableBackupDir(image.getRootDir(), image.getBackupId(), table);	if (!BackupUtils.checkPathExist(imageDir, conf)) {	isValid = false;	break;	}	
backup image for is available 

========================= hbase sample_575 =========================

public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {	if (filterConfig == null) return;	String uri = ((HttpServletRequest)request).getRequestURI();	
filtering 

static void access(String urlstring) throws IOException {	
access 

========================= hbase sample_3213 =========================

public void intercept(FastFailInterceptorContext context) throws PreemptiveFastFailException {	context.setFailureInfo(repeatedFailuresMap.get(context.getServer()));	if (inFastFailMode(context.getServer()) && !currentThreadInFastFailMode()) {	context.setRetryDespiteFastFailMode(shouldRetryInspiteOfFastFail(context .getFailureInfo()));	if (!context.isRetryDespiteFastFailMode()) {	
throwing pffe tries 

protected void occasionallyCleanupFailureInformation() {	long now = System.currentTimeMillis();	if (!(now > lastFailureMapCleanupTimeMilliSec + failureMapCleanupIntervalMilliSec)) return;	StringBuilder sb = new StringBuilder();	for (Entry<ServerName, FailureInfo> entry : repeatedFailuresMap.entrySet()) {	if (now > entry.getValue().timeOfLatestAttemptMilliSec + failureMapCleanupIntervalMilliSec) {	repeatedFailuresMap.remove(entry.getKey());	} else if (now > entry.getValue().timeOfFirstFailureMilliSec + this.fastFailClearingTimeMilliSec) {	
been failing for a long time clearing out 

for (Entry<ServerName, FailureInfo> entry : repeatedFailuresMap.entrySet()) {	if (now > entry.getValue().timeOfLatestAttemptMilliSec + failureMapCleanupIntervalMilliSec) {	repeatedFailuresMap.remove(entry.getKey());	} else if (now > entry.getValue().timeOfFirstFailureMilliSec + this.fastFailClearingTimeMilliSec) {	repeatedFailuresMap.remove(entry.getKey());	} else {	sb.append(entry.getKey().toString()).append(" failing ") .append(entry.getValue().toString()).append("\n");	}	}	if (sb.length() > 0) {	
preemptive failure enabled for 

private void updateFailureInfoForServer(ServerName server, FailureInfo fInfo, boolean didTry, boolean couldNotCommunicate, boolean retryDespiteFastFailMode) {	if (server == null || fInfo == null || didTry == false) return;	if (couldNotCommunicate == false) {	
clearing out pffe for server 

========================= hbase sample_349 =========================

}	}	actionSet.addAll(Arrays.asList(actions));	byte[] value = new byte[actionSet.size()];	int index = 0;	for (Permission.Action action : actionSet) {	value[index++] = action.code();	}	p.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY) .setRow(p.getRow()) .setFamily(ACL_LIST_FAMILY) .setQualifier(key) .setTimestamp(p.getTimeStamp()) .setType(Type.Put) .setValue(value) .build());	if (LOG.isDebugEnabled()) {	
writing permission with rowkey 

perm.setActions(remainingActions.toArray(new Permission.Action[remainingActions.size()]));	addUserPermission(conf, perm, t);	} else {	removePermissionRecord(conf, userPerm, t);	}	break;	}	}	}	if (LOG.isDebugEnabled()) {	
removed permission 

static void removeTablePermissions(Configuration conf, TableName tableName, Table t) throws IOException{	Delete d = new Delete(tableName.getName());	if (LOG.isDebugEnabled()) {	
removing permissions of removed table 

static void removeNamespacePermissions(Configuration conf, String namespace, Table t) throws IOException{	Delete d = new Delete(Bytes.toBytes(toNamespaceEntry(namespace)));	if (LOG.isDebugEnabled()) {	
removing permissions of removed namespace 

static void removeTablePermissions(Configuration conf, TableName tableName, byte[] column, Table t) throws IOException {	if (LOG.isDebugEnabled()) {	
removing permissions of removed column from table 

try (Table table = connection.getTable(ACL_TABLE_NAME)) {	row = table.get(get);	}	}	} else {	row = t.get(get);	}	if (!row.isEmpty()) {	perms = parsePermissions(entryName, row);	} else {	
no permissions found in for acl entry 

private static Pair<String, TablePermission> parsePermissionRecord( byte[] entryName, Cell kv) {	byte[] family = CellUtil.cloneFamily(kv);	if (!Bytes.equals(family, ACL_LIST_FAMILY)) {	return null;	}	byte[] key = CellUtil.cloneQualifier(kv);	byte[] value = CellUtil.cloneValue(kv);	if (LOG.isDebugEnabled()) {	
read acl kv 

========================= hbase sample_2286 =========================

public Deserializer<Result> getDeserializer(Class<Result> c) {	Configuration conf = getConf();	if (conf != null) {	String inputVersion = conf.get(IMPORT_FORMAT_VER);	if (inputVersion != null && inputVersion.equals("0.94")) {	
load exported file using deserializer for hbase format 

========================= hbase sample_3478 =========================

public static Hashtable<String, String> buldKeyValueTable(String[] keys, String[] values) {	if (keys.length != values.length) {	
keys and values arrays must be same size 

public static Hashtable<String, String> buldKeyValueTable(String[] keys, String[] values) {	if (keys.length != values.length) {	return null;	}	if (keys.length == 0 || values.length == 0) {	
keys and values arrays can not be empty 

========================= hbase sample_1015 =========================

}	startPathSB.append(HConstants.HREGION_LOGDIR_NAME);	if (!HConstants.HREGION_LOGDIR_NAME.endsWith("/")) {	startPathSB.append('/');	}	final String startPath = startPathSB.toString();	String fullPath;	try {	fullPath = FileSystem.get(conf).makeQualified(new Path(path)).toString();	} catch (IllegalArgumentException e) {	
call to makequalified failed on 

private static void recoverLease(final Configuration conf, final Path path) {	try {	final FileSystem dfs = FSUtils.getCurrentFileSystem(conf);	FSUtils fsUtils = FSUtils.getInstance(dfs, conf);	fsUtils.recoverFileLease(dfs, path, conf, new CancelableProgressable() {	public boolean progress() {	
still trying to recover wal lease 

private static void recoverLease(final Configuration conf, final Path path) {	try {	final FileSystem dfs = FSUtils.getCurrentFileSystem(conf);	FSUtils fsUtils = FSUtils.getInstance(dfs, conf);	fsUtils.recoverFileLease(dfs, path, conf, new CancelableProgressable() {	public boolean progress() {	return true;	}	});	} catch (IOException e) {	
unable to recover lease for wal 

========================= hbase sample_2269 =========================

private void waitForSplittingCompletion(TaskBatch batch, MonitoredTask status) {	synchronized (batch) {	while ((batch.done + batch.error) != batch.installed) {	try {	status.setStatus("Waiting for distributed tasks to finish. " + " scheduled=" + batch.installed + " done=" + batch.done + " error=" + batch.error);	int remaining = batch.installed - (batch.done + batch.error);	int actual = activeTasks(batch);	if (remaining != actual) {	
expected active tasks but actually there are 

synchronized (batch) {	while ((batch.done + batch.error) != batch.installed) {	try {	status.setStatus("Waiting for distributed tasks to finish. " + " scheduled=" + batch.installed + " done=" + batch.done + " error=" + batch.error);	int remaining = batch.installed - (batch.done + batch.error);	int actual = activeTasks(batch);	if (remaining != actual) {	}	int remainingTasks = getSplitLogManagerCoordination().remainingTasksInCoordination();	if (remainingTasks >= 0 && actual > remainingTasks) {	
expected at least tasks remaining but actually there are 

try {	status.setStatus("Waiting for distributed tasks to finish. " + " scheduled=" + batch.installed + " done=" + batch.done + " error=" + batch.error);	int remaining = batch.installed - (batch.done + batch.error);	int actual = activeTasks(batch);	if (remaining != actual) {	}	int remainingTasks = getSplitLogManagerCoordination().remainingTasksInCoordination();	if (remainingTasks >= 0 && actual > remainingTasks) {	}	if (remainingTasks == 0 || actual == 0) {	
no more task remaining splitting should have completed remaining tasks is active tasks in map 

int remainingTasks = getSplitLogManagerCoordination().remainingTasksInCoordination();	if (remainingTasks >= 0 && actual > remainingTasks) {	}	if (remainingTasks == 0 || actual == 0) {	if (remainingTasks == 0 && actual == 0) {	return;	}	}	batch.wait(100);	if (server.isStopped()) {	
stopped while waiting for log splits to be completed 

if (remainingTasks == 0 || actual == 0) {	if (remainingTasks == 0 && actual == 0) {	return;	}	}	batch.wait(100);	if (server.isStopped()) {	return;	}	} catch (InterruptedException e) {	
interrupted while waiting for log splits to be completed 

return null;	}	synchronized (oldtask) {	if (oldtask.isOrphan()) {	if (oldtask.status == SUCCESS) {	return (null);	}	if (oldtask.status == IN_PROGRESS) {	oldtask.batch = batch;	batch.installed++;	
previously orphan task is now being waited upon 

if (oldtask.isOrphan()) {	if (oldtask.status == SUCCESS) {	return (null);	}	if (oldtask.status == IN_PROGRESS) {	oldtask.batch = batch;	batch.installed++;	return null;	}	while (oldtask.status == FAILURE) {	
wait for status of task to change to deleted 

oldtask.batch = batch;	batch.installed++;	return null;	}	while (oldtask.status == FAILURE) {	SplitLogCounters.tot_mgr_wait_for_zk_delete.increment();	try {	oldtask.wait();	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	
interrupted when waiting for znode delete callback 

}	if (oldtask.status != DELETED) {	LOG.warn("Failure because previously failed task" + " state still present. Waiting for znode delete callback" + " path=" + path);	return oldtask;	}	Task t = tasks.putIfAbsent(path, newtask);	if (t == null) {	batch.installed++;	return null;	}	
logic error deleted task still present in tasks map 

unassigned++;	continue;	}	found_assigned_task = true;	if (localDeadWorkers != null && localDeadWorkers.contains(cur_worker)) {	SplitLogCounters.tot_mgr_resubmit_dead_server_task.increment();	if (getSplitLogManagerCoordination().resubmitTask(path, task, FORCE)) {	resubmitted++;	} else {	handleDeadWorker(cur_worker);	
failed to resubmit task owned by dead will retry 

}	}	if (tot > 0) {	long now = EnvironmentEdgeManager.currentTime();	if (now > lastLog + 5000) {	lastLog = now;	LOG.info("total=" + tot + ", unassigned=" + unassigned + ", tasks=" + tasks);	}	}	if (resubmitted > 0) {	
resubmitted out of tasks 

if (tot > 0 && !found_assigned_task && ((EnvironmentEdgeManager.currentTime() - lastTaskCreateTime) > unassignedTimeout)) {	for (Map.Entry<String, Task> e : tasks.entrySet()) {	String key = e.getKey();	Task task = e.getValue();	if (task.isUnassigned() && (task.status != FAILURE)) {	getSplitLogManagerCoordination().checkTaskStillAvailable(key);	}	}	getSplitLogManagerCoordination().checkTasks();	SplitLogCounters.tot_mgr_resubmit_unassigned.increment();	
resubmitting unassigned task s after timeout 

========================= hbase sample_2793 =========================

public void testDeleteTypes() throws Exception {	
testDeleteTypes 

put.addColumn(famName, row, t + 2, v3);	htable1.put(put);	Get get = new Get(row);	get.readAllVersions();	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.size() < 3) {	
rows not available 

d.addColumn(famName, row, t);	htable1.delete(d);	get = new Get(row);	get.readAllVersions();	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.size() > 2) {	
version not deleted 

d = new Delete(row);	d.addColumns(famName, row, t + 2);	htable1.delete(d);	get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for del replication");	}	Result res = htable2.get(get);	if (res.size() >= 1) {	
rows not deleted 

public void testSimplePutDelete() throws Exception {	
testSimplePutDelete 

public void testSmallBatch() throws Exception {	
testSmallBatch 

byte[] rowkey = Bytes.toBytes("disable enable");	Put put = new Put(rowkey);	put.addColumn(famName, row, row);	htable1.put(put);	Get get = new Get(rowkey);	for (int i = 0; i < NB_RETRIES; i++) {	Result res = htable2.get(get);	if (res.size() >= 1) {	fail("Replication wasn't disabled");	} else {	
row not replicated let s wait a bit more 

if (res.size() >= 1) {	fail("Replication wasn't disabled");	} else {	Thread.sleep(SLEEP_TIME);	}	}	hbaseAdmin.enableReplicationPeer(PEER_ID);	for (int i = 0; i < NB_RETRIES; i++) {	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

public void testAddAndRemoveClusters() throws Exception {	
testAddAndRemoveClusters 

htable1.put(put);	Get get = new Get(rowKey);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	break;	}	Result res = htable2.get(get);	if (res.size() >= 1) {	fail("Not supposed to be replicated");	} else {	
row not replicated let s wait a bit more 

} else {	Thread.sleep(SLEEP_TIME);	}	}	ReplicationPeerConfig rpc = ReplicationPeerConfig.newBuilder().setClusterKey(utility2.getClusterKey()).build();	hbaseAdmin.addReplicationPeer(PEER_ID, rpc);	Thread.sleep(SLEEP_TIME);	rowKey = Bytes.toBytes("do rep");	put = new Put(rowKey);	put.addColumn(famName, row, row);	
adding new row 

put = new Put(rowKey);	put.addColumn(famName, row, row);	htable1.put(put);	get = new Get(rowKey);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

public void testLoading() throws Exception {	
writing out rows to in testloading 

Put put = new Put(Bytes.toBytes(i));	put.addColumn(famName, row, row);	puts.add(put);	}	htable1.put(puts);	Scan scan = new Scan();	ResultScanner scanner = htable1.getScanner(scan);	Result[] res = scanner.next(NB_ROWS_IN_BIG_BATCH);	scanner.close();	assertEquals(NB_ROWS_IN_BIG_BATCH, res.length);	
looking in for replicated rows in testloading 

scan = new Scan();	scanner = htable2.getScanner(scan);	res = scanner.next(NB_ROWS_IN_BIG_BATCH);	scanner.close();	if (res.length != NB_ROWS_IN_BIG_BATCH) {	if (i == retries - 1) {	int lastRow = -1;	for (Result result : res) {	int currentRow = Bytes.toInt(result.getRow());	for (int row = lastRow + 1; row < currentRow; row++) {	
row missing 

scanner.close();	if (res.length != NB_ROWS_IN_BIG_BATCH) {	if (i == retries - 1) {	int lastRow = -1;	for (Result result : res) {	int currentRow = Bytes.toInt(result.getRow());	for (int row = lastRow + 1; row < currentRow; row++) {	}	lastRow = currentRow;	}	
last row 

if (i == retries - 1) {	int lastRow = -1;	for (Result result : res) {	int currentRow = Bytes.toInt(result.getRow());	for (int row = lastRow + 1; row < currentRow; row++) {	}	lastRow = currentRow;	}	fail("Waited too much time for normal batch replication, " + res.length + " instead of " + NB_ROWS_IN_BIG_BATCH + "; waited=" + (System.currentTimeMillis() - start) + "ms");	} else {	
only got rows retrying 

public void testVerifyListReplicatedTable() throws Exception {	
testVerifyListReplicatedTable 

wal.sync();	Get get = new Get(rowName);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	break;	}	Result res = htable2.get(get);	if (res.size() >= 1) {	fail("Not supposed to be replicated for " + Bytes.toString(res.getRow()));	} else {	
row not replicated let s wait a bit more 

========================= hbase sample_1916 =========================

public void perform() throws Exception {	
unbalancing regions 

========================= hbase sample_3301 =========================

if (regionServers.get(sn) == null) {	RegionServerInfo.Builder rsInfoBuilder = RegionServerInfo.newBuilder();	try {	String nodePath = ZNodePaths.joinZNode(watcher.znodePaths.rsZNode, n);	byte[] data = ZKUtil.getData(watcher, nodePath);	if (data != null && data.length > 0 && ProtobufUtil.isPBMagicPrefix(data)) {	int magicLen = ProtobufUtil.lengthOfPBMagic();	ProtobufUtil.mergeFrom(rsInfoBuilder, data, magicLen, data.length - magicLen);	}	if (LOG.isTraceEnabled()) {	
added tracking of rs 

try {	String nodePath = ZNodePaths.joinZNode(watcher.znodePaths.rsZNode, n);	byte[] data = ZKUtil.getData(watcher, nodePath);	if (data != null && data.length > 0 && ProtobufUtil.isPBMagicPrefix(data)) {	int magicLen = ProtobufUtil.lengthOfPBMagic();	ProtobufUtil.mergeFrom(rsInfoBuilder, data, magicLen, data.length - magicLen);	}	if (LOG.isTraceEnabled()) {	}	} catch (KeeperException e) {	
get rs info port from ephemeral node 

String nodePath = ZNodePaths.joinZNode(watcher.znodePaths.rsZNode, n);	byte[] data = ZKUtil.getData(watcher, nodePath);	if (data != null && data.length > 0 && ProtobufUtil.isPBMagicPrefix(data)) {	int magicLen = ProtobufUtil.lengthOfPBMagic();	ProtobufUtil.mergeFrom(rsInfoBuilder, data, magicLen, data.length - magicLen);	}	if (LOG.isTraceEnabled()) {	}	} catch (KeeperException e) {	} catch (IOException e) {	
illegal data from ephemeral node 

public void nodeDeleted(String path) {	if (path.startsWith(watcher.znodePaths.rsZNode)) {	String serverName = ZKUtil.getNodeName(path);	
regionserver ephemeral node deleted processing expiration 

public void nodeDeleted(String path) {	if (path.startsWith(watcher.znodePaths.rsZNode)) {	String serverName = ZKUtil.getNodeName(path);	ServerName sn = ServerName.parseServerName(serverName);	if (!serverManager.isServerOnline(sn)) {	
is not online or isn t known to the master the latter could be caused by a dns misconfiguration 

========================= hbase sample_2843 =========================

public void testIllegalHTableNamesRegex() {	for (String tn : illegalTableNames) {	
testing 

========================= hbase sample_94 =========================

if (!coprocessorsEnabled) {	return;	}	Class<?> implClass;	String[] defaultCPClasses = conf.getStrings(confKey);	if (defaultCPClasses == null || defaultCPClasses.length == 0) return;	int priority = Coprocessor.PRIORITY_SYSTEM;	for (String className : defaultCPClasses) {	className = className.trim();	if (findCoprocessor(className) != null) {	
attempted duplicate loading of skipped 

if (findCoprocessor(className) != null) {	continue;	}	ClassLoader cl = this.getClass().getClassLoader();	Thread.currentThread().setContextClassLoader(cl);	try {	implClass = cl.loadClass(className);	E env = checkAndLoadInstance(implClass, priority, conf);	if (env != null) {	this.coprocEnvironments.add(env);	
system coprocessor was loaded successfully with priority 

public E load(Path path, String className, int priority, Configuration conf, String[] includedClassPrefixes) throws IOException {	Class<?> implClass;	
loading coprocessor class with path and priority 

public E checkAndLoadInstance(Class<?> implClass, int priority, Configuration conf) throws IOException {	C impl;	try {	impl = checkAndGetInstance(implClass);	if (impl == null) {	
cannot load coprocessor 

public abstract E createEnvironment(C instance, int priority, int sequence, Configuration conf);	public abstract C checkAndGetInstance(Class<?> implClass) throws InstantiationException, IllegalAccessException;	public void shutdown(E e) {	assert e instanceof BaseEnvironment;	if (LOG.isDebugEnabled()) {	
stop coprocessor 

protected void abortServer(final String coprocessorName, final Throwable e) {	String message = "The coprocessor " + coprocessorName + " threw " + e.toString();	LOG.error(message, e);	if (abortable != null) {	abortable.abort(message, e);	} else {	
no available abortable process was not aborted 

protected void handleCoprocessorThrowable(final E env, final Throwable e) throws IOException {	if (e instanceof IOException) {	throw (IOException)e;	}	if (env.getConfiguration().getBoolean(ABORT_ON_ERROR_KEY, DEFAULT_ABORT_ON_ERROR)) {	abortServer(env, e);	} else {	if(env instanceof RegionCoprocessorEnvironment) {	String tableName = ((RegionCoprocessorEnvironment)env).getRegionInfo().getTable().getNameAsString();	
removing coprocessor from table 

protected void handleCoprocessorThrowable(final E env, final Throwable e) throws IOException {	if (e instanceof IOException) {	throw (IOException)e;	}	if (env.getConfiguration().getBoolean(ABORT_ON_ERROR_KEY, DEFAULT_ABORT_ON_ERROR)) {	abortServer(env, e);	} else {	if(env instanceof RegionCoprocessorEnvironment) {	String tableName = ((RegionCoprocessorEnvironment)env).getRegionInfo().getTable().getNameAsString();	} else {	
removing coprocessor from environment 

abortServer(env, e);	} else {	if(env instanceof RegionCoprocessorEnvironment) {	String tableName = ((RegionCoprocessorEnvironment)env).getRegionInfo().getTable().getNameAsString();	} else {	}	coprocEnvironments.remove(env);	try {	shutdown(env);	} catch (Exception x) {	
uncaught exception when shutting down coprocessor 

========================= hbase sample_2455 =========================

public static void snapshot(Admin admin, final String snapshotName, final TableName tableName, final SnapshotType type, final int numTries) throws IOException {	int tries = 0;	CorruptedSnapshotException lastEx = null;	while (tries++ < numTries) {	try {	admin.snapshot(snapshotName, tableName, type);	return;	} catch (CorruptedSnapshotException cse) {	
got corruptedsnapshotexception 

public static void createSnapshotAndValidate(Admin admin, TableName tableName, List<byte[]> nonEmptyFamilyNames, List<byte[]> emptyFamilyNames, String snapshotNameString, Path rootDir, FileSystem fs, boolean onlineSnapshot) throws Exception {	if (!onlineSnapshot) {	try {	
prepping for offline snapshot 

public static void createSnapshotAndValidate(Admin admin, TableName tableName, List<byte[]> nonEmptyFamilyNames, List<byte[]> emptyFamilyNames, String snapshotNameString, Path rootDir, FileSystem fs, boolean onlineSnapshot) throws Exception {	if (!onlineSnapshot) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException tne) {	
in attempting to disable it turns out that the this table is already disabled 

public static void createSnapshotAndValidate(Admin admin, TableName tableName, List<byte[]> nonEmptyFamilyNames, List<byte[]> emptyFamilyNames, String snapshotNameString, Path rootDir, FileSystem fs, boolean onlineSnapshot) throws Exception {	if (!onlineSnapshot) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException tne) {	}	}	
taking snapshot 

public static void createSnapshotAndValidate(Admin admin, TableName tableName, List<byte[]> nonEmptyFamilyNames, List<byte[]> emptyFamilyNames, String snapshotNameString, Path rootDir, FileSystem fs, boolean onlineSnapshot) throws Exception {	if (!onlineSnapshot) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException tne) {	}	}	admin.snapshot(snapshotNameString, tableName);	
confirming snapshot exists 

try {	admin.disableTable(tableName);	} catch (TableNotEnabledException tne) {	}	}	admin.snapshot(snapshotNameString, tableName);	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertExistsMatchingSnapshot(admin, snapshotNameString, tableName);	if (snapshots == null || snapshots.size() != 1) {	Assert.fail("Incorrect number of snapshots for table " + tableName);	}	
validating snapshot 

========================= hbase sample_1279 =========================

private static void createLabels() throws IOException, InterruptedException {	PrivilegedExceptionAction<VisibilityLabelsResponse> action = new PrivilegedExceptionAction<VisibilityLabelsResponse>() {	public VisibilityLabelsResponse run() throws Exception {	String[] labels = { SECRET, TOPSECRET, CONFIDENTIAL, PUBLIC, PRIVATE };	try (Connection conn = ConnectionFactory.createConnection(conf)) {	VisibilityClient.addLabels(conn, labels);	
added labels 

private static void createLabels() throws IOException, InterruptedException {	PrivilegedExceptionAction<VisibilityLabelsResponse> action = new PrivilegedExceptionAction<VisibilityLabelsResponse>() {	public VisibilityLabelsResponse run() throws Exception {	String[] labels = { SECRET, TOPSECRET, CONFIDENTIAL, PUBLIC, PRIVATE };	try (Connection conn = ConnectionFactory.createConnection(conf)) {	VisibilityClient.addLabels(conn, labels);	} catch (Throwable t) {	
error in adding labels 

private void issueDeleteAndVerifyData(TableName tableName) throws IOException {	
validating table after delete 

TableName table = TableName.valueOf(args[args.length - 1]);	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util .getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	if (data == null) {	data = "KEY\u001bVALUE1\u001bVALUE2\n";	}	op.write(Bytes.toBytes(data));	op.close();	
wrote test data to file s 

Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util .getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	if (data == null) {	data = "KEY\u001bVALUE1\u001bVALUE2\n";	}	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	
forcing combiner 

data = "KEY\u001bVALUE1\u001bVALUE2\n";	}	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	conf.setInt("mapreduce.map.combine.minspills", 1);	}	List<String> argv = new ArrayList<>(Arrays.asList(args));	argv.add(inputPath.toString());	Tool tool = new ImportTsv();	
running importtsv with arguments 

assertEquals(0, ToolRunner.run(conf, tool, argv.toArray(args)));	boolean createdHFiles = false;	String outputPath = null;	for (String arg : argv) {	if (arg.contains(ImportTsv.BULK_OUTPUT_CONF_KEY)) {	createdHFiles = true;	outputPath = arg.split("=")[1];	break;	}	}	
validating the table 

for (String arg : argv) {	if (arg.contains(ImportTsv.BULK_OUTPUT_CONF_KEY)) {	createdHFiles = true;	outputPath = arg.split("=")[1];	break;	}	}	if (createdHFiles) validateHFiles(fs, outputPath, family,expectedKVCount);	else validateTable(conf, table, family, valueMultiplier);	if (conf.getBoolean(DELETE_AFTER_LOAD_CONF, true)) {	
deleting test subdirectory 

private static void validateHFiles(FileSystem fs, String outputPath, String family, int expectedKVCount) throws IOException {	
validating hfiles 

private static void validateHFiles(FileSystem fs, String outputPath, String family, int expectedKVCount) throws IOException {	Set<String> configFamilies = new HashSet<>();	configFamilies.add(family);	Set<String> foundFamilies = new HashSet<>();	int actualKVCount = 0;	for (FileStatus cfStatus : fs.listStatus(new Path(outputPath), new OutputFilesFilter())) {	
the output path has files 

private static void validateTable(Configuration conf, TableName tableName, String family, int valueMultiplier) throws IOException {	
validating table 

int numRetries = conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	Scan scan = new Scan();	scan.addFamily(Bytes.toBytes(family));	scan.setAuthorizations(new Authorizations("secret","private"));	ResultScanner resScanner = table.getScanner(scan);	Result[] next = resScanner.next(5);	assertEquals(1, next.length);	for (Result res : resScanner) {	
getting results 

========================= hbase sample_3399 =========================

public void testFlushTableAndRegion() throws Exception {	RegionInfo hri = createTableAndGetOneRegion(tableName);	ServerName serverName = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getRegionStates() .getRegionServerOfRegion(hri);	HRegionServer regionServer = TEST_UTIL.getHBaseCluster().getLiveRegionServerThreads().stream() .map(rsThread -> rsThread.getRegionServer()) .filter(rs -> rs.getServerName().equals(serverName)).findFirst().get();	ASYNC_CONN.getTable(tableName) .put(new Put(hri.getStartKey()).addColumn(FAMILY, FAMILY_0, Bytes.toBytes("value-1"))) .join();	Assert.assertTrue(regionServer.getOnlineRegion(hri.getRegionName()).getMemStoreSize() > 0);	
flushing region 

public void testFlushTableAndRegion() throws Exception {	RegionInfo hri = createTableAndGetOneRegion(tableName);	ServerName serverName = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager().getRegionStates() .getRegionServerOfRegion(hri);	HRegionServer regionServer = TEST_UTIL.getHBaseCluster().getLiveRegionServerThreads().stream() .map(rsThread -> rsThread.getRegionServer()) .filter(rs -> rs.getServerName().equals(serverName)).findFirst().get();	ASYNC_CONN.getTable(tableName) .put(new Put(hri.getStartKey()).addColumn(FAMILY, FAMILY_0, Bytes.toBytes("value-1"))) .join();	Assert.assertTrue(regionServer.getOnlineRegion(hri.getRegionName()).getMemStoreSize() > 0);	admin.flushRegion(hri.getRegionName()).get();	
blocking until flush is complete 

========================= hbase sample_2072 =========================

} else {	delay = 0;	}	try {	if (LOG.isDebugEnabled()) {	LOG.debug("Prefetch requested for " + path + ", delay=" + delay + " ms");	}	prefetchFutures.put(path, prefetchExecutorPool.schedule(runnable, delay, TimeUnit.MILLISECONDS));	} catch (RejectedExecutionException e) {	prefetchFutures.remove(path);	
prefetch request rejected for 

public static void complete(Path path) {	prefetchFutures.remove(path);	if (LOG.isDebugEnabled()) {	
prefetch completed for 

public static void cancel(Path path) {	Future<?> future = prefetchFutures.get(path);	if (future != null) {	future.cancel(true);	prefetchFutures.remove(path);	if (LOG.isDebugEnabled()) {	
prefetch cancelled for 

========================= hbase sample_2422 =========================

byte[][] endRows = rl.getEndKeys();	for (int i = 0; i < NUM_REGIONS; i++) {	byte [] row = startRows[i];	if (row == null || row.length <= 0) continue;	Put put = new Put(row).addColumn(FAMILY, QUALIFIER, VALUE1);	success = multiplexer.put(tableName1, put);	assertTrue("multiplexer.put returns", success);	put = new Put(row).addColumn(FAMILY, QUALIFIER, VALUE1);	success = multiplexer.put(tableName2, put);	assertTrue("multiplexer.put failed", success);	
put for iteration 

========================= hbase sample_2137 =========================

public void onConfigurationChange(Configuration conf) {	float originSlop = slop;	float originOverallSlop = overallSlop;	super.setConf(conf);	
update configuration of simpleloadbalancer previous slop is current slop is previous overallslop is current overallslop is 

private boolean overallNeedsBalance() {	int floor = (int) Math.floor(avgLoadOverall * (1 - overallSlop));	int ceiling = (int) Math.ceil(avgLoadOverall * (1 + overallSlop));	int max = 0, min = Integer.MAX_VALUE;	for(ServerAndLoad server : serverLoadList){	max = Math.max(server.getLoad(), max);	min = Math.min(server.getLoad(), min);	}	if (max <= ceiling && min >= floor) {	if (LOG.isTraceEnabled()) {	
skipping load balancing because cluster is balanced at overall level 

long endTime = System.currentTimeMillis();	if (!regionsToMove.isEmpty() || neededRegions != 0) {	LOG.warn("regionsToMove=" + totalNumMoved + ", numServers=" + numServers + ", serversOverloaded=" + serversOverloaded + ", serversUnderloaded=" + serversUnderloaded);	StringBuilder sb = new StringBuilder();	for (Map.Entry<ServerName, List<RegionInfo>> e: clusterMap.entrySet()) {	if (sb.length() > 0) sb.append(", ");	sb.append(e.getKey().toString());	sb.append(" ");	sb.append(e.getValue().size());	}	
input 

if (!regionsToMove.isEmpty() || neededRegions != 0) {	LOG.warn("regionsToMove=" + totalNumMoved + ", numServers=" + numServers + ", serversOverloaded=" + serversOverloaded + ", serversUnderloaded=" + serversUnderloaded);	StringBuilder sb = new StringBuilder();	for (Map.Entry<ServerName, List<RegionInfo>> e: clusterMap.entrySet()) {	if (sb.length() > 0) sb.append(", ");	sb.append(e.getKey().toString());	sb.append(" ");	sb.append(e.getValue().size());	}	}	
done calculated a load balance in ms moving regions off of overloaded servers onto less loaded servers 

}	pos.add(i);	}	for (int i = 0; i < serverLoadList.size(); i++) {	ServerAndLoad serverload = serverLoadList.get(i);	BalanceInfo balanceInfo = serverBalanceInfo.get(serverload.getServerName());	setLoad(serverLoadList, i, balanceInfo.getNumRegionsAdded());	if (balanceInfo.getHriList().size() + balanceInfo.getNumRegionsAdded() == max) {	RegionInfo hriToPlan;	if (balanceInfo.getHriList().isEmpty()) {	
during balanceoverall we found has no regioninfo no operation needed 

public List<RegionPlan> balanceCluster(TableName tableName, Map<ServerName, List<RegionInfo>> clusterState) throws HBaseIOException {	
start generate balance plan for table 

========================= hbase sample_2834 =========================

protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {	String effectiveUser = request.getRemoteUser();	if (securityEnabled) {	try {	effectiveUser = doKerberosAuth(request);	response.addHeader(WWW_AUTHENTICATE,  NEGOTIATE + " " + outToken);	} catch (HttpAuthenticationException e) {	
kerberos authentication failed 

private String doKerberosAuth(HttpServletRequest request) throws HttpAuthenticationException {	HttpKerberosServerAction action = new HttpKerberosServerAction(request, realUser);	try {	String principal = realUser.doAs(action);	outToken = action.outToken;	return principal;	} catch (Exception e) {	
failed to perform authentication 

throw new HttpAuthenticationException("Kerberos authentication failed: " + "unable to establish context with the service ticket " + "provided by the client.");	}	return SecurityUtil.getUserFromPrincipal(gssContext.getSrcName().toString());	} catch (GSSException e) {	throw new HttpAuthenticationException("Kerberos authentication failed: ", e);	} finally {	if (gssContext != null) {	try {	gssContext.dispose();	} catch (GSSException e) {	
error while disposing gss context 

========================= hbase sample_806 =========================

public void testTablesInheritSnapshotSize() throws Exception {	TableName tn = helper.createTableWithRegions(1);	
writing data 

public void testTablesInheritSnapshotSize() throws Exception {	TableName tn = helper.createTableWithRegions(1);	QuotaSettings settings = QuotaSettingsFactory.limitTableSpace( tn, SpaceQuotaHelperForTests.ONE_GIGABYTE, SpaceViolationPolicy.NO_INSERTS);	admin.setQuota(settings);	final long initialSize = 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	helper.writeData(tn, initialSize);	
waiting until table size reflects written data 

public void testNamespacesInheritSnapshotSize() throws Exception {	String ns = helper.createNamespace().getName();	TableName tn = helper.createTableWithRegions(ns, 1);	
writing data 

public void testNamespacesInheritSnapshotSize() throws Exception {	String ns = helper.createNamespace().getName();	TableName tn = helper.createTableWithRegions(ns, 1);	QuotaSettings settings = QuotaSettingsFactory.limitNamespaceSpace( ns, SpaceQuotaHelperForTests.ONE_GIGABYTE, SpaceViolationPolicy.NO_INSERTS);	admin.setQuota(settings);	final long initialSize = 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	helper.writeData(tn, initialSize);	admin.flush(tn);	
waiting until namespace size reflects written data 

public boolean evaluate() throws Exception {	Map<TableName,Long> sizes = QuotaTableUtil.getMasterReportedTableSizes(conn);	
master observed table sizes from region size reports 

public void testTablesWithSnapshots() throws Exception {	final Connection conn = TEST_UTIL.getConnection();	final SpaceViolationPolicy policy = SpaceViolationPolicy.NO_INSERTS;	final TableName tn = helper.createTableWithRegions(10);	final long tableLimit = 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	TEST_UTIL.getAdmin().setQuota(QuotaSettingsFactory.limitTableSpace(tn, tableLimit, policy));	
writing first data set 

public void testTablesWithSnapshots() throws Exception {	final Connection conn = TEST_UTIL.getConnection();	final SpaceViolationPolicy policy = SpaceViolationPolicy.NO_INSERTS;	final TableName tn = helper.createTableWithRegions(10);	final long tableLimit = 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	TEST_UTIL.getAdmin().setQuota(QuotaSettingsFactory.limitTableSpace(tn, tableLimit, policy));	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q1");	
creating snapshot 

public void testTablesWithSnapshots() throws Exception {	final Connection conn = TEST_UTIL.getConnection();	final SpaceViolationPolicy policy = SpaceViolationPolicy.NO_INSERTS;	final TableName tn = helper.createTableWithRegions(10);	final long tableLimit = 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	TEST_UTIL.getAdmin().setQuota(QuotaSettingsFactory.limitTableSpace(tn, tableLimit, policy));	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q1");	TEST_UTIL.getAdmin().snapshot(tn.toString() + "snap1", tn, SnapshotType.FLUSH);	
writing second data set 

public void testTablesWithSnapshots() throws Exception {	final Connection conn = TEST_UTIL.getConnection();	final SpaceViolationPolicy policy = SpaceViolationPolicy.NO_INSERTS;	final TableName tn = helper.createTableWithRegions(10);	final long tableLimit = 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	TEST_UTIL.getAdmin().setQuota(QuotaSettingsFactory.limitTableSpace(tn, tableLimit, policy));	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q1");	TEST_UTIL.getAdmin().snapshot(tn.toString() + "snap1", tn, SnapshotType.FLUSH);	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q2");	
flushing and major compacting table 

final Connection conn = TEST_UTIL.getConnection();	final SpaceViolationPolicy policy = SpaceViolationPolicy.NO_INSERTS;	final TableName tn = helper.createTableWithRegions(10);	final long tableLimit = 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	TEST_UTIL.getAdmin().setQuota(QuotaSettingsFactory.limitTableSpace(tn, tableLimit, policy));	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q1");	TEST_UTIL.getAdmin().snapshot(tn.toString() + "snap1", tn, SnapshotType.FLUSH);	helper.writeData(tn, 1L * SpaceQuotaHelperForTests.ONE_MEGABYTE, "q2");	TEST_UTIL.getAdmin().flush(tn);	TEST_UTIL.compact(tn, true);	
checking for quota violation 

public void testRematerializedTablesDoNoInheritSpace() throws Exception {	TableName tn = helper.createTableWithRegions(1);	TableName tn2 = helper.getNextTableName();	
writing data 

public void testRematerializedTablesDoNoInheritSpace() throws Exception {	TableName tn = helper.createTableWithRegions(1);	TableName tn2 = helper.getNextTableName();	QuotaSettings settings = QuotaSettingsFactory.limitTableSpace( tn, SpaceQuotaHelperForTests.ONE_GIGABYTE, SpaceViolationPolicy.NO_INSERTS);	admin.setQuota(settings);	QuotaSettings settings2 = QuotaSettingsFactory.limitTableSpace( tn2, SpaceQuotaHelperForTests.ONE_GIGABYTE, SpaceViolationPolicy.NO_INSERTS);	admin.setQuota(settings2);	final long initialSize = 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	helper.writeData(tn, initialSize);	
waiting until table size reflects written data 

========================= hbase sample_1432 =========================

public void tearDown() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public static void testRecoveryAndDoubleExecution(final HBaseTestingUtility testUtil, final long procId, final int lastStepBeforeFailover) throws Exception {	ProcedureExecutor<MasterProcedureEnv> procExec = testUtil.getHBaseCluster().getMaster().getMasterProcedureExecutor();	ProcedureTestingUtility.waitProcedure(procExec, procId);	final Procedure proc = procExec.getProcedure(procId);	for (int i = 0; i < lastStepBeforeFailover; ++i) {	
restart exec state 

public static void testRecoveryAndDoubleExecution(final HBaseTestingUtility testUtil, final long procId, final int lastStepBeforeFailover) throws Exception {	ProcedureExecutor<MasterProcedureEnv> procExec = testUtil.getHBaseCluster().getMaster().getMasterProcedureExecutor();	ProcedureTestingUtility.waitProcedure(procExec, procId);	final Procedure proc = procExec.getProcedure(procId);	for (int i = 0; i < lastStepBeforeFailover; ++i) {	ProcedureTestingUtility.assertProcNotYetCompleted(procExec, procId);	MasterProcedureTestingUtility.restartMasterProcedureExecutor(procExec);	ProcedureTestingUtility.waitProcedure(procExec, procId);	}	ProcedureTestingUtility.assertProcNotYetCompleted(procExec, procId);	
trigger master failover 

========================= hbase sample_1824 =========================

public void setUp() throws Exception {	util = new IntegrationTestingUtility();	Configuration conf = util.getConfiguration();	regionsCountPerServer = conf.getInt(REGION_COUNT_KEY, DEFAULT_REGION_COUNT);	regionServerCount = conf.getInt(REGIONSERVER_COUNT_KEY, DEFAULT_REGIONSERVER_COUNT);	rowsInBatch = conf.getInt(NB_ROWS_IN_BATCH_KEY, DEFAULT_NB_ROWS_IN_BATCH);	enableBackup(conf);	
initializing cluster with d region servers 

public void setUp() throws Exception {	util = new IntegrationTestingUtility();	Configuration conf = util.getConfiguration();	regionsCountPerServer = conf.getInt(REGION_COUNT_KEY, DEFAULT_REGION_COUNT);	regionServerCount = conf.getInt(REGIONSERVER_COUNT_KEY, DEFAULT_REGIONSERVER_COUNT);	rowsInBatch = conf.getInt(NB_ROWS_IN_BATCH_KEY, DEFAULT_NB_ROWS_IN_BATCH);	enableBackup(conf);	util.initializeCluster(regionServerCount);	
cluster initialized 

public void setUp() throws Exception {	util = new IntegrationTestingUtility();	Configuration conf = util.getConfiguration();	regionsCountPerServer = conf.getInt(REGION_COUNT_KEY, DEFAULT_REGION_COUNT);	regionServerCount = conf.getInt(REGIONSERVER_COUNT_KEY, DEFAULT_REGIONSERVER_COUNT);	rowsInBatch = conf.getInt(NB_ROWS_IN_BATCH_KEY, DEFAULT_NB_ROWS_IN_BATCH);	enableBackup(conf);	util.initializeCluster(regionServerCount);	util.deleteTableIfAny(TABLE_NAME1);	util.deleteTableIfAny(TABLE_NAME2);	
cluster ready 

public void tearDown() throws IOException {	
cleaning up after test 

public void tearDown() throws IOException {	if(util.isDistributedCluster()) {	util.deleteTableIfAny(TABLE_NAME1);	
cleaning up after test done 

public void tearDown() throws IOException {	if(util.isDistributedCluster()) {	util.deleteTableIfAny(TABLE_NAME1);	util.deleteTableIfAny(TABLE_NAME2);	
cleaning up after test done 

public void tearDown() throws IOException {	if(util.isDistributedCluster()) {	util.deleteTableIfAny(TABLE_NAME1);	util.deleteTableIfAny(TABLE_NAME2);	cleanUpBackupDir();	}	
restoring cluster 

public void tearDown() throws IOException {	if(util.isDistributedCluster()) {	util.deleteTableIfAny(TABLE_NAME1);	util.deleteTableIfAny(TABLE_NAME2);	cleanUpBackupDir();	}	util.restoreCluster();	
cluster restored 

private void createTable(TableName tableName) throws Exception {	long startTime, endTime;	HTableDescriptor desc = new HTableDescriptor(tableName);	HColumnDescriptor[] columns = new HColumnDescriptor[]{new HColumnDescriptor(COLUMN_NAME)};	
creating table s with d splits 

private void createTable(TableName tableName) throws Exception {	long startTime, endTime;	HTableDescriptor desc = new HTableDescriptor(tableName);	HColumnDescriptor[] columns = new HColumnDescriptor[]{new HColumnDescriptor(COLUMN_NAME)};	startTime = System.currentTimeMillis();	HBaseTestingUtility.createPreSplitLoadTestTable(util.getConfiguration(), desc, columns, regionsCountPerServer);	util.waitTableAvailable(tableName);	endTime = System.currentTimeMillis();	
pre split table created successfully in dms 

private void runTest() throws IOException {	try (Connection conn = util.getConnection();	Admin admin = conn.getAdmin();	BackupAdmin client = new BackupAdminImpl(conn)) {	loadData(TABLE_NAME1, rowsInBatch);	loadData(TABLE_NAME2, rowsInBatch);	
create full backup image for all tables 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	enableBackup(getConf());	
initializing checking cluster has servers 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	enableBackup(getConf());	util.initializeCluster(regionServerCount);	
done initializing checking cluster 

protected void processOptions(CommandLine cmd) {	super.processOptions(cmd);	regionsCountPerServer = Integer.parseInt(cmd.getOptionValue(REGION_COUNT_KEY, Integer.toString(DEFAULT_REGION_COUNT)));	regionServerCount = Integer.parseInt(cmd.getOptionValue(REGIONSERVER_COUNT_KEY, Integer.toString(DEFAULT_REGIONSERVER_COUNT)));	rowsInBatch = Integer.parseInt(cmd.getOptionValue(NB_ROWS_IN_BATCH_KEY, Integer.toString(DEFAULT_NB_ROWS_IN_BATCH)));	
parsed options 

========================= hbase sample_3264 =========================

public void testCompaction() throws Exception {	long limitTime = testCompactionWithThroughputLimit();	long noLimitTime = testCompactionWithoutThroughputLimit();	
with s limit compaction use ms without limit compaction use ms 

========================= hbase sample_1609 =========================

public void run() {	
starting 

public void run() {	try {	doRunLoop();	} finally {	
stopping 

public void run() {	try {	doRunLoop();	} finally {	try {	writeSelector.close();	} catch (IOException ioe) {	
couldn t close write selector 

Iterator<SimpleServerRpcConnection> it = writingCons.iterator();	while (it.hasNext()) {	SimpleServerRpcConnection c = it.next();	it.remove();	SelectionKey sk = c.channel.keyFor(writeSelector);	try {	if (sk == null) {	try {	c.channel.register(writeSelector, SelectionKey.OP_WRITE, c);	} catch (ClosedChannelException e) {	
ignored 

try {	if (sk == null) {	try {	c.channel.register(writeSelector, SelectionKey.OP_WRITE, c);	} catch (ClosedChannelException e) {	}	} else {	sk.interestOps(SelectionKey.OP_WRITE);	}	} catch (CancelledKeyException e) {	
ignored 

Set<SelectionKey> keys = writeSelector.selectedKeys();	Iterator<SelectionKey> iter = keys.iterator();	while (iter.hasNext()) {	SelectionKey key = iter.next();	iter.remove();	try {	if (key.isValid() && key.isWritable()) {	doAsyncWrite(key);	}	} catch (IOException e) {	
asyncwrite 

if (key.isValid() && key.isWritable()) {	doAsyncWrite(key);	}	} catch (IOException e) {	}	}	lastPurgeTime = purge(lastPurgeTime);	} catch (OutOfMemoryError e) {	if (this.simpleRpcServer.errorHandler != null) {	if (this.simpleRpcServer.errorHandler.checkOOME(e)) {	
exiting on outofmemoryerror 

} catch (IOException e) {	}	}	lastPurgeTime = purge(lastPurgeTime);	} catch (OutOfMemoryError e) {	if (this.simpleRpcServer.errorHandler != null) {	if (this.simpleRpcServer.errorHandler.checkOOME(e)) {	return;	}	} else {	
outofmemoryerror in server select 

lastPurgeTime = purge(lastPurgeTime);	} catch (OutOfMemoryError e) {	if (this.simpleRpcServer.errorHandler != null) {	if (this.simpleRpcServer.errorHandler.checkOOME(e)) {	return;	}	} else {	try {	Thread.sleep(60000);	} catch (InterruptedException ex) {	
interrupted while sleeping 

return;	}	} else {	try {	Thread.sleep(60000);	} catch (InterruptedException ex) {	return;	}	}	} catch (Exception e) {	
exception in responder 

} else {	try {	Thread.sleep(60000);	} catch (InterruptedException ex) {	return;	}	}	} catch (Exception e) {	}	}	
stopped 

if (connection == null) {	throw new IOException("doAsyncWrite: no connection");	}	if (key.channel() != connection.channel) {	throw new IOException("doAsyncWrite: bad channel");	}	if (processAllResponses(connection)) {	try {	key.interestOps(0);	} catch (CancelledKeyException e) {	
exception while changing ops 

boolean error = true;	BufferChain buf = resp.getResponse();	try {	long numBytes = this.simpleRpcServer.channelWrite(conn.channel, buf);	if (numBytes < 0) {	throw new HBaseIOException("Error writing on the socket " + conn);	}	error = false;	} finally {	if (error) {	
output error closing 

========================= hbase sample_2926 =========================

public void perform() throws Exception {	TableDescriptor tableDescriptor = admin.getDescriptor(tableName);	ColumnFamilyDescriptor columnDescriptor = null;	while (columnDescriptor == null || tableDescriptor.getColumnFamily(columnDescriptor.getName()) != null) {	columnDescriptor = ColumnFamilyDescriptorBuilder.of(RandomStringUtils.randomAlphabetic(5));	}	if (context.isStopping()) {	return;	}	
performing action adding to 

========================= hbase sample_3321 =========================

public static void setUp() throws Exception {	TEST_UTIL = new HBaseTestingUtility();	TEST_UTIL.startMiniCluster(NUM_SLAVES_BASE);	admin = TEST_UTIL.getAdmin();	cluster = TEST_UTIL.getHBaseCluster();	master = ((MiniHBaseCluster)cluster).getMaster();	zkNamespaceManager = new ZKNamespaceManager(master.getZooKeeper());	zkNamespaceManager.start();	
done initializing cluster 

admin.createNamespace(NamespaceDescriptor.create(nsName).build());	admin.createTable(desc);	TEST_UTIL.waitTableAvailable(desc.getTableName().getName(), 10000);	FileSystem fs = FileSystem.get(TEST_UTIL.getConfiguration());	assertTrue(fs.exists( new Path(master.getMasterFileSystem().getRootDir(), new Path(HConstants.BASE_NAMESPACE_DIR, new Path(nsName, desc.getTableName().getQualifierAsString())))));	assertEquals(1, admin.listTables().length);	try {	admin.deleteNamespace(nsName);	fail("Expected non-empty namespace constraint exception");	} catch (Exception ex) {	
caught expected exception 

========================= hbase sample_2160 =========================

public void init() {	Table labelsTable = null;	Connection connection = null;	try {	connection = ConnectionFactory.createConnection(conf);	try {	labelsTable = connection.getTable(LABELS_TABLE_NAME);	} catch (IOException e) {	
error opening labels table 

scanner = labelsTable.getScanner(scan);	Result next = null;	while ((next = scanner.next()) != null) {	byte[] row = next.getRow();	byte[] value = next.getValue(LABELS_TABLE_FAMILY, LABEL_QUALIFIER);	labels.put(Bytes.toString(value), Bytes.toInt(row));	}	} catch (TableNotFoundException e) {	return;	} catch (IOException e) {	
error scanning labels table 

byte[] value = next.getValue(LABELS_TABLE_FAMILY, LABEL_QUALIFIER);	labels.put(Bytes.toString(value), Bytes.toInt(row));	}	} catch (TableNotFoundException e) {	return;	} catch (IOException e) {	} finally {	if (scanner != null) scanner.close();	}	} catch (IOException ioe) {	
failed reading labels tags 

} finally {	if (scanner != null) scanner.close();	}	} catch (IOException ioe) {	return;	} finally {	if (labelsTable != null) {	try {	labelsTable.close();	} catch (IOException ioe) {	
error closing labels table 

} finally {	if (labelsTable != null) {	try {	labelsTable.close();	} catch (IOException ioe) {	}	}	if (connection != null) try {	connection.close();	} catch (IOException ioe) {	
failed close of temporary connection 

========================= hbase sample_3458 =========================

long timeToLive = columnDescriptor.getTimeToLive();	if (Integer.MAX_VALUE == timeToLive) {	return;	}	Calendar calendar = Calendar.getInstance();	calendar.setTimeInMillis(current - timeToLive * 1000);	calendar.set(Calendar.HOUR_OF_DAY, 0);	calendar.set(Calendar.MINUTE, 0);	calendar.set(Calendar.SECOND, 0);	Date expireDate = calendar.getTime();	
mob hfiles older than will be deleted 

calendar.set(Calendar.HOUR_OF_DAY, 0);	calendar.set(Calendar.MINUTE, 0);	calendar.set(Calendar.SECOND, 0);	Date expireDate = calendar.getTime();	FileStatus[] stats = null;	Path mobTableDir = FSUtils.getTableDir(getMobHome(conf), tableName);	Path path = getMobFamilyPath(conf, tableName, columnDescriptor.getNameAsString());	try {	stats = fs.listStatus(path);	} catch (FileNotFoundException e) {	
failed to find the mob file 

int deletedFileCount = 0;	for (FileStatus file : stats) {	String fileName = file.getPath().getName();	try {	if (HFileLink.isHFileLink(file.getPath())) {	HFileLink hfileLink = HFileLink.buildFromHFileLinkPattern(conf, file.getPath());	fileName = hfileLink.getOriginPath().getName();	}	Date fileDate = parseDate(MobFileName.getDateFromName(fileName));	if (LOG.isDebugEnabled()) {	
checking file 

try {	if (HFileLink.isHFileLink(file.getPath())) {	HFileLink hfileLink = HFileLink.buildFromHFileLinkPattern(conf, file.getPath());	fileName = hfileLink.getOriginPath().getName();	}	Date fileDate = parseDate(MobFileName.getDateFromName(fileName));	if (LOG.isDebugEnabled()) {	}	if (fileDate.getTime() < expireDate.getTime()) {	if (LOG.isDebugEnabled()) {	
is an expired file 

}	Date fileDate = parseDate(MobFileName.getDateFromName(fileName));	if (LOG.isDebugEnabled()) {	}	if (fileDate.getTime() < expireDate.getTime()) {	if (LOG.isDebugEnabled()) {	}	filesToClean .add(new HStoreFile(fs, file.getPath(), conf, cacheConfig, BloomType.NONE, true));	}	} catch (Exception e) {	
cannot parse the filename 

filesToClean .add(new HStoreFile(fs, file.getPath(), conf, cacheConfig, BloomType.NONE, true));	}	} catch (Exception e) {	}	}	if (!filesToClean.isEmpty()) {	try {	removeMobFiles(conf, fs, tableName, mobTableDir, columnDescriptor.getName(), filesToClean);	deletedFileCount = filesToClean.size();	} catch (IOException e) {	
failed to delete the mob files 

} catch (Exception e) {	}	}	if (!filesToClean.isEmpty()) {	try {	removeMobFiles(conf, fs, tableName, mobTableDir, columnDescriptor.getName(), filesToClean);	deletedFileCount = filesToClean.size();	} catch (IOException e) {	}	}	
expired mob files are deleted 

private static void validateMobFile(Configuration conf, FileSystem fs, Path path, CacheConfig cacheConfig, boolean primaryReplica) throws IOException {	HStoreFile storeFile = null;	try {	storeFile = new HStoreFile(fs, path, conf, cacheConfig, BloomType.NONE, primaryReplica);	storeFile.initReader();	} catch (IOException e) {	
failed to open mob file keep it in temp directory 

try {	compactor = ReflectionUtils.instantiateWithCustomCtor(className, new Class[] {	Configuration.class, FileSystem.class, TableName.class, ColumnFamilyDescriptor.class, ExecutorService.class }, new Object[] { conf, fs, tableName, hcd, pool });	} catch (Exception e) {	throw new IOException("Unable to load configured mob file compactor '" + className + "'", e);	}	try {	lock.acquire();	compactor.compact(allFiles);	} catch (Exception e) {	
failed to compact the mob files for the column in the table 

return false;	}	Date expireDate = new Date(current - timeToLive * 1000);	expireDate = new Date(expireDate.getYear(), expireDate.getMonth(), expireDate.getDate());	try {	Date date = parseDate(fileDate);	if (date.getTime() < expireDate.getTime()) {	return true;	}	} catch (ParseException e) {	
failed to parse the date 

id.setThreshold(threshold);	if (threshold <= 0) {	id.setDate(dateStr);	return skipCompcation;	}	long finalThreshold;	Date date;	try {	date = MobUtils.parseDate(dateStr);	} catch (ParseException e)  {	
failed to parse date 

========================= hbase sample_3008 =========================

private boolean isFileClosed(final DistributedFileSystem dfs, final Method m, final Path p) {	try {	return (Boolean) m.invoke(dfs, p);	} catch (SecurityException e) {	
no access 

private boolean isFileClosed(final DistributedFileSystem dfs, final Method m, final Path p) {	try {	return (Boolean) m.invoke(dfs, p);	} catch (SecurityException e) {	} catch (Exception e) {	
failed invocation for 

========================= hbase sample_2249 =========================

public void testRegionMoveAndFailover() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor table = new HTableDescriptor(tableName);	HColumnDescriptor fam = new HColumnDescriptor(famName);	fam.setScope(HConstants.REPLICATION_SCOPE_SERIAL);	table.addFamily(fam);	utility1.getAdmin().createTable(table);	utility2.getAdmin().createTable(table);	try(Table t1 = utility1.getConnection().getTable(tableName);	Table t2 = utility2.getConnection().getTable(tableName)) {	
move to 

final TableName tableName = TableName.valueOf(name.getMethodName());	HTableDescriptor table = new HTableDescriptor(tableName);	HColumnDescriptor fam = new HColumnDescriptor(famName);	fam.setScope(HConstants.REPLICATION_SCOPE_SERIAL);	table.addFamily(fam);	utility1.getAdmin().createTable(table);	utility2.getAdmin().createTable(table);	try(Table t1 = utility1.getConnection().getTable(tableName);	Table t2 = utility2.getConnection().getTable(tableName)) {	moveRegion(t1, 1);	
move to 

utility2.getAdmin().createTable(table);	try(Table t1 = utility1.getConnection().getTable(tableName);	Table t2 = utility2.getConnection().getTable(tableName)) {	moveRegion(t1, 1);	moveRegion(t1, 0);	for (int i = 10; i < 20; i++) {	Put put = new Put(ROWS[i]);	put.addColumn(famName, VALUE, VALUE);	t1.put(put);	}	
move to 

try (ResultScanner results = t2.getScanner(scan)) {	for (Result result : results) {	assertEquals(1, result.rawCells().length);	list.add(result.rawCells()[0]);	}	}	List<Integer> listOfNumbers = getRowNumbers(list);	LOG.info(Arrays.toString(listOfNumbers.toArray()));	assertIntegerList(listOfNumbers, 10, 1);	if (listOfNumbers.size() != 30) {	
waiting all logs pushed to slave expected actual 

LOG.info(Arrays.toString(list22.toArray()));	assertIntegerList(list1, 10, 10);	assertIntegerList(list21, 11, 10);	assertIntegerList(list22, 51, 10);	if (!list21.isEmpty() || !list22.isEmpty()) {	assertEquals(9, list1.size());	}	if (list.size() == 18) {	return;	}	
waiting all logs pushed to slave expected actual 

}	LOG.info(Arrays.toString(list0.toArray()));	LOG.info(Arrays.toString(list1.toArray()));	assertIntegerList(list1, 11, 10);	if (!list1.isEmpty()) {	assertEquals(9, list0.size());	}	if (list.size() == 18) {	return;	}	
waiting all logs pushed to slave expected actual 

========================= hbase sample_1936 =========================

int numRegions = conf.getInt(NUM_REGIONS_KEY, DEFAULT_NUM_REGIONS);	String tableDirStr = conf.get(TABLE_DIR_KEY);	Path tableDir;	if (tableDirStr == null) {	tableDir = util.getDataTestDirOnTestFS(tableName.getQualifierAsString());	} else {	tableDir = new Path(tableDirStr);	}	final String mr = conf.get(MR_IMPLEMENTATION_KEY, MAPREDUCE_IMPLEMENTATION);	if (mr.equalsIgnoreCase(MAPREDUCE_IMPLEMENTATION)) {	
running job with mapreduce api 

if (tableDirStr == null) {	tableDir = util.getDataTestDirOnTestFS(tableName.getQualifierAsString());	} else {	tableDir = new Path(tableDirStr);	}	final String mr = conf.get(MR_IMPLEMENTATION_KEY, MAPREDUCE_IMPLEMENTATION);	if (mr.equalsIgnoreCase(MAPREDUCE_IMPLEMENTATION)) {	int expectedNumSplits = numRegions > 2 ? numRegions - 2 : numRegions;	org.apache.hadoop.hbase.mapreduce.TestTableSnapshotInputFormat.doTestWithMapReduce(util, tableName, snapshotName, START_ROW, END_ROW, tableDir, numRegions, 1, expectedNumSplits, false);	} else if (mr.equalsIgnoreCase(MAPRED_IMPLEMENTATION)) {	
running job with mapred api 

========================= hbase sample_3272 =========================

for (int i = 0; i < 10; i++) {	do {	int sign = i % 2 == 0 ? 1 : -1;	connectorPort += sign * rand.nextInt(100);	} while (!HBaseTestingUtility.available(connectorPort));	try {	conf.setInt("regionserver.rmi.registry.port", connectorPort);	UTIL.startMiniCluster();	break;	} catch (Exception e) {	
encountered exception when starting cluster trying port 

connectorPort += sign * rand.nextInt(100);	} while (!HBaseTestingUtility.available(connectorPort));	try {	conf.setInt("regionserver.rmi.registry.port", connectorPort);	UTIL.startMiniCluster();	break;	} catch (Exception e) {	try {	UTIL.shutdownMiniCluster();	} catch (Exception ex) {	
encountered exception shutting down cluster 

private Set<String> readJmxMetricsWithRetry() throws IOException {	final int count = 0;	for (int i = 0; i < 10; i++) {	Set<String> metrics = readJmxMetrics();	if (metrics != null) return metrics;	
failed to get jmxmetrics sleeping retrying of times 

pairs.put("name", "Master");	pairs.put("sub", "Balancer");	target = new ObjectName("Hadoop", pairs);	MBeanInfo beanInfo = mb.getMBeanInfo(target);	Set<String> existingAttrs = new HashSet<>();	for (MBeanAttributeInfo attrInfo : beanInfo.getAttributes()) {	existingAttrs.add(attrInfo.getName());	}	return existingAttrs;	} catch (Exception e) {	
failed to get bean 

========================= hbase sample_2176 =========================

public boolean isFileDeletable(FileStatus fStat) {	if (!AbstractFSWALProvider.validateWALFilename(fStat.getPath().getName())) {	return true;	}	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	
log life ttl current from 

public boolean isFileDeletable(FileStatus fStat) {	if (!AbstractFSWALProvider.validateWALFilename(fStat.getPath().getName())) {	return true;	}	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	}	if (life < 0) {	
found a log newer than current time probably a clock skew 

========================= hbase sample_2875 =========================

assertEquals(3, barGroup.getServers().size());	assertEquals(0, fooGroup.getServers().size());	try {	rsGroupAdmin.moveServers(Sets.newHashSet(Address.fromString("foo:9999")),"foo");	fail("Bogus servers shouldn't have been successfully moved.");	} catch(IOException ex) {	String exp = "Source RSGroup for server foo:9999 does not exist.";	String msg = "Expected '"+exp+"' in exception message: ";	assertTrue(msg+" "+ex.getMessage(), ex.getMessage().contains(exp));	}	
moving servers to group foo 

} catch(IOException ex) {	String exp = "Source RSGroup for server foo:9999 does not exist.";	String msg = "Expected '"+exp+"' in exception message: ";	assertTrue(msg+" "+ex.getMessage(), ex.getMessage().contains(exp));	}	rsGroupAdmin.moveServers(barGroup.getServers(), fooGroup.getName());	barGroup = rsGroupAdmin.getRSGroupInfo("bar");	fooGroup = rsGroupAdmin.getRSGroupInfo("foo");	assertEquals(0,barGroup.getServers().size());	assertEquals(3,fooGroup.getServers().size());	
moving servers to group default 

assertEquals(0,barGroup.getServers().size());	assertEquals(3,fooGroup.getServers().size());	rsGroupAdmin.moveServers(fooGroup.getServers(), RSGroupInfo.DEFAULT_GROUP);	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return getNumServers() == rsGroupAdmin.getRSGroupInfo(RSGroupInfo.DEFAULT_GROUP).getServers().size();	}	});	fooGroup = rsGroupAdmin.getRSGroupInfo("foo");	assertEquals(0,fooGroup.getServers().size());	
remove group 

rsGroupAdmin.moveServers(fooGroup.getServers(), RSGroupInfo.DEFAULT_GROUP);	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return getNumServers() == rsGroupAdmin.getRSGroupInfo(RSGroupInfo.DEFAULT_GROUP).getServers().size();	}	});	fooGroup = rsGroupAdmin.getRSGroupInfo("foo");	assertEquals(0,fooGroup.getServers().size());	rsGroupAdmin.removeRSGroup(barGroup.getName());	Assert.assertEquals(null, rsGroupAdmin.getRSGroupInfo(barGroup.getName()));	
remove group 

public boolean evaluate() throws Exception {	List<String> regions = getTableRegionMap().get(tableName);	if (regions == null) {	return false;	}	return getTableRegionMap().get(tableName).size() >= 5;	}	});	RSGroupInfo tableGrp = rsGroupAdmin.getRSGroupInfoOfTable(tableName);	assertTrue(tableGrp.getName().equals(RSGroupInfo.DEFAULT_GROUP));	
moving table to 

if (regionsB == null) {	return false;	}	return getTableRegionMap().get(tableNameA).size() >= 1 && getTableRegionMap().get(tableNameB).size() >= 1;	}	});	RSGroupInfo tableGrpA = rsGroupAdmin.getRSGroupInfoOfTable(tableNameA);	assertTrue(tableGrpA.getName().equals(RSGroupInfo.DEFAULT_GROUP));	RSGroupInfo tableGrpB = rsGroupAdmin.getRSGroupInfoOfTable(tableNameB);	assertTrue(tableGrpB.getName().equals(RSGroupInfo.DEFAULT_GROUP));	
moving table to 

List<String> regions = getTableRegionMap().get(tableName);	if (regions == null) {	return false;	}	return getTableRegionMap().get(tableName).size() >= 5;	}	});	RSGroupInfo tableGrp = rsGroupAdmin.getRSGroupInfoOfTable(tableName);	assertTrue(tableGrp.getName().equals(RSGroupInfo.DEFAULT_GROUP));	admin.disableTable(tableName);	
moving table to 

public void testMoveServersAndTables() throws Exception {	
testMoveServersAndTables 

return getTableRegionMap().get(tableName).size() >= 5;	}	});	ServerName targetServer = null;	for(ServerName server : admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().keySet()) {	if(!newGroup.containsServer(server.getAddress()) && !rsGroupAdmin.getRSGroupInfo("master").containsServer(server.getAddress())) {	targetServer = server;	break;	}	}	
print group info 

List<String> regionList = getTableRegionMap().get(tableName);	for(String region : regionList) {	TEST_UTIL.getAdmin().move(Bytes.toBytes(RegionInfo.encodeRegionName(Bytes.toBytes(region))), Bytes.toBytes(targetServer.getServerName()));	}	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return getTableRegionMap().get(tableName) != null && getTableRegionMap().get(tableName).size() == 5 && getTableServerRegionMap().get(tableName).size() == 1 && admin.getClusterMetrics(EnumSet.of(Option.REGIONS_IN_TRANSITION)) .getRegionStatesInTransition().size() < 1;	}	});	Assert.assertEquals(5, getTableServerRegionMap().get(tableName).get(targetServer).size());	
moving server and table to newgroup 

public void testClearDeadServers() throws Exception {	
testClearDeadServers 

public void testRemoveServers() throws Exception {	
testRemoveServers 

========================= hbase sample_3337 =========================

protected Flow executeFromState(TestProcEnv env, TestSMProcedureState state) {	
exec 

protected void rollbackState(TestProcEnv env, TestSMProcedureState state) {	
rollback 

protected Procedure[] execute(TestProcEnv env) {	
exec 

protected void rollback(TestProcEnv env) {	
rollback 

========================= hbase sample_1189 =========================

assertEquals(master.getClusterId(), info.getClusterId());	assertEquals(master.getMasterActiveTime(), info.getActiveTime());	assertEquals(master.getMasterStartTime(), info.getStartTime());	assertEquals(master.getMasterCoprocessors().length, info.getCoprocessors().length);	assertEquals(master.getServerManager().getOnlineServersList().size(), info.getNumRegionServers());	int regionServerCount = NUM_RS + (LoadBalancer.isTablesOnMaster(TEST_UTIL.getConfiguration())? 1: 0);	assertEquals(regionServerCount, info.getNumRegionServers());	String zkServers = info.getZookeeperQuorum();	assertEquals(zkServers.split(",").length, TEST_UTIL.getZkCluster().getZooKeeperServerNum());	final int index = 3;	
stopping 

========================= hbase sample_1865 =========================

if (initializers != null) {	conf = new Configuration(conf);	conf.set(BIND_ADDRESS, hostName);	for (FilterInitializer c : initializers) {	c.initFilter(this, conf);	}	}	addDefaultServlets();	if (pathSpecs != null) {	for (String path : pathSpecs) {	
adding path spec 

public void addInternalServlet(String name, String pathSpec, Class<? extends HttpServlet> clazz, boolean requireAuth) {	ServletHolder holder = new ServletHolder(clazz);	if (name != null) {	holder.setName(name);	}	webAppContext.addServlet(holder, pathSpec);	if(requireAuth && UserGroupInformation.isSecurityEnabled()) {	
adding kerberos spnego filter to 

public void start() throws IOException {	try {	try {	openListeners();	webServer.start();	} catch (IOException ex) {	
httpserver start threw a non bind ioexception 

public void start() throws IOException {	try {	try {	openListeners();	webServer.start();	} catch (IOException ex) {	throw ex;	} catch (MultiException ex) {	
httpserver start threw a multiexception 

public void stop() throws Exception {	MultiException exception = null;	for (ListenerInfo li : listeners) {	if (!li.isManaged) {	continue;	}	try {	li.listener.close();	} catch (Exception e) {	
error while stopping listener for webapp 

try {	li.listener.close();	} catch (Exception e) {	exception = addMultiException(exception, e);	}	}	try {	webAppContext.clearAttributes();	webAppContext.stop();	} catch (Exception e) {	
error while stopping web app context for webapp 

}	try {	webAppContext.clearAttributes();	webAppContext.stop();	} catch (Exception e) {	exception = addMultiException(exception, e);	}	try {	webServer.stop();	} catch (Exception e) {	
error while stopping web server for webapp 

========================= hbase sample_3225 =========================

public void preClean() {	readZKTimestamp = EnvironmentEdgeManager.currentTime();	try {	wals = queueStorage.getAllWALs();	} catch (ReplicationException e) {	
failed to read zookeeper skipping checking deletable files 

}	if (wals == null) {	return Collections.emptyList();	}	return Iterables.filter(files, new Predicate<FileStatus>() {	public boolean apply(FileStatus file) {	String wal = file.getPath().getName();	boolean logInReplicationQueue = wals.contains(wal);	if (LOG.isDebugEnabled()) {	if (logInReplicationQueue) {	
found log in zk keeping 

public void setConf(Configuration config) {	Configuration conf = new Configuration(config);	try {	setConf(conf, new ZKWatcher(conf, "replicationLogCleaner", null));	} catch (IOException e) {	
error while configuring 

public void setConf(Configuration conf, ZKWatcher zk) {	super.setConf(conf);	try {	this.zkw = zk;	this.queueStorage = ReplicationStorageFactory.getReplicationQueueStorage(zk, conf);	} catch (Exception e) {	
error while configuring 

public void stop(String why) {	if (this.stopped) return;	this.stopped = true;	if (this.zkw != null) {	
stopping 

========================= hbase sample_2967 =========================

protected void runJob(String jobName, Configuration c, List<Scan> scans) throws IOException, InterruptedException, ClassNotFoundException {	JobConf job = new JobConf(TEST_UTIL.getConfiguration());	job.setJobName(jobName);	job.setMapperClass(Mapper.class);	job.setReducerClass(Reducer.class);	TableMapReduceUtil.initMultiTableSnapshotMapperJob(getSnapshotScanMapping(scans), Mapper.class, ImmutableBytesWritable.class, ImmutableBytesWritable.class, job, true, restoreDir);	TableMapReduceUtil.addDependencyJars(job);	job.setReducerClass(Reducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	
started 

job.setMapperClass(Mapper.class);	job.setReducerClass(Reducer.class);	TableMapReduceUtil.initMultiTableSnapshotMapperJob(getSnapshotScanMapping(scans), Mapper.class, ImmutableBytesWritable.class, ImmutableBytesWritable.class, job, true, restoreDir);	TableMapReduceUtil.addDependencyJars(job);	job.setReducerClass(Reducer.class);	job.setNumReduceTasks(1);	FileOutputFormat.setOutputPath(job, new Path(job.getJobName()));	RunningJob runningJob = JobClient.runJob(job);	runningJob.waitForCompletion();	assertTrue(runningJob.isSuccessful());	
after map reduce completion job 

========================= hbase sample_3360 =========================

public void cacheLocation(final TableName tableName, final ServerName source, final HRegionLocation location) {	assert source != null;	byte [] startKey = location.getRegion().getStartKey();	ConcurrentMap<byte[], RegionLocations> tableLocations = getTableLocations(tableName);	RegionLocations locations = new RegionLocations(new HRegionLocation[] {location}) ;	RegionLocations oldLocations = tableLocations.putIfAbsent(startKey, locations);	boolean isNewCacheEntry = (oldLocations == null);	if (isNewCacheEntry) {	if (LOG.isTraceEnabled()) {	
cached location 

}	addToCachedServers(locations);	return;	}	HRegionLocation oldLocation = oldLocations.getRegionLocation( location.getRegion().getReplicaId());	boolean force = oldLocation != null && oldLocation.getServerName() != null && oldLocation.getServerName().equals(source);	RegionLocations updatedLocations = oldLocations.updateLocation(location, false, force);	if (oldLocations != updatedLocations) {	boolean replaced = tableLocations.replace(startKey, oldLocations, updatedLocations);	if (replaced && LOG.isTraceEnabled()) {	
changed cached location to 

public void cacheLocation(final TableName tableName, final RegionLocations locations) {	byte [] startKey = locations.getRegionLocation().getRegion().getStartKey();	ConcurrentMap<byte[], RegionLocations> tableLocations = getTableLocations(tableName);	RegionLocations oldLocation = tableLocations.putIfAbsent(startKey, locations);	boolean isNewCacheEntry = (oldLocation == null);	if (isNewCacheEntry) {	if (LOG.isTraceEnabled()) {	
cached location 

boolean isNewCacheEntry = (oldLocation == null);	if (isNewCacheEntry) {	if (LOG.isTraceEnabled()) {	}	addToCachedServers(locations);	return;	}	RegionLocations mergedLocation = oldLocation.mergeLocations(locations);	boolean replaced = tableLocations.replace(startKey, oldLocation, mergedLocation);	if (replaced && LOG.isTraceEnabled()) {	
merged cached locations 

}	}	}	this.cachedServers.remove(serverName);	}	if (deletedSomething) {	if (metrics != null) {	metrics.incrMetaCacheNumClearServer();	}	if (LOG.isTraceEnabled()) {	
removed all cached region locations that map to 

public void clearCache(final TableName tableName) {	if (LOG.isTraceEnabled()) {	
removed all cached region locations for table 

ConcurrentMap<byte[], RegionLocations> tableLocations = getTableLocations(tableName);	RegionLocations regionLocations = getCachedLocation(tableName, row);	if (regionLocations != null) {	byte[] startKey = regionLocations.getRegionLocation().getRegion().getStartKey();	boolean removed = tableLocations.remove(startKey, regionLocations);	if (removed) {	if (metrics != null) {	metrics.incrMetaCacheNumClearRegion();	}	if (LOG.isTraceEnabled()) {	
removed from cache 

if (updatedLocations.isEmpty()) {	removed = tableLocations.remove(startKey, regionLocations);	} else {	removed = tableLocations.replace(startKey, regionLocations, updatedLocations);	}	if (removed) {	if (metrics != null) {	metrics.incrMetaCacheNumClearRegion();	}	if (LOG.isTraceEnabled()) {	
removed from cache 

if (updatedLocations.isEmpty()) {	removed = tableLocations.remove(startKey, regionLocations);	} else {	removed = tableLocations.replace(startKey, regionLocations, updatedLocations);	}	if (removed) {	if (metrics != null) {	metrics.incrMetaCacheNumClearRegion();	}	if (LOG.isTraceEnabled()) {	
removed locations of table row mapping to server from cache 

if (updatedLocations.isEmpty()) {	removed = tableLocations.remove(hri.getStartKey(), regionLocations);	} else {	removed = tableLocations.replace(hri.getStartKey(), regionLocations, updatedLocations);	}	if (removed) {	if (metrics != null) {	metrics.incrMetaCacheNumClearRegion();	}	if (LOG.isTraceEnabled()) {	
removed from cache 

if (updatedLocations.isEmpty()) {	removed = tableLocations.remove(location.getRegion().getStartKey(), regionLocations);	} else {	removed = tableLocations.replace(location.getRegion().getStartKey(), regionLocations, updatedLocations);	}	if (removed) {	if (metrics != null) {	metrics.incrMetaCacheNumClearRegion();	}	if (LOG.isTraceEnabled()) {	
removed from cache 

========================= hbase sample_390 =========================

TableName tn = helper.createTableWithRegions(10);	final long sizeLimit = 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	final SpaceViolationPolicy violationPolicy = SpaceViolationPolicy.NO_INSERTS;	QuotaSettings settings = QuotaSettingsFactory.limitTableSpace(tn, sizeLimit, violationPolicy);	TEST_UTIL.getAdmin().setQuota(settings);	helper.writeData(tn, 3L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	Map<TableName,SpaceQuotaSnapshot> quotaSnapshots = snapshotNotifier.copySnapshots();	boolean foundSnapshot = false;	while (!foundSnapshot) {	if (quotaSnapshots.isEmpty()) {	
found no violated quotas sleeping and retrying current reports 

boolean foundSnapshot = false;	while (!foundSnapshot) {	if (quotaSnapshots.isEmpty()) {	sleepWithInterrupt(DEFAULT_WAIT_MILLIS);	quotaSnapshots = snapshotNotifier.copySnapshots();	} else {	Entry<TableName,SpaceQuotaSnapshot> entry = Iterables.getOnlyElement(quotaSnapshots.entrySet());	assertEquals(tn, entry.getKey());	final SpaceQuotaSnapshot snapshot = entry.getValue();	if (!snapshot.getQuotaStatus().isInViolation()) {	
found a snapshot but it was not yet in violation 

QuotaSettings settings = QuotaSettingsFactory.limitNamespaceSpace(namespace, sizeLimit, violationPolicy);	admin.setQuota(settings);	helper.writeData(tn1, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn1);	Map<TableName,SpaceQuotaSnapshot> snapshots = snapshotNotifier.copySnapshots();	for (int i = 0; i < 5; i++) {	assertEquals( "Should not see any quota violations after writing 2MB of data", 0, numSnapshotsInViolation(snapshots));	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

snapshots = snapshotNotifier.copySnapshots();	}	helper.writeData(tn2, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn2);	snapshots = snapshotNotifier.copySnapshots();	for (int i = 0; i < 5; i++) {	assertEquals("Should not see any quota violations after writing 4MB of data", 0, numSnapshotsInViolation(snapshots));	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	}	snapshots = snapshotNotifier.copySnapshots();	}	helper.writeData(tn3, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn3);	snapshots = snapshotNotifier.copySnapshots();	while (numSnapshotsInViolation(snapshots) < 3) {	
saw fewer violations than desired expected current reports 

}	snapshots = snapshotNotifier.copySnapshots();	}	helper.writeData(tn3, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn3);	snapshots = snapshotNotifier.copySnapshots();	while (numSnapshotsInViolation(snapshots) < 3) {	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

QuotaSettings namespaceSettings = QuotaSettingsFactory.limitNamespaceSpace(namespace, namespaceSizeLimit, namespaceViolationPolicy);	admin.setQuota(namespaceSettings);	helper.writeData(tn1, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn1);	Map<TableName,SpaceQuotaSnapshot> snapshots = snapshotNotifier.copySnapshots();	for (int i = 0; i < 5; i++) {	assertEquals("Should not see any quota violations after writing 2MB of data: " + snapshots, 0, numSnapshotsInViolation(snapshots));	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	}	snapshots = snapshotNotifier.copySnapshots();	}	helper.writeData(tn2, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn2);	snapshots = snapshotNotifier.copySnapshots();	while (numSnapshotsInViolation(snapshots) < 2) {	
saw fewer violations than desired expected current reports 

}	snapshots = snapshotNotifier.copySnapshots();	}	helper.writeData(tn2, 2L * SpaceQuotaHelperForTests.ONE_MEGABYTE);	admin.flush(tn2);	snapshots = snapshotNotifier.copySnapshots();	while (numSnapshotsInViolation(snapshots) < 2) {	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

assertEquals(namespaceViolationPolicy, actualPolicyTN2.getQuotaStatus().getPolicy());	final long tableSizeLimit = SpaceQuotaHelperForTests.ONE_MEGABYTE;	final SpaceViolationPolicy tableViolationPolicy = SpaceViolationPolicy.NO_INSERTS;	QuotaSettings tableSettings = QuotaSettingsFactory.limitTableSpace(tn1, tableSizeLimit, tableViolationPolicy);	admin.setQuota(tableSettings);	while (true) {	snapshots = snapshotNotifier.copySnapshots();	SpaceQuotaSnapshot actualTableSnapshot = snapshots.get(tn1);	assertNotNull("Violation policy should never be null", actualTableSnapshot);	if (tableViolationPolicy != actualTableSnapshot.getQuotaStatus().getPolicy()) {	
saw unexpected table violation policy waiting and re checking 

QuotaSettings tableSettings = QuotaSettingsFactory.limitTableSpace(tn1, tableSizeLimit, tableViolationPolicy);	admin.setQuota(tableSettings);	while (true) {	snapshots = snapshotNotifier.copySnapshots();	SpaceQuotaSnapshot actualTableSnapshot = snapshots.get(tn1);	assertNotNull("Violation policy should never be null", actualTableSnapshot);	if (tableViolationPolicy != actualTableSnapshot.getQuotaStatus().getPolicy()) {	try {	Thread.sleep(DEFAULT_WAIT_MILLIS);	} catch (InterruptedException e) {	
interrupted while sleeping 

private void sleepWithInterrupt(long millis) {	try {	Thread.sleep(millis);	} catch (InterruptedException e) {	
interrupted while sleeping 

========================= hbase sample_1424 =========================

System.out.println(str);	printUsageAndExit();	}	}	System.out.println("OfflineMetaRepair command line options: " + StringUtils.join(args, " "));	boolean success = false;	try {	success = fsck.rebuildMeta(fixHoles);	} catch (MultipleIOException mioes) {	for (IOException ioe : mioes.getExceptions()) {	
bailed out due to 

}	}	System.out.println("OfflineMetaRepair command line options: " + StringUtils.join(args, " "));	boolean success = false;	try {	success = fsck.rebuildMeta(fixHoles);	} catch (MultipleIOException mioes) {	for (IOException ioe : mioes.getExceptions()) {	}	} catch (Exception e) {	
bailed out due to 

========================= hbase sample_2208 =========================

public void testBackupDeleteRestore() throws Exception {	
test full restore on a single table empty table 

public void testBackupDeleteRestore() throws Exception {	List<TableName> tables = Lists.newArrayList(table1);	String backupId = fullTableBackup(tables);	assertTrue(checkSucceeded(backupId));	
backup complete 

========================= hbase sample_543 =========================

builder.clear();	tries = 0;	} catch (IOException e) {	boolean pause = e instanceof ServerNotRunningYetException || e instanceof PleaseHoldException;	long pauseTime;	if (pause) {	pauseTime = ConnectionUtils.getPauseTime(INIT_PAUSE_TIME_MS, tries);	} else {	pauseTime = INIT_PAUSE_TIME_MS;	}	
failed report procedure retry after ms delay master is coming online immediately 

========================= hbase sample_2658 =========================

public void tearDown() throws Exception {	try {	FileSystem fs = UTIL.getTestFileSystem();	for (Path file : toCleanup) {	FSUtils.delete(fs, file, true);	}	} catch (IOException e) {	
failure to delete archive directory 

public static void cleanupTest() throws Exception {	try {	CONNECTION.close();	UTIL.shutdownMiniZKCluster();	} catch (Exception e) {	
problem shutting down cluster 

public void testArchivingEnableDisable() throws Exception {	
starting archiving 

private List<BaseHFileCleanerDelegate> turnOnArchiving(String tableName, HFileCleaner cleaner) throws IOException, KeeperException {	
starting archiving for table 

private CountDownLatch setupCleanerWatching(LongTermArchivingHFileCleaner cleaner, List<BaseHFileCleanerDelegate> cleaners, final int expected) {	BaseHFileCleanerDelegate delegateSpy = Mockito.spy(cleaner);	final int[] counter = new int[] { 0 };	final CountDownLatch finished = new CountDownLatch(1);	Mockito.doAnswer(new Answer<Iterable<FileStatus>>() {	public Iterable<FileStatus> answer(InvocationOnMock invocation) throws Throwable {	counter[0]++;	
wrapping call to getdeletablefiles for files 

private List<Path> getAllFiles(FileSystem fs, Path dir) throws IOException {	FileStatus[] files = FSUtils.listStatus(fs, dir, null);	if (files == null) {	
no files under 

private void loadFlushAndCompact(HRegion region, byte[] family) throws IOException {	createHFileInRegion(region, family);	createHFileInRegion(region, family);	HStore s = region.getStore(family);	int count = s.getStorefilesCount();	assertTrue("Don't have the expected store files, wanted >= 2 store files, but was:" + count, count >= 2);	
compacting stores 

========================= hbase sample_1998 =========================

RegionInfo[] regions = MasterProcedureTestingUtility.createTable( procExec, tableName, null, "f");	UTIL.getAdmin().disableTable(tableName);	long procId1 = procExec.submitProcedure( new DeleteTableProcedure(procExec.getEnvironment(), tableName));	long procId2 = procExec.submitProcedure( new DeleteTableProcedure(procExec.getEnvironment(), tableName));	ProcedureTestingUtility.waitProcedure(procExec, procId1);	ProcedureTestingUtility.waitProcedure(procExec, procId2);	ProcedureTestingUtility.assertProcNotFailed(procExec, procId1);	MasterProcedureTestingUtility.validateTableDeletion(getMaster(), tableName);	Procedure<?> result = procExec.getResult(procId2);	assertTrue(result.isFailed());	
delete failed with exception 

========================= hbase sample_1832 =========================

public void testExpectedNumberOfCellsPerPartialResult(Scan baseScan, int expectedNumberOfCells) throws Exception {	
groupsize 

if (CELL_HEAP_SIZE == -1) {	Scan scan = new Scan();	scan.setMaxResultSize(2);	scan.setAllowPartialResults(true);	ResultScanner scanner = TABLE.getScanner(scan);	Result result = scanner.next();	assertTrue(result != null);	assertTrue(result.rawCells() != null);	assertTrue(result.rawCells().length == 1);	CELL_HEAP_SIZE = PrivateCellUtil.estimatedHeapSizeOf(result.rawCells()[0]) - (ClassSize.ARRAY+3);	
cell heap size 

public void testPartialResultsAndBatch(final int batch, final int cellsPerPartialResult) throws Exception {	if (LOG.isInfoEnabled()) {	
batch cellsperpartialresult 

static void verifyResult(Result result, List<Cell> expKvList, String msg) {	if (LOG.isInfoEnabled()) {	LOG.info(msg);	
expected count 

static void verifyResult(Result result, List<Cell> expKvList, String msg) {	if (LOG.isInfoEnabled()) {	LOG.info(msg);	
actual count 

========================= hbase sample_1561 =========================

memstorescanners = this.memstore.getScanners(mvcc.getReadPoint());	count = 0;	try (StoreScanner s = new StoreScanner(scan, scanInfo, null, memstorescanners)) {	while (s.next(result)) {	LOG.info(Objects.toString(result));	assertTrue(CellUtil.matchingRows(result.get(0), Bytes.toBytes(count)));	count++;	assertEquals(rowCount, result.size());	if (count == 2) {	this.memstore.snapshot();	
Snapshotted 

try (StoreScanner s = new StoreScanner(scan, scanInfo, null, memstorescanners)) {	while (s.next(result)) {	LOG.info(Objects.toString(result));	assertTrue(CellUtil.matchingRows(result.get(0), Bytes.toBytes(count)));	assertEquals("count=" + count + ", result=" + result, rowCount, result.size());	count++;	if (count == snapshotIndex) {	MemStoreSnapshot snapshot = this.memstore.snapshot();	this.memstore.clearSnapshot(snapshot.getId());	addRows(this.memstore, ts);	
snapshotted cleared it and then added values which wont be seen 

========================= hbase sample_1776 =========================

public TestCallQueue(int elementsAdded, int elementsRemoved) {	this.elementsAdded = elementsAdded;	this.elementsRemoved = elementsRemoved;	
elementsadded elementsremoved 

========================= hbase sample_754 =========================

public void start(CoprocessorEnvironment env) {	this.env = (RegionCoprocessorEnvironment)env;	rsServices = ((HasRegionServerServices)this.env).getRegionServerServices();	
securebulkloadendpoint is deprecated it will be removed in future releases 

public void start(CoprocessorEnvironment env) {	this.env = (RegionCoprocessorEnvironment)env;	rsServices = ((HasRegionServerServices)this.env).getRegionServerServices();	
secure bulk load has been integrated into hbase core 

========================= hbase sample_1263 =========================

public void transitionTable( TableName tableName, SpaceQuotaSnapshot snapshot) throws IOException {	final Put p = QuotaTableUtil.createPutForSpaceSnapshot(tableName, snapshot);	try (Table quotaTable = conn.getTable(QuotaTableUtil.QUOTA_TABLE_NAME)) {	if (LOG.isTraceEnabled()) {	
persisting a space quota snapshot for 

========================= hbase sample_2336 =========================

public void processed(RegionServerOperation op) {	if (this.closed || !(op instanceof ProcessRegionClose)) return;	ProcessRegionClose close = (ProcessRegionClose)op;	for (HRegion r: this.copyOfOnlineRegions) {	if (r.getRegionInfo().equals(close.regionInfo)) {	
found close of setting close happened flag 

========================= hbase sample_1849 =========================

public void preBatchMutate(final ObserverContext<RegionCoprocessorEnvironment> c, final MiniBatchOperationInProgress<Mutation> miniBatchOp) throws IOException {	if (ops.incrementAndGet() % 20000 == 0) {	
wrote times in region 

========================= hbase sample_3032 =========================

public void start() {	try {	this.zkWatcher.start();	this.leaderElector.start();	} catch (KeeperException ke) {	
zookeeper initialization failed 

public byte[] retrievePassword(AuthenticationTokenIdentifier identifier) throws InvalidToken {	long now = EnvironmentEdgeManager.currentTime();	if (identifier.getExpirationDate() < now) {	throw new InvalidToken("Token has expired");	}	AuthenticationKey masterKey = allKeys.get(identifier.getKeyId());	if(masterKey == null) {	if(zkWatcher.getWatcher().isAborted()) {	
zkwatcher is abort 

if (identifier.getExpirationDate() < now) {	throw new InvalidToken("Token has expired");	}	AuthenticationKey masterKey = allKeys.get(identifier.getKeyId());	if(masterKey == null) {	if(zkWatcher.getWatcher().isAborted()) {	throw new InvalidToken("Token keys could not be sync from zookeeper" + " because of ZKWatcher abort");	}	synchronized (this) {	if (!leaderElector.isAlive() || leaderElector.isStopped()) {	
thread leaderelector is stopped or not alive 

throw new InvalidToken("Token has expired");	}	AuthenticationKey masterKey = allKeys.get(identifier.getKeyId());	if(masterKey == null) {	if(zkWatcher.getWatcher().isAborted()) {	throw new InvalidToken("Token keys could not be sync from zookeeper" + " because of ZKWatcher abort");	}	synchronized (this) {	if (!leaderElector.isAlive() || leaderElector.isStopped()) {	leaderElector.start();	
thread leaderelector is started 

if(zkWatcher.getWatcher().isAborted()) {	throw new InvalidToken("Token keys could not be sync from zookeeper" + " because of ZKWatcher abort");	}	synchronized (this) {	if (!leaderElector.isAlive() || leaderElector.isStopped()) {	leaderElector.start();	}	}	zkWatcher.refreshKeys();	if (LOG.isDebugEnabled()) {	
sync token keys from zookeeper 

public synchronized void addKey(AuthenticationKey key) throws IOException {	if (leaderElector.isMaster()) {	if (LOG.isDebugEnabled()) {	
running as master ignoring new key 

public synchronized void addKey(AuthenticationKey key) throws IOException {	if (leaderElector.isMaster()) {	if (LOG.isDebugEnabled()) {	}	return;	}	if (LOG.isDebugEnabled()) {	
adding key 

public void stop(String reason) {	if (stopped) {	return;	}	stopped = true;	if (isMaster) {	zkLeader.stepDownAsLeader();	}	isMaster = false;	
stopping leader election because 

long now = EnvironmentEdgeManager.currentTime();	removeExpiredKeys();	long localLastKeyUpdate = getLastKeyUpdate();	if (localLastKeyUpdate + keyUpdateInterval < now) {	rollCurrentKey();	}	try {	Thread.sleep(5000);	} catch (InterruptedException ie) {	if (LOG.isDebugEnabled()) {	
interrupted waiting for next update 

========================= hbase sample_2273 =========================

public void TestIncBackupRestore() throws Exception {	int ADD_ROWS = 99;	
create full backup image for all tables 

Connection conn = ConnectionFactory.createConnection(conf1);	int NB_ROWS_FAM3 = 6;	insertIntoTable(conn, table1, fam3Name, 3, NB_ROWS_FAM3).close();	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	
writing rows to 

insertIntoTable(conn, table1, fam3Name, 3, NB_ROWS_FAM3).close();	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH + ADD_ROWS + NB_ROWS_FAM3);	t1.close();	
written rows to 

t1.close();	HTable t2 = (HTable) conn.getTable(table2);	Put p2;	for (int i = 0; i < 5; i++) {	p2 = new Put(Bytes.toBytes("row-t2" + i));	p2.addColumn(famName, qualName, Bytes.toBytes("val" + i));	t2.put(p2);	}	Assert.assertEquals(TEST_UTIL.countRows(t2), NB_ROWS_IN_BATCH + 5);	t2.close();	
written rows to 

}	Assert.assertEquals(TEST_UTIL.countRows(t2), NB_ROWS_IN_BATCH + 5);	t2.close();	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	List<HRegion> regions = cluster.getRegions(table1);	byte[] name = regions.get(0).getRegionInfo().getRegionName();	long startSplitTime = EnvironmentEdgeManager.currentTime();	try {	admin.splitRegion(name);	} catch (IOException e) {	
region is not splittable because 

table1Desc.removeFamily(fam3Name);	HBaseTestingUtility.modifyTableSync(TEST_UTIL.getAdmin(), table1Desc);	int NB_ROWS_FAM2 = 7;	HTable t3 = insertIntoTable(conn, table1, fam2Name, 2, NB_ROWS_FAM2);	t3.close();	request = createBackupRequest(BackupType.INCREMENTAL, tables, BACKUP_ROOT_DIR);	String backupIdIncMultiple2 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdIncMultiple2));	TableName[] tablesRestoreFull = new TableName[] { table1, table2 };	TableName[] tablesMapFull = new TableName[] { table1_restore, table2_restore };	
restoring full 

HTable hTable = (HTable) conn.getTable(table1_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH + NB_ROWS_FAM3);	hTable.close();	hTable = (HTable) conn.getTable(table2_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH);	hTable.close();	TableName[] tablesRestoreIncMultiple = new TableName[] { table1, table2 };	TableName[] tablesMapIncMultiple = new TableName[] { table1_restore, table2_restore };	client.restore(BackupUtils.createRestoreRequest(BACKUP_ROOT_DIR, backupIdIncMultiple2, false, tablesRestoreIncMultiple, tablesMapIncMultiple, true));	hTable = (HTable) conn.getTable(table1_restore);	
after incremental restore 

HTable hTable = (HTable) conn.getTable(table1_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH + NB_ROWS_FAM3);	hTable.close();	hTable = (HTable) conn.getTable(table2_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH);	hTable.close();	TableName[] tablesRestoreIncMultiple = new TableName[] { table1, table2 };	TableName[] tablesMapIncMultiple = new TableName[] { table1_restore, table2_restore };	client.restore(BackupUtils.createRestoreRequest(BACKUP_ROOT_DIR, backupIdIncMultiple2, false, tablesRestoreIncMultiple, tablesMapIncMultiple, true));	hTable = (HTable) conn.getTable(table1_restore);	
has rows 

Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH + NB_ROWS_FAM3);	hTable.close();	hTable = (HTable) conn.getTable(table2_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable), NB_ROWS_IN_BATCH);	hTable.close();	TableName[] tablesRestoreIncMultiple = new TableName[] { table1, table2 };	TableName[] tablesMapIncMultiple = new TableName[] { table1_restore, table2_restore };	client.restore(BackupUtils.createRestoreRequest(BACKUP_ROOT_DIR, backupIdIncMultiple2, false, tablesRestoreIncMultiple, tablesMapIncMultiple, true));	hTable = (HTable) conn.getTable(table1_restore);	Assert.assertEquals(TEST_UTIL.countRows(hTable, famName), NB_ROWS_IN_BATCH + ADD_ROWS);	
has rows 

========================= hbase sample_538 =========================

protected boolean addToRemoteDispatcher(final MasterProcedureEnv env, final ServerName targetServer) {	assert targetServer == null || targetServer.equals(getRegionState(env).getRegionLocation()): "targetServer=" + targetServer + " getRegionLocation=" + getRegionState(env).getRegionLocation();	
dispatch 

if (regionNode.getProcedureEvent().suspendIfNotReady(this)) {	throw new ProcedureSuspendedException();	}	break;	case REGION_TRANSITION_FINISH: finishTransition(env, regionNode);	am.removeRegionInTransition(regionNode, this);	return null;	}	} while (retry);	} catch (IOException e) {	
retryable error trying to transition 

========================= hbase sample_2789 =========================

public void abort(String reason, Throwable error) {	
aborting on 

public void stop(String reason) {	
stopping due to 

public AuthenticationProtos.GetAuthenticationTokenResponse getAuthenticationToken( RpcController controller, AuthenticationProtos.GetAuthenticationTokenRequest request) throws ServiceException {	
authentication token request from 

public AuthenticationProtos.WhoAmIResponse whoAmI( RpcController controller, AuthenticationProtos.WhoAmIRequest request) throws ServiceException {	
whoami request from 

========================= hbase sample_1371 =========================

public void testPrimaryRegionKill() throws Exception {	try (Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(htd.getTableName())) {	HTU.loadNumericRows(table, fam, 0, 1000);	verifyNumericRowsWithTimeout(table, fam, 0, 1000, 1, 30000);	verifyNumericRowsWithTimeout(table, fam, 0, 1000, 2, 30000);	boolean aborted = false;	for (RegionServerThread rs : HTU.getMiniHBaseCluster().getRegionServerThreads()) {	for (Region r : rs.getRegionServer().getRegions(htd.getTableName())) {	if (r.getRegionInfo().getReplicaId() == 0) {	
aborting region server hosting primary region replica 

public void testSecondaryRegionKill() throws Exception {	try (Connection connection = ConnectionFactory.createConnection(HTU.getConfiguration());	Table table = connection.getTable(htd.getTableName())) {	HTU.loadNumericRows(table, fam, 0, 1000);	verifyNumericRowsWithTimeout(table, fam, 0, 1000, 1, 30000);	verifyNumericRowsWithTimeout(table, fam, 0, 1000, 2, 30000);	boolean aborted = false;	for (RegionServerThread rs : HTU.getMiniHBaseCluster().getRegionServerThreads()) {	for (Region r : rs.getRegionServer().getRegions(htd.getTableName())) {	if (r.getRegionInfo().getReplicaId() == 1) {	
aborting region server hosting secondary region replica 

}	};	loader.start();	Thread aborter = new Thread() {	public void run() {	try {	boolean aborted = false;	for (RegionServerThread rs : HTU.getMiniHBaseCluster().getRegionServerThreads()) {	for (Region r : rs.getRegionServer().getRegions(htd.getTableName())) {	if (r.getRegionInfo().getReplicaId() == 1) {	
aborting region server hosting secondary region replica 

ex.compareAndSet(null, e);	}	}	};	aborter.start();	aborter.join();	done.set(true);	loader.join();	assertNull(ex.get());	assertTrue(key.get() > 1000);	
loaded up to key 

========================= hbase sample_1664 =========================

this.enforceStreamCapability = conf.getBoolean(CommonFSUtils.UNSAFE_STREAM_CAPABILITY_ENFORCE, true);	if (!fs.exists(walDir)) {	if (!fs.mkdirs(walDir)) {	throw new IOException("Unable to mkdir " + walDir);	}	}	CommonFSUtils.setStoragePolicy(fs, conf, walDir, HConstants.WAL_STORAGE_POLICY, HConstants.DEFAULT_WAL_STORAGE_POLICY);	if (this.walArchiveDir != null && !this.fs.exists(this.walArchiveDir)) {	if (this.fs.mkdirs(this.walArchiveDir)) {	if (LOG.isDebugEnabled()) {	
created procedure store wal archive dir 

if (!fs.mkdirs(walDir)) {	throw new IOException("Unable to mkdir " + walDir);	}	}	CommonFSUtils.setStoragePolicy(fs, conf, walDir, HConstants.WAL_STORAGE_POLICY, HConstants.DEFAULT_WAL_STORAGE_POLICY);	if (this.walArchiveDir != null && !this.fs.exists(this.walArchiveDir)) {	if (this.fs.mkdirs(this.walArchiveDir)) {	if (LOG.isDebugEnabled()) {	}	} else {	
failed create of 

rollThreshold = conf.getLong(ROLL_THRESHOLD_CONF_KEY, DEFAULT_ROLL_THRESHOLD);	periodicRollMsec = conf.getInt(PERIODIC_ROLL_CONF_KEY, DEFAULT_PERIODIC_ROLL);	syncWaitMsec = conf.getInt(SYNC_WAIT_MSEC_CONF_KEY, DEFAULT_SYNC_WAIT_MSEC);	useHsync = conf.getBoolean(USE_HSYNC_CONF_KEY, DEFAULT_USE_HSYNC);	syncMetricsQueue = new CircularFifoQueue( conf.getInt(STORE_WAL_SYNC_STATS_COUNT, DEFAULT_SYNC_STATS_COUNT));	syncThread = new Thread("WALProcedureStoreSyncThread") {	public void run() {	try {	syncLoop();	} catch (Throwable e) {	
got an exception from the sync loop 

}	LOG.info("Stopping the WAL Procedure Store, isAbort=" + abort + (isSyncAborted() ? " (self aborting)" : ""));	sendStopSignal();	if (!isSyncAborted()) {	try {	while (syncThread.isAlive()) {	sendStopSignal();	syncThread.join(250);	}	} catch (InterruptedException e) {	
join interrupted 

public void recoverLease() throws IOException {	lock.lock();	try {	
starting wal procedure store lease recovery 

public void recoverLease() throws IOException {	lock.lock();	try {	FileStatus[] oldLogs = getLogFiles();	while (isRunning()) {	try {	flushLogId = initOldLogs(oldLogs);	} catch (FileNotFoundException e) {	
someone else is active and deleted logs retrying 

try {	FileStatus[] oldLogs = getLogFiles();	while (isRunning()) {	try {	flushLogId = initOldLogs(oldLogs);	} catch (FileNotFoundException e) {	oldLogs = getLogFiles();	continue;	}	if (!rollWriter(flushLogId + 1)) {	
someone else has already created log 

} catch (FileNotFoundException e) {	oldLogs = getLogFiles();	continue;	}	if (!rollWriter(flushLogId + 1)) {	continue;	}	oldLogs = getLogFiles();	if (getMaxLogId(oldLogs) > flushLogId) {	if (LOG.isDebugEnabled()) {	
someone else created new logs expected maxlogid 

if (!rollWriter(flushLogId + 1)) {	continue;	}	oldLogs = getLogFiles();	if (getMaxLogId(oldLogs) > flushLogId) {	if (LOG.isDebugEnabled()) {	}	logs.getLast().removeFile(this.walArchiveDir);	continue;	}	
lease acquired for flushlogid 

public void load(final ProcedureLoader loader) throws IOException {	lock.lock();	try {	if (logs.isEmpty()) {	throw new RuntimeException("recoverLease() must be called before loading data");	}	if (logs.size() == 1) {	if (LOG.isDebugEnabled()) {	
no state logs to replay 

public void insert(final Procedure[] procs) {	if (LOG.isTraceEnabled()) {	
insert 

ByteSlot slot = acquireSlot();	try {	long[] procIds = new long[procs.length];	for (int i = 0; i < procs.length; ++i) {	assert !procs[i].hasParent();	procIds[i] = procs[i].getProcId();	ProcedureWALFormat.writeInsert(slot, procs[i]);	}	pushData(PushType.INSERT, slot, Procedure.NO_PROC_ID, procIds);	} catch (IOException e) {	
unable to serialize one of the procedure 

public void update(final Procedure proc) {	if (LOG.isTraceEnabled()) {	
update 

public void update(final Procedure proc) {	if (LOG.isTraceEnabled()) {	}	ByteSlot slot = acquireSlot();	try {	ProcedureWALFormat.writeUpdate(slot, proc);	pushData(PushType.UPDATE, slot, proc.getProcId(), null);	} catch (IOException e) {	
unable to serialize the procedure 

public void delete(final long procId) {	if (LOG.isTraceEnabled()) {	
delete 

public void delete(final long procId) {	if (LOG.isTraceEnabled()) {	}	ByteSlot slot = acquireSlot();	try {	ProcedureWALFormat.writeDelete(slot, procId);	pushData(PushType.DELETE, slot, procId, null);	} catch (IOException e) {	
unable to serialize the procedure 

public void delete(final Procedure proc, final long[] subProcIds) {	assert proc != null : "expected a non-null procedure";	assert subProcIds != null && subProcIds.length > 0 : "expected subProcIds";	if (LOG.isTraceEnabled()) {	
update and delete 

public void delete(final Procedure proc, final long[] subProcIds) {	assert proc != null : "expected a non-null procedure";	assert subProcIds != null && subProcIds.length > 0 : "expected subProcIds";	if (LOG.isTraceEnabled()) {	}	ByteSlot slot = acquireSlot();	try {	ProcedureWALFormat.writeDelete(slot, proc, subProcIds);	pushData(PushType.DELETE, slot, proc.getProcId(), subProcIds);	} catch (IOException e) {	
unable to serialize the procedure 

private void delete(final long[] procIds) {	if (LOG.isTraceEnabled()) {	
delete 

private void delete(final long[] procIds) {	if (LOG.isTraceEnabled()) {	}	final ByteSlot slot = acquireSlot();	try {	for (int i = 0; i < procIds.length; ++i) {	ProcedureWALFormat.writeDelete(slot, procIds[i]);	}	pushData(PushType.DELETE, slot, Procedure.NO_PROC_ID, procIds);	} catch (IOException e) {	
unable to serialize the procedures 

int logRolled = 0;	long totalSynced = 0;	do {	try {	totalSynced = syncSlots(stream, slots, 0, slotIndex);	break;	} catch (Throwable e) {	LOG.warn("unable to sync slots, retry=" + retry);	if (++retry >= maxRetriesBeforeRoll) {	if (logRolled >= maxSyncFailureRoll && isRunning()) {	
sync slots after log roll failed abort 

for (int i = 0; i < rollRetries && isRunning(); ++i) {	if (i > 0) Threads.sleepWithoutInterrupt(waitBeforeRoll * i);	try {	if (rollWriter()) {	return true;	}	} catch (IOException e) {	LOG.warn("Unable to roll the log, attempt=" + (i + 1), e);	}	}	
unable to roll the log 

private boolean tryRollWriter() {	try {	return rollWriter();	} catch (IOException e) {	
unable to roll the log 

private void periodicRoll() throws IOException {	if (storeTracker.isEmpty()) {	if (LOG.isTraceEnabled()) {	
no active procedures 

private void periodicRoll() throws IOException {	if (storeTracker.isEmpty()) {	if (LOG.isTraceEnabled()) {	}	tryRollWriter();	removeAllLogs(flushLogId - 1);	} else {	if (storeTracker.isUpdated()) {	if (LOG.isTraceEnabled()) {	
all the active procedures are in the latest log 

private boolean rollWriter() throws IOException {	if (!isRunning()) return false;	if (!rollWriter(flushLogId + 1)) {	
someone else has already created log 

private boolean rollWriter() throws IOException {	if (!isRunning()) return false;	if (!rollWriter(flushLogId + 1)) {	return false;	}	if (getMaxLogId(getLogFiles()) > flushLogId) {	
someone else created new logs expected maxlogid 

========================= hbase sample_1234 =========================

if (blockNumCapacity >= Integer.MAX_VALUE) {	throw new IllegalArgumentException("Cache capacity is too large, only support 32TB now");	}	this.acceptableFactor = conf.getFloat(ACCEPT_FACTOR_CONFIG_NAME, DEFAULT_ACCEPT_FACTOR);	this.minFactor = conf.getFloat(MIN_FACTOR_CONFIG_NAME, DEFAULT_MIN_FACTOR);	this.extraFreeFactor = conf.getFloat(EXTRA_FREE_FACTOR_CONFIG_NAME, DEFAULT_EXTRA_FREE_FACTOR);	this.singleFactor = conf.getFloat(SINGLE_FACTOR_CONFIG_NAME, DEFAULT_SINGLE_FACTOR);	this.multiFactor = conf.getFloat(MULTI_FACTOR_CONFIG_NAME, DEFAULT_MULTI_FACTOR);	this.memoryFactor = conf.getFloat(MEMORY_FACTOR_CONFIG_NAME, DEFAULT_MEMORY_FACTOR);	sanityCheckConfigs();	
instantiating bucketcache with acceptablefactor minfactor extrafreefactor singlefactor multifactor memoryfactor 

for (int i = 0; i < writerThreads.length; ++i) {	writerQueues.add(new ArrayBlockingQueue<>(writerQLen));	}	assert writerQueues.size() == writerThreads.length;	this.ramCache = new ConcurrentHashMap<>();	this.backingMap = new ConcurrentHashMap<>((int) blockNumCapacity);	if (ioEngine.isPersistent() && persistencePath != null) {	try {	retrieveFromFile(bucketSizes);	} catch (IOException ioex) {	
can t restore from file because of 

writerQueues.add(new ArrayBlockingQueue<>(writerQLen));	}	assert writerQueues.size() == writerThreads.length;	this.ramCache = new ConcurrentHashMap<>();	this.backingMap = new ConcurrentHashMap<>((int) blockNumCapacity);	if (ioEngine.isPersistent() && persistencePath != null) {	try {	retrieveFromFile(bucketSizes);	} catch (IOException ioex) {	} catch (ClassNotFoundException cnfe) {	
can t restore from file in rebuild because can t deserialise 

if (cachedBlock.getMemoryType() == MemoryType.SHARED) {	bucketEntry.refCount.incrementAndGet();	}	bucketEntry.access(accessCount.incrementAndGet());	if (this.ioErrorStartTime > 0) {	ioErrorStartTime = -1;	}	return cachedBlock;	}	} catch (IOException ioex) {	
failed reading block from bucket cache 

int refCount = bucketEntry.refCount.get();	if(refCount == 0) {	if (backingMap.remove(cacheKey, bucketEntry)) {	blockEvicted(cacheKey, bucketEntry, removedBlock == null);	} else {	return false;	}	} else {	if(!deletedBlock) {	if (LOG.isDebugEnabled()) {	
this block is still referred by readers can not be freed now 

} else {	return false;	}	} else {	if(!deletedBlock) {	if (LOG.isDebugEnabled()) {	}	return false;	} else {	if (LOG.isDebugEnabled()) {	
this block is still referred by readers can not be freed now hence will mark this for evicting at a later point 

freeEntireBuckets(DEFAULT_FREE_ENTIRE_BLOCK_FACTOR * bucketSizesAboveThresholdCount(1.0f));	if (LOG.isDebugEnabled()) {	long single = bucketSingle.totalSize();	long multi = bucketMulti.totalSize();	long memory = bucketMemory.totalSize();	if (LOG.isDebugEnabled()) {	LOG.debug("Bucket cache free space completed; " + "freed=" + StringUtils.byteDesc(bytesFreed) + ", " + "total=" + StringUtils.byteDesc(totalSize) + ", " + "single=" + StringUtils.byteDesc(single) + ", " + "multi=" + StringUtils.byteDesc(multi) + ", " + "memory=" + StringUtils.byteDesc(memory));	}	}	} catch (Throwable t) {	
failed freeing space 

try {	while (cacheEnabled && writerEnabled) {	try {	try {	entries = getRAMQueueEntries(inputQueue, entries);	} catch (InterruptedException ie) {	if (!cacheEnabled) break;	}	doDrain(entries);	} catch (Exception ioe) {	
writerthread encountered error 

try {	entries = getRAMQueueEntries(inputQueue, entries);	} catch (InterruptedException ie) {	if (!cacheEnabled) break;	}	doDrain(entries);	} catch (Exception ioe) {	}	}	} catch (Throwable t) {	
failed doing drain 

private void checkIOErrorIsTolerated() {	long now = EnvironmentEdgeManager.currentTime();	if (this.ioErrorStartTime > 0) {	if (cacheEnabled && (now - ioErrorStartTime) > this.ioErrorsTolerationDuration) {	
io errors duration time has exceeded ms disabling cache please check your ioengine 

public void shutdown() {	disableCache();	LOG.info("Shutdown bucket cache: IO persistent=" + ioEngine.isPersistent() + "; path to write=" + persistencePath);	if (ioEngine.isPersistent() && persistencePath != null) {	try {	join();	persistToFile();	} catch (IOException ex) {	
unable to persist data on exit 

public void shutdown() {	disableCache();	LOG.info("Shutdown bucket cache: IO persistent=" + ioEngine.isPersistent() + "; path to write=" + persistencePath);	if (ioEngine.isPersistent() && persistencePath != null) {	try {	join();	persistToFile();	} catch (IOException ex) {	} catch (InterruptedException e) {	
failed to persist data on exit 

========================= hbase sample_2418 =========================

public Boolean run() {	try {	Class<?> clazz = Class.forName(CLASS_NAME);	Field f = clazz.getDeclaredField("theUnsafe");	f.setAccessible(true);	return f.get(null) != null;	} catch (Throwable e) {	
sun misc unsafe is not available accessible 

========================= hbase sample_979 =========================

for (Map.Entry<K, V> entry: fetcher.fetchEntries(gets).entrySet()) {	V quotaInfo = quotasMap.putIfAbsent(entry.getKey(), entry.getValue());	if (quotaInfo != null) {	quotaInfo.update(entry.getValue());	}	if (LOG.isTraceEnabled()) {	LOG.trace("refresh " + type + " key=" + entry.getKey() + " quotas=" + quotaInfo);	}	}	} catch (IOException e) {	
unable to read from quota table 

========================= hbase sample_2361 =========================

return Optional.of(state.stripeEndRows[leftIndex]);	}	boolean isRightLarger = rightSize >= leftSize;	double newRatio = isRightLarger ? getMidStripeSplitRatio(leftSize, rightSize, lastRightSize) : getMidStripeSplitRatio(rightSize, leftSize, lastLeftSize);	if (newRatio < 1) {	newRatio = 1 / newRatio;	}	if (newRatio >= ratio) {	return Optional.of(state.stripeEndRows[leftIndex]);	}	
splitting the stripe ratio w o split ratio with split configured ratio 

public void addCompactionResults( Collection<HStoreFile> compactedFiles, Collection<HStoreFile> results) throws IOException {	
attempting to merge compaction results files replaced by 

public void removeCompactedFiles(Collection<HStoreFile> compactedFiles) throws IOException {	
attempting to delete compaction results 

private void loadUnclassifiedStoreFiles(List<HStoreFile> storeFiles) {	
attempting to load store files 

private void loadUnclassifiedStoreFiles(List<HStoreFile> storeFiles) {	TreeMap<byte[], ArrayList<HStoreFile>> candidateStripes = new TreeMap<>(MAP_COMPARATOR);	ArrayList<HStoreFile> level0Files = new ArrayList<>();	for (HStoreFile sf : storeFiles) {	byte[] startRow = startOf(sf), endRow = endOf(sf);	if (isInvalid(startRow) || isInvalid(endRow)) {	insertFileIntoStripe(level0Files, sf);	ensureLevel0Metadata(sf);	} else if (!isOpen(startRow) && !isOpen(endRow) && nonOpenRowCompare(startRow, endRow) >= 0) {	
unexpected metadata start row end row in file pushing to 

while (entryIter.hasNext()) {	Map.Entry<byte[], ArrayList<HStoreFile>> entry = entryIter.next();	ArrayList<HStoreFile> files = entry.getValue();	for (int i = 0; i < files.size(); ++i) {	HStoreFile sf = files.get(i);	byte[] startRow = startOf(sf);	if (expectedStartRow == null) {	expectedStartRow = startRow;	} else if (!rowEquals(expectedStartRow, startRow)) {	hasOverlaps = true;	
store file doesn t fit into the tentative stripes expected to start at but starts at to it goes 

if (!files.isEmpty()) {	expectedStartRow = endRow;	} else {	entryIter.remove();	}	}	if (!candidateStripes.isEmpty()) {	HStoreFile firstFile = candidateStripes.firstEntry().getValue().get(0);	boolean isOpen = isOpen(startOf(firstFile)) && isOpen(candidateStripes.lastKey());	if (!isOpen) {	
the range of the loaded files does not cover full key space from to 

}	}	if (!candidateStripes.isEmpty()) {	HStoreFile firstFile = candidateStripes.firstEntry().getValue().get(0);	boolean isOpen = isOpen(startOf(firstFile)) && isOpen(candidateStripes.lastKey());	if (!isOpen) {	if (!hasOverlaps) {	ensureEdgeStripeMetadata(candidateStripes.firstEntry().getValue(), true);	ensureEdgeStripeMetadata(candidateStripes.lastEntry().getValue(), false);	} else {	
inconsistent files everything goes to 

private TreeMap<byte[], HStoreFile> processResults() throws IOException {	TreeMap<byte[], HStoreFile> newStripes = null;	for (HStoreFile sf : this.results) {	byte[] startRow = startOf(sf), endRow = endOf(sf);	if (isInvalid(endRow) || isInvalid(startRow)) {	if (!isFlush) {	
the newly compacted file doesn t have stripes set 

}	int removeTo = findStripeIndexByEndRow(lastEndRow);	if (removeTo < 0) throw new IOException("Compaction is trying to add a bad range.");	ArrayList<HStoreFile> conflictingFiles = new ArrayList<>();	for (int removeIndex = removeTo; removeIndex >= removeFrom; --removeIndex) {	conflictingFiles.addAll(this.stripeFiles.get(removeIndex));	}	if (!conflictingFiles.isEmpty()) {	if (isFlush) {	long newSize = StripeCompactionPolicy.getTotalFileSize(newStripes.values());	
stripes were created by a flush but results of size cannot be added because the stripes have changed 

for (int removeIndex = removeTo; removeIndex >= removeFrom; --removeIndex) {	conflictingFiles.addAll(this.stripeFiles.get(removeIndex));	}	if (!conflictingFiles.isEmpty()) {	if (isFlush) {	long newSize = StripeCompactionPolicy.getTotalFileSize(newStripes.values());	canAddNewStripes = false;	filesForL0 = newStripes.values();	} else {	long oldSize = StripeCompactionPolicy.getTotalFileSize(conflictingFiles);	
conflicting files likely created by a flush of size are moved to due to concurrent stripe change 

private Collection<HStoreFile> findExpiredFiles(ImmutableList<HStoreFile> stripe, long maxTs, List<HStoreFile> filesCompacting, Collection<HStoreFile> expiredStoreFiles) {	for (int i = 1; i < stripe.size(); ++i) {	HStoreFile sf = stripe.get(i);	synchronized (sf) {	long fileTs = sf.getReader().getMaxTimestamp();	if (fileTs < maxTs && !filesCompacting.contains(sf)) {	
found an expired store file whose maxtimestamp is which is below 

========================= hbase sample_2674 =========================

public Object run() {	try {	Field f = Unsafe.class.getDeclaredField("theUnsafe");	f.setAccessible(true);	return f.get(null);	} catch (Throwable e) {	
sun misc unsafe is not accessible 

========================= hbase sample_996 =========================

final int temp = CONF.getInt(NUM_REGION_GROUPS, DEFAULT_NUM_REGION_GROUPS);	WALFactory wals = null;	try {	CONF.setInt(NUM_REGION_GROUPS, temp * 4);	FSUtils.setRootDir(CONF, TEST_UTIL.getDataTestDirOnTestFS());	wals = new WALFactory(CONF, null, "setMembershipDedups");	Set<WAL> seen = new HashSet<>(temp * 4);	int count = 0;	for (int i = 0; i < temp * 8; i++) {	WAL maybeNewWAL = wals.getWAL(RegionInfoBuilder .newBuilder(TableName.valueOf("Table-" + ThreadLocalRandom.current().nextInt())) .build());	
iteration checking wal 

========================= hbase sample_1367 =========================

if (tableName.equals(TableName.META_TABLE_NAME)) {	setFailure("master-disable-table", new ConstraintException("Cannot disable catalog table"));	canTableBeDisabled = false;	} else if (!MetaTableAccessor.tableExists(env.getMasterServices().getConnection(), tableName)) {	setFailure("master-disable-table", new TableNotFoundException(tableName));	canTableBeDisabled = false;	} else if (!skipTableStateCheck) {	TableStateManager tsm = env.getMasterServices().getTableStateManager();	TableState.State state = tsm.getTableState(tableName);	if (!state.equals(TableState.State.ENABLED)){	
table isn t enabled is skipping disable 

protected static void setTableStateToDisabled( final MasterProcedureEnv env, final TableName tableName) throws IOException {	env.getMasterServices().getTableStateManager().setTableState( tableName, TableState.State.DISABLED);	
disabled table is completed 

========================= hbase sample_2818 =========================

grantOnTable(TEST_UTIL, USER_RO.getShortName(), TEST_TABLE, TEST_FAMILY, null, Permission.Action.READ);	grantOnTable(TEST_UTIL, USER_ADMIN_CF.getShortName(), TEST_TABLE, TEST_FAMILY, null, Permission.Action.ADMIN, Permission.Action.CREATE);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_ADMIN), Permission.Action.ADMIN);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_CREATE), Permission.Action.CREATE);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_READ), Permission.Action.READ);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_WRITE), Permission.Action.WRITE);	assertEquals(5, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());	try {	assertEquals(5, AccessControlClient.getUserPermissions(systemUserConnection, TEST_TABLE.toString()).size());	} catch (Throwable e) {	
error during call of accesscontrolclient getuserpermissions 

private static void cleanUp() throws Exception {	try {	deleteTable(TEST_UTIL, TEST_TABLE);	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1388 =========================

public void test() throws Exception {	HRegionServer regionSvr = UTIL.getRSForFirstRegionInTable(TABLE_NAME);	HRegion region = regionSvr.getRegions(TABLE_NAME).get(0);	String regName = region.getRegionInfo().getEncodedName();	List<HRegion> metaRegs = regionSvr.getRegions(TableName.META_TABLE_NAME);	if (metaRegs != null && !metaRegs.isEmpty()) {	
meta is on the same server 

public void test() throws Exception {	HRegionServer regionSvr = UTIL.getRSForFirstRegionInTable(TABLE_NAME);	HRegion region = regionSvr.getRegions(TABLE_NAME).get(0);	String regName = region.getRegionInfo().getEncodedName();	List<HRegion> metaRegs = regionSvr.getRegions(TableName.META_TABLE_NAME);	if (metaRegs != null && !metaRegs.isEmpty()) {	HRegionServer otherRs = UTIL.getOtherRegionServer(regionSvr);	UTIL.moveRegionAndWait(region.getRegionInfo(), otherRs.getServerName());	
moved region to 

String regName = region.getRegionInfo().getEncodedName();	List<HRegion> metaRegs = regionSvr.getRegions(TableName.META_TABLE_NAME);	if (metaRegs != null && !metaRegs.isEmpty()) {	HRegionServer otherRs = UTIL.getOtherRegionServer(regionSvr);	UTIL.moveRegionAndWait(region.getRegionInfo(), otherRs.getServerName());	}	HRegionServer rsToSuspend = UTIL.getRSForFirstRegionInTable(TABLE_NAME);	region = rsToSuspend.getRegions(TABLE_NAME).get(0);	ZKWatcher watcher = UTIL.getZooKeeperWatcher();	watcher.getRecoverableZooKeeper().delete( ZNodePaths.joinZNode(watcher.getZNodePaths().rsZNode, rsToSuspend.getServerName().toString()), -1);	
suspending 

return false;	}	public String explainFailure() throws Exception {	return "The region for " + TABLE_NAME + " is still on " + rsToSuspend.getServerName();	}	});	try {	region.compact(true);	fail("Should fail as our wal file has already been closed, " + "and walDir has also been renamed");	} catch (Exception e) {	
expected exception 

========================= hbase sample_1672 =========================

static void updateProgress(BackupInfo backupInfo, BackupManager backupManager, int newProgress, long bytesCopied) throws IOException {	String backupProgressData = newProgress + "%";	backupInfo.setProgress(newProgress);	backupManager.updateBackupInfo(backupInfo);	
backup progress data backupprogressdata has been updated to backup system table for 

totalSrcLgth += BackupUtils.getFilesLength(aSrc.getFileSystem(super.getConf()), aSrc);	}	job = super.execute();	int progressReportFreq = MapReduceBackupCopyJob.this.getConf().getInt("hbase.backup.progressreport.frequency", 500);	float lastProgress = progressDone;	while (!job.isComplete()) {	float newProgress = progressDone + job.mapProgress() * subTaskPercntgInWholeTask * (1 - INIT_PROGRESS);	if (newProgress > lastProgress) {	BigDecimal progressData = new BigDecimal(newProgress * 100).setScale(1, BigDecimal.ROUND_HALF_UP);	String newProgressStr = progressData + "%";	
progress 

}	job = super.execute();	int progressReportFreq = MapReduceBackupCopyJob.this.getConf().getInt("hbase.backup.progressreport.frequency", 500);	float lastProgress = progressDone;	while (!job.isComplete()) {	float newProgress = progressDone + job.mapProgress() * subTaskPercntgInWholeTask * (1 - INIT_PROGRESS);	if (newProgress > lastProgress) {	BigDecimal progressData = new BigDecimal(newProgress * 100).setScale(1, BigDecimal.ROUND_HALF_UP);	String newProgressStr = progressData + "%";	updateProgress(backupInfo, backupManager, progressData.intValue(), bytesCopied);	
backup progress data updated to backup system table newprogressstr 

BigDecimal progressData = new BigDecimal(newProgress * 100).setScale(1, BigDecimal.ROUND_HALF_UP);	String newProgressStr = progressData + "%";	updateProgress(backupInfo, backupManager, progressData.intValue(), bytesCopied);	lastProgress = newProgress;	}	Thread.sleep(progressReportFreq);	}	float newProgress = progressDone + job.mapProgress() * subTaskPercntgInWholeTask * (1 - INIT_PROGRESS);	BigDecimal progressData = new BigDecimal(newProgress * 100).setScale(1, BigDecimal.ROUND_HALF_UP);	String newProgressStr = progressData + "%";	
progress subtask mapprogress 

lastProgress = newProgress;	}	Thread.sleep(progressReportFreq);	}	float newProgress = progressDone + job.mapProgress() * subTaskPercntgInWholeTask * (1 - INIT_PROGRESS);	BigDecimal progressData = new BigDecimal(newProgress * 100).setScale(1, BigDecimal.ROUND_HALF_UP);	String newProgressStr = progressData + "%";	progressDone = newProgress;	bytesCopied += totalSrcLgth;	updateProgress(backupInfo, backupManager, progressData.intValue(), bytesCopied);	
backup progress data updated to backup system table newprogressstr bytescopied 

String newProgressStr = progressData + "%";	progressDone = newProgress;	bytesCopied += totalSrcLgth;	updateProgress(backupInfo, backupManager, progressData.intValue(), bytesCopied);	} catch (Throwable t) {	LOG.error(t.toString(), t);	throw t;	}	String jobID = job.getJobID().toString();	job.getConfiguration().set(DistCpConstants.CONF_LABEL_DISTCP_JOB_ID, jobID);	
distcp job id completed 

public int copy(BackupInfo context, BackupManager backupManager, Configuration conf, BackupType copyType, String[] options) throws IOException {	int res = 0;	try {	if (copyType == BackupType.FULL) {	SnapshotCopy snapshotCp = new SnapshotCopy(context, context.getTableBySnapshot(options[1]));	
doing snapshot copy 

public int copy(BackupInfo context, BackupManager backupManager, Configuration conf, BackupType copyType, String[] options) throws IOException {	int res = 0;	try {	if (copyType == BackupType.FULL) {	SnapshotCopy snapshotCp = new SnapshotCopy(context, context.getTableBySnapshot(options[1]));	snapshotCp.setConf(new Configuration(conf));	res = snapshotCp.run(options);	} else if (copyType == BackupType.INCREMENTAL) {	
doing copy type distcp 

public int copy(BackupInfo context, BackupManager backupManager, Configuration conf, BackupType copyType, String[] options) throws IOException {	int res = 0;	try {	if (copyType == BackupType.FULL) {	SnapshotCopy snapshotCp = new SnapshotCopy(context, context.getTableBySnapshot(options[1]));	snapshotCp.setConf(new Configuration(conf));	res = snapshotCp.run(options);	} else if (copyType == BackupType.INCREMENTAL) {	setSubTaskPercntgInWholeTask(1f);	BackupDistCp distcp = new BackupDistCp(new Configuration(conf), null, context, backupManager);	
distcp options 

public void cancel(String jobId) throws IOException {	JobID id = JobID.forName(jobId);	Cluster cluster = new Cluster(this.getConf());	try {	Job job = cluster.getJob(id);	if (job == null) {	
no job found for 

Cluster cluster = new Cluster(this.getConf());	try {	Job job = cluster.getJob(id);	if (job == null) {	return;	}	if (job.isComplete() || job.isRetired()) {	return;	}	job.killJob();	
killed copy job 

========================= hbase sample_596 =========================

while(!t.manager.clusterHasActiveMaster.get() && sleeps < 100) {	Thread.sleep(10);	sleeps++;	}	assertTrue(activeMasterManager.clusterHasActiveMaster.get());	assertTrue(t.manager.clusterHasActiveMaster.get());	assertFalse(t.isActiveMaster);	ms1.stop("stopping first server");	NodeDeletionListener listener = new NodeDeletionListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	
deleting master node 

Thread.sleep(10);	sleeps++;	}	assertTrue(activeMasterManager.clusterHasActiveMaster.get());	assertTrue(t.manager.clusterHasActiveMaster.get());	assertFalse(t.isActiveMaster);	ms1.stop("stopping first server");	NodeDeletionListener listener = new NodeDeletionListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	ZKUtil.deleteNode(zk, zk.znodePaths.masterAddressZNode);	
waiting for active master manager to be notified 

sleeps++;	}	assertTrue(activeMasterManager.clusterHasActiveMaster.get());	assertTrue(t.manager.clusterHasActiveMaster.get());	assertFalse(t.isActiveMaster);	ms1.stop("stopping first server");	NodeDeletionListener listener = new NodeDeletionListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	ZKUtil.deleteNode(zk, zk.znodePaths.masterAddressZNode);	listener.waitForDeletion();	
master node deleted 

ms1.stop("stopping first server");	NodeDeletionListener listener = new NodeDeletionListener(zk, zk.znodePaths.masterAddressZNode);	zk.registerListener(listener);	ZKUtil.deleteNode(zk, zk.znodePaths.masterAddressZNode);	listener.waitForDeletion();	sleeps = 0;	while(!t.isActiveMaster && sleeps < 100) {	Thread.sleep(10);	sleeps++;	}	
slept times 

zk.registerListener(listener);	ZKUtil.deleteNode(zk, zk.znodePaths.masterAddressZNode);	listener.waitForDeletion();	sleeps = 0;	while(!t.isActiveMaster && sleeps < 100) {	Thread.sleep(10);	sleeps++;	}	assertTrue(t.manager.clusterHasActiveMaster.get());	assertTrue(t.isActiveMaster);	
deleting master node 

public void run() {	manager.blockUntilBecomingActiveMaster(100, Mockito.mock(MonitoredTask.class));	
second master has become the active master 

public void nodeDeleted(String path) {	if(path.equals(node)) {	
nodedeleted 

========================= hbase sample_1808 =========================

public boolean add(R range) {	byte[] start = range.getStartKey();	byte[] end = specialEndKey(range);	if (end != ENDKEY && Bytes.compareTo(start, end) > 0) {	
attempted to add backwards edge 

========================= hbase sample_2232 =========================

Put put3 = new Put(DUMMY_BYTES_3);	put3.addColumn(DUMMY_BYTES_3, DUMMY_BYTES_3, DUMMY_BYTES_3);	putSizeSN += (put1.heapSize() + put2.heapSize());	putSizeSN2 += put3.heapSize();	puts.add(put1);	puts.add(put2);	puts.add(put3);	}	int minCountSnRequest = (int) calculateRequestCount(putSizeSN, maxHeapSizePerRequest);	int minCountSn2Request = (int) calculateRequestCount(putSizeSN2, maxHeapSizePerRequest);	
total put count putsizesn maxheapsizeperrequest mincountsnrequest 

mutator.flush();	Assert.fail();	} catch (RetriesExhaustedWithDetailsException expected) {	}	long actualSleep = System.currentTimeMillis() - startTime;	long expectedSleep = 0L;	for (int i = 0; i < retries; i++) {	expectedSleep += ConnectionUtils.getPauseTime(specialPause, i);	actualSleep += (long) (specialPause * 0.01f);	}	
expected to sleep ms actually slept ms 

mutator.flush();	Assert.fail();	} catch (RetriesExhaustedWithDetailsException expected) {	}	actualSleep = System.currentTimeMillis() - startTime;	expectedSleep = 0L;	for (int i = 0; i < retries; i++) {	expectedSleep += ConnectionUtils.getPauseTime(normalPause, i);	}	expectedSleep += normalPause;	
expected to sleep ms actually slept ms 

========================= hbase sample_77 =========================

public static boolean compareArchiveToOriginal(FileStatus[] previous, FileStatus[] archived, FileSystem fs, boolean hasTimedBackup) {	List<List<String>> lists = getFileLists(previous, archived);	List<String> original = lists.get(0);	Collections.sort(original);	List<String> currentFiles = lists.get(1);	Collections.sort(currentFiles);	List<String> backedup = lists.get(2);	Collections.sort(backedup);	if (!hasTimedBackup == (backedup.size() > 0)) {	
backedup files doesn t match expected 

========================= hbase sample_1330 =========================

protected void createSchema() throws IOException {	
creating tables 

protected void createSchema() throws IOException {	boolean acl = AccessControlClient.isAccessControllerRunning(ConnectionFactory .createConnection(getConf()));	if(!acl) {	
no acl available 

private void createTable(Admin admin, TableName tableName, boolean setVersion, boolean acl) throws IOException {	if (!admin.tableExists(tableName)) {	HTableDescriptor htd = new HTableDescriptor(tableName);	HColumnDescriptor family = new HColumnDescriptor(FAMILY_NAME);	if (setVersion) {	family.setMaxVersions(DEFAULT_TABLES_COUNT);	}	htd.addFamily(family);	admin.createTable(htd);	if (acl) {	
granting permissions for user 

if (setVersion) {	family.setMaxVersions(DEFAULT_TABLES_COUNT);	}	htd.addFamily(family);	admin.createTable(htd);	if (acl) {	Permission.Action[] actions = { Permission.Action.READ };	try {	AccessControlClient.grant(ConnectionFactory.createConnection(getConf()), tableName, USER.getShortName(), null, null, actions);	} catch (Throwable e) {	
error in granting permission for the user 

job.setJobName("Data copier");	job.getConfiguration().setInt("INDEX", labelIndex);	job.getConfiguration().set("LABELS", labels);	job.setJarByClass(getClass());	scan = new Scan();	scan.setCacheBlocks(false);	scan.setRaw(true);	String[] split = labels.split(COMMA);	scan.setAuthorizations(new Authorizations(split[this.labelIndex * 2], split[(this.labelIndex * 2) + 1]));	if (delete) {	
running deletes 

job.getConfiguration().setInt("INDEX", labelIndex);	job.getConfiguration().set("LABELS", labels);	job.setJarByClass(getClass());	scan = new Scan();	scan.setCacheBlocks(false);	scan.setRaw(true);	String[] split = labels.split(COMMA);	scan.setAuthorizations(new Authorizations(split[this.labelIndex * 2], split[(this.labelIndex * 2) + 1]));	if (delete) {	} else {	
running copiers 

protected void handleFailure(Counters counters) throws IOException {	Configuration conf = job.getConfiguration();	ClusterConnection conn = (ClusterConnection) ConnectionFactory.createConnection(conf);	TableName tableName = TableName.valueOf(COMMON_TABLE_NAME);	CounterGroup g = counters.getGroup("undef");	Iterator<Counter> it = g.iterator();	while (it.hasNext()) {	String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = conn.relocateRegion(tableName, key);	
undefined row 

String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = conn.relocateRegion(tableName, key);	}	g = counters.getGroup("unref");	it = g.iterator();	while (it.hasNext()) {	String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = conn.relocateRegion(tableName, key);	
unreferred row 

protected void runDelete(int numMappers, long numNodes, String outputDir, Integer width, Integer wrapMultiplier, int tableIndex) throws Exception {	
running copier on table 

protected void runVerify(String outputDir, int numReducers, long expectedNumNodes, boolean allTables) throws Exception {	Path outputPath = new Path(outputDir);	if (allTables) {	for (int i = 0; i < DEFAULT_TABLES_COUNT; i++) {	
verifying table 

private void runVerify(String outputDir, int numReducers, long expectedNodes, int tableIndex) throws Exception {	long temp = expectedNodes;	for (int i = 0; i < DEFAULT_TABLES_COUNT; i++) {	if (i <= tableIndex) {	expectedNodes = 0;	} else {	expectedNodes = temp;	}	
verifying data in the table with index and expected nodes is 

protected void runVerifyCommonTable(String outputDir, int numReducers, long expectedNumNodes, int index) throws Exception {	
verifying common table with index 

protected void runCopier(String outputDir) throws Exception {	for (int i = 0; i < DEFAULT_TABLES_COUNT; i++) {	
running copier 

public int run(String[] args) throws Exception {	if (args.length < 5) {	System.err .println("Usage: Loop <num iterations> " + "<num mappers> <num nodes per mapper> <output dir> " + "<num reducers> [<width> <wrap multiplier>]");	return 1;	}	
running loop with args 

String outputDir = args[3];	int numReducers = Integer.parseInt(args[4]);	Integer width = (args.length < 6) ? null : Integer.parseInt(args[5]);	Integer wrapMultiplier = (args.length < 7) ? null : Integer.parseInt(args[6]);	long expectedNumNodes = 0;	if (numIterations < 0) {	numIterations = Integer.MAX_VALUE;	}	for (int i = 0; i < numIterations; i++) {	LOG.info("Starting iteration = " + i);	
generating data 

Integer width = (args.length < 6) ? null : Integer.parseInt(args[5]);	Integer wrapMultiplier = (args.length < 7) ? null : Integer.parseInt(args[6]);	long expectedNumNodes = 0;	if (numIterations < 0) {	numIterations = Integer.MAX_VALUE;	}	for (int i = 0; i < numIterations; i++) {	LOG.info("Starting iteration = " + i);	runGenerator(numMappers, numNodes, outputDir, width, wrapMultiplier, 0);	expectedNumNodes += numMappers * numNodes;	
running copier 

long expectedNumNodes = 0;	if (numIterations < 0) {	numIterations = Integer.MAX_VALUE;	}	for (int i = 0; i < numIterations; i++) {	LOG.info("Starting iteration = " + i);	runGenerator(numMappers, numNodes, outputDir, width, wrapMultiplier, 0);	expectedNumNodes += numMappers * numNodes;	sleep(SLEEP_IN_MS);	runCopier(outputDir);	
verifying copied data 

for (int i = 0; i < numIterations; i++) {	LOG.info("Starting iteration = " + i);	runGenerator(numMappers, numNodes, outputDir, width, wrapMultiplier, 0);	expectedNumNodes += numMappers * numNodes;	sleep(SLEEP_IN_MS);	runCopier(outputDir);	sleep(SLEEP_IN_MS);	runVerify(outputDir, numReducers, expectedNumNodes, true);	sleep(SLEEP_IN_MS);	for (int j = 0; j < DEFAULT_TABLES_COUNT; j++) {	
deleting data on table with index 

runGenerator(numMappers, numNodes, outputDir, width, wrapMultiplier, 0);	expectedNumNodes += numMappers * numNodes;	sleep(SLEEP_IN_MS);	runCopier(outputDir);	sleep(SLEEP_IN_MS);	runVerify(outputDir, numReducers, expectedNumNodes, true);	sleep(SLEEP_IN_MS);	for (int j = 0; j < DEFAULT_TABLES_COUNT; j++) {	runDelete(numMappers, numNodes, outputDir, width, wrapMultiplier, j);	sleep(SLEEP_IN_MS);	
verifying common table after deleting 

========================= hbase sample_3248 =========================

public void testValidateMissingTableName() throws IOException {	Configuration conf = new Configuration(false);	try {	SnapshotDescriptionUtils.validate(SnapshotDescription.newBuilder().setName("fail").build(), conf);	fail("Snapshot was considered valid without a table name");	} catch (IllegalArgumentException e) {	
correctly failed when snapshot doesn t have a tablename 

public void testCompleteSnapshotWithNoSnapshotDirectoryFailure() throws Exception {	Path snapshotDir = new Path(root, HConstants.SNAPSHOT_DIR_NAME);	Path tmpDir = new Path(snapshotDir, ".tmp");	Path workingDir = new Path(tmpDir, "not_a_snapshot");	assertFalse("Already have working snapshot dir: " + workingDir + " but shouldn't. Test file leak?", fs.exists(workingDir));	SnapshotDescription snapshot = SnapshotDescription.newBuilder().setName("snapshot").build();	try {	SnapshotDescriptionUtils.completeSnapshot(snapshot, root, workingDir, fs);	fail("Shouldn't successfully complete move of a non-existent directory.");	} catch (IOException e) {	
correctly failed to move non existant directory 

========================= hbase sample_1275 =========================

if(file.getLen() < mergeSize * mergeSizeMultiFactor) {	String fileName = file.getPath().getName();	String startKey = fileName.substring(0, 32);	boolean skipCompaction = false;	if (policy == MobCompactPartitionPolicy.MONTHLY) {	String fileDateStr = MobFileName.getDateFromName(fileName);	Date fileDate;	try {	fileDate = MobUtils.parseDate(fileDateStr);	} catch (ParseException e)  {	
failed to parse date 

========================= hbase sample_2009 =========================

} else {	throw new UnsupportedOperationException("no namespace/table/region provided");	}	proc.setOwner(master.getMasterProcedureExecutor().getEnvironment().getRequestUser());	master.getMasterProcedureExecutor().submitProcedure(proc);	long deadline = (timeoutMs > 0) ? System.currentTimeMillis() + timeoutMs : Long.MAX_VALUE;	while (deadline >= System.currentTimeMillis() && !proc.isLocked()) {	try {	lockAcquireLatch.await(deadline - System.currentTimeMillis(), TimeUnit.MILLISECONDS);	} catch (InterruptedException e) {	
interruptedexception when waiting for lock 

long deadline = (timeoutMs > 0) ? System.currentTimeMillis() + timeoutMs : Long.MAX_VALUE;	while (deadline >= System.currentTimeMillis() && !proc.isLocked()) {	try {	lockAcquireLatch.await(deadline - System.currentTimeMillis(), TimeUnit.MILLISECONDS);	} catch (InterruptedException e) {	release();	throw e;	}	}	if (!proc.isLocked()) {	
timed out waiting to acquire procedure lock 

========================= hbase sample_2770 =========================

future.complete(false);	} else {	AsyncMetaTableAccessor.getTableHRegionLocations(metaTable, Optional.of(tableName)) .whenComplete( (locations, error1) -> {	if (error1 != null) {	future.completeExceptionally(error1);	return;	}	List<HRegionLocation> notDeployedRegions = locations.stream().filter(loc -> loc.getServerName() == null) .collect(Collectors.toList());	if (notDeployedRegions.size() > 0) {	if (LOG.isDebugEnabled()) {	
table has regions 

private CompletableFuture<Void> restoreSnapshot(String snapshotName, TableName tableName, boolean takeFailSafeSnapshot) {	if (takeFailSafeSnapshot) {	CompletableFuture<Void> future = new CompletableFuture<>();	String failSafeSnapshotSnapshotNameFormat = this.connection.getConfiguration().get( HConstants.SNAPSHOT_RESTORE_FAILSAFE_NAME, HConstants.DEFAULT_SNAPSHOT_RESTORE_FAILSAFE_NAME);	final String failSafeSnapshotSnapshotName = failSafeSnapshotSnapshotNameFormat .replace("{snapshot.name}", snapshotName) .replace("{table.name}", tableName.toString().replace(TableName.NAMESPACE_DELIM, '.')) .replace("{restore.timestamp}", String.valueOf(EnvironmentEdgeManager.currentTime()));	
taking restore failsafe snapshot 

if (err2 != null) {	internalRestoreSnapshot(failSafeSnapshotSnapshotName, tableName).whenComplete( (void3, err3) -> {	if (err3 != null) {	future.completeExceptionally(err3);	} else {	String msg = "Restore snapshot=" + snapshotName + " failed. Rollback to snapshot=" + failSafeSnapshotSnapshotName + " succeeded.";	future.completeExceptionally(new RestoreSnapshotException(msg));	}	});	} else {	
deleting restore failsafe snapshot 

if (err3 != null) {	future.completeExceptionally(err3);	} else {	String msg = "Restore snapshot=" + snapshotName + " failed. Rollback to snapshot=" + failSafeSnapshotSnapshotName + " succeeded.";	future.completeExceptionally(new RestoreSnapshotException(msg));	}	});	} else {	deleteSnapshot(failSafeSnapshotSnapshotName).whenComplete( (ret3, err3) -> {	if (err3 != null) {	
unable to remove the failsafe snapshot 

========================= hbase sample_484 =========================

private static MemoryLayout getMemoryLayout() {	String enabled = System.getProperty("hbase.memorylayout.use.unsafe");	if (UnsafeAvailChecker.isAvailable() && (enabled == null || Boolean.parseBoolean(enabled))) {	
using unsafe to estimate memory layout 

private static MemoryLayout getMemoryLayout() {	String enabled = System.getProperty("hbase.memorylayout.use.unsafe");	if (UnsafeAvailChecker.isAvailable() && (enabled == null || Boolean.parseBoolean(enabled))) {	return new UnsafeLayout();	}	
not using unsafe to estimate memory layout 

========================= hbase sample_1019 =========================

static List<? extends Constraint> getConstraints(TableDescriptor desc, ClassLoader classloader) throws IOException {	List<Constraint> constraints = new ArrayList<>();	for (Map.Entry<Bytes, Bytes> e : desc .getValues().entrySet()) {	String key = Bytes.toString(e.getKey().get()).trim();	String[] className = CONSTRAINT_HTD_ATTR_KEY_PATTERN.split(key);	if (className.length == 2) {	key = className[1];	if (LOG.isDebugEnabled()) {	
loading constraint 

String key = Bytes.toString(e.getKey().get()).trim();	String[] className = CONSTRAINT_HTD_ATTR_KEY_PATTERN.split(key);	if (className.length == 2) {	key = className[1];	if (LOG.isDebugEnabled()) {	}	Configuration conf;	try {	conf = readConfiguration(e.getValue().get());	} catch (IOException e1) {	
corrupted configuration found for key skipping it 

key = className[1];	if (LOG.isDebugEnabled()) {	}	Configuration conf;	try {	conf = readConfiguration(e.getValue().get());	} catch (IOException e1) {	continue;	}	if (!conf.getBoolean(ENABLED_KEY, false)) {	
constraint is disabled skipping it 

========================= hbase sample_3024 =========================

public void updateHeartBeat() {	lastHeartBeat.set(System.currentTimeMillis());	if (LOG.isDebugEnabled()) {	
heartbeat 

protected boolean setTimeoutFailure(final MasterProcedureEnv env) {	synchronized (event) {	
timeout failure 

protected boolean setTimeoutFailure(final MasterProcedureEnv env) {	synchronized (event) {	if (!event.isReady()) {	setState(ProcedureProtos.ProcedureState.RUNNABLE);	
calling wake on 

protected Procedure<MasterProcedureEnv>[] execute(final MasterProcedureEnv env) throws ProcedureSuspendedException {	if (recoveredMasterLock) return null;	if (lockAcquireLatch != null) {	lockAcquireLatch.countDown();	}	if (unlock.get() || hasHeartbeatExpired()) {	locked.set(false);	
unlocked timed out 

protected LockState acquireLock(final MasterProcedureEnv env) {	boolean ret = lock.acquireLock(env);	locked.set(ret);	hasLock = ret;	if (ret) {	if (LOG.isDebugEnabled()) {	
locked 

protected LockState acquireLock(final MasterProcedureEnv env) {	boolean ret = lock.acquireLock(env);	locked.set(ret);	hasLock = ret;	if (ret) {	if (LOG.isDebugEnabled()) {	}	lastHeartBeat.set(System.currentTimeMillis());	return LockState.LOCK_ACQUIRED;	}	
failed acquire lock yielding 

private LockInterface setupLock() throws IllegalArgumentException {	if (regionInfos != null) {	return setupRegionLock();	} else if (namespace != null) {	return setupNamespaceLock();	} else if (tableName != null) {	return setupTableLock();	} else {	
unknown level specified in 

private LockInterface setupNamespaceLock() throws IllegalArgumentException {	this.tableName = TableName.NAMESPACE_TABLE_NAME;	switch (type) {	case EXCLUSIVE: this.opType = TableOperationType.EDIT;	return new NamespaceExclusiveLock();	
shared lock on namespace not supported for 

private LockInterface setupNamespaceLock() throws IllegalArgumentException {	this.tableName = TableName.NAMESPACE_TABLE_NAME;	switch (type) {	case EXCLUSIVE: this.opType = TableOperationType.EDIT;	return new NamespaceExclusiveLock();	throw new IllegalArgumentException("Shared lock on namespace not supported");	
unexpected lock type 

private LockInterface setupTableLock() throws IllegalArgumentException {	switch (type) {	case EXCLUSIVE: this.opType = TableOperationType.EDIT;	return new TableExclusiveLock();	case SHARED: this.opType = TableOperationType.READ;	return new TableSharedLock();	
unexpected lock type 

private LockInterface setupRegionLock() throws IllegalArgumentException {	this.tableName = regionInfos[0].getTable();	switch (type) {	case EXCLUSIVE: this.opType = TableOperationType.REGION_EDIT;	return new RegionExclusiveLock();	
only exclusive lock supported on regions for 

========================= hbase sample_2771 =========================

throw new IllegalArgumentException( "Constraints only act on regions - started in an environment that was not a region");	}	RegionCoprocessorEnvironment env = (RegionCoprocessorEnvironment) environment;	TableDescriptor desc = env.getRegion().getTableDescriptor();	try {	this.constraints = Constraints.getConstraints(desc, classloader);	} catch (IOException e) {	throw new IllegalArgumentException(e);	}	if (LOG.isInfoEnabled()) {	
finished loading user constraints on table 

========================= hbase sample_3025 =========================

private void generatePartitions(Path partitionsPath) throws IOException {	Connection connection = ConnectionFactory.createConnection(getConf());	Pair<byte[][], byte[][]> regionKeys = connection.getRegionLocator(TableName.valueOf(tableHash.tableName)).getStartEndKeys();	connection.close();	tableHash.selectPartitions(regionKeys);	
writing partition keys to 

public int run(String[] args) throws Exception {	String[] otherArgs = new GenericOptionsParser(getConf(), args).getRemainingArgs();	if (!doCommandLine(otherArgs)) {	return 1;	}	Job job = createSubmittableJob(otherArgs);	writeTempManifestFile();	if (!job.waitForCompletion(true)) {	
map reduce job failed 

========================= hbase sample_3475 =========================

if( progress != null ) {	++storeCount;	assertTrue(progress.currentCompactedKVs > 0);	assertTrue(progress.totalCompactingKVs > 0);	}	assertTrue(storeCount > 0);	}	byte [] secondRowBytes = START_KEY_BYTES.clone();	secondRowBytes[START_KEY_BYTES.length - 1]++;	result = r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));	
row after initial compaction 

++storeCount;	assertTrue(progress.currentCompactedKVs > 0);	assertTrue(progress.totalCompactingKVs > 0);	}	assertTrue(storeCount > 0);	}	byte [] secondRowBytes = START_KEY_BYTES.clone();	secondRowBytes[START_KEY_BYTES.length - 1]++;	result = r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));	assertEquals("Invalid number of versions of row " + Bytes.toStringBinary(secondRowBytes) + ".", compactionThreshold, result.size());	
adding deletes to memstore and flushing 

========================= hbase sample_1761 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	
fs state before snapshot 

public void testFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	admin.snapshot(snapshotString, TABLE_NAME, SnapshotType.FLUSH);	
snapshot completed 

public void testFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	admin.snapshot(snapshotString, TABLE_NAME, SnapshotType.FLUSH);	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertOneSnapshotThatMatches(admin, snapshot, TABLE_NAME);	
fs state after snapshot 

public void testSkipFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	UTIL.flush(TABLE_NAME);	
fs state before snapshot 

public void testSkipFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	UTIL.flush(TABLE_NAME);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "skipFlushTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	admin.snapshot(snapshotString, TABLE_NAME, SnapshotType.SKIPFLUSH);	
snapshot completed 

public void testSkipFlushTableSnapshot() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	Table table = UTIL.getConnection().getTable(TABLE_NAME);	UTIL.loadTable(table, TEST_FAM);	UTIL.flush(TABLE_NAME);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "skipFlushTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	admin.snapshot(snapshotString, TABLE_NAME, SnapshotType.SKIPFLUSH);	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertOneSnapshotThatMatches(admin, snapshot, TABLE_NAME);	
fs state after snapshot 

public void testFlushTableSnapshotWithProcedure() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	
fs state before snapshot 

public void testFlushTableSnapshotWithProcedure() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	Map<String, String> props = new HashMap<>();	props.put("table", TABLE_NAME.getNameAsString());	admin.execProcedure(SnapshotManager.ONLINE_SNAPSHOT_CONTROLLER_DESCRIPTION, snapshotString, props);	
snapshot completed 

public void testFlushTableSnapshotWithProcedure() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	String snapshotString = "offlineTableSnapshot";	byte[] snapshot = Bytes.toBytes(snapshotString);	Map<String, String> props = new HashMap<>();	props.put("table", TABLE_NAME.getNameAsString());	admin.execProcedure(SnapshotManager.ONLINE_SNAPSHOT_CONTROLLER_DESCRIPTION, snapshotString, props);	List<SnapshotDescription> snapshots = SnapshotTestingUtils.assertOneSnapshotThatMatches(admin, snapshot, TABLE_NAME);	
fs state after snapshot 

public void testSnapshotFailsOnNonExistantTable() throws Exception {	SnapshotTestingUtils.assertNoSnapshots(admin);	TableName tableName = TableName.valueOf("_not_a_table");	boolean fail = false;	do {	try {	admin.getTableDescriptor(tableName);	fail = true;	
table already exists checking a new name 

fail = true;	tableName = TableName.valueOf(tableName+"!");	} catch (TableNotFoundException e) {	fail = false;	}	} while (fail);	try {	admin.snapshot("fail", tableName, SnapshotType.FLUSH);	fail("Snapshot succeeded even though there is not table.");	} catch (SnapshotCreationException e) {	
correctly failed to snapshot a non existant table 

public void testFlushCreateListDestroy() throws Exception {	
starting snapshot test 

SnapshotTestingUtils.loadData(UTIL, TABLE_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	SnapshotTestingUtils.loadData(UTIL, TABLE2_NAME, DEFAULT_NUM_ROWS, TEST_FAM);	final CountDownLatch toBeSubmitted = new CountDownLatch(ssNum);	class SSRunnable implements Runnable {	SnapshotDescription ss;	SSRunnable(SnapshotDescription ss) {	this.ss = ss;	}	public void run() {	try {	
submitting snapshot request 

final CountDownLatch toBeSubmitted = new CountDownLatch(ssNum);	class SSRunnable implements Runnable {	SnapshotDescription ss;	SSRunnable(SnapshotDescription ss) {	this.ss = ss;	}	public void run() {	try {	admin.takeSnapshotAsync(ss);	} catch (Exception e) {	
exception during snapshot request this is ok we expect some 

class SSRunnable implements Runnable {	SnapshotDescription ss;	SSRunnable(SnapshotDescription ss) {	this.ss = ss;	}	public void run() {	try {	admin.takeSnapshotAsync(ss);	} catch (Exception e) {	}	
submitted snapshot request 

}	toBeSubmitted.await();	while (true) {	int doneCount = 0;	for (SnapshotDescription ss : descs) {	try {	if (admin.isSnapshotFinished(ss)) {	doneCount++;	}	} catch (Exception e) {	
got an exception when checking for snapshot 

}	}	if (doneCount == descs.length) {	break;	}	Thread.sleep(100);	}	UTIL.getHBaseCluster().getMaster().getMasterFileSystem().logFileSystemState(LOG);	List<SnapshotDescription> taken = admin.listSnapshots();	int takenSize = taken.size();	
taken snapshots 

========================= hbase sample_1274 =========================

protected void initTable() throws IOException {	super.initTable();	TableName tableName = getTablename();	try (Connection connection = ConnectionFactory.createConnection();	Admin admin = connection.getAdmin()) {	HTableDescriptor tableDesc = admin.getTableDescriptor(tableName);	
disabling table 

protected void initTable() throws IOException {	super.initTable();	TableName tableName = getTablename();	try (Connection connection = ConnectionFactory.createConnection();	Admin admin = connection.getAdmin()) {	HTableDescriptor tableDesc = admin.getTableDescriptor(tableName);	admin.disableTable(tableName);	ColumnFamilyDescriptor mobColumn = tableDesc.getColumnFamily(mobColumnFamily);	ColumnFamilyDescriptor cfd = ColumnFamilyDescriptorBuilder.newBuilder(mobColumn) .setMobEnabled(true) .setMobThreshold((long) threshold) .build();	admin.modifyColumnFamily(tableName, cfd);	
enabling table 

========================= hbase sample_3249 =========================

public static boolean watchAndCheckExists(ZKWatcher zkw, String znode) throws KeeperException {	try {	Stat s = zkw.getRecoverableZooKeeper().exists(znode, zkw);	boolean exists = s != null ? true : false;	if (exists) {	LOG.debug(zkw.prefix("Set watcher on existing znode=" + znode));	} else {	
set watcher on znode that does not yet exist 

public static boolean watchAndCheckExists(ZKWatcher zkw, String znode) throws KeeperException {	try {	Stat s = zkw.getRecoverableZooKeeper().exists(znode, zkw);	boolean exists = s != null ? true : false;	if (exists) {	LOG.debug(zkw.prefix("Set watcher on existing znode=" + znode));	} else {	}	return exists;	} catch (KeeperException e) {	
unable to set watcher on znode 

boolean exists = s != null ? true : false;	if (exists) {	LOG.debug(zkw.prefix("Set watcher on existing znode=" + znode));	} else {	}	return exists;	} catch (KeeperException e) {	zkw.keeperException(e);	return false;	} catch (InterruptedException e) {	
unable to set watcher on znode 

public static boolean setWatchIfNodeExists(ZKWatcher zkw, String znode) throws KeeperException {	try {	zkw.getRecoverableZooKeeper().getData(znode, true, null);	return true;	} catch (NoNodeException e) {	return false;	} catch (InterruptedException e) {	
unable to set watcher on znode 

public static int checkExists(ZKWatcher zkw, String znode) throws KeeperException {	try {	Stat s = zkw.getRecoverableZooKeeper().exists(znode, null);	return s != null ? s.getVersion() : -1;	} catch (KeeperException e) {	
unable to set watcher on znode 

public static int checkExists(ZKWatcher zkw, String znode) throws KeeperException {	try {	Stat s = zkw.getRecoverableZooKeeper().exists(znode, null);	return s != null ? s.getVersion() : -1;	} catch (KeeperException e) {	zkw.keeperException(e);	return -1;	} catch (InterruptedException e) {	
unable to set watcher on znode 

public static List<String> listChildrenAndWatchForNewChildren( ZKWatcher zkw, String znode) throws KeeperException {	try {	List<String> children = zkw.getRecoverableZooKeeper().getChildren(znode, zkw);	return children;	} catch(KeeperException.NoNodeException ke) {	
unable to list children of znode because node does not exist not an error 

public static List<String> listChildrenAndWatchForNewChildren( ZKWatcher zkw, String znode) throws KeeperException {	try {	List<String> children = zkw.getRecoverableZooKeeper().getChildren(znode, zkw);	return children;	} catch(KeeperException.NoNodeException ke) {	return null;	} catch (KeeperException e) {	
unable to list children of znode 

public static List<String> listChildrenAndWatchForNewChildren( ZKWatcher zkw, String znode) throws KeeperException {	try {	List<String> children = zkw.getRecoverableZooKeeper().getChildren(znode, zkw);	return children;	} catch(KeeperException.NoNodeException ke) {	return null;	} catch (KeeperException e) {	zkw.keeperException(e);	return null;	} catch (InterruptedException e) {	
unable to list children of znode 

public static boolean nodeHasChildren(ZKWatcher zkw, String znode) throws KeeperException {	try {	return !zkw.getRecoverableZooKeeper().getChildren(znode, null).isEmpty();	} catch(KeeperException.NoNodeException ke) {	
unable to list children of znode because node does not exist not an error 

public static boolean nodeHasChildren(ZKWatcher zkw, String znode) throws KeeperException {	try {	return !zkw.getRecoverableZooKeeper().getChildren(znode, null).isEmpty();	} catch(KeeperException.NoNodeException ke) {	return false;	} catch (KeeperException e) {	
unable to list children of znode 

public static boolean nodeHasChildren(ZKWatcher zkw, String znode) throws KeeperException {	try {	return !zkw.getRecoverableZooKeeper().getChildren(znode, null).isEmpty();	} catch(KeeperException.NoNodeException ke) {	return false;	} catch (KeeperException e) {	zkw.keeperException(e);	return false;	} catch (InterruptedException e) {	
unable to list children of znode 

public static int getNumberOfChildren(ZKWatcher zkw, String znode) throws KeeperException {	try {	Stat stat = zkw.getRecoverableZooKeeper().exists(znode, null);	return stat == null ? 0 : stat.getNumChildren();	} catch(KeeperException e) {	
unable to get children of node 

public static byte [] getData(ZKWatcher zkw, String znode) throws KeeperException, InterruptedException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, null, null);	logRetrievedMsg(zkw, znode, data, false);	return data;	} catch (KeeperException.NoNodeException e) {	
unable to get data of znode because node does not exist not an error 

public static byte [] getData(ZKWatcher zkw, String znode) throws KeeperException, InterruptedException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, null, null);	logRetrievedMsg(zkw, znode, data, false);	return data;	} catch (KeeperException.NoNodeException e) {	return null;	} catch (KeeperException e) {	
unable to get data of znode 

private static byte[] getDataInternal(ZKWatcher zkw, String znode, Stat stat, boolean watcherSet) throws KeeperException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, zkw, stat);	logRetrievedMsg(zkw, znode, data, watcherSet);	return data;	} catch (KeeperException.NoNodeException e) {	
unable to get data of znode because node does not exist not an error 

private static byte[] getDataInternal(ZKWatcher zkw, String znode, Stat stat, boolean watcherSet) throws KeeperException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, zkw, stat);	logRetrievedMsg(zkw, znode, data, watcherSet);	return data;	} catch (KeeperException.NoNodeException e) {	return null;	} catch (KeeperException e) {	
unable to get data of znode 

try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, zkw, stat);	logRetrievedMsg(zkw, znode, data, watcherSet);	return data;	} catch (KeeperException.NoNodeException e) {	return null;	} catch (KeeperException e) {	zkw.keeperException(e);	return null;	} catch (InterruptedException e) {	
unable to get data of znode 

public static byte [] getDataNoWatch(ZKWatcher zkw, String znode, Stat stat) throws KeeperException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, null, stat);	logRetrievedMsg(zkw, znode, data, false);	return data;	} catch (KeeperException.NoNodeException e) {	
unable to get data of znode because node does not exist not necessarily an error 

public static byte [] getDataNoWatch(ZKWatcher zkw, String znode, Stat stat) throws KeeperException {	try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, null, stat);	logRetrievedMsg(zkw, znode, data, false);	return data;	} catch (KeeperException.NoNodeException e) {	return null;	} catch (KeeperException e) {	
unable to get data of znode 

try {	byte [] data = zkw.getRecoverableZooKeeper().getData(znode, null, stat);	logRetrievedMsg(zkw, znode, data, false);	return data;	} catch (KeeperException.NoNodeException e) {	return null;	} catch (KeeperException e) {	zkw.keeperException(e);	return null;	} catch (InterruptedException e) {	
unable to get data of znode 

if (!node.startsWith(zkw.znodePaths.baseZNode)) {	return Ids.OPEN_ACL_UNSAFE;	}	if (isSecureZooKeeper) {	ArrayList<ACL> acls = new ArrayList<>();	String[] superUsers = zkw.getConfiguration().getStrings(Superusers.SUPERUSER_CONF_KEY);	String hbaseUser = null;	try {	hbaseUser = UserGroupInformation.getCurrentUser().getShortUserName();	} catch (IOException e) {	
could not acquire current user 

for (String user : superUsers) {	if (AuthUtil.isGroupPrincipal(user)) {	groups.add(user);	} else {	if(!user.equals(hbaseUser)) {	acls.add(new ACL(Perms.ALL, new Id("sasl", user)));	}	}	}	if (!groups.isEmpty()) {	
znode acl setting for group is skipped zookeeper doesn t support this feature presently 

public static boolean createEphemeralNodeAndWatch(ZKWatcher zkw, String znode, byte [] data) throws KeeperException {	boolean ret = true;	try {	zkw.getRecoverableZooKeeper().create(znode, data, createACL(zkw, znode), CreateMode.EPHEMERAL);	} catch (KeeperException.NodeExistsException nee) {	ret = false;	} catch (InterruptedException e) {	
Interrupted 

public static void deleteChildrenRecursivelyMultiOrSequential( ZKWatcher zkw, boolean runSequentialOnMultiFailure, String... pathRoots) throws KeeperException {	if (pathRoots == null || pathRoots.length <= 0) {	
given path is not valid 

public static void deleteNodeRecursivelyMultiOrSequential(ZKWatcher zkw, boolean runSequentialOnMultiFailure, String... pathRoots) throws KeeperException {	if (pathRoots == null || pathRoots.length <= 0) {	
given path is not valid 

public static void multiOrSequential(ZKWatcher zkw, List<ZKUtilOp> ops, boolean runSequentialOnMultiFailure) throws KeeperException {	if (zkw.getConfiguration().get("hbase.zookeeper.useMulti") != null) {	
hbase zookeeper usemulti is deprecated default to true always 

}	List<Op> zkOps = new LinkedList<>();	for (ZKUtilOp op : ops) {	zkOps.add(toZooKeeperOp(zkw, op));	}	try {	zkw.getRecoverableZooKeeper().multi(zkOps);	} catch (KeeperException ke) {	switch (ke.code()) {	case NODEEXISTS: case NONODE: case BADVERSION: case NOAUTH: if (runSequentialOnMultiFailure) {	
on call to zk multi received exception attempting to run operations sequentially because runsequentialonmultifailure is 

for (int i = 1; i < numMetaReplicas; i++) {	sb.append("\nRegion server holding hbase:meta, replicaId " + i + " " + new MetaTableLocator().getMetaRegionLocation(zkw, i));	}	sb.append("\nRegion servers:");	for (String child : listChildrenNoWatch(zkw, zkw.znodePaths.rsZNode)) {	sb.append("\n ").append(child);	}	try {	getReplicationZnodesDump(zkw, sb);	} catch (KeeperException ke) {	
couldn t get the replication znode dump 

zkw.interruptedException(e);	return;	}	try {	ReplicationProtos.ReplicationPeer.Builder builder = ReplicationProtos.ReplicationPeer.newBuilder();	ProtobufUtil.mergeFrom(builder, data, pblen, data.length - pblen);	String clusterKey = builder.getClusterkey();	sb.append("\n").append(znodeToProcess).append(": ").append(clusterKey);	appendPeerState(zkw, znodeToProcess, sb);	} catch (IOException ipbe) {	
got exception while parsing peer 

}	String peerStateZnode = ZNodePaths.joinZNode(znodeToProcess, child);	sb.append("\n").append(peerStateZnode).append(": ");	byte[] peerStateData;	try {	peerStateData = ZKUtil.getData(zkw, peerStateZnode);	ReplicationProtos.ReplicationState.Builder builder = ReplicationProtos.ReplicationState.newBuilder();	ProtobufUtil.mergeFrom(builder, peerStateData, pblen, peerStateData.length - pblen);	sb.append(builder.getState().name());	} catch (IOException ipbe) {	
got exception while parsing peer 

public static void waitForBaseZNode(Configuration conf) throws IOException {	
waiting until the base znode is available 

String parentZNode = conf.get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT);	ZooKeeper zk = new ZooKeeper(ZKConfig.getZKQuorumServersString(conf), conf.getInt(HConstants.ZK_SESSION_TIMEOUT, HConstants.DEFAULT_ZK_SESSION_TIMEOUT), EmptyWatcher.instance);	final int maxTimeMs = 10000;	final int maxNumAttempts = maxTimeMs / HConstants.SOCKET_RETRY_WAIT_MS;	KeeperException keeperEx = null;	try {	try {	for (int attempt = 0; attempt < maxNumAttempts; ++attempt) {	try {	if (zk.exists(parentZNode, false) != null) {	
parent znode exists 

========================= hbase sample_743 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1809 =========================

public void run(Path[] dirPaths, TableName[] tableNames, TableName[] newTableNames, boolean fullBackupRestore) throws IOException {	String bulkOutputConfKey;	player = new MapReduceHFileSplitterJob();	bulkOutputConfKey = MapReduceHFileSplitterJob.BULK_OUTPUT_CONF_KEY;	String dirs = StringUtils.join(dirPaths, ",");	if (LOG.isDebugEnabled()) {	
restore full incremental backup from directory from hbase tables to tables 

public void run(Path[] dirPaths, TableName[] tableNames, TableName[] newTableNames, boolean fullBackupRestore) throws IOException {	String bulkOutputConfKey;	player = new MapReduceHFileSplitterJob();	bulkOutputConfKey = MapReduceHFileSplitterJob.BULK_OUTPUT_CONF_KEY;	String dirs = StringUtils.join(dirPaths, ",");	if (LOG.isDebugEnabled()) {	}	for (int i = 0; i < tableNames.length; i++) {	
restore into 

String[] playerArgs = {	dirs, fullBackupRestore ? newTableNames[i].getNameAsString() : tableNames[i] .getNameAsString() };	int result = 0;	int loaderResult = 0;	try {	player.setConf(getConf());	result = player.run(playerArgs);	if (succeeded(result)) {	LoadIncrementalHFiles loader = BackupUtils.createLoader(getConf());	if (LOG.isDebugEnabled()) {	
restoring hfiles from directory 

if (LOG.isDebugEnabled()) {	}	String[] args = { bulkOutputPath.toString(), newTableNames[i].getNameAsString() };	loaderResult = loader.run(args);	if (failed(loaderResult)) {	throw new IOException("Can not restore from backup directory " + dirs + " (check Hadoop and HBase logs). Bulk loader return code =" + loaderResult);	}	} else {	throw new IOException("Can not restore from backup directory " + dirs + " (check Hadoop/MR and HBase logs). Player return code =" + result);	}	
restore job finished 

========================= hbase sample_597 =========================

public Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	if (conf == null) {	return files;	}	if (checkForFullyBackedUpTables) {	if (connection == null) return files;	try (BackupSystemTable tbl = new BackupSystemTable(connection)) {	fullyBackedUpTables = tbl.getTablesForBackupType(BackupType.FULL);	} catch (IOException ioe) {	
failed to get tables which have been fully backed up skipping checking 

fullyBackedUpTables = tbl.getTablesForBackupType(BackupType.FULL);	} catch (IOException ioe) {	return Collections.emptyList();	}	Collections.sort(fullyBackedUpTables);	}	final Set<String> hfileRefs;	try {	hfileRefs = loadHFileRefs(fullyBackedUpTables);	} catch (IOException ioe) {	
failed to read hfile references skipping checking deletable files 

public void setConf(Configuration config) {	this.conf = config;	this.connection = null;	try {	this.connection = ConnectionFactory.createConnection(conf);	} catch (IOException ioe) {	
couldn t establish connection 

public void stop(String why) {	if (this.stopped) {	return;	}	if (this.connection != null) {	try {	this.connection.close();	} catch (IOException ioe) {	
got when closing connection 

public void abort(String why, Throwable e) {	
aborting replicationhfilecleaner because 

========================= hbase sample_578 =========================

protected boolean shouldKillBeforeStoreUpdate() {	final boolean kill = this.killBeforeStoreUpdate;	if (this.toggleKillBeforeStoreUpdate) {	this.killBeforeStoreUpdate = !kill;	
toggle kill before store update to 

protected void periodicExecute(final TEnvironment env) {	if (completed.isEmpty()) {	if (LOG.isTraceEnabled()) {	
no completed procedures to cleanup 

int batchCount = 0;	final long now = EnvironmentEdgeManager.currentTime();	final Iterator<Map.Entry<Long, CompletedProcedureRetainer>> it = completed.entrySet().iterator();	final boolean debugEnabled = LOG.isDebugEnabled();	while (it.hasNext() && store.isRunning()) {	final Map.Entry<Long, CompletedProcedureRetainer> entry = it.next();	final CompletedProcedureRetainer retainer = entry.getValue();	final Procedure<?> proc = retainer.getProcedure();	if (retainer.isExpired(now, evictTtl, evictAckTtl)) {	if (debugEnabled) {	
evict completed 

LOG.debug("Load max pid=" + maxProcId);	lastProcId.set(maxProcId);	}	public void load(ProcedureIterator procIter) throws IOException {	loadProcedures(procIter, abortOnCorruption);	}	public void handleCorrupted(ProcedureIterator procIter) throws IOException {	int corruptedCount = 0;	while (procIter.hasNext()) {	Procedure<?> proc = procIter.next();	
corrupt 

final boolean debugEnabled = LOG.isDebugEnabled();	int runnablesCount = 0;	while (procIter.hasNext()) {	boolean finished = procIter.isNextFinished();	Procedure proc = procIter.next();	NonceKey nonceKey = proc.getNonceKey();	long procId = proc.getProcId();	if (finished) {	completed.put(proc.getProcId(), new CompletedProcedureRetainer(proc));	if (debugEnabled) {	
completed 

HashSet<Procedure> waitingSet = null;	procIter.reset();	while (procIter.hasNext()) {	if (procIter.isNextFinished()) {	procIter.skipNext();	continue;	}	Procedure proc = procIter.next();	assert !(proc.isFinished() && !proc.hasParent()) : "unexpected completed proc=" + proc;	if (debugEnabled) {	
loading s 

default: break;	}	}	int corruptedCount = 0;	Iterator<Map.Entry<Long, RootProcedureState>> itStack = rollbackStack.entrySet().iterator();	while (itStack.hasNext()) {	Map.Entry<Long, RootProcedureState> entry = itStack.next();	RootProcedureState procStack = entry.getValue();	if (procStack.isValid()) continue;	for (Procedure proc: procStack.getSubproceduresStack()) {	
corrupted 

public void start(int numThreads, boolean abortOnCorruption) throws IOException {	if (running.getAndSet(true)) {	
already running 

timeoutExecutor = new TimeoutExecutorThread(threadGroup);	workerId.set(0);	workerThreads = new CopyOnWriteArrayList<>();	for (int i = 0; i < corePoolSize; ++i) {	workerThreads.add(new WorkerThread(threadGroup));	}	long st, et;	st = EnvironmentEdgeManager.currentTime();	store.recoverLease();	et = EnvironmentEdgeManager.currentTime();	
recover store s lease s 

workerThreads.add(new WorkerThread(threadGroup));	}	long st, et;	st = EnvironmentEdgeManager.currentTime();	store.recoverLease();	et = EnvironmentEdgeManager.currentTime();	scheduler.start();	st = EnvironmentEdgeManager.currentTime();	load(abortOnCorruption);	et = EnvironmentEdgeManager.currentTime();	
load store s s 

}	long st, et;	st = EnvironmentEdgeManager.currentTime();	store.recoverLease();	et = EnvironmentEdgeManager.currentTime();	scheduler.start();	st = EnvironmentEdgeManager.currentTime();	load(abortOnCorruption);	et = EnvironmentEdgeManager.currentTime();	if (LOG.isTraceEnabled()) {	
start workers 

public void stop() {	if (!running.getAndSet(false)) {	return;	}	
Stopping 

assert !isRunning() : "expected not running";	timeoutExecutor.awaitTermination();	timeoutExecutor = null;	for (WorkerThread worker: workerThreads) {	worker.awaitTermination();	}	workerThreads = null;	try {	threadGroup.destroy();	} catch (IllegalThreadStateException e) {	
threadgroup contains running threads 

if (nonceKey != null) {	currentProcId = nonceKeysToProcIdsMap.get(nonceKey);	Preconditions.checkArgument(currentProcId != null, "Expected nonceKey=" + nonceKey + " to be reserved, use registerNonce(); proc=" + proc);	} else {	currentProcId = nextProcId();	}	proc.setNonceKey(nonceKey);	proc.setProcId(currentProcId.longValue());	store.insert(proc, null);	if (LOG.isDebugEnabled()) {	
stored 

Preconditions.checkArgument(lastProcId.get() >= 0);	Preconditions.checkArgument(isRunning(), "executor not running");	if (procs == null || procs.length <= 0) {	return;	}	for (int i = 0; i < procs.length; ++i) {	prepareProcedure(procs[i]).setProcId(nextProcId());	}	store.insert(procs);	if (LOG.isDebugEnabled()) {	
stored 

private void sendProcedureLoadedNotification(final long procId) {	if (!this.listeners.isEmpty()) {	for (ProcedureExecutorListener listener: this.listeners) {	try {	listener.procedureLoaded(procId);	} catch (Throwable e) {	
listener had an error 

private void sendProcedureAddedNotification(final long procId) {	if (!this.listeners.isEmpty()) {	for (ProcedureExecutorListener listener: this.listeners) {	try {	listener.procedureAdded(procId);	} catch (Throwable e) {	
listener had an error 

private void sendProcedureFinishedNotification(final long procId) {	if (!this.listeners.isEmpty()) {	for (ProcedureExecutorListener listener: this.listeners) {	try {	listener.procedureFinished(procId);	} catch (Throwable e) {	
listener had an error 

private void executeProcedure(final Procedure proc) {	final Long rootProcId = getRootProcedureId(proc);	if (rootProcId == null) {	LOG.warn("Rollback because parent is done/rolledback proc=" + proc);	executeRollback(proc);	return;	}	final RootProcedureState procStack = rollbackStack.get(rootProcId);	if (procStack == null) {	
rootprocedurestate is null for 

return;	}	do {	if (!procStack.acquire(proc)) {	if (procStack.setRollback()) {	switch (executeRollback(rootProcId, procStack)) {	case LOCK_ACQUIRED: break;	case LOCK_YIELD_WAIT: procStack.unsetRollback();	scheduler.yield(proc);	break;	
lock event wait rollback 

procStack.unsetRollback();	break;	default: throw new UnsupportedOperationException();	}	} else {	if (!proc.wasExecuted()) {	switch (executeRollback(proc)) {	case LOCK_ACQUIRED: break;	case LOCK_YIELD_WAIT: scheduler.yield(proc);	break;	
lock event wait can t rollback child running 

case LOCK_EVENT_WAIT: LOG.debug(lockState + " " + proc);	break;	default: throw new UnsupportedOperationException();	}	procStack.release(proc);	if (testing != null && !isRunning()) {	break;	}	if (proc.isSuccess()) {	proc.updateMetricsOnFinish(getEnvironment(), proc.elapsedTime(), true);	
finished in 

private LockState executeRollback(final Procedure proc) {	try {	proc.doRollback(getEnvironment());	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
roll back attempt failed for 

try {	proc.doRollback(getEnvironment());	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	}	return LockState.LOCK_YIELD_WAIT;	} catch (InterruptedException e) {	handleInterruptedException(proc, e);	return LockState.LOCK_YIELD_WAIT;	} catch (Throwable e) {	
code bug uncaught runtime exception for 

} catch (IOException e) {	if (LOG.isDebugEnabled()) {	}	return LockState.LOCK_YIELD_WAIT;	} catch (InterruptedException e) {	handleInterruptedException(proc, e);	return LockState.LOCK_YIELD_WAIT;	} catch (Throwable e) {	}	if (testing != null && testing.shouldKillBeforeStoreUpdate()) {	
testing kill before store update 

Procedure<TEnvironment>[] subprocs = null;	do {	reExecute = false;	try {	subprocs = procedure.doExecute(getEnvironment());	if (subprocs != null && subprocs.length == 0) {	subprocs = null;	}	} catch (ProcedureSuspendedException e) {	if (LOG.isTraceEnabled()) {	
suspend 

subprocs = procedure.doExecute(getEnvironment());	if (subprocs != null && subprocs.length == 0) {	subprocs = null;	}	} catch (ProcedureSuspendedException e) {	if (LOG.isTraceEnabled()) {	}	suspended = true;	} catch (ProcedureYieldException e) {	if (LOG.isTraceEnabled()) {	
yield 

if (LOG.isTraceEnabled()) {	}	suspended = true;	} catch (ProcedureYieldException e) {	if (LOG.isTraceEnabled()) {	}	scheduler.yield(procedure);	return;	} catch (InterruptedException e) {	if (LOG.isTraceEnabled()) {	
yield interrupt 

reExecute = true;	if (LOG.isTraceEnabled()) {	LOG.trace("Short-circuit to next step on pid=" + procedure.getProcId());	}	} else {	subprocs = initializeChildren(procStack, procedure, subprocs);	LOG.info("Initialized subprocedures=" + (subprocs == null? null: Stream.of(subprocs).map(e -> "{" + e.toString() + "}"). collect(Collectors.toList()).toString()));	}	} else if (procedure.getState() == ProcedureState.WAITING_TIMEOUT) {	if (LOG.isTraceEnabled()) {	
added to timeoutexecutor 

} else if (procedure.getState() == ProcedureState.WAITING_TIMEOUT) {	if (LOG.isTraceEnabled()) {	}	timeoutExecutor.add(procedure);	} else if (!suspended) {	procedure.setState(ProcedureState.SUCCESS);	}	}	procStack.addRollbackStep(procedure);	if (testing != null && testing.shouldKillBeforeStoreUpdate(suspended)) {	
testing kill before store update 

private void countDownChildren(final RootProcedureState procStack, final Procedure procedure) {	final Procedure parent = procedures.get(procedure.getParentProcId());	if (parent == null) {	assert procStack.isRollingback();	return;	}	
finish suprocedure 

private void countDownChildren(final RootProcedureState procStack, final Procedure procedure) {	final Procedure parent = procedures.get(procedure.getParentProcId());	if (parent == null) {	assert procStack.isRollingback();	return;	}	if (parent.tryRunnable()) {	store.update(parent);	scheduler.addFront(parent);	
finished subprocedure s of resume parent processing 

private void updateStoreOnExec(final RootProcedureState procStack, final Procedure procedure, final Procedure[] subprocs) {	if (subprocs != null && !procedure.isFailed()) {	if (LOG.isTraceEnabled()) {	
stored children 

private void updateStoreOnExec(final RootProcedureState procStack, final Procedure procedure, final Procedure[] subprocs) {	if (subprocs != null && !procedure.isFailed()) {	if (LOG.isTraceEnabled()) {	}	store.insert(procedure, subprocs);	} else {	if (LOG.isTraceEnabled()) {	
store update 

private void handleInterruptedException(final Procedure proc, final InterruptedException e) {	if (LOG.isTraceEnabled()) {	
interrupt during suspend and retry it later 

private void execCompletionCleanup(final Procedure proc) {	final TEnvironment env = getEnvironment();	if (proc.holdLock(env) && proc.hasLock(env)) {	releaseLock(proc, true);	}	try {	proc.completionCleanup(env);	} catch (Throwable e) {	
code bug uncatched runtime exception for procedure 

CompletedProcedureRetainer retainer = new CompletedProcedureRetainer(proc);	if (!proc.shouldWaitClientAck(getEnvironment())) {	retainer.setClientAckTime(0);	}	completed.put(proc.getProcId(), retainer);	rollbackStack.remove(proc.getProcId());	procedures.remove(proc.getProcId());	try {	scheduler.completionCleanup(proc);	} catch (Throwable e) {	
code bug uncatched runtime exception for completion cleanup 

runningCount = store.setRunningProcedureCount(activeCount);	if (LOG.isTraceEnabled()) {	LOG.trace("Halt pid=" + this.activeProcedure.getProcId() + " runningCount=" + runningCount + ", activeCount=" + activeCount);	}	this.activeProcedure = null;	lastUpdate = EnvironmentEdgeManager.currentTime();	executionStartTime.set(Long.MAX_VALUE);	}	}	} catch (Throwable t) {	
worker terminating unnaturally 

if (LOG.isTraceEnabled()) {	LOG.trace("Halt pid=" + this.activeProcedure.getProcId() + " runningCount=" + runningCount + ", activeCount=" + activeCount);	}	this.activeProcedure = null;	lastUpdate = EnvironmentEdgeManager.currentTime();	executionStartTime.set(Long.MAX_VALUE);	}	}	} catch (Throwable t) {	} finally {	
worker terminated 

public void run() {	final boolean traceEnabled = LOG.isTraceEnabled();	while (isRunning()) {	final DelayedWithTimeout task = DelayedUtil.takeWithoutInterrupt(queue);	if (task == null || task == DelayedUtil.DELAYED_POISON) {	continue;	}	if (traceEnabled) {	
executing 

if (task == null || task == DelayedUtil.DELAYED_POISON) {	continue;	}	if (traceEnabled) {	}	if (task instanceof InlineChore) {	execInlineChore((InlineChore)task);	} else if (task instanceof DelayedProcedure) {	execDelayedProcedure((DelayedProcedure)task);	} else {	
code bug unknown timeout task type 

private void executeInMemoryChore(final ProcedureInMemoryChore chore) {	if (!chore.isWaiting()) return;	try {	chore.periodicExecute(getEnvironment());	} catch (Throwable e) {	
ignoring exception 

public abstract void sendStopSignal();	public void awaitTermination() {	try {	final long startTime = EnvironmentEdgeManager.currentTime();	for (int i = 0; isAlive(); ++i) {	sendStopSignal();	join(250);	if (i > 0 && (i % 8) == 0) {	
waiting termination of thread sending interrupt 

try {	final long startTime = EnvironmentEdgeManager.currentTime();	for (int i = 0; isAlive(); ++i) {	sendStopSignal();	join(250);	if (i > 0 && (i % 8) == 0) {	interrupt();	}	}	} catch (InterruptedException e) {	
join wait got interrupted 

private int checkForStuckWorkers() {	int stuckCount = 0;	for (WorkerThread worker: workerThreads) {	if (worker.getCurrentRunTime() < stuckThreshold) {	continue;	}	stuckCount++;	
worker stuck run time 

private void checkThreadCount(final int stuckCount) {	if (stuckCount < 1 || !scheduler.hasRunnables()) return;	final float stuckPerc = ((float)stuckCount) / workerThreads.size();	if (stuckPerc >= addWorkerStuckPercentage && activeExecutorCount.get() == workerThreads.size()) {	final WorkerThread worker = new WorkerThread(threadGroup);	workerThreads.add(worker);	worker.start();	
added new worker thread 

========================= hbase sample_1223 =========================

public Response get(final @Context ServletContext context, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

public Response put(final NamespacesInstanceModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
put 

public Response putNoBody(final byte[] message, final @Context UriInfo uriInfo, final @Context HttpHeaders headers) {	if (LOG.isTraceEnabled()) {	
put 

public Response post(final NamespacesInstanceModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
post 

public Response postNoBody(final byte[] message, final @Context UriInfo uriInfo, final @Context HttpHeaders headers) {	if (LOG.isTraceEnabled()) {	
post 

public Response deleteNoBody(final byte[] message, final @Context UriInfo uriInfo, final @Context HttpHeaders headers) {	if (LOG.isTraceEnabled()) {	
delete 

========================= hbase sample_3121 =========================

public void uncaughtException(Thread t, Throwable e) {	
thread exited with exception 

public static void sleep(long millis) {	try {	Thread.sleep(millis);	} catch (InterruptedException e) {	
sleep interrupted 

try {	hadoop27Method.invoke(null, stream, title);	} catch (IllegalAccessException | IllegalArgumentException e) {	throw new RuntimeException(e);	} catch (InvocationTargetException e) {	throw new RuntimeException(e.getCause());	}	}	};	} catch (NoSuchMethodException e) {	
can not find hadoop printthreadinfo method try hadoop hadoop and earlier 

try {	hadoop26Method.invoke(null, new PrintWriter( new OutputStreamWriter(stream, StandardCharsets.UTF_8)), title);	} catch (IllegalAccessException | IllegalArgumentException e) {	throw new RuntimeException(e);	} catch (InvocationTargetException e) {	throw new RuntimeException(e.getCause());	}	}	};	} catch (NoSuchMethodException e) {	
cannot find printthreadinfo method check hadoop jars linked 

========================= hbase sample_978 =========================

toWait = nextLease.getDelay(TimeUnit.MILLISECONDS);	}	toWait = Math.min(leaseCheckFrequency, toWait);	toWait = Math.max(MIN_WAIT_TIME, toWait);	Thread.sleep(toWait);	} catch (InterruptedException e) {	continue;	} catch (ConcurrentModificationException e) {	continue;	} catch (Throwable e) {	
unexpected exception killed leases thread 

Map.Entry<String, Lease> entry = it.next();	Lease lease = entry.getValue();	long thisLeaseDelay = lease.getDelay(TimeUnit.MILLISECONDS);	if ( thisLeaseDelay > 0) {	if (nextLease == null || thisLeaseDelay < nextLeaseDelay) {	nextLease = lease;	nextLeaseDelay = thisLeaseDelay;	}	} else {	if (lease.getListener() == null) {	
lease listener is null for lease 

public void close() {	
closing leases 

public void close() {	this.stopRequested = true;	leases.clear();	
closed leases 

========================= hbase sample_2730 =========================

if (midKey == null) {	LOG.debug("Region " + r.getRegionInfo().getRegionNameAsString() + " not splittable because midkey=null");	if (((HRegion)r).shouldForceSplit()) {	((HRegion)r).clearSplit();	}	return;	}	try {	this.splits.execute(new SplitRequest(r, midKey, this.server, user));	if (LOG.isDebugEnabled()) {	
splitting 

if (((HRegion)r).shouldForceSplit()) {	((HRegion)r).clearSplit();	}	return;	}	try {	this.splits.execute(new SplitRequest(r, midKey, this.server, user));	if (LOG.isDebugEnabled()) {	}	} catch (RejectedExecutionException ree) {	
could not execute split for 

private void waitFor(ThreadPoolExecutor t, String name) {	boolean done = false;	while (!done) {	try {	done = t.awaitTermination(60, TimeUnit.SECONDS);	
waiting for to finish 

private void waitFor(ThreadPoolExecutor t, String name) {	boolean done = false;	while (!done) {	try {	done = t.awaitTermination(60, TimeUnit.SECONDS);	if (!done) {	t.shutdownNow();	}	} catch (InterruptedException ie) {	
interrupted waiting for to finish 

private boolean shouldSplitRegion() {	if(server.getNumberOfOnlineRegions() > 0.9*regionSplitLimit) {	
total number of regions is approaching the upper limit please consider taking a look at http 

int oldPriority = this.queuedPriority;	this.queuedPriority = this.store.getCompactPriority();	if (this.queuedPriority > oldPriority) {	this.parent.execute(this);	return;	}	Optional<CompactionContext> selected;	try {	selected = selectCompaction(this.region, this.store, queuedPriority, tracker, completeTracker, user);	} catch (IOException ex) {	
compaction selection failed 

LOG.info(((completed) ? "Completed" : "Aborted") + " compaction: " + this + "; duration=" + StringUtils.formatTimeDiff(now, start));	if (completed) {	if (store.getCompactPriority() <= 0) {	requestSystemCompaction(region, store, "Recursive enqueue");	} else {	requestSplit(region);	}	}	} catch (IOException ex) {	IOException remoteEx = ex instanceof RemoteException ? ((RemoteException) ex).unwrapRemoteException() : ex;	
compaction failed 

if (completed) {	if (store.getCompactPriority() <= 0) {	requestSystemCompaction(region, store, "Recursive enqueue");	} else {	requestSplit(region);	}	}	} catch (IOException ex) {	IOException remoteEx = ex instanceof RemoteException ? ((RemoteException) ex).unwrapRemoteException() : ex;	if (remoteEx != ex) {	
compaction failed at original callstack 

requestSplit(region);	}	}	} catch (IOException ex) {	IOException remoteEx = ex instanceof RemoteException ? ((RemoteException) ex).unwrapRemoteException() : ex;	if (remoteEx != ex) {	}	region.reportCompactionRequestFailure();	server.checkFileSystem();	} catch (Exception ex) {	
compaction failed 

}	region.reportCompactionRequestFailure();	server.checkFileSystem();	} catch (Exception ex) {	region.reportCompactionRequestFailure();	server.checkFileSystem();	} finally {	tracker.afterExecution(store);	completeTracker.completed(store);	region.decrementCompactionsQueuedCount();	
compactsplitthread status 

public void rejectedExecution(Runnable runnable, ThreadPoolExecutor pool) {	if (runnable instanceof CompactionRunner) {	CompactionRunner runner = (CompactionRunner) runnable;	
compaction rejected 

public void onConfigurationChange(Configuration newConf) {	int largeThreads = Math.max(1, newConf.getInt( LARGE_COMPACTION_THREADS, LARGE_COMPACTION_THREADS_DEFAULT));	if (this.longCompactions.getCorePoolSize() != largeThreads) {	
changing the value of from to 

if(this.longCompactions.getCorePoolSize() < largeThreads) {	this.longCompactions.setMaximumPoolSize(largeThreads);	this.longCompactions.setCorePoolSize(largeThreads);	} else {	this.longCompactions.setCorePoolSize(largeThreads);	this.longCompactions.setMaximumPoolSize(largeThreads);	}	}	int smallThreads = newConf.getInt(SMALL_COMPACTION_THREADS, SMALL_COMPACTION_THREADS_DEFAULT);	if (this.shortCompactions.getCorePoolSize() != smallThreads) {	
changing the value of from to 

if(this.shortCompactions.getCorePoolSize() < smallThreads) {	this.shortCompactions.setMaximumPoolSize(smallThreads);	this.shortCompactions.setCorePoolSize(smallThreads);	} else {	this.shortCompactions.setCorePoolSize(smallThreads);	this.shortCompactions.setMaximumPoolSize(smallThreads);	}	}	int splitThreads = newConf.getInt(SPLIT_THREADS, SPLIT_THREADS_DEFAULT);	if (this.splits.getCorePoolSize() != splitThreads) {	
changing the value of from to 

========================= hbase sample_2675 =========================

assertTrue(Bytes.equals(row, CellUtil.cloneRow(kv)));	}	}	results.clear();	Iterator<KeyValueScanner> scanners = ((HRegion.RegionScannerImpl)s).storeHeap.getHeap().iterator();	while (scanners.hasNext()) {	StoreScanner ss = (StoreScanner)scanners.next();	ss.updateReaders(Collections.EMPTY_LIST, Collections.EMPTY_LIST);	}	} while (more);	
inserted scanned 

========================= hbase sample_1720 =========================

public MasterCoprocessorHost(final MasterServices services, final Configuration conf) {	super(services);	this.conf = conf;	this.masterServices = services;	boolean coprocessorsEnabled = conf.getBoolean(COPROCESSORS_ENABLED_CONF_KEY, DEFAULT_COPROCESSORS_ENABLED);	
system coprocessor loading is enabled disabled 

public MasterCoprocessor checkAndGetInstance(Class<?> implClass) throws InstantiationException, IllegalAccessException {	if (MasterCoprocessor.class.isAssignableFrom(implClass)) {	return (MasterCoprocessor)implClass.newInstance();	} else if (CoprocessorService.class.isAssignableFrom(implClass)) {	return new CoprocessorServiceBackwardCompatiblity.MasterCoprocessorService( (CoprocessorService)implClass.newInstance());	} else {	
is not of type mastercoprocessor check the configuration 

========================= hbase sample_2767 =========================

private void outputTickCount() {	
chore count of chore calls 

========================= hbase sample_885 =========================

public void nodeChildrenChanged(String path) {	if (nsZNode.equals(path)) {	try {	List<ZKUtil.NodeAndData> nodes = ZKUtil.getChildDataAndWatchForNewChildren(watcher, nsZNode);	refreshNodes(nodes);	} catch (KeeperException ke) {	
error reading data from zookeeper for path 

public void nodeChildrenChanged(String path) {	if (nsZNode.equals(path)) {	try {	List<ZKUtil.NodeAndData> nodes = ZKUtil.getChildDataAndWatchForNewChildren(watcher, nsZNode);	refreshNodes(nodes);	} catch (KeeperException ke) {	watcher.abort("ZooKeeper error get node children for path "+path, ke);	} catch (IOException e) {	
error deserializing namespace child from 

private void deleteNamespace(String name) throws IOException {	String zNode = ZNodePaths.joinZNode(nsZNode, name);	try {	ZKUtil.deleteNode(watcher, zNode);	} catch (KeeperException e) {	if (e instanceof KeeperException.NoNodeException) {	
the znode for namespace does not exist 

private void deleteNamespace(String name) throws IOException {	String zNode = ZNodePaths.joinZNode(nsZNode, name);	try {	ZKUtil.deleteNode(watcher, zNode);	} catch (KeeperException e) {	if (e instanceof KeeperException.NoNodeException) {	} else {	
failed updating permissions for namespace 

private void writeNamespace(NamespaceDescriptor ns) throws IOException {	String zNode = ZNodePaths.joinZNode(nsZNode, ns.getName());	try {	ZKUtil.createWithParents(watcher, zNode);	ZKUtil.updateExistingNodeData(watcher, zNode, ProtobufUtil.toProtoNamespaceDescriptor(ns).toByteArray(), -1);	} catch (KeeperException e) {	
failed updating permissions for namespace 

private void refreshNodes(List<ZKUtil.NodeAndData> nodes) throws IOException {	for (ZKUtil.NodeAndData n : nodes) {	if (n.isEmpty()) continue;	String path = n.getNode();	String namespace = ZKUtil.getNodeName(path);	byte[] nodeData = n.getData();	if (LOG.isTraceEnabled()) {	
updating namespace cache from node with data 

========================= hbase sample_3033 =========================

public static void obtainAndCacheToken(final Connection conn, User user) throws IOException, InterruptedException {	try {	Token<AuthenticationTokenIdentifier> token = obtainToken(conn, user);	if (token == null) {	throw new IOException("No token returned for user " + user.getName());	}	if (LOG.isDebugEnabled()) {	
obtained token for user 

public static void obtainTokenForJob(final Connection conn, User user, Job job) throws IOException, InterruptedException {	try {	Token<AuthenticationTokenIdentifier> token = obtainToken(conn, user);	if (token == null) {	throw new IOException("No token returned for user " + user.getName());	}	Text clusterId = getClusterId(token);	if (LOG.isDebugEnabled()) {	
obtained token for user on cluster 

public static void obtainTokenForJob(final Connection conn, final JobConf job, User user) throws IOException, InterruptedException {	try {	Token<AuthenticationTokenIdentifier> token = obtainToken(conn, user);	if (token == null) {	throw new IOException("No token returned for user " + user.getName());	}	Text clusterId = getClusterId(token);	if (LOG.isDebugEnabled()) {	
obtained token for user on cluster 

========================= hbase sample_2272 =========================

MetaTableAccessor.deleteRegion(masterServices.getConnection(), getRegion());	masterServices.getServerManager().removeRegion(getRegion());	FavoredNodesManager fnm = masterServices.getFavoredNodesManager();	if (fnm != null) {	fnm.deleteFavoredNodesForRegions(Lists.newArrayList(getRegion()));	}	return Flow.NO_MORE_STATE;	default: throw new UnsupportedOperationException(this + " unhandled state=" + state);	}	} catch (IOException ioe) {	
error trying to gc retrying 

========================= hbase sample_2788 =========================

public void testBackupDelete() throws Exception {	
test backup delete on a single table with data 

public void testBackupDelete() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	
backup complete 

BackupSystemTable table = new BackupSystemTable(TEST_UTIL.getConnection());	BackupInfo info = table.readBackupInfo(backupId);	Path path = new Path(info.getBackupRootDir(), backupId);	FileSystem fs = FileSystem.get(path.toUri(), conf1);	assertTrue(fs.exists(path));	int deleted = getBackupAdmin().deleteBackups(backupIds);	assertTrue(!fs.exists(path));	assertTrue(fs.exists(new Path(info.getBackupRootDir())));	assertTrue(1 == deleted);	table.close();	
delete backup 

public void testBackupDeleteCommand() throws Exception {	
test backup delete on a single table with data command line 

public void testBackupDeleteCommand() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	
backup complete 

List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	ByteArrayOutputStream baos = new ByteArrayOutputStream();	System.setOut(new PrintStream(baos));	String[] args = new String[] { "delete", backupId };	try {	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	} catch (Exception e) {	
failed 

String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	ByteArrayOutputStream baos = new ByteArrayOutputStream();	System.setOut(new PrintStream(baos));	String[] args = new String[] { "delete", backupId };	try {	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret == 0);	} catch (Exception e) {	}	
delete backup 

========================= hbase sample_539 =========================

public static void parseResult(final Result result, final QuotasVisitor visitor) throws IOException {	byte[] row = result.getRow();	if (isNamespaceRowKey(row)) {	parseNamespaceResult(result, visitor);	} else if (isTableRowKey(row)) {	parseTableResult(result, visitor);	} else if (isUserRowKey(row)) {	parseUserResult(result, visitor);	} else {	
unexpected row key 

========================= hbase sample_169 =========================

static void setServerImpl(CommandLine cmd, Configuration conf) {	ImplType chosenType = null;	int numChosen = 0;	for (ImplType t : values()) {	if (cmd.hasOption(t.option)) {	chosenType = t;	++numChosen;	}	}	if (numChosen < 1) {	
using default thrift server type 

if (cmd.hasOption(t.option)) {	chosenType = t;	++numChosen;	}	}	if (numChosen < 1) {	chosenType = DEFAULT;	} else if (numChosen > 1) {	throw new AssertionError("Exactly one option out of " + Arrays.toString(values()) + " has to be specified");	}	
using thrift server type 

this.hbaseHandler.initMetrics(metrics);	this.handler = HbaseHandlerMetricsProxy.newInstance( hbaseHandler, metrics, conf);	this.realUser = userProvider.getCurrent().getUGI();	String strQop = conf.get(THRIFT_QOP_KEY);	if (strQop != null) {	this.qop = SaslUtil.getQop(strQop);	}	doAsEnabled = conf.getBoolean(THRIFT_SUPPORT_PROXYUSER, false);	if (doAsEnabled) {	if (!conf.getBoolean(USE_HTTP_CONF_KEY, false)) {	
fail to enable the doas feature hbase regionserver thrift http is not configured 

pauseMonitor.start();	if (conf.getBoolean(USE_HTTP_CONF_KEY, false)) {	setupHTTPServer();	httpServer.start();	httpServer.join();	} else {	setupServer();	tserver.serve();	}	} catch (Exception e) {	
cannot run thriftserver 

}	if (tserver != null) {	tserver.stop();	tserver = null;	}	if (httpServer != null) {	try {	httpServer.stop();	httpServer = null;	} catch (Exception e) {	
problem encountered in shutting down http server 

serverConnector = new ServerConnector(httpServer, new HttpConnectionFactory(httpConfig));	}	serverConnector.setPort(listenPort);	String host = getBindAddress(conf).getHostAddress();	serverConnector.setHost(host);	httpServer.addConnector(serverConnector);	httpServer.setStopAtShutdown(true);	if (doAsEnabled) {	ProxyUsers.refreshSuperUserGroupsConfiguration(conf);	}	
starting thrift http server on 

TProtocolFactory protocolFactory = getProtocolFactory();	final TProcessor p = new Hbase.Processor<>(handler);	ImplType implType = ImplType.getServerImpl(conf);	TProcessor processor = p;	TTransportFactory transportFactory;	if (conf.getBoolean(FRAMED_CONF_KEY, false) || implType.isAlwaysFramed) {	if (qop != null) {	throw new RuntimeException("Thrift server authentication" + " doesn't work with framed transport yet");	}	transportFactory = new TFramedTransport.Factory( conf.getInt(MAX_FRAME_SIZE_CONF_KEY, 2)  * 1024 * 1024);	
using framed transport 

}	}	if (ac != null) {	String authid = ac.getAuthenticationID();	String authzid = ac.getAuthorizationID();	if (!authid.equals(authzid)) {	ac.setAuthorized(false);	} else {	ac.setAuthorized(true);	String userName = SecurityUtil.getUserFromPrincipal(authzid);	
effective user 

public boolean process(TProtocol inProt, TProtocol outProt) throws TException {	TSaslServerTransport saslServerTransport = (TSaslServerTransport)inProt.getTransport();	SaslServer saslServer = saslServerTransport.getSaslServer();	String principal = saslServer.getAuthorizationID();	hbaseHandler.setEffectiveUser(principal);	return p.process(inProt, outProt);	}	};	}	if (conf.get(BIND_CONF_KEY) != null && !implType.canSpecifyBindIP) {	
server types don t support ip address binding at the moment see https throw new runtimeexception bind conf key impltype 

ExecutorService executorService = createExecutor( callQueue, serverArgs.getMaxWorkerThreads(), serverArgs.getMaxWorkerThreads());	serverArgs.executorService(executorService).processor(processor) .transportFactory(transportFactory).protocolFactory(protocolFactory);	tserver = new THsHaServer(serverArgs);	} else {	TThreadedSelectorServer.Args serverArgs = new HThreadedSelectorServerArgs(serverTransport, conf);	CallQueue callQueue = new CallQueue(new LinkedBlockingQueue<>(), metrics);	ExecutorService executorService = createExecutor( callQueue, serverArgs.getWorkerThreads(), serverArgs.getWorkerThreads());	serverArgs.executorService(executorService).processor(processor) .transportFactory(transportFactory).protocolFactory(protocolFactory);	tserver = new TThreadedSelectorServer(serverArgs);	}	
starting hbase server on 

ExecutorService executorService = createExecutor( callQueue, serverArgs.getWorkerThreads(), serverArgs.getWorkerThreads());	serverArgs.executorService(executorService).processor(processor) .transportFactory(transportFactory).protocolFactory(protocolFactory);	tserver = new TThreadedSelectorServer(serverArgs);	}	} else if (implType == ImplType.THREAD_POOL) {	InetAddress listenAddress = getBindAddress(conf);	int readTimeout = conf.getInt(THRIFT_SERVER_SOCKET_READ_TIMEOUT_KEY, THRIFT_SERVER_SOCKET_READ_TIMEOUT_DEFAULT);	TServerTransport serverTransport = new TServerSocket( new TServerSocket.ServerSocketTransportArgs(). bindAddr(new InetSocketAddress(listenAddress, listenPort)).backlog(backlog). clientTimeout(readTimeout));	TBoundedThreadPoolServer.Args serverArgs = new TBoundedThreadPoolServer.Args(serverTransport, conf);	serverArgs.processor(processor).transportFactory(transportFactory) .protocolFactory(protocolFactory);	
starting on with readtimeout ms 

private TProtocolFactory getProtocolFactory() {	TProtocolFactory protocolFactory;	if (conf.getBoolean(COMPACT_CONF_KEY, false)) {	
using compact protocol 

private TProtocolFactory getProtocolFactory() {	TProtocolFactory protocolFactory;	if (conf.getBoolean(COMPACT_CONF_KEY, false)) {	protocolFactory = new TCompactProtocol.Factory();	} else {	
using binary protocol 

byte[][] famAndQf = CellUtil.parseColumn(getBytes(m.column));	if (m.isDelete) {	if (famAndQf.length == 1) {	delete.addFamily(famAndQf[0], timestamp);	} else {	delete.addColumns(famAndQf[0], famAndQf[1], timestamp);	}	delete.setDurability(m.writeToWAL ? Durability.SYNC_WAL : Durability.SKIP_WAL);	} else {	if(famAndQf.length == 1) {	
no column qualifier specified delete is the only mutation supported over the whole column family 

byte[][] famAndQf = CellUtil.parseColumn(getBytes(m.column));	if (m.isDelete) {	if (famAndQf.length == 1) {	delete.addFamily(famAndQf[0], timestamp);	} else {	delete.addColumns(famAndQf[0], famAndQf[1], timestamp);	}	delete.setDurability(m.writeToWAL ? Durability.SYNC_WAL : Durability.SKIP_WAL);	} else {	if (famAndQf.length == 1) {	
no column qualifier specified delete is the only mutation supported over the whole column family 

public static void registerFilters(Configuration conf) {	String[] filters = conf.getStrings("hbase.thrift.filters");	if(filters != null) {	for(String filterClass: filters) {	String[] filterPart = filterClass.split(":");	if(filterPart.length != 2) {	
invalid filter specification skipping 

========================= hbase sample_811 =========================

public void testBackupMultipleDeletes() throws Exception {	
create full backup image for all tables 

String backupIdInc4 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdInc4));	tables = Lists.newArrayList(table3);	request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull2 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull2));	tables = Lists.newArrayList(table3);	request = createBackupRequest(BackupType.INCREMENTAL, tables, BACKUP_ROOT_DIR);	String backupIdInc5 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdInc5));	
delete 

assertTrue(checkSucceeded(backupIdInc4));	tables = Lists.newArrayList(table3);	request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull2 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull2));	tables = Lists.newArrayList(table3);	request = createBackupRequest(BackupType.INCREMENTAL, tables, BACKUP_ROOT_DIR);	String backupIdInc5 = client.backupTables(request);	assertTrue(checkSucceeded(backupIdInc5));	client.deleteBackups(new String[] { backupIdInc2 });	
delete done 

========================= hbase sample_542 =========================

public long getLastMajorCompactionAge() {	long lastMajorCompactionTs = 0L;	try {	lastMajorCompactionTs = this.region.getOldestHfileTs(true);	} catch (IOException ioe) {	
could not load hfile info 

========================= hbase sample_2659 =========================

PageFilter f2 = new PageFilter(2);	fs.add(f1);	fs.add(f2);	FilterList filter = new FilterList(fs);	scan.setFilter(filter);	Table table = connection.getTable(name);	ResultScanner scanner = table.getScanner(scan);	for (Result result : scanner) {	row_number++;	for (Cell kv : result.listCells()) {	
kv 

for (Cell kv : result.listCells()) {	kv_number++;	assertEquals("Returned row is not correct", new String(CellUtil.cloneRow(kv)), "row" + ( row_number + 1 ));	}	}	scanner.close();	table.close();	} catch (Exception e) {	assertNull("Exception happens in scan", e);	}	
check the fetched kv number 

========================= hbase sample_1976 =========================

public boolean isSplitParent() {	if (!isSplit()) return false;	if (!isOffline()) {	
region is split but not offline 

========================= hbase sample_407 =========================

FileSystem fs = region.getRegionFileSystem().getFileSystem();	Path rootDir = FSUtils.getRootDir(fs.getConf());	Path regionDir = HRegion.getRegionDir(rootDir, region.getRegionInfo());	FileStatus[] regionFiles = FSUtils.listStatus(fs, regionDir, null);	Assert.assertNotNull("No files in the region directory", regionFiles);	if (LOG.isDebugEnabled()) {	List<Path> files = new ArrayList<>();	for (FileStatus file : regionFiles) {	files.add(file.getPath());	}	
current files 

}	}	final PathFilter dirFilter = new FSUtils.DirFilter(fs);	PathFilter nonHidden = new PathFilter() {	public boolean accept(Path file) {	return dirFilter.accept(file) && !file.getName().toString().startsWith(".");	}	};	FileStatus[] storeDirs = FSUtils.listStatus(fs, regionDir, nonHidden);	for (FileStatus store : storeDirs) {	
deleting store for test 

public void testArchiveOnTableDelete() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	UTIL.createTable(tableName, TEST_FAM);	List<HRegion> servingRegions = UTIL.getHBaseCluster().getRegions(tableName);	assertEquals(1, servingRegions.size());	HRegion region = servingRegions.get(0);	HRegionServer hrs = UTIL.getRSForFirstRegionInTable(tableName);	FileSystem fs = hrs.getFileSystem();	
loading table 

assertEquals(1, servingRegions.size());	HRegion region = servingRegions.get(0);	HRegionServer hrs = UTIL.getRSForFirstRegionInTable(tableName);	FileSystem fs = hrs.getFileSystem();	UTIL.loadRegion(region, TEST_FAM);	List<HRegion> regions = hrs.getRegions(tableName);	assertEquals("More that 1 region for test table.", 1, regions.size());	region = regions.get(0);	region.waitForFlushesAndCompactions();	UTIL.getAdmin().disableTable(tableName);	
disabled table 

UTIL.loadRegion(region, TEST_FAM);	List<HRegion> regions = hrs.getRegions(tableName);	assertEquals("More that 1 region for test table.", 1, regions.size());	region = regions.get(0);	region.waitForFlushesAndCompactions();	UTIL.getAdmin().disableTable(tableName);	clearArchiveDirectory();	byte[][]columns = region.getTableDescriptor().getColumnFamilyNames().toArray(new byte[0][]);	List<String> storeFiles = region.getStoreFileList(columns);	UTIL.deleteTable(tableName);	
deleted table 

Path archiveDir = HFileArchiveUtil.getArchivePath(UTIL.getConfiguration());	List<String> archivedFiles = new ArrayList<>();	while (System.currentTimeMillis() < end) {	archivedFiles = getAllFileNames(fs, archiveDir);	if (archivedFiles.size() >= storeFiles.size()) {	break;	}	}	Collections.sort(storeFiles);	Collections.sort(archivedFiles);	
store files 

archivedFiles = getAllFileNames(fs, archiveDir);	if (archivedFiles.size() >= storeFiles.size()) {	break;	}	}	Collections.sort(storeFiles);	Collections.sort(archivedFiles);	for (int i = 0; i < storeFiles.size(); i++) {	LOG.debug(i + " - " + storeFiles.get(i));	}	
archive files 

public void testArchiveOnTableFamilyDelete() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	UTIL.createTable(tableName, new byte[][] {TEST_FAM, Bytes.toBytes("fam2")});	List<HRegion> servingRegions = UTIL.getHBaseCluster().getRegions(tableName);	assertEquals(1, servingRegions.size());	HRegion region = servingRegions.get(0);	HRegionServer hrs = UTIL.getRSForFirstRegionInTable(tableName);	FileSystem fs = hrs.getFileSystem();	
loading table 

assertEquals(1, servingRegions.size());	HRegion region = servingRegions.get(0);	HRegionServer hrs = UTIL.getRSForFirstRegionInTable(tableName);	FileSystem fs = hrs.getFileSystem();	UTIL.loadRegion(region, TEST_FAM);	List<HRegion> regions = hrs.getRegions(tableName);	assertEquals("More that 1 region for test table.", 1, regions.size());	region = regions.get(0);	region.waitForFlushesAndCompactions();	UTIL.getAdmin().disableTable(tableName);	
disabled table 

========================= hbase sample_1999 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1833 =========================

public HBaseTestingUtility(Configuration conf) {	super(conf);	ChecksumUtil.generateExceptionForChecksumFailureForTest(true);	if (conf != null) {	if (conf.getInt(HConstants.MASTER_INFO_PORT, HConstants.DEFAULT_MASTER_INFOPORT) == HConstants.DEFAULT_MASTER_INFOPORT) {	conf.setInt(HConstants.MASTER_INFO_PORT, -1);	
config property changed to 

public HBaseTestingUtility(Configuration conf) {	super(conf);	ChecksumUtil.generateExceptionForChecksumFailureForTest(true);	if (conf != null) {	if (conf.getInt(HConstants.MASTER_INFO_PORT, HConstants.DEFAULT_MASTER_INFOPORT) == HConstants.DEFAULT_MASTER_INFOPORT) {	conf.setInt(HConstants.MASTER_INFO_PORT, -1);	}	if (conf.getInt(HConstants.REGIONSERVER_PORT, HConstants.DEFAULT_REGIONSERVER_PORT) == HConstants.DEFAULT_REGIONSERVER_PORT) {	conf.setInt(HConstants.REGIONSERVER_PORT, -1);	
config property changed to 

public static HBaseTestingUtility createLocalHTU(Configuration c) {	HBaseTestingUtility htu = new HBaseTestingUtility(c);	String dataTestDir = htu.getDataTestDir().toString();	
fs defaultfs file htu getconfiguration set hconstants hbase dir setting to 

private void createSubDirAndSystemProperty( String propertyName, Path parent, String subDirName){	String sysValue = System.getProperty(propertyName);	if (sysValue != null) {	
system getproperty propertyname already set to so i do not create it in 

private void setupDataTestDirOnTestFS() throws IOException {	if (dataTestDirOnTestFS != null) {	
data test on test fs dir already setup in 

private void setFs() throws IOException {	if(this.dfsCluster == null){	
skipping setting fs because dfscluster is null 

private void enableShortCircuit() {	if (isReadShortCircuitOn()) {	String curUser = System.getProperty("user.name");	
read short circuit is on for user 

private void enableShortCircuit() {	if (isReadShortCircuitOn()) {	String curUser = System.getProperty("user.name");	conf.set("dfs.block.local-path-access.user", curUser);	conf.setBoolean("dfs.client.read.shortcircuit", true);	conf.setBoolean("dfs.client.read.shortcircuit.skip.checksum", true);	} else {	
read short circuit is off 

private String createDirAndSetProperty(final String relPath, String property) {	String path = getDataTestDir(relPath).toString();	System.setProperty(property, path);	conf.set(property, path);	new File(path).mkdirs();	
setting to in system properties and hbase conf 

public MiniHBaseCluster startMiniCluster(final int numMasters, final int numSlaves, int numDataNodes, final String[] dataNodeHosts, Class<? extends HMaster> masterClass, Class<? extends MiniHBaseCluster.MiniHBaseClusterRegionServer> regionserverClass, boolean create, boolean withWALDir) throws Exception {	if (dataNodeHosts != null && dataNodeHosts.length != 0) {	numDataNodes = dataNodeHosts.length;	}	
starting up minicluster with master s and regionserver s and datanode s 

if (dataNodeHosts != null && dataNodeHosts.length != 0) {	numDataNodes = dataNodeHosts.length;	}	if (miniClusterRunning) {	throw new IllegalStateException("A mini-cluster is already running");	}	miniClusterRunning = true;	setupClusterTestDir();	System.setProperty(TEST_DIRECTORY_KEY, this.clusterTestDir.getPath());	if(this.dfsCluster == null && !localMode) {	
starting dfs 

numDataNodes = dataNodeHosts.length;	}	if (miniClusterRunning) {	throw new IllegalStateException("A mini-cluster is already running");	}	miniClusterRunning = true;	setupClusterTestDir();	System.setProperty(TEST_DIRECTORY_KEY, this.clusterTestDir.getPath());	if(this.dfsCluster == null && !localMode) {	dfsCluster = startMiniDFSCluster(numDataNodes, dataNodeHosts);	
not starting dfs 

if(connection != null){	connection.close();	connection = null;	}	this.hbaseCluster = new MiniHBaseCluster(this.conf, servers);	Connection conn = ConnectionFactory.createConnection(this.conf);	Table t = conn.getTable(TableName.META_TABLE_NAME);	ResultScanner s = t.getScanner(new Scan());	while (s.next() != null) {	}	
hbase has been restarted 

public void shutdownMiniCluster() throws Exception {	
shutting down minicluster 

public void shutdownMiniCluster() throws Exception {	if (this.connection != null && !this.connection.isClosed()) {	this.connection.close();	this.connection = null;	}	shutdownMiniHBaseCluster();	shutdownMiniDFSCluster();	shutdownMiniZKCluster();	cleanupTestDir();	miniClusterRunning = false;	
minicluster is down 

private void setHBaseFsTmpDir() throws IOException {	String hbaseFsTmpDirInString = this.conf.get("hbase.fs.tmp.dir");	if (hbaseFsTmpDirInString == null) {	this.conf.set("hbase.fs.tmp.dir",  getDataTestDirOnTestFS("hbase-staging").toString());	
setting hbase fs tmp dir to hbase fs tmp dir 

private void setHBaseFsTmpDir() throws IOException {	String hbaseFsTmpDirInString = this.conf.get("hbase.fs.tmp.dir");	if (hbaseFsTmpDirInString == null) {	this.conf.set("hbase.fs.tmp.dir",  getDataTestDirOnTestFS("hbase-staging").toString());	} else {	
the hbase fs tmp dir is set to 

public static void modifyTableSync(Admin admin, TableDescriptor desc) throws IOException, InterruptedException {	admin.modifyTable(desc);	Pair<Integer, Integer> status = new Pair<Integer, Integer>() {{	setFirst(0);	setSecond(0);	}};	int i = 0;	do {	status = admin.getAlterStatus(desc.getTableName());	if (status.getSecond() != 0) {	
regions updated 

Pair<Integer, Integer> status = new Pair<Integer, Integer>() {{	setFirst(0);	setSecond(0);	}};	int i = 0;	do {	status = admin.getAlterStatus(desc.getTableName());	if (status.getSecond() != 0) {	Thread.sleep(1 * 1000l);	} else {	
all regions updated 

public void deleteTable(TableName tableName) throws IOException {	try {	getAdmin().disableTable(tableName);	} catch (TableNotEnabledException e) {	
table already disabled so just deleting it 

public List<byte[]> getMetaTableRows() throws IOException {	Table t = getConnection().getTable(TableName.META_TABLE_NAME);	List<byte[]> rows = new ArrayList<>();	ResultScanner s = t.getScanner(new Scan());	for (Result result : s) {	
getmetatablerows row 

public List<byte[]> getMetaTableRows(TableName tableName) throws IOException {	Table t = getConnection().getTable(TableName.META_TABLE_NAME);	List<byte[]> rows = new ArrayList<>();	ResultScanner s = t.getScanner(new Scan());	for (Result result : s) {	RegionInfo info = MetaTableAccessor.getRegionInfo(result);	if (info == null) {	
no region info for row 

public List<byte[]> getMetaTableRows(TableName tableName) throws IOException {	Table t = getConnection().getTable(TableName.META_TABLE_NAME);	List<byte[]> rows = new ArrayList<>();	ResultScanner s = t.getScanner(new Scan());	for (Result result : s) {	RegionInfo info = MetaTableAccessor.getRegionInfo(result);	if (info == null) {	continue;	}	if (info.getTable().equals(tableName)) {	
getmetatablerows row 

public HRegionServer getRSForFirstRegionInTable(TableName tableName) throws IOException, InterruptedException {	List<byte[]> metaRows = getMetaTableRows(tableName);	if (metaRows == null || metaRows.isEmpty()) {	return null;	}	
found rows for table 

private void startMiniMapReduceCluster(final int servers) throws IOException {	if (mrCluster != null) {	throw new IllegalStateException("MiniMRCluster is already running");	}	
starting mini mapreduce cluster 

forceChangeTaskLogDir();	conf.setFloat("yarn.nodemanager.vmem-pmem-ratio", 8.0f);	conf.setBoolean("mapreduce.map.speculative", false);	conf.setBoolean("mapreduce.reduce.speculative", false);	mrCluster = new MiniMRCluster(servers, FS_URI != null ? FS_URI : FileSystem.get(conf).getUri().toString(), 1, null, null, new JobConf(this.conf));	JobConf jobConf = MapreduceTestingShim.getJobConf(mrCluster);	if (jobConf == null) {	jobConf = mrCluster.createJobConf();	}	jobConf.set("mapreduce.cluster.local.dir", conf.get("mapreduce.cluster.local.dir"));	
mini mapreduce cluster started 

public void shutdownMiniMapReduceCluster() {	if (mrCluster != null) {	
stopping mini mapreduce cluster 

public void shutdownMiniMapReduceCluster() {	if (mrCluster != null) {	mrCluster.shutdown();	mrCluster = null;	
mini mapreduce cluster stopped 

public void process(WatchedEvent watchedEvent) {	LOG.info("Monitor ZKW received event="+watchedEvent);	}	} , sessionID, password);	ZooKeeper newZK = new ZooKeeper(quorumServers, 1000, EmptyWatcher.instance, sessionID, password);	long start = System.currentTimeMillis();	while (newZK.getState() != States.CONNECTED && System.currentTimeMillis() - start < 1000) {	Thread.sleep(1);	}	newZK.close();	
zk closed session 

attempted.clear();	}	regCount = regions.size();	if (regCount > 0) {	idx = random.nextInt(regCount);	if (attempted.contains(idx)) continue;	try {	regions.get(idx).checkSplit();	return regions.get(idx);	} catch (Exception ex) {	
caught exception 

public boolean ensureSomeNonStoppedRegionServersAvailable(final int num) throws IOException {	boolean startedServer = ensureSomeRegionServersAvailable(num);	int nonStoppedServers = 0;	for (JVMClusterUtil.RegionServerThread rst : getMiniHBaseCluster().getRegionServerThreads()) {	HRegionServer hrs = rst.getRegionServer();	if (hrs.isStopping() || hrs.isStopped()) {	
a region server is stopped or stopping 

if (className.equals("DFSOutputStream")) {	if (clazz.isInstance(stream)) {	Field maxRecoveryErrorCountField = stream.getClass().getDeclaredField("maxRecoveryErrorCount");	maxRecoveryErrorCountField.setAccessible(true);	maxRecoveryErrorCountField.setInt(stream, max);	break;	}	}	}	} catch (Exception e) {	
could not set max recovery field 

return false;	}	}	if (RegionStateStore.getRegionState(r, info.getReplicaId()) != RegionState.State.OPEN) {	return false;	}	}	}	}	if (!tableFound) {	
didn t find the entries for table in meta already deleted 

}	}	}	if (!tableFound) {	}	return tableFound;	}	});	}	}	
all regions for table assigned to meta checking am states 

waitFor(timeout, 200, new ExplainingPredicate<IOException>() {	public String explainFailure() throws IOException {	return explainTableAvailability(tableName);	}	public boolean evaluate() throws IOException {	List<RegionInfo> hris = states.getRegionsOfTable(tableName);	return hris != null && !hris.isEmpty();	}	});	}	
all regions for table assigned 

del.addColumns(cf, qual, ts);	}	}	if (!put.isEmpty()) {	mutator.mutate(put);	}	if (!del.isEmpty()) {	mutator.mutate(del);	}	}	
initiating flush for table 

public static void waitForHostPort(String host, int port) throws IOException {	final int maxTimeMs = 10000;	final int maxNumAttempts = maxTimeMs / HConstants.SOCKET_RETRY_WAIT_MS;	IOException savedException = null;	
waiting for server at 

public static void waitForHostPort(String host, int port) throws IOException {	final int maxTimeMs = 10000;	final int maxNumAttempts = maxTimeMs / HConstants.SOCKET_RETRY_WAIT_MS;	IOException savedException = null;	for (int attempt = 0; attempt < maxNumAttempts; ++attempt) {	try {	Socket sock = new Socket(InetAddress.getByName(host), port);	sock.close();	savedException = null;	
server at is available 

td = builder.build();	int totalNumberOfRegions = 0;	Connection unmanagedConnection = ConnectionFactory.createConnection(conf);	Admin admin = unmanagedConnection.getAdmin();	try {	int numberOfServers = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics() .size();	if (numberOfServers == 0) {	throw new IllegalStateException("No live regionservers");	}	totalNumberOfRegions = numberOfServers * numRegionsPerServer;	
number of live regionservers pre splitting table into regions regions per server 

Admin admin = unmanagedConnection.getAdmin();	try {	int numberOfServers = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics() .size();	if (numberOfServers == 0) {	throw new IllegalStateException("No live regionservers");	}	totalNumberOfRegions = numberOfServers * numRegionsPerServer;	byte[][] splits = splitter.split( totalNumberOfRegions);	admin.createTable(td, splits);	} catch (MasterNotRunningException e) {	
master not running 

int numberOfServers = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics() .size();	if (numberOfServers == 0) {	throw new IllegalStateException("No live regionservers");	}	totalNumberOfRegions = numberOfServers * numRegionsPerServer;	byte[][] splits = splitter.split( totalNumberOfRegions);	admin.createTable(td, splits);	} catch (MasterNotRunningException e) {	throw new IOException(e);	} catch (TableExistsException e) {	
table already exists continuing 

do {	try {	bindException = false;	dir = new File(getDataTestDir("kdc").toUri().getPath());	kdc = new MiniKdc(conf, dir);	kdc.start();	} catch (BindException e) {	FileUtils.deleteDirectory(dir);	numTries++;	if (numTries == 3) {	
failed setting up minikdc tried times 

bindException = false;	dir = new File(getDataTestDir("kdc").toUri().getPath());	kdc = new MiniKdc(conf, dir);	kdc.start();	} catch (BindException e) {	FileUtils.deleteDirectory(dir);	numTries++;	if (numTries == 3) {	throw e;	}	
bindexception encountered when setting up minikdc trying again 

========================= hbase sample_1560 =========================

public HFileBlock readBlockData(long offset, long onDiskSizeWithHeaderL, boolean pread, boolean updateMetrics) throws IOException {	boolean doVerificationThruHBaseChecksum = streamWrapper.shouldUseHBaseChecksum();	FSDataInputStream is = streamWrapper.getStream(doVerificationThruHBaseChecksum);	HFileBlock blk = readBlockDataInternal(is, offset, onDiskSizeWithHeaderL, pread, doVerificationThruHBaseChecksum, updateMetrics);	if (blk == null) {	
hbase checksum verification failed for file at offset filesize retrying read with hdfs checksums turned on 

if (!doVerificationThruHBaseChecksum) {	String msg = "HBase checksum verification failed for file " + pathName + " at offset " + offset + " filesize " + fileSize + " but this cannot happen because doVerify is " + doVerificationThruHBaseChecksum;	HFile.LOG.warn(msg);	throw new IOException(msg);	}	HFile.CHECKSUM_FAILURES.increment();	is = this.streamWrapper.fallbackToFsChecksum(CHECKSUM_VERIFICATION_NUM_IO_THRESHOLD);	doVerificationThruHBaseChecksum = false;	blk = readBlockDataInternal(is, offset, onDiskSizeWithHeaderL, pread, doVerificationThruHBaseChecksum, updateMetrics);	if (blk != null) {	
hdfs checksum verification succeeded for file at offset filesize 

int onDiskSizeWithHeader = checkAndGetSizeAsInt(onDiskSizeWithHeaderL, hdrSize);	ByteBuffer headerBuf = getCachedHeader(offset);	if (LOG.isTraceEnabled()) {	LOG.trace("Reading " + this.fileContext.getHFileName() + " at offset=" + offset + ", pread=" + pread + ", verifyChecksum=" + verifyChecksum + ", cachedHeader=" + headerBuf + ", onDiskSizeWithHeader=" + onDiskSizeWithHeader);	}	boolean checksumSupport = this.fileContext.isUseHBaseChecksum();	long startTime = System.currentTimeMillis();	if (onDiskSizeWithHeader <= 0) {	if (headerBuf == null) {	if (LOG.isTraceEnabled()) {	
extra see to get block size 

}	long duration = System.currentTimeMillis() - startTime;	if (updateMetrics) {	HFile.updateReadLatency(duration, pread);	}	HFileBlock hFileBlock = new HFileBlock(new SingleByteBuff(onDiskBlockByteBuffer), checksumSupport, MemoryType.EXCLUSIVE, offset, nextBlockOnDiskSize, fileContext);	if (!fileContext.isCompressedOrEncrypted()) {	hFileBlock.sanityCheckUncompressed();	}	if (LOG.isTraceEnabled()) {	
read in ns 

========================= hbase sample_2435 =========================

public Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	if (this.getConf() == null) {	return files;	}	final Set<String> hfileRefs;	try {	hfileRefs = rqs.getAllHFileRefs();	} catch (ReplicationException e) {	
failed to read hfile references from zookeeper skipping checking deletable files 

hfileRefs = rqs.getAllHFileRefs();	} catch (ReplicationException e) {	return Collections.emptyList();	}	return Iterables.filter(files, new Predicate<FileStatus>() {	public boolean apply(FileStatus file) {	String hfile = file.getPath().getName();	boolean foundHFileRefInQueue = hfileRefs.contains(hfile);	if (LOG.isDebugEnabled()) {	if (foundHFileRefInQueue) {	
found hfile reference in zk keeping 

} catch (ReplicationException e) {	return Collections.emptyList();	}	return Iterables.filter(files, new Predicate<FileStatus>() {	public boolean apply(FileStatus file) {	String hfile = file.getPath().getName();	boolean foundHFileRefInQueue = hfileRefs.contains(hfile);	if (LOG.isDebugEnabled()) {	if (foundHFileRefInQueue) {	} else {	
did not find hfile reference in zk deleting 

public void setConf(Configuration config) {	if (!(config.getBoolean( HConstants.REPLICATION_BULKLOAD_ENABLE_KEY, HConstants.REPLICATION_BULKLOAD_ENABLE_DEFAULT))) {	
is not enabled better to remove from configuration 

public void setConf(Configuration config) {	if (!(config.getBoolean( HConstants.REPLICATION_BULKLOAD_ENABLE_KEY, HConstants.REPLICATION_BULKLOAD_ENABLE_DEFAULT))) {	return;	}	Configuration conf = new Configuration(config);	try {	setConf(conf, new ZKWatcher(conf, "replicationHFileCleaner", null));	} catch (IOException e) {	
error while configuring 

public void setConf(Configuration conf, ZKWatcher zk) {	super.setConf(conf);	try {	initReplicationQueueStorage(conf, zk);	} catch (Exception e) {	
error while configuring 

public void stop(String why) {	if (this.stopped) {	return;	}	this.stopped = true;	if (this.zkw != null) {	
stopping 

public boolean isFileDeletable(FileStatus fStat) {	Set<String> hfileRefsFromQueue;	if (getConf() == null) {	return true;	}	try {	hfileRefsFromQueue = rqs.getAllHFileRefs();	} catch (ReplicationException e) {	
failed to read hfile references from zookeeper skipping checking deletable file for 

========================= hbase sample_2966 =========================

addWALEdits(tableName, hri, rowName, hcd.getName(), countPerFamily, ee, wal2, htd, mvcc, scopes);	}	wal2.shutdown();	runWALSplit(this.conf);	WAL wal3 = createWAL(this.conf, hbaseRootDir, logName);	try {	HRegion region = HRegion.openHRegion(this.conf, this.fs, hbaseRootDir, hri, htd, wal3);	long seqid = region.getOpenSeqNum();	assertTrue(seqid > mvcc.getWritePoint());	assertEquals(seqid - 1, mvcc.getWritePoint());	
region getopenseqnum id 

put.addColumn(families.get(i % families.size()).getName(), Bytes.toBytes("q"), Bytes.toBytes("val"));	region.put(put);	}	RegionScanner scanner = region.getScanner(new Scan());	assertEquals(writtenRowCount, getScannedCount(scanner));	CustomStoreFlusher.throwExceptionWhenFlushing.set(true);	try {	region.flush(true);	fail("Injected exception hasn't been thrown");	} catch (Throwable t) {	
expected simulated exception when flushing region 

for (int i = writtenRowCount; i < writtenRowCount + moreRow; i++) {	Put put = new Put(Bytes.toBytes(tableName + Integer.toString(i)));	put.addColumn(families.get(i % families.size()).getName(), Bytes.toBytes("q"), Bytes.toBytes("val"));	region.put(put);	}	writtenRowCount += moreRow;	CustomStoreFlusher.throwExceptionWhenFlushing.set(false);	try {	region.flush(true);	} catch (IOException t) {	
expected exception when flushing region because server is stopped 

user.runAs(new PrivilegedExceptionAction<Void>() {	public Void run() throws Exception {	runWALSplit(newConf);	FileSystem newFS = FileSystem.get(newConf);	newConf.setInt(HConstants.HREGION_MEMSTORE_FLUSH_SIZE, 1024 * 100);	WAL newWal = createWAL(newConf, hbaseRootDir, logName);	final AtomicInteger flushcount = new AtomicInteger(0);	try {	final HRegion region = new HRegion(basedir, newWal, newFS, newConf, hri, htd, null) {	protected FlushResultImpl internalFlushcache(final WAL wal, final long myseqid, final Collection<HStore> storesToFlush, MonitoredTask status, boolean writeFlushWalMarker, FlushLifeCycleTracker tracker) throws IOException {	
internalflushcache invoked 

========================= hbase sample_1649 =========================

public void before() throws IOException {	
before 

public void before() throws IOException {	UTIL.ensureSomeRegionServersAvailable(1);	
before done 

static void openCloseTableOutputFormat(int iter)  throws IOException {	
instantiating tableoutputformat connection 

public void testConnectionExhaustion() throws IOException {	int MAX_INSTANCES = 5;	for (int i = 0; i < MAX_INSTANCES; i++) {	final int iter = i;	try {	openCloseTableOutputFormat(iter);	} catch (Exception e) {	
exception encountered 

========================= hbase sample_3361 =========================

public synchronized void addTable(String table) {	if (this.shouldArchiveTable(table)) {	
already archiving table ignoring it 

========================= hbase sample_2989 =========================

public void testConcurrentPeerOperations() throws Exception {	int threadNum = 5;	AtomicLong successCount = new AtomicLong(0);	Thread[] addPeers = new Thread[threadNum];	for (int i = 0; i < threadNum; i++) {	addPeers[i] = new Thread(() -> {	try {	hbaseAdmin.addReplicationPeer(ID_ONE, ReplicationPeerConfig.newBuilder().setClusterKey(KEY_ONE).build());	successCount.incrementAndGet();	} catch (Exception e) {	
got exception when add replication peer 

}	assertEquals(1, successCount.get());	successCount.set(0);	Thread[] removePeers = new Thread[threadNum];	for (int i = 0; i < threadNum; i++) {	removePeers[i] = new Thread(() -> {	try {	hbaseAdmin.removeReplicationPeer(ID_ONE);	successCount.incrementAndGet();	} catch (Exception e) {	
got exception when remove replication peer 

}	assertEquals(1, successCount.get());	successCount.set(0);	addPeers = new Thread[threadNum];	for (int i = 0; i < threadNum; i++) {	addPeers[i] = new Thread(() -> {	try {	hbaseAdmin.addReplicationPeer(ID_ONE, ReplicationPeerConfig.newBuilder().setClusterKey(KEY_ONE).build());	successCount.incrementAndGet();	} catch (Exception e) {	
got exception when add replication peer 

========================= hbase sample_2120 =========================

public static Key unwrapKey(Configuration conf, byte[] keyBytes) throws IOException {	Key key;	String masterKeyName = conf.get(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, User.getCurrent().getShortName());	try {	key = unwrapKey(conf, masterKeyName, keyBytes);	} catch (KeyException e) {	if (LOG.isDebugEnabled()) {	
unable to unwrap key with current master key 

========================= hbase sample_145 =========================

static void writeTestDataBatch(TableName tableName, int batchId) throws Exception {	
writing test data batch 

static void verifyTestDataBatch(TableName tableName, int batchId) throws Exception {	
verifying test data batch 

private void compactAndWait() throws IOException, InterruptedException {	
compacting table 

admin.majorCompact(tableName);	final long maxWaitime = System.currentTimeMillis() + 500;	boolean cont;	do {	cont = rs.compactSplitThread.getCompactionQueueSize() == 0;	Threads.sleep(1);	} while (cont && System.currentTimeMillis() < maxWaitime);	while (rs.compactSplitThread.getCompactionQueueSize() > 0) {	Threads.sleep(1);	}	
compaction queue size reached continuing 

========================= hbase sample_1472 =========================

public void postCreateTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableDescriptor desc, RegionInfo[] regions) throws IOException {	if (this.createTableStartTime > 0) {	long time = System.currentTimeMillis() - this.createTableStartTime;	
create table took 

========================= hbase sample_1167 =========================

if (LoadBalancer.isTablesOnMaster(loadBalancer.getConf())) {	assertTrue(plans.get(master).contains(RegionInfoBuilder.FIRST_META_REGIONINFO));	assertEquals(1, plans.get(master).size());	}	int totalRegion = 0;	for (List<RegionInfo> regions: plans.values()) {	totalRegion += regions.size();	}	assertEquals(hris.size(), totalRegion);	for (int[] mock : regionsAndServersMocks) {	
testbulkassignment with regions and servers 

public void testRandomAssignment() throws Exception {	for (int i = 1; i != 5; ++i) {	
run testrandomassignment with idle servers 

========================= hbase sample_1864 =========================

protected void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e) {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	try {	if (sleepTime.get() > 0) {	
sleeping for ms 

public void runLoad() throws Exception {	setupTable();	int numImportRounds = getConf().getInt(NUM_IMPORT_ROUNDS_KEY, NUM_IMPORT_ROUNDS);	
running load with numiterations 

protected void map(LongWritable key, LongWritable value, Context context) throws IOException, InterruptedException {	long chainId = value.get();	
starting mapper with chainid 

private void runCheckWithRetry() throws IOException, ClassNotFoundException, InterruptedException {	try {	runCheck();	} catch (Throwable t) {	
received 

private void runCheckWithRetry() throws IOException, ClassNotFoundException, InterruptedException {	try {	runCheck();	} catch (Throwable t) {	
running the check mr job again to see whether an ephemeral problem or not 

private void runCheck() throws IOException, ClassNotFoundException, InterruptedException {	
running check 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	util.initializeCluster(1);	int replicaCount = getConf().getInt(NUM_REPLICA_COUNT_KEY, NUM_REPLICA_COUNT_DEFAULT);	if (LOG.isDebugEnabled() && replicaCount != NUM_REPLICA_COUNT_DEFAULT) {	
region replicas enabled 

========================= hbase sample_3273 =========================

TEST_UTIL.waitTableDisabled(tableName.getName());	admin.enableTable(tableName);	TEST_UTIL.waitTableEnabled(tableName);	admin.disableTable(tableName);	TEST_UTIL.waitUntilNoRegionsInTransition(60000);	JVMClusterUtil.RegionServerThread rs = cluster.getRegionServerThreads().get(0);	rs.getRegionServer().stop("stop");	cluster.waitForRegionServerToStop(rs.getRegionServer().getServerName(), 10000);	JVMClusterUtil.RegionServerThread rs2 = cluster.startRegionServer();	cluster.waitForRegionServerToStart(rs2.getRegionServer().getServerName().getHostname(), rs2.getRegionServer().getServerName().getPort(), 60000);	
now enabling table 

cluster.waitForRegionServerToStop(rs.getRegionServer().getServerName(), 10000);	JVMClusterUtil.RegionServerThread rs2 = cluster.startRegionServer();	cluster.waitForRegionServerToStart(rs2.getRegionServer().getServerName().getHostname(), rs2.getRegionServer().getServerName().getPort(), 60000);	admin.enableTable(tableName);	assertTrue(admin.isTableEnabled(tableName));	List<HRegionInfo> regions = TEST_UTIL.getAdmin().getTableRegions(tableName);	assertEquals(1, regions.size());	for (HRegionInfo region : regions) {	TEST_UTIL.getAdmin().assign(region.getEncodedNameAsBytes());	}	
waiting for table assigned 

createTable(TEST_UTIL, desc, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);	} catch (Exception e) {	e.printStackTrace();	fail("Got an exception while creating " + tableName);	}	try (Table metaTable = TEST_UTIL.getConnection().getTable(TableName.META_TABLE_NAME)) {	try (ResultScanner scanner = metaTable.getScanner( MetaTableAccessor.getScanForTableName(TEST_UTIL.getConnection(), tableName))) {	for (Result result : scanner) {	Delete d = new Delete(result.getRow());	d.addColumn(HConstants.CATALOG_FAMILY, HConstants.REGIONINFO_QUALIFIER);	
mangled 

TEST_UTIL.waitTableDisabled(tableName.getName());	try {	deleteTable(TEST_UTIL, tableName);	} catch (Exception e) {	e.printStackTrace();	fail("Got an exception while deleting " + tableName);	}	int rowCount = 0;	try (ResultScanner scanner = metaTable.getScanner(MetaTableAccessor.getScanForTableName(TEST_UTIL.getConnection(), tableName))) {	for (Result result : scanner) {	
found when none expected 

public static void deleteTable(HBaseTestingUtility testUtil, TableName tableName) throws Exception {	MasterSyncObserver observer = testUtil.getHBaseCluster().getMaster() .getMasterCoprocessorHost().findCoprocessor(MasterSyncObserver.class);	observer.tableDeletionLatch = new CountDownLatch(1);	Admin admin = testUtil.getAdmin();	try {	admin.disableTable(tableName);	} catch (Exception e) {	
table already disabled so just deleting it 

========================= hbase sample_2032 =========================

this.choreService = new ChoreService("ConnectionCache");	ScheduledChore cleaner = new ScheduledChore("ConnectionCleaner", stoppable, cleanInterval) {	protected void chore() {	for (Map.Entry<String, ConnectionInfo> entry: connections.entrySet()) {	ConnectionInfo connInfo = entry.getValue();	if (connInfo.timedOut(maxIdleTime)) {	if (connInfo.admin != null) {	try {	connInfo.admin.close();	} catch (Throwable t) {	
got exception in closing idle admin 

if (connInfo.timedOut(maxIdleTime)) {	if (connInfo.admin != null) {	try {	connInfo.admin.close();	} catch (Throwable t) {	}	}	try {	connInfo.connection.close();	} catch (Throwable t) {	
got exception in closing idle connection 

========================= hbase sample_2198 =========================

Delete delete = new Delete(encodedBytes);	for (int i = 0; i < index - 1; i++) {	delete.addColumn(HConstants.REPLICATION_BARRIER_FAMILY, Bytes.toBytes(barriers.get(i)));	}	try (Table metaTable = master.getConnection().getTable(TableName.META_TABLE_NAME)) {	metaTable.delete(delete);	}	}	}	} catch (IOException e) {	
exception during cleaning up 

========================= hbase sample_2874 =========================

public void testBalanceCluster() throws Exception {	Map<ServerName, List<RegionInfo>> servers = mockClusterServers();	ArrayListMultimap<String, ServerAndLoad> list = convertToGroupBasedMap(servers);	
mock cluster 

public void testBalanceCluster() throws Exception {	Map<ServerName, List<RegionInfo>> servers = mockClusterServers();	ArrayListMultimap<String, ServerAndLoad> list = convertToGroupBasedMap(servers);	List<RegionPlan> plans = loadBalancer.balanceCluster(servers);	ArrayListMultimap<String, ServerAndLoad> balancedCluster = reconcile( list, plans);	
mock balance 

========================= hbase sample_3336 =========================

job.setMapOutputKeyClass(ImmutableBytesWritable.class);	String hfileOutPath = conf.get(BULK_OUTPUT_CONF_KEY);	String[] columns = conf.getStrings(COLUMNS_CONF_KEY);	if(StringUtils.isNotEmpty(conf.get(CREDENTIALS_LOCATION))) {	String fileLoc = conf.get(CREDENTIALS_LOCATION);	Credentials cred = Credentials.readTokenStorageFile(new File(fileLoc), conf);	job.getCredentials().addAll(cred);	}	if (hfileOutPath != null) {	if (!admin.tableExists(tableName)) {	
table s does not exist 

if(StringUtils.isNotEmpty(conf.get(CREDENTIALS_LOCATION))) {	String fileLoc = conf.get(CREDENTIALS_LOCATION);	Credentials cred = Credentials.readTokenStorageFile(new File(fileLoc), conf);	job.getCredentials().addAll(cred);	}	if (hfileOutPath != null) {	if (!admin.tableExists(tableName)) {	if ("yes".equalsIgnoreCase(conf.get(CREATE_TABLE_CONF_KEY, "yes"))) {	createTable(admin, tableName, columns);	if (isDryRun) {	
dry run table will be deleted at end of dry run 

private static void createTable(Admin admin, TableName tableName, String[] columns) throws IOException {	HTableDescriptor htd = new HTableDescriptor(tableName);	Set<String> cfSet = getColumnFamilies(columns);	for (String cf : cfSet) {	HColumnDescriptor hcd = new HColumnDescriptor(Bytes.toBytes(cf));	htd.addFamily(hcd);	}	
creating table s with s columns and default descriptors 

private static void deleteTable(Configuration conf, String[] args) {	TableName tableName = TableName.valueOf(args[0]);	try (Connection connection = ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin()) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException e) {	
dry mode table already disabled so just deleting it 

private static void deleteTable(Configuration conf, String[] args) {	TableName tableName = TableName.valueOf(args[0]);	try (Connection connection = ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin()) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException e) {	}	admin.deleteTable(tableName);	} catch (IOException e) {	
dry run failed to delete table s n s 

try (Connection connection = ConnectionFactory.createConnection(conf);	Admin admin = connection.getAdmin()) {	try {	admin.disableTable(tableName);	} catch (TableNotEnabledException e) {	}	admin.deleteTable(tableName);	} catch (IOException e) {	return;	}	
dry run deleted table s 

========================= hbase sample_3459 =========================

public List<Path> compact(List<FileStatus> files, boolean allFiles) throws IOException {	if (files == null || files.isEmpty()) {	
no candidate mob files 

public List<Path> compact(List<FileStatus> files, boolean allFiles) throws IOException {	if (files == null || files.isEmpty()) {	return null;	}	
is allfiles 

allDelPartitions.add(entry.getValue());	}	} else {	allDelPartitions.add(entry.getValue());	}	}	PartitionedMobCompactionRequest request = new PartitionedMobCompactionRequest( filesToCompact.values(), allDelPartitions);	if (candidates.size() == (totalDelFiles + selectedFileCount + irrelevantFileCount)) {	request.setCompactionType(CompactionType.ALL_FILES);	}	
the compaction type is the request has del files selected files and irrelevant files 

int totalDelFileCount = 0;	try {	for (CompactionDelPartition delPartition : request.getDelPartitions()) {	for (Path newDelPath : delPartition.listDelFiles()) {	HStoreFile sf = new HStoreFile(fs, newDelPath, conf, compactionCacheConfig, BloomType.NONE, true);	sf.initReader();	delPartition.addStoreFile(sf);	totalDelFileCount++;	}	}	
after merging there are del files 

try {	for (CompactionDelPartition delPartition : request.getDelPartitions()) {	for (Path newDelPath : delPartition.listDelFiles()) {	HStoreFile sf = new HStoreFile(fs, newDelPath, conf, compactionCacheConfig, BloomType.NONE, true);	sf.initReader();	delPartition.addStoreFile(sf);	totalDelFileCount++;	}	}	paths = compactMobFiles(request);	
after compaction there are mob files 

totalDelFileCount++;	}	}	paths = compactMobFiles(request);	} finally {	for (CompactionDelPartition delPartition : request.getDelPartitions()) {	closeStoreFileReaders(delPartition.getStoreFiles());	}	}	if (request.type == CompactionType.ALL_FILES && !request.getDelPartitions().isEmpty()) {	
after a mob compaction with all files selected archiving the del files 

for (CompactionDelPartition delPartition : request.getDelPartitions()) {	closeStoreFileReaders(delPartition.getStoreFiles());	}	}	if (request.type == CompactionType.ALL_FILES && !request.getDelPartitions().isEmpty()) {	for (CompactionDelPartition delPartition : request.getDelPartitions()) {	LOG.info(Objects.toString(delPartition.listDelFiles()));	try {	MobUtils.removeMobFiles(conf, fs, tableName, mobTableDir, column.getName(), delPartition.getStoreFiles());	} catch (IOException e) {	
failed to archive the del files 

protected List<Path> compactMobFiles(final PartitionedMobCompactionRequest request) throws IOException {	Collection<CompactionPartition> partitions = request.compactionPartitions;	if (partitions == null || partitions.isEmpty()) {	
no partitions of mob files 

}	List<Path> paths = new ArrayList<>();	final Connection c = ConnectionFactory.createConnection(conf);	final Table table = c.getTable(tableName);	try {	Map<CompactionPartitionId, Future<List<Path>>> results = new HashMap<>();	for (final CompactionPartition partition : partitions) {	List<HStoreFile> delFiles = getListOfDelFilesForPartition(partition, request.getDelPartitions());	results.put(partition.getPartitionId(), pool.submit(new Callable<List<Path>>() {	public List<Path> call() throws Exception {	
compacting mob files for partition 

public List<Path> call() throws Exception {	return compactMobFilePartition(request, partition, delFiles, c, table);	}	}));	}	List<CompactionPartitionId> failedPartitions = new ArrayList<>();	for (Entry<CompactionPartitionId, Future<List<Path>>> result : results.entrySet()) {	try {	paths.addAll(result.getValue().get());	} catch (Exception e) {	
failed to compact the partition 

failedPartitions.add(result.getKey());	}	}	if (!failedPartitions.isEmpty()) {	throw new IOException("Failed to compact the partitions " + failedPartitions);	}	} finally {	try {	table.close();	} catch (IOException e) {	
failed to close the table 

fs.delete(bulkloadPathOfPartition, true);	List<HStoreFile> filesToCompact = new ArrayList<>();	for (int i = offset; i < batch + offset; i++) {	HStoreFile sf = new HStoreFile(fs, files.get(i).getPath(), conf, compactionCacheConfig, BloomType.NONE, true);	filesToCompact.add(sf);	}	filesToCompact.addAll(delFiles);	compactMobFilesInBatch(request, partition, connection, table, filesToCompact, batch, bulkloadPathOfPartition, bulkloadColumnPath, newFiles);	offset += batch;	}	
compaction is finished the number of mob files is changed from to 

private void closeStoreFileReaders(List<HStoreFile> storeFiles) {	for (HStoreFile storeFile : storeFiles) {	try {	storeFile.closeStoreFile(true);	} catch (IOException e) {	
failed to close the reader on store file 

cleanupCommittedMobFile = true;	bulkloadRefFile(connection, table, bulkloadPathOfPartition, filePath.getName());	cleanupCommittedMobFile = false;	newFiles.add(new Path(mobFamilyDir, filePath.getName()));	}	try {	closeStoreFileReaders(mobFilesToCompact);	closeReaders = false;	MobUtils.removeMobFiles(conf, fs, tableName, mobTableDir, column.getName(), mobFilesToCompact);	} catch (IOException e) {	
failed to archive the files 

writer.append(cell);	}	cells.clear();	} while (hasMore);	} finally {	scanner.close();	if (writer != null) {	try {	writer.close();	} catch (IOException e) {	
failed to close the writer of the file 

try {	writer.close();	} catch (IOException e) {	}	}	}	Path path = MobUtils.commitFile(conf, fs, filePath, mobFamilyDir, compactionCacheConfig);	try {	MobUtils.removeMobFiles(conf, fs, tableName, mobTableDir, column.getName(), delFiles);	} catch (IOException e) {	
failed to archive the old del files 

private void closeMobFileWriter(StoreFileWriter writer, long maxSeqId, long mobCellsCount) throws IOException {	if (writer != null) {	writer.appendMetadata(maxSeqId, false, mobCellsCount);	try {	writer.close();	} catch (IOException e) {	
failed to close the writer of the file 

private void closeRefFileWriter(StoreFileWriter writer, long maxSeqId, long bulkloadTime) throws IOException {	if (writer != null) {	writer.appendMetadata(maxSeqId, false);	writer.appendFileInfo(BULKLOAD_TIME_KEY, Bytes.toBytes(bulkloadTime));	writer.appendFileInfo(SKIP_RESET_SEQ_ID, Bytes.toBytes(true));	try {	writer.close();	} catch (IOException e) {	
failed to close the writer of the ref file 

private void deletePath(Path path) {	try {	if (path != null) {	fs.delete(path, true);	}	} catch (IOException e) {	
failed to delete the file 

if (location != null) {	try {	file = fs.getFileStatus(location);	if (file != null) {	return file;	}	}  catch (FileNotFoundException e) {	}	}	}	
the file links to can not be found 

========================= hbase sample_3009 =========================

public void testMultiSlaveReplication() throws Exception {	
testCyclicReplication 

final WALActionsListener listener = new WALActionsListener() {	public void postLogRoll(final Path oldPath, final Path newPath) throws IOException {	latch.countDown();	}	};	region.getWAL().registerWALActionsListener(listener);	admin.rollWALWriter(cluster.getServerHoldingRegion(region.getTableDescriptor().getTableName(), region.getRegionInfo().getRegionName()));	try {	latch.await();	} catch (InterruptedException exception) {	
interrupted while waiting for the wal of to roll if later replication tests fail it s probably because we should still be waiting 

private void checkWithWait(byte[] row, int count, Table table) throws Exception {	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time while getting the row.");	}	boolean rowReplicated = false;	Result res = table.get(get);	if (res.size() >= 1) {	
row is replicated 

source.delete(del);	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i==NB_RETRIES-1) {	fail("Waited too much time for del replication");	}	boolean removedFromAll = true;	for (Table target : targets) {	Result res = target.get(get);	if (res.size() >= 1) {	
row not deleted 

source.put(put);	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i==NB_RETRIES-1) {	fail("Waited too much time for put replication");	}	boolean replicatedToAll = true;	for (Table target : targets) {	Result res = target.get(get);	if (res.isEmpty()) {	
row not available 

========================= hbase sample_1937 =========================

public boolean matches(String stringQop) {	if (saslQop.equals(stringQop)) {	
use authentication integrity privacy as value for rpc protection configurations instead of auth auth int auth conf 

static void safeDispose(SaslClient saslClient) {	try {	saslClient.dispose();	} catch (SaslException e) {	
error disposing of sasl client 

static void safeDispose(SaslServer saslServer) {	try {	saslServer.dispose();	} catch (SaslException e) {	
error disposing of sasl server 

========================= hbase sample_153 =========================

try {	return HConnectionTestingUtility.getMockedConnectionAndDecorate( TESTUTIL.getConfiguration(), rs0, rs0, rs0.getServerName(), HRegionInfo.FIRST_META_REGIONINFO);	} catch (IOException e) {	return null;	}	}	};	master.start();	try {	while (!master.isInitialized()) Threads.sleep(10);	
master is initialized 

========================= hbase sample_1872 =========================

public HealthCheckChore(int sleepTime, Stoppable stopper, Configuration conf) {	super("HealthChecker", stopper, sleepTime);	
health check chore runs every 

protected void chore() {	HealthReport report = healthChecker.checkHealth();	boolean isHealthy = (report.getStatus() == HealthCheckerExitStatus.SUCCESS);	if (!isHealthy) {	boolean needToStop = decideToStop();	if (needToStop) {	this.getStopper().stop("The  node reported unhealthy " + threshold + " number of times consecutively.");	}	
health status at 

========================= hbase sample_2474 =========================

private void cleanupTables(AsyncAdmin admin, Pattern pattern) {	admin.listTableNames(pattern, false).whenCompleteAsync((tables, err) -> {	if (tables != null) {	tables.forEach(table -> {	try {	admin.disableTable(table).join();	} catch (Exception e) {	
table already disabled so just deleting it 

========================= hbase sample_2024 =========================

public void testSingleProxy() throws Throwable {	Table table = util.getConnection().getTable(TEST_TABLE);	Map<byte [], String> results = ping(table, null, null);	assertEquals(3, results.size());	for (Map.Entry<byte [], String> e: results.entrySet()) {	assertEquals("Invalid custom protocol response", "pong", e.getValue());	}	hello(table, "George", HELLO + "George");	
did george 

public void testSingleProxy() throws Throwable {	Table table = util.getConnection().getTable(TEST_TABLE);	Map<byte [], String> results = ping(table, null, null);	assertEquals(3, results.size());	for (Map.Entry<byte [], String> e: results.entrySet()) {	assertEquals("Invalid custom protocol response", "pong", e.getValue());	}	hello(table, "George", HELLO + "George");	hello(table, null, "Who are you?");	
who are you 

========================= hbase sample_1258 =========================

public void setUp() throws Exception {	
initializing cluster with d region servers 

public void setUp() throws Exception {	UTIL.initializeCluster(REGION_SERVER_COUNT);	
cluster initialized 

public void setUp() throws Exception {	UTIL.initializeCluster(REGION_SERVER_COUNT);	admin = UTIL.getAdmin();	if (admin.tableExists(TABLE_NAME)) {	
deleting existing table s 

public void setUp() throws Exception {	UTIL.initializeCluster(REGION_SERVER_COUNT);	admin = UTIL.getAdmin();	if (admin.tableExists(TABLE_NAME)) {	if (admin.isTableEnabled(TABLE_NAME)) admin.disableTable(TABLE_NAME);	admin.deleteTable(TABLE_NAME);	
existing table s deleted 

public void setUp() throws Exception {	UTIL.initializeCluster(REGION_SERVER_COUNT);	admin = UTIL.getAdmin();	if (admin.tableExists(TABLE_NAME)) {	if (admin.isTableEnabled(TABLE_NAME)) admin.disableTable(TABLE_NAME);	admin.deleteTable(TABLE_NAME);	}	
cluster ready 

public void tearDown() throws IOException {	
cleaning up after test 

public void tearDown() throws IOException {	if (admin.tableExists(TABLE_NAME)) {	if (admin.isTableEnabled(TABLE_NAME)) admin.disableTable(TABLE_NAME);	admin.deleteTable(TABLE_NAME);	}	
restoring cluster 

public void tearDown() throws IOException {	if (admin.tableExists(TABLE_NAME)) {	if (admin.isTableEnabled(TABLE_NAME)) admin.disableTable(TABLE_NAME);	admin.deleteTable(TABLE_NAME);	}	UTIL.restoreCluster();	
cluster restored 

public void testCreateTableWithRegions() throws Exception {	HTableDescriptor desc = new HTableDescriptor(TABLE_NAME);	desc.addFamily(new HColumnDescriptor("cf"));	SplitAlgorithm algo = new RegionSplitter.HexStringSplit();	byte[][] splits = algo.split(REGION_COUNT);	
creating table s with d splits 

public void testCreateTableWithRegions() throws Exception {	HTableDescriptor desc = new HTableDescriptor(TABLE_NAME);	desc.addFamily(new HColumnDescriptor("cf"));	SplitAlgorithm algo = new RegionSplitter.HexStringSplit();	byte[][] splits = algo.split(REGION_COUNT);	long startTime = System.currentTimeMillis();	try {	admin.createTable(desc, splits);	
pre split table created successfully in dms 

public void testCreateTableWithRegions() throws Exception {	HTableDescriptor desc = new HTableDescriptor(TABLE_NAME);	desc.addFamily(new HColumnDescriptor("cf"));	SplitAlgorithm algo = new RegionSplitter.HexStringSplit();	byte[][] splits = algo.split(REGION_COUNT);	long startTime = System.currentTimeMillis();	try {	admin.createTable(desc, splits);	} catch (IOException e) {	
failed to create table 

========================= hbase sample_3265 =========================

private long testFlushWithThroughputLimit() throws Exception {	final long throughputLimit = 1024 * 1024;	setMaxMinThroughputs(throughputLimit, throughputLimit);	Configuration conf = hbtu.getConfiguration();	conf.setLong( PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_THROUGHPUT_CONTROL_CHECK_INTERVAL, throughputLimit);	hbtu.startMiniCluster(1);	Table table = hbtu.createTable(tableName, family);	Pair<Double, Long> result = generateAndFlushData(table);	hbtu.deleteTable(tableName);	
throughput is mb s 

========================= hbase sample_1608 =========================

protected void initReconfigurable(Configuration confToLoad) {	this.allowFallbackToSimpleAuth = confToLoad.getBoolean(FALLBACK_TO_INSECURE_CLIENT_AUTH, false);	if (isSecurityEnabled && allowFallbackToSimpleAuth) {	
warning 

protected void initReconfigurable(Configuration confToLoad) {	this.allowFallbackToSimpleAuth = confToLoad.getBoolean(FALLBACK_TO_INSECURE_CLIENT_AUTH, false);	if (isSecurityEnabled && allowFallbackToSimpleAuth) {	
this server is configured to allow connections from insecure clients 

protected void initReconfigurable(Configuration confToLoad) {	this.allowFallbackToSimpleAuth = confToLoad.getBoolean(FALLBACK_TO_INSECURE_CLIENT_AUTH, false);	if (isSecurityEnabled && allowFallbackToSimpleAuth) {	LOG.warn("(" + FALLBACK_TO_INSECURE_CLIENT_AUTH + " = true).");	
while this option is enabled client identities cannot be secured and user 

protected void initReconfigurable(Configuration confToLoad) {	this.allowFallbackToSimpleAuth = confToLoad.getBoolean(FALLBACK_TO_INSECURE_CLIENT_AUTH, false);	if (isSecurityEnabled && allowFallbackToSimpleAuth) {	LOG.warn("(" + FALLBACK_TO_INSECURE_CLIENT_AUTH + " = true).");	
impersonation is possible 

protected void initReconfigurable(Configuration confToLoad) {	this.allowFallbackToSimpleAuth = confToLoad.getBoolean(FALLBACK_TO_INSECURE_CLIENT_AUTH, false);	if (isSecurityEnabled && allowFallbackToSimpleAuth) {	LOG.warn("(" + FALLBACK_TO_INSECURE_CLIENT_AUTH + " = true).");	
for secure operation please disable simple authentication as soon as possible 

HBaseRpcController controller = new HBaseRpcControllerImpl(call.getCellScanner());	controller.setCallTimeout(call.getTimeout());	Message result = call.getService().callBlockingMethod(md, controller, param);	long receiveTime = call.getReceiveTime();	long startTime = call.getStartTime();	long endTime = System.currentTimeMillis();	int processingTime = (int) (endTime - startTime);	int qTime = (int) (startTime - receiveTime);	int totalTime = (int) (endTime - receiveTime);	if (LOG.isTraceEnabled()) {	
response queuetime processingtime totaltime 

metrics.sentResponse(responseSize);	boolean tooSlow = (processingTime > warnResponseTime && warnResponseTime > -1);	boolean tooLarge = (responseSize > warnResponseSize && warnResponseSize > -1);	if (tooSlow || tooLarge) {	logResponse(param, md.getName(), md.getName() + "(" + param.getClass().getName() + ")", (tooLarge ? "TooLarge" : "TooSlow"), status.getClient(), startTime, processingTime, qTime, responseSize);	}	return new Pair<>(result, controller.cellScanner());	} catch (Throwable e) {	if (e instanceof ServiceException) {	if (e.getCause() == null) {	
caught a serviceexception with null cause 

} catch (Throwable e) {	if (e instanceof ServiceException) {	if (e.getCause() == null) {	} else {	e = e.getCause();	}	}	metrics.exception(e);	if (e instanceof LinkageError) throw new DoNotRetryIOException(e);	if (e instanceof IOException) throw (IOException)e;	
unexpected throwable object 

========================= hbase sample_2927 =========================

public void perform() throws Exception {	if (context.isStopping()) {	return;	}	
balancing regions 

========================= hbase sample_3320 =========================

public void testBackupDescribe() throws Exception {	
test backup describe on a single table with data 

public void testBackupDescribe() throws Exception {	String[] args = new String[] { "describe", "backup_2" };	int ret = ToolRunner.run(conf1, new BackupDriver(), args);	assertTrue(ret < 0);	ByteArrayOutputStream baos = new ByteArrayOutputStream();	System.setErr(new PrintStream(baos));	args = new String[] { "progress" };	ToolRunner.run(TEST_UTIL.getConfiguration(), new BackupDriver(), args);	String output = baos.toString();	
output from progress 

public void testBackupDescribeCommand() throws Exception {	
test backup describe on a single table with data command line 

public void testBackupDescribeCommand() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	
backup complete 

========================= hbase sample_554 =========================

runReadBenchmark(cryptoconf, aesfs, aesmf, "gz", "aes");	if (fs.exists(mf)) {	fs.delete(mf, true);	}	if (aesfs.exists(aesmf)) {	aesfs.delete(aesmf, true);	}	if (cryptofs.exists(aesmf)) {	cryptofs.delete(cryptof, true);	}	
result summary 

protected void runBenchmark(RowOrientedBenchmark benchmark, int rowCount, String codec, String cipher) throws Exception {	
running with codec cipher for rows 

protected void runBenchmark(RowOrientedBenchmark benchmark, int rowCount, String codec, String cipher) throws Exception {	long elapsedTime = benchmark.run();	
running with codec cipher for rows took ms 

========================= hbase sample_1576 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

private void testProcedureEventWaitWake(final HMaster master, final ProcedureEvent event, final Procedure proc) throws Exception {	final ProcedureExecutor<MasterProcedureEnv> procExec = master.getMasterProcedureExecutor();	final MasterProcedureScheduler procSched = procExec.getEnvironment().getProcedureScheduler();	final long startPollCalls = procSched.getPollCalls();	final long startNullPollCalls = procSched.getNullPollCalls();	
checking 

private void testProcedureEventWaitWake(final HMaster master, final ProcedureEvent event, final Procedure proc) throws Exception {	final ProcedureExecutor<MasterProcedureEnv> procExec = master.getMasterProcedureExecutor();	final MasterProcedureScheduler procSched = procExec.getEnvironment().getProcedureScheduler();	final long startPollCalls = procSched.getPollCalls();	final long startNullPollCalls = procSched.getNullPollCalls();	assertEquals(false, event.isReady());	assertEquals(0, event.getSuspendedProcedures().size());	
submit 

private void testProcedureEventWaitWake(final HMaster master, final ProcedureEvent event, final Procedure proc) throws Exception {	final ProcedureExecutor<MasterProcedureEnv> procExec = master.getMasterProcedureExecutor();	final MasterProcedureScheduler procSched = procExec.getEnvironment().getProcedureScheduler();	final long startPollCalls = procSched.getPollCalls();	final long startNullPollCalls = procSched.getNullPollCalls();	assertEquals(false, event.isReady());	assertEquals(0, event.getSuspendedProcedures().size());	long procId = procExec.submitProcedure(proc);	
wait procedure suspended on 

final MasterProcedureScheduler procSched = procExec.getEnvironment().getProcedureScheduler();	final long startPollCalls = procSched.getPollCalls();	final long startNullPollCalls = procSched.getNullPollCalls();	assertEquals(false, event.isReady());	assertEquals(0, event.getSuspendedProcedures().size());	long procId = procExec.submitProcedure(proc);	while (event.getSuspendedProcedures().size() < 1) Thread.sleep(25);	LOG.debug("checking " + event + " size=" + event.getSuspendedProcedures().size());	assertEquals(false, event.isReady());	assertEquals(1, event.getSuspendedProcedures().size());	
wake 

final long startNullPollCalls = procSched.getNullPollCalls();	assertEquals(false, event.isReady());	assertEquals(0, event.getSuspendedProcedures().size());	long procId = procExec.submitProcedure(proc);	while (event.getSuspendedProcedures().size() < 1) Thread.sleep(25);	LOG.debug("checking " + event + " size=" + event.getSuspendedProcedures().size());	assertEquals(false, event.isReady());	assertEquals(1, event.getSuspendedProcedures().size());	event.wake(procSched);	assertEquals(true, event.isReady());	
waiting 

========================= hbase sample_1825 =========================

private void doTestFlushCommits(boolean doAbort) throws Exception {	
get new table 

private void doTestFlushCommits(boolean doAbort) throws Exception {	Table table = UTIL.getConnection().getTable(TEST_TABLE);	
constructPutRequests 

private void doTestFlushCommits(boolean doAbort) throws Exception {	Table table = UTIL.getConnection().getTable(TEST_TABLE);	List<Put> puts = constructPutRequests();	table.put(puts);	
puts 

assert liveRScount > 0;	JVMClusterUtil.RegionServerThread liveRS = UTIL.getMiniHBaseCluster() .getLiveRegionServerThreads().get(0);	if (doAbort) {	liveRS.getRegionServer().abort("Aborting for tests", new Exception("doTestFlushCommits"));	while (liveRS.getRegionServer().getNumberOfOnlineRegions() != 0) {	Thread.sleep(100);	}	puts = constructPutRequests();	table.put(puts);	}	
validating loaded data 

if (doAbort) {	UTIL.getMiniHBaseCluster().waitOnRegionServer(0);	UTIL.waitFor(15 * 1000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return UTIL.getMiniHBaseCluster().getMaster() .getClusterMetrics().getLiveServerMetrics().size() == liveRScount;	}	});	UTIL.waitFor(15 * 1000, UTIL.predicateNoRegionsInTransition());	}	table.close();	
done 

private void validateLoadedData(Table table) throws IOException {	
validating data on 

retryNum--;	} while (retryNum > 0);	if (retryNum == 0) {	fail("Timeout for validate data");	} else {	if (results != null) {	for (Result r : results) {	Assert.assertTrue(r.containsColumn(BYTES_FAMILY, QUALIFIER));	Assert.assertEquals(0, Bytes.compareTo(VALUE, r .getValue(BYTES_FAMILY, QUALIFIER)));	}	
validating data on successfully 

========================= hbase sample_2073 =========================

if (!path.equals(pathToWatch)) {	return;	}	try {	if (!(ZKUtil.setWatchIfNodeExists(watcher, pathToWatch))) {	deletedLatch.countDown();	}	} catch (KeeperException ex) {	exception = ex;	deletedLatch.countDown();	
error when re setting the watch on 

public void nodeDeleted(String path) {	if (!path.equals(pathToWatch)) {	return;	}	if (LOG.isDebugEnabled()) {	
processing delete on 

========================= hbase sample_738 =========================

public void deregister(String table) {	try {	tableSources.remove(table);	} catch (Exception e) {	
error trying to remove from 

========================= hbase sample_692 =========================

try (Connection conn = ConnectionFactory.createConnection(c)) {	SleepAndFailFirstTime.ct.set(0);	try (Table table = conn.getTableBuilder(tableName, null).setOperationTimeout(8000).build()) {	table.get(new Get(FAM_NAM));	}	SleepAndFailFirstTime.ct.set(0);	try (Table table = conn.getTableBuilder(tableName, null).setOperationTimeout(6000).build()) {	table.get(new Get(FAM_NAM));	fail("We expect an exception here");	} catch (SocketTimeoutException e) {	
we received an exception as expected 

========================= hbase sample_2136 =========================

}	metricsBalancer.incrMiscInvocations();	List<ServerName> favoredNodes = fnm.getFavoredNodes(regionInfo);	if (favoredNodes == null || favoredNodes.isEmpty()) {	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(servers, getConf());	helper.initialize();	try {	favoredNodes = helper.generateFavoredNodes(regionInfo);	updateFavoredNodesForRegion(regionInfo, favoredNodes);	} catch (IOException e) {	
encountered exception while doing favored nodes random assignment 

} catch (IOException e) {	throw new HBaseIOException(e);	}	}	List<ServerName> onlineServers = getOnlineFavoredNodes(servers, favoredNodes);	if (onlineServers.size() > 0) {	destination = onlineServers.get(RANDOM.nextInt(onlineServers.size()));	}	boolean alwaysAssign = getConf().getBoolean(FAVORED_ALWAYS_ASSIGN_REGIONS, true);	if (destination == null && alwaysAssign) {	
can t generate fn for region falling back 

public Map<ServerName, List<RegionInfo>> retainAssignment(Map<RegionInfo, ServerName> regions, List<ServerName> servers) throws HBaseIOException {	Map<ServerName, List<RegionInfo>> assignmentMap = Maps.newHashMap();	Map<ServerName, List<RegionInfo>> result = super.retainAssignment(regions, servers);	if (result == null || result.isEmpty()) {	
nothing to assign to probably no servers or no regions 

Map<ServerName, List<RegionInfo>> result = super.retainAssignment(regions, servers);	if (result == null || result.isEmpty()) {	return null;	}	if (servers != null && servers.contains(masterServerName)) {	servers = new ArrayList<>(servers);	servers.remove(masterServerName);	}	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(servers, getConf());	helper.initialize();	
generating favored nodes for regions missing them 

helper.initialize();	Map<RegionInfo, List<ServerName>> regionFNMap = Maps.newHashMap();	try {	for (Entry<ServerName, List<RegionInfo>> entry : result.entrySet()) {	ServerName sn = entry.getKey();	ServerName primary = ServerName.valueOf(sn.getHostname(), sn.getPort(), NON_STARTCODE);	for (RegionInfo hri : entry.getValue()) {	if (FavoredNodesManager.isFavoredNodeApplicable(hri)) {	List<ServerName> favoredNodes = fnm.getFavoredNodes(hri);	if (favoredNodes == null || favoredNodes.size() < FAVORED_NODES_NUM) {	
generating favored nodes for with primary 

}	} else {	List<ServerName> onlineFN = getOnlineFavoredNodes(servers, favoredNodes);	if (onlineFN.isEmpty()) {	addRegionToMap(assignmentMap, hri, BOGUS_SERVER_NAME);	} else {	if (FavoredNodesPlan.getFavoredServerPosition(favoredNodes, sn) != null) {	addRegionToMap(assignmentMap, hri, sn);	} else {	ServerName destination = onlineFN.get(RANDOM.nextInt(onlineFN.size()));	
region not hosted on favored nodes current moving to 

addRegionToMap(assignmentMap, hri, destination);	}	}	}	} else {	addRegionToMap(assignmentMap, hri, sn);	}	}	}	if (!regionFNMap.isEmpty()) {	
updating fn in meta for missing regions count 

public void generateFavoredNodesForDaughter(List<ServerName> servers, RegionInfo parent, RegionInfo regionA, RegionInfo regionB) throws IOException {	Map<RegionInfo, List<ServerName>> result = new HashMap<>();	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(servers, rackManager);	helper.initialize();	List<ServerName> parentFavoredNodes = fnm.getFavoredNodes(parent);	if (parentFavoredNodes == null) {	
unable to find favored nodes for parent generating new favored nodes for daughter 

protected Cluster.Action generate(Cluster cluster) {	int thisServer = pickRandomServer(cluster);	int thisRegion;	if (thisServer == -1) {	
could not pick lowest local region server 

protected Cluster.Action generate(Cluster cluster) {	int thisServer = pickRandomServer(cluster);	int thisRegion;	if (thisServer == -1) {	return Cluster.NullAction;	} else {	thisRegion = pickLowestLocalRegionOnServer(cluster, thisServer);	}	if (thisRegion == -1) {	if (cluster.regionsPerServer[thisServer].length > 0) {	
could not pick lowest local region even when region server held regions 

}	return Cluster.NullAction;	}	RegionInfo hri = cluster.regions[thisRegion];	List<ServerName> favoredNodes = fnm.getFavoredNodes(hri);	int otherServer;	if (favoredNodes == null) {	if (!FavoredNodesManager.isFavoredNodeApplicable(hri)) {	otherServer = pickOtherRandomServer(cluster, thisServer);	} else {	
ignoring no favored nodes for region 

int misplacedRegions = 0;	for (Entry<ServerName, List<RegionInfo>> entry : clusterState.entrySet()) {	ServerName current = entry.getKey();	List<RegionInfo> regions = Lists.newArrayList();	correctAssignments.put(current, regions);	for (RegionInfo hri : entry.getValue()) {	List<ServerName> favoredNodes = fnm.getFavoredNodes(hri);	if (FavoredNodesPlan.getFavoredServerPosition(favoredNodes, current) != null || !FavoredNodesManager.isFavoredNodeApplicable(hri)) {	regions.add(hri);	} else {	
region not on favored nodes unassign region current favored nodes 

List<RegionInfo> regions = Lists.newArrayList();	correctAssignments.put(current, regions);	for (RegionInfo hri : entry.getValue()) {	List<ServerName> favoredNodes = fnm.getFavoredNodes(hri);	if (FavoredNodesPlan.getFavoredServerPosition(favoredNodes, current) != null || !FavoredNodesManager.isFavoredNodeApplicable(hri)) {	regions.add(hri);	} else {	try {	this.services.getAssignmentManager().unassign(hri);	} catch (IOException e) {	
failed unassign 

this.services.getAssignmentManager().unassign(hri);	} catch (IOException e) {	continue;	}	RegionPlan rp = new RegionPlan(hri, null, null);	regionPlans.add(rp);	misplacedRegions++;	}	}	}	
found misplaced regions not on favored nodes 

========================= hbase sample_2835 =========================

public void perform() throws Exception {	
performing action restart random zookeeper node 

========================= hbase sample_3300 =========================

private void handleMasterNodeChange() {	try {	synchronized(clusterHasActiveMaster) {	if (ZKUtil.watchAndCheckExists(watcher, watcher.znodePaths.masterAddressZNode)) {	
a master is now available 

private void handleMasterNodeChange() {	try {	synchronized(clusterHasActiveMaster) {	if (ZKUtil.watchAndCheckExists(watcher, watcher.znodePaths.masterAddressZNode)) {	clusterHasActiveMaster.set(true);	} else {	
no master available notifying waiting threads 

public void stop() {	try {	synchronized (clusterHasActiveMaster) {	clusterHasActiveMaster.notifyAll();	}	ServerName activeMaster = null;	try {	activeMaster = MasterAddressTracker.getMasterAddress(this.watcher);	} catch (IOException e) {	
failed get of master address 

ServerName activeMaster = null;	try {	activeMaster = MasterAddressTracker.getMasterAddress(this.watcher);	} catch (IOException e) {	}	if (activeMaster != null &&  activeMaster.equals(this.sn)) {	ZKUtil.deleteNode(watcher, watcher.znodePaths.masterAddressZNode);	ZNodeClearer.deleteMyEphemeralNodeOnDisk();	}	} catch (KeeperException e) {	
failed delete of our master address node 

========================= hbase sample_2842 =========================

public void testSplitCalculator() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("C"));	SimpleRange c = new SimpleRange(Bytes.toBytes("C"), Bytes.toBytes("D"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	sc.add(c);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
Standard 

public void testSplitCalculatorNoEdge() {	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
Empty 

public void testSplitCalculatorSingleEdge() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
single edge 

public void testSplitCalculatorDegenerateEdge() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("A"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
single empty edge 

public void testSplitCalculatorCoverSplit() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("C"));	SimpleRange c = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	sc.add(c);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ac covers ab bc 

public void testSplitCalculatorOverEndpoint() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("C"));	SimpleRange c = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("D"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	sc.add(c);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ab bd covers bc 

public void testSplitCalculatorHoles() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("C"));	SimpleRange c = new SimpleRange(Bytes.toBytes("E"), Bytes.toBytes("F"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	sc.add(c);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
hole between c and e 

public void testSplitCalculatorOverreach() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("D"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ac and bd overlap but share no start end keys 

public void testSplitCalculatorFloor() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	SimpleRange b = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ac and ab overlap in the beginning 

public void testSplitCalculatorCeil() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	SimpleRange b = new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("C"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ac and bc overlap in the end 

public void testSplitCalculatorEq() {	SimpleRange a = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	SimpleRange b = new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C"));	LOG.info(a.tiebreaker + " - " + b.tiebreaker);	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	sc.add(b);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ac and ac overlap completely 

public void testSplitCalculatorBackwards() {	SimpleRange a = new SimpleRange(Bytes.toBytes("C"), Bytes.toBytes("A"));	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(a);	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
ca is backwards 

RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("Am")));	sc.add(new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("C")));	sc.add(new SimpleRange(Bytes.toBytes("Am"), Bytes.toBytes("C")));	sc.add(new SimpleRange(Bytes.toBytes("D"), Bytes.toBytes("E")));	sc.add(new SimpleRange(Bytes.toBytes("F"), Bytes.toBytes("G")));	sc.add(new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("E")));	sc.add(new SimpleRange(Bytes.toBytes("H"), Bytes.toBytes("I")));	sc.add(new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B")));	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
something fairly complex 

public void testBeginEndMarker() {	RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);	sc.add(new SimpleRange(Bytes.toBytes(""), Bytes.toBytes("A")));	sc.add(new SimpleRange(Bytes.toBytes("A"), Bytes.toBytes("B")));	sc.add(new SimpleRange(Bytes.toBytes("B"), Bytes.toBytes("")));	Multimap<byte[], SimpleRange> regions = sc.calcCoverage();	
special cases empty 

========================= hbase sample_1297 =========================

protected int doWork() throws Exception {	if (!isForce) {	if (!"kerberos".equalsIgnoreCase(conf.get("hbase.security.authentication"))) {	
hbase security authentication is not kerberos and f is not supplied skip running the test 

private void testZNodeACLs() throws IOException, KeeperException, InterruptedException {	ZKWatcher watcher = new ZKWatcher(conf, "IntegrationTestZnodeACLs", null);	RecoverableZooKeeper zk = ZKUtil.connect(this.conf, watcher);	String baseZNode = watcher.znodePaths.baseZNode;	LOG.info("");	LOG.info("***********************************************************************************");	
checking zk permissions root znode 

private void testZNodeACLs() throws IOException, KeeperException, InterruptedException {	ZKWatcher watcher = new ZKWatcher(conf, "IntegrationTestZnodeACLs", null);	RecoverableZooKeeper zk = ZKUtil.connect(this.conf, watcher);	String baseZNode = watcher.znodePaths.baseZNode;	LOG.info("");	LOG.info("***********************************************************************************");	LOG.info("***********************************************************************************");	LOG.info("");	checkZnodePermsRecursive(watcher, zk, baseZNode);	
checking zk permissions success 

private void assertZnodePerms(RecoverableZooKeeper zk, String znode, boolean expectedWorldReadable) throws KeeperException, InterruptedException {	Stat stat = new Stat();	List<ACL> acls;	try {	acls = zk.getZooKeeper().getACL(znode, stat);	} catch (NoNodeException ex) {	
caught exception for missing znode 

private void assertZnodePerms(RecoverableZooKeeper zk, String znode, boolean expectedWorldReadable) throws KeeperException, InterruptedException {	Stat stat = new Stat();	List<ACL> acls;	try {	acls = zk.getZooKeeper().getACL(znode, stat);	} catch (NoNodeException ex) {	return;	}	String[] superUsers = superUser == null ? null : superUser.split(",");	
checking acls for znode znode acls 

private void testFSPerms() throws IOException {	Path rootDir = FSUtils.getRootDir(conf);	LOG.info("");	LOG.info("***********************************************************************************");	
checking fs permissions for root dir 

private void testFSPerms() throws IOException {	Path rootDir = FSUtils.getRootDir(conf);	LOG.info("");	LOG.info("***********************************************************************************");	LOG.info("***********************************************************************************");	LOG.info("");	FileSystem fs = rootDir.getFileSystem(conf);	short expectedPerms = Short.valueOf(fsPerms, 8);	assertEquals( FsPermission.createImmutable(expectedPerms), fs.getFileStatus(rootDir).getPermission());	
checking fs permissions success 

========================= hbase sample_3245 =========================

public void testReadSnapshotManifest() throws IOException {	Path p = createDataManifest();	try {	SnapshotManifest.open(conf, fs, snapshotDir, snapshotDesc);	fail("fail to test snapshot manifest because message size is too small.");	} catch (CorruptedSnapshotException cse) {	try {	conf.setInt(SnapshotManifest.SNAPSHOT_MANIFEST_SIZE_LIMIT_CONF_KEY, 128 * 1024 * 1024);	SnapshotManifest.open(conf, fs, snapshotDir, snapshotDesc);	
open snapshot manifest succeed 

========================= hbase sample_1278 =========================

public synchronized void stop() {	if (!running) {	return;	}	
stopping server on 

========================= hbase sample_2907 =========================

protected void testWithCluster(Map<ServerName, List<RegionInfo>> serverMap, RackManager rackManager, boolean assertFullyBalanced, boolean assertFullyBalancedForReplicas) {	List<ServerAndLoad> list = convertToList(serverMap);	
mock cluster 

protected void testWithCluster(Map<ServerName, List<RegionInfo>> serverMap, RackManager rackManager, boolean assertFullyBalanced, boolean assertFullyBalancedForReplicas) {	List<ServerAndLoad> list = convertToList(serverMap);	loadBalancer.setRackManager(rackManager);	List<RegionPlan> plans = loadBalancer.balanceCluster(serverMap);	assertNotNull(plans);	if (assertFullyBalanced || assertFullyBalancedForReplicas) {	List<ServerAndLoad> balancedCluster = reconcile(list, plans, serverMap);	
mock balance 

========================= hbase sample_1852 =========================

public MemcachedBlockCache(Configuration c) throws IOException {	
creating memcachedblockcache 

public void cacheBlock(BlockCacheKey cacheKey, Cacheable buf) {	if (buf instanceof HFileBlock) {	client.add(cacheKey.toString(), MAX_SIZE, (HFileBlock) buf, tc);	} else {	if (LOG.isDebugEnabled()) {	
memcachedblockcache can not cache cacheable s of type 

public Cacheable getBlock(BlockCacheKey cacheKey, boolean caching, boolean repeat, boolean updateCacheMetrics) {	HFileBlock result = null;	try (TraceScope traceScope = TraceUtil.createTrace("MemcachedBlockCache.getBlock")) {	result = client.get(cacheKey.toString(), tc);	} catch (Exception e) {	if (LOG.isDebugEnabled()) {	
exception pulling from memcached treating as a miss 

public boolean evictBlock(BlockCacheKey cacheKey) {	try {	cacheStats.evict();	return client.delete(cacheKey.toString()).get();	} catch (InterruptedException e) {	
error deleting 

public boolean evictBlock(BlockCacheKey cacheKey) {	try {	cacheStats.evict();	return client.delete(cacheKey.toString()).get();	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	} catch (ExecutionException e) {	if (LOG.isDebugEnabled()) {	
error deleting 

public HFileBlock decode(CachedData d) {	try {	ByteBuff buf = new SingleByteBuff(ByteBuffer.wrap(d.getData()));	return (HFileBlock) HFileBlock.BLOCK_DESERIALIZER.deserialize(buf, true, MemoryType.EXCLUSIVE);	} catch (IOException e) {	
error deserializing data from memcached 

========================= hbase sample_3496 =========================

static Path getRegionSplitEditsPath(final FileSystem fs, final Entry logEntry, final Path rootDir, String fileNameBeingSplit) throws IOException {	Path tableDir = FSUtils.getTableDir(rootDir, logEntry.getKey().getTablename());	String encodedRegionName = Bytes.toString(logEntry.getKey().getEncodedRegionName());	Path regiondir = HRegion.getRegionDir(tableDir, encodedRegionName);	Path dir = getRegionDirRecoveredEditsDir(regiondir);	if (!fs.exists(regiondir)) {	
this region s directory does not exist it is very likely that it was already split so it is safe to discard those edits 

Path dir = getRegionDirRecoveredEditsDir(regiondir);	if (!fs.exists(regiondir)) {	return null;	}	if (fs.exists(dir) && fs.isFile(dir)) {	Path tmp = new Path("/tmp");	if (!fs.exists(tmp)) {	fs.mkdirs(tmp);	}	tmp = new Path(tmp, HConstants.RECOVERED_EDITS_DIR + "_" + encodedRegionName);	
found existing old file it could be some leftover of an old installation it should be a folder instead so moving it to 

if (!fs.exists(regiondir)) {	return null;	}	if (fs.exists(dir) && fs.isFile(dir)) {	Path tmp = new Path("/tmp");	if (!fs.exists(tmp)) {	fs.mkdirs(tmp);	}	tmp = new Path(tmp, HConstants.RECOVERED_EDITS_DIR + "_" + encodedRegionName);	if (!fs.rename(dir, tmp)) {	
failed to sideline old file 

if (fs.exists(dir) && fs.isFile(dir)) {	Path tmp = new Path("/tmp");	if (!fs.exists(tmp)) {	fs.mkdirs(tmp);	}	tmp = new Path(tmp, HConstants.RECOVERED_EDITS_DIR + "_" + encodedRegionName);	if (!fs.rename(dir, tmp)) {	}	}	if (!fs.exists(dir) && !fs.mkdirs(dir)) {	
mkdir failed on 

try {	Matcher m = EDITFILES_NAME_PATTERN.matcher(p.getName());	result = fs.isFile(p) && m.matches();	if (p.getName().endsWith(RECOVERED_LOG_TMPFILE_SUFFIX)) {	result = false;	}	if (isSequenceIdFile(p)) {	result = false;	}	} catch (IOException e) {	
failed isfile check on 

public static Path moveAsideBadEditsFile(final FileSystem fs, final Path edits) throws IOException {	Path moveAsideName = new Path(edits.getParent(), edits.getName() + "." + System.currentTimeMillis());	if (!fs.rename(edits, moveAsideName)) {	
rename failed from to 

protected Reader getReader(FileStatus file, boolean skipErrors, CancelableProgressable reporter) throws IOException, CorruptedLogFileException {	Path path = file.getPath();	long length = file.getLen();	Reader in;	if (length <= 0) {	
file might be still open length is 

long length = file.getLen();	Reader in;	if (length <= 0) {	}	try {	FSUtils.getInstance(fs, conf).recoverFileLease(fs, path, conf, reporter);	try {	in = getReader(path, reporter);	} catch (EOFException e) {	if (length <= 0) {	
could not open for reading file is empty 

FSUtils.getInstance(fs, conf).recoverFileLease(fs, path, conf, reporter);	try {	in = getReader(path, reporter);	} catch (EOFException e) {	if (length <= 0) {	}	return null;	}	} catch (IOException e) {	if (e instanceof FileNotFoundException) {	
file does not exist anymore 

buffer = buffers.get(key.getEncodedRegionName());	if (buffer == null) {	buffer = new RegionEntryBuffer(key.getTablename(), key.getEncodedRegionName());	buffers.put(key.getEncodedRegionName(), buffer);	}	incrHeap= buffer.appendEntry(entry);	}	synchronized (controller.dataAvailable) {	totalBuffered += incrHeap;	while (totalBuffered > maxHeapUsage && controller.thrown.get() == null) {	
used bytes of buffered edits waiting for io threads 

public void waitUntilDrained() {	synchronized (controller.dataAvailable) {	while (totalBuffered > 0) {	try {	controller.dataAvailable.wait(2000);	} catch (InterruptedException e) {	
got interrupted while waiting for entrybuffers is drained 

public void run()  {	try {	doRun();	} catch (Throwable t) {	
exiting thread 

private void doRun() throws IOException {	
writer thread starting 

protected boolean finishWriting(boolean interrupt) throws IOException {	
waiting for split writer threads to finish 

}	try {	t.join();	} catch (InterruptedException ie) {	IOException iie = new InterruptedIOException();	iie.initCause(ie);	throw iie;	}	}	controller.checkForErrors();	
split writers finished closing 

return splits;	}	private void deleteOneWithFewerEntries(WriterAndPath wap, Path dst) throws IOException {	long dstMinLogSeqNum = -1L;	try (WAL.Reader reader = walFactory.createReader(fs, dst)) {	WAL.Entry entry = reader.next();	if (entry != null) {	dstMinLogSeqNum = entry.getKey().getSequenceId();	}	} catch (EOFException e) {	
got eof when reading first wal entry from an empty or broken wal file 

try (WAL.Reader reader = walFactory.createReader(fs, dst)) {	WAL.Entry entry = reader.next();	if (entry != null) {	dstMinLogSeqNum = entry.getKey().getSequenceId();	}	} catch (EOFException e) {	}	if (wap.minLogSeqNum < dstMinLogSeqNum) {	LOG.warn("Found existing old edits file. It could be the result of a previous failed" + " split attempt or we have duplicated wal entries. Deleting " + dst + ", length=" + fs.getFileStatus(dst).getLen());	if (!fs.delete(dst, false)) {	
failed deleting of old 

} catch (EOFException e) {	}	if (wap.minLogSeqNum < dstMinLogSeqNum) {	LOG.warn("Found existing old edits file. It could be the result of a previous failed" + " split attempt or we have duplicated wal entries. Deleting " + dst + ", length=" + fs.getFileStatus(dst).getLen());	if (!fs.delete(dst, false)) {	throw new IOException("Failed deleting of old " + dst);	}	} else {	LOG.warn("Found existing old edits file and we have less entries. Deleting " + wap.p + ", length=" + fs.getFileStatus(wap.p).getLen());	if (!fs.delete(wap.p, false)) {	
failed deleting of 

========================= hbase sample_2268 =========================

protected boolean initialChore() {	try {	if (this.enabled.get()) scan();	} catch (IOException e) {	
failed initial scan of catalog table 

protected void chore() {	try {	AssignmentManager am = this.services.getAssignmentManager();	if (this.enabled.get() && !this.services.isInMaintenanceMode() && am != null && am.isFailoverCleanupDone() && !am.hasRegionsInTransition()) {	scan();	} else {	LOG.warn("CatalogJanitor is disabled! Enabled=" + this.enabled.get() + ", maintenanceMode=" + this.services.isInMaintenanceMode() + ", am=" + am + ", failoverCleanupDone=" + (am != null && am.isFailoverCleanupDone()) + ", hasRIT=" + (am != null && am.hasRegionsInTransition()));	}	} catch (IOException e) {	
failed scan of catalog table 

public boolean cleanMergeQualifier(final RegionInfo region) throws IOException {	Pair<RegionInfo, RegionInfo> mergeRegions = MetaTableAccessor .getRegionsFromMergeQualifier(this.services.getConnection(), region.getRegionName());	if (mergeRegions == null || (mergeRegions.getFirst() == null && mergeRegions.getSecond() == null)) {	return true;	}	if (mergeRegions.getFirst() == null || mergeRegions.getSecond() == null) {	
merged region has only one merge qualifier in meta 

========================= hbase sample_2792 =========================

try {	HTable.validatePut(put, maxKeyValueSize);	ClusterConnection conn = (ClusterConnection) getConnection();	HRegionLocation loc = conn.getRegionLocation(tableName, put.getRow(), false);	if (loc != null) {	LinkedBlockingQueue<PutStatus> queue = getQueue(loc);	PutStatus s = new PutStatus(loc.getRegion(), put, maxAttempts);	return queue.offer(s);	}	} catch (IOException e) {	
cannot process the put 

}	List<PutStatus> failed = null;	Object[] results = new Object[actions.size()];	ServerName server = addr.getServerName();	Map<ServerName, MultiAction> actionsByServer = Collections.singletonMap(server, actions);	try {	AsyncProcessTask task = AsyncProcessTask.newBuilder() .setResults(results) .setPool(pool) .setRpcTimeout(writeRpcTimeout) .setOperationTimeout(operationTimeout) .build();	AsyncRequestFuture arf = ap.submitMultiActions(task, retainedActions, 0L, null, null, actionsByServer);	arf.waitUntilDone();	if (arf.hasError()) {	
caught some exceptions when flushing puts to region server 

failedCount--;	}	}	}	long elapsed = EnvironmentEdgeManager.currentTime() - start;	averageLatency.add(elapsed);	if (elapsed > maxLatency.get()) {	maxLatency.set(elapsed);	}	if (LOG.isDebugEnabled()) {	
processed put requests for and failed latency for this send 

}	long elapsed = EnvironmentEdgeManager.currentTime() - start;	averageLatency.add(elapsed);	if (elapsed > maxLatency.get()) {	maxLatency.set(elapsed);	}	if (LOG.isDebugEnabled()) {	}	currentProcessingCount.set(0);	} catch (RuntimeException e) {	
caught some exceptions when flushing puts to region server 

maxLatency.set(elapsed);	}	if (LOG.isDebugEnabled()) {	}	currentProcessingCount.set(0);	} catch (RuntimeException e) {	} catch (Exception e) {	if (e instanceof InterruptedException) {	Thread.currentThread().interrupt();	}	
caught some exceptions when flushing puts to region server 

========================= hbase sample_489 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_2116 =========================

private void tune(double flushPressure) {	double maxThroughputToSet;	if (flushPressure >= 1.0) {	maxThroughputToSet = Double.MAX_VALUE;	} else {	maxThroughputToSet = maxThroughputLowerBound + (maxThroughputUpperBound - maxThroughputLowerBound) }	if (LOG.isDebugEnabled()) {	
flushpressure is tune flush throughput to 

super.setConf(conf);	if (conf == null) {	return;	}	this.maxThroughputUpperBound = conf.getLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND, DEFAULT_HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND);	this.maxThroughputLowerBound = conf.getLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND, DEFAULT_HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND);	this.offPeakHours = OffPeakHours.getInstance(conf);	this.controlPerSize = conf.getLong(HBASE_HSTORE_FLUSH_THROUGHPUT_CONTROL_CHECK_INTERVAL, DEFAULT_HBASE_HSTORE_FLUSH_THROUGHPUT_CONTROL_CHECK_INTERVAL);	this.setMaxThroughput(this.maxThroughputLowerBound);	this.tuningPeriod = getConf().getInt(HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD, DEFAULT_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD);	
flush throughput configurations upper bound lower bound tuning period ms 

========================= hbase sample_2546 =========================

}	ListMultimap<String,TablePermission> preperms = AccessControlLists.getTablePermissions(conf, TEST_TABLE);	Table table = UTIL.getConnection().getTable(TEST_TABLE);	table.put(new Put(Bytes.toBytes("row1")) .addColumn(TEST_FAMILY, TEST_QUALIFIER, Bytes.toBytes("v1")));	table.put(new Put(Bytes.toBytes("row2")) .addColumn(TEST_FAMILY, TEST_QUALIFIER, Bytes.toBytes("v2")));	Admin admin = UTIL.getAdmin();	try {	admin.split(TEST_TABLE);	}	catch (IOException e) {	
region is not splittable because 

public void checkMultimapEqual(ListMultimap<String,TablePermission> first, ListMultimap<String,TablePermission> second) {	assertEquals(first.size(), second.size());	for (String key : first.keySet()) {	List<TablePermission> firstPerms = first.get(key);	List<TablePermission> secondPerms = second.get(key);	assertNotNull(secondPerms);	assertEquals(firstPerms.size(), secondPerms.size());	
first permissions 

public void checkMultimapEqual(ListMultimap<String,TablePermission> first, ListMultimap<String,TablePermission> second) {	assertEquals(first.size(), second.size());	for (String key : first.keySet()) {	List<TablePermission> firstPerms = first.get(key);	List<TablePermission> secondPerms = second.get(key);	assertNotNull(secondPerms);	assertEquals(firstPerms.size(), secondPerms.size());	
second permissions 

========================= hbase sample_1385 =========================

public void test2772() throws Exception {	
start 

conf.setInt(HConstants.HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD, SCANNER_TIMEOUT * 100);	Connection connection = ConnectionFactory.createConnection(conf);	Table higherScanTimeoutTable = connection.getTable(TABLE_NAME);	ResultScanner r = higherScanTimeoutTable.getScanner(scan);	rs.abort("die!");	Result[] results = r.next(NB_ROWS);	assertEquals(NB_ROWS, results.length);	r.close();	higherScanTimeoutTable.close();	connection.close();	
end 

public void test3686a() throws Exception {	
start 

public void test3686a() throws Exception {	HRegionServer rs = TEST_UTIL.getRSForFirstRegionInTable(TABLE_NAME);	
start 

public void test3686a() throws Exception {	HRegionServer rs = TEST_UTIL.getRSForFirstRegionInTable(TABLE_NAME);	Scan scan = new Scan();	scan.setCaching(SCANNER_CACHING);	LOG.info("************ TEST3686A");	MetaTableAccessor.fullScanMetaAndPrint(TEST_UTIL.getAdmin().getConnection());	Configuration conf = new Configuration(TEST_UTIL.getConfiguration());	conf.setInt( HConstants.HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD, SCANNER_TIMEOUT*100);	Connection connection = ConnectionFactory.createConnection(conf);	Table table = connection.getTable(TABLE_NAME);	
start 

HRegionServer rs = TEST_UTIL.getRSForFirstRegionInTable(TABLE_NAME);	Scan scan = new Scan();	scan.setCaching(SCANNER_CACHING);	LOG.info("************ TEST3686A");	MetaTableAccessor.fullScanMetaAndPrint(TEST_UTIL.getAdmin().getConnection());	Configuration conf = new Configuration(TEST_UTIL.getConfiguration());	conf.setInt( HConstants.HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD, SCANNER_TIMEOUT*100);	Connection connection = ConnectionFactory.createConnection(conf);	Table table = connection.getTable(TABLE_NAME);	ResultScanner r = table.getScanner(scan);	
start 

scan.setCaching(SCANNER_CACHING);	LOG.info("************ TEST3686A");	MetaTableAccessor.fullScanMetaAndPrint(TEST_UTIL.getAdmin().getConnection());	Configuration conf = new Configuration(TEST_UTIL.getConfiguration());	conf.setInt( HConstants.HBASE_CLIENT_SCANNER_TIMEOUT_PERIOD, SCANNER_TIMEOUT*100);	Connection connection = ConnectionFactory.createConnection(conf);	Table table = connection.getTable(TABLE_NAME);	ResultScanner r = table.getScanner(scan);	int count = 1;	r.next();	
start 

int count = 1;	r.next();	rs.abort("die!");	while(r.next() != null) {	count ++;	}	assertEquals(NB_ROWS, count);	r.close();	table.close();	connection.close();	
end 

public void test3686b() throws Exception {	
start 

int count = 1;	r.next();	Thread.sleep(SCANNER_TIMEOUT+2000);	while(r.next() != null) {	count ++;	}	assertEquals(NB_ROWS, count);	r.close();	higherScanTimeoutTable.close();	connection.close();	
end end 

========================= hbase sample_2053 =========================

fail("Waited too much time for truncate");	}	ResultScanner scanner = htable2.getScanner(scan);	Result[] res = scanner.next(rowCount);	scanner.close();	if (res.length != 0) {	if (res.length < lastCount) {	i--;	}	lastCount = res.length;	
still got rows 

Scan scan;	for (int i = 0; i < retries; i++) {	scan = new Scan();	if (i== retries -1) {	fail("Waited too much time for normal batch replication");	}	ResultScanner scanner = htable2.getScanner(scan);	Result[] res = scanner.next(expectedRows);	scanner.close();	if (res.length != expectedRows) {	
only got rows 

conf1.setInt("replication.source.maxretriesmultiplier", 10);	conf1.setFloat("replication.source.ratio", 1.0f);	conf1.setBoolean("replication.source.eof.autorecovery", true);	conf1.setBoolean(AbstractFSWALProvider.SEPARATE_OLDLOGDIR, seperateOldWALs);	utility1 = new HBaseTestingUtility(conf1);	utility1.startMiniZKCluster();	MiniZooKeeperCluster miniZK = utility1.getZkCluster();	conf1 = utility1.getConfiguration();	zkw1 = new ZKWatcher(conf1, "cluster1", null, true);	admin = new ReplicationAdmin(conf1);	
setup first zk 

conf1 = utility1.getConfiguration();	zkw1 = new ZKWatcher(conf1, "cluster1", null, true);	admin = new ReplicationAdmin(conf1);	conf2 = HBaseConfiguration.create(conf1);	conf2.set(HConstants.ZOOKEEPER_ZNODE_PARENT, "/2");	conf2.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 6);	conf2.setBoolean("hbase.tests.use.shortcircuit.reads", false);	utility2 = new HBaseTestingUtility(conf2);	utility2.setZkCluster(miniZK);	zkw2 = new ZKWatcher(conf2, "cluster2", null, true);	
setup second zk 

put.addColumn(famName, row, row);	htable1 = utility1.getConnection().getTable(tableName);	htable1.put(put);	Get get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for put replication");	}	Result res = htable2.get(get);	if (res.isEmpty()) {	
row not available 

}	Delete del = new Delete(row);	htable1.delete(del);	get = new Get(row);	for (int i = 0; i < NB_RETRIES; i++) {	if (i == NB_RETRIES - 1) {	fail("Waited too much time for del replication");	}	Result res = htable2.get(get);	if (res.size() >= 1) {	
row not deleted 

========================= hbase sample_1940 =========================

grantOnTable(TEST_UTIL, USER_CREATE.getShortName(), TEST_TABLE, null, null, Permission.Action.CREATE, Permission.Action.READ, Permission.Action.WRITE);	grantOnTable(TEST_UTIL, USER_RO.getShortName(), TEST_TABLE, TEST_FAMILY, null, Permission.Action.READ);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_ADMIN), Permission.Action.ADMIN);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_CREATE), Permission.Action.CREATE);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_READ), Permission.Action.READ);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_WRITE), Permission.Action.WRITE);	assertEquals(4, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());	try {	assertEquals(4, AccessControlClient.getUserPermissions(systemUserConnection, TEST_TABLE.toString()).size());	} catch (Throwable e) {	
error during call of accesscontrolclient getuserpermissions 

private static void cleanUp() throws Exception {	try {	deleteTable(TEST_UTIL, TEST_TABLE);	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_3341 =========================

public void testIncrementMultiThreads() throws IOException {	boolean fast = true;	
starting test testincrementmultithreads 

all[i] = new Incrementer(region, i, i, incrementsPerThread);	expectedTotal += (i * incrementsPerThread);	}	for (int i = 0; i < numThreads; i++) {	all[i].start();	}	for (int i = 0; i < numThreads; i++) {	try {	all[i].join();	} catch (InterruptedException e) {	
Ignored 

}	for (int i = 0; i < numThreads; i++) {	try {	all[i].join();	} catch (InterruptedException e) {	}	}	assertICV(row, fam1, qual1, expectedTotal, fast);	assertICV(row, fam1, qual2, expectedTotal*2, fast);	assertICV(row, fam2, qual3, expectedTotal*3, fast);	
testincrementmultithreads successfully verified that total is 

public void testAppendMultiThreads() throws IOException {	
starting test testappendmultithreads 

public void testRowMutationMultiThreads() throws IOException {	
starting test testrowmutationmultithreads 

AtomicLong timeStamps = new AtomicLong(0);	AtomicInteger failures = new AtomicInteger(0);	for (int i = 0; i < numThreads; i++) {	all[i] = new AtomicOperation(region, opsPerThread, timeStamps, failures) {	public void run() {	boolean op = true;	for (int i=0; i<numOps; i++) {	try {	if (i%10==0) {	synchronized(region) {	
flushing 

public void testMultiRowMutationMultiThreads() throws IOException {	
starting test testmultirowmutationmultithreads 

AtomicInteger failures = new AtomicInteger(0);	final List<byte[]> rowsToLock = Arrays.asList(row, row2);	for (int i = 0; i < numThreads; i++) {	all[i] = new AtomicOperation(region, opsPerThread, timeStamps, failures) {	public void run() {	boolean op = true;	for (int i=0; i<numOps; i++) {	try {	if (i%10==0) {	synchronized(region) {	
flushing 

========================= hbase sample_1686 =========================

public FileMmapEngine(String filePath, long capacity) throws IOException {	this.path = filePath;	this.size = capacity;	long fileSize = 0;	try {	raf = new RandomAccessFile(filePath, "rw");	fileSize = roundUp(capacity, ByteBufferArray.DEFAULT_BUFFER_SIZE);	raf.setLength(fileSize);	fileChannel = raf.getChannel();	
allocating on the path 

public FileMmapEngine(String filePath, long capacity) throws IOException {	this.path = filePath;	this.size = capacity;	long fileSize = 0;	try {	raf = new RandomAccessFile(filePath, "rw");	fileSize = roundUp(capacity, ByteBufferArray.DEFAULT_BUFFER_SIZE);	raf.setLength(fileSize);	fileChannel = raf.getChannel();	} catch (java.io.FileNotFoundException fex) {	
can t create bucket cache file 

this.size = capacity;	long fileSize = 0;	try {	raf = new RandomAccessFile(filePath, "rw");	fileSize = roundUp(capacity, ByteBufferArray.DEFAULT_BUFFER_SIZE);	raf.setLength(fileSize);	fileChannel = raf.getChannel();	} catch (java.io.FileNotFoundException fex) {	throw fex;	} catch (IOException ioex) {	
can t extend bucket cache file insufficient space for 

public void shutdown() {	try {	fileChannel.close();	} catch (IOException ex) {	
can t shutdown cleanly 

public void shutdown() {	try {	fileChannel.close();	} catch (IOException ex) {	}	try {	raf.close();	} catch (IOException ex) {	
can t shutdown cleanly 

========================= hbase sample_2415 =========================

private boolean checkAllBytesParsed() throws IOException {	final long trailerSize = currentTrailerSize();	FileStatus stat = null;	try {	stat = fs.getFileStatus(this.currentPath);	} catch (IOException exception) {	
couldn t get file length information about log it was not was closed cleanly 

try {	stat = fs.getFileStatus(this.currentPath);	} catch (IOException exception) {	metrics.incrUnknownFileLengthForClosedWAL();	}	if (stat != null) {	if (trailerSize < 0) {	if (currentPosition < stat.getLen()) {	final long skippedBytes = stat.getLen() - currentPosition;	if (LOG.isDebugEnabled()) {	
reached the end of wal file it was not closed cleanly so we did not parse bytes of data this is normally ok 

if (stat != null) {	if (trailerSize < 0) {	if (currentPosition < stat.getLen()) {	final long skippedBytes = stat.getLen() - currentPosition;	if (LOG.isDebugEnabled()) {	}	metrics.incrUncleanlyClosedWALs();	metrics.incrBytesSkippedInUncleanlyClosedWALs(skippedBytes);	}	} else if (currentPosition + trailerSize < stat.getLen()) {	
processing end of wal file at position which is too far away from reported file length restarting wal reading see hbase for details 

private boolean readNextEntryAndSetPosition() throws IOException {	Entry readEntry = reader.next();	long readerPos = reader.getPosition();	OptionalLong fileLength = walFileLengthProvider.getLogFileSizeIfBeingWritten(currentPath);	if (fileLength.isPresent() && readerPos > fileLength.getAsLong()) {	if (LOG.isDebugEnabled()) {	
the provider tells us the valid length for is but we have advanced to 

} else {	resetReader();	}	} catch (FileNotFoundException fnfe) {	handleFileNotFound(path, fnfe);	}  catch (RemoteException re) {	IOException ioe = re.unwrapRemoteException(FileNotFoundException.class);	if (!(ioe instanceof FileNotFoundException)) throw ioe;	handleFileNotFound(path, (FileNotFoundException)ioe);	} catch (LeaseNotRecoveredException lnre) {	
try to recover the wal lease 

} catch (FileNotFoundException fnfe) {	handleFileNotFound(path, fnfe);	}  catch (RemoteException re) {	IOException ioe = re.unwrapRemoteException(FileNotFoundException.class);	if (!(ioe instanceof FileNotFoundException)) throw ioe;	handleFileNotFound(path, (FileNotFoundException)ioe);	} catch (LeaseNotRecoveredException lnre) {	recoverLease(conf, currentPath);	reader = null;	} catch (NullPointerException npe) {	
got npe opening reader will retry 

private void recoverLease(final Configuration conf, final Path path) {	try {	final FileSystem dfs = FSUtils.getCurrentFileSystem(conf);	FSUtils fsUtils = FSUtils.getInstance(dfs, conf);	fsUtils.recoverFileLease(dfs, path, conf, new CancelableProgressable() {	public boolean progress() {	
recover wal lease 

private void recoverLease(final Configuration conf, final Path path) {	try {	final FileSystem dfs = FSUtils.getCurrentFileSystem(conf);	FSUtils fsUtils = FSUtils.getInstance(dfs, conf);	fsUtils.recoverFileLease(dfs, path, conf, new CancelableProgressable() {	public boolean progress() {	return true;	}	});	} catch (IOException e) {	
unable to recover lease for wal 

========================= hbase sample_2946 =========================

public CompactionRequestImpl selectCompaction(Collection<HStoreFile> candidateFiles, List<HStoreFile> filesCompacting, boolean isUserCompaction, boolean mayUseOffPeak, boolean forceMajor) throws IOException {	if(forceMajor){	
major compaction is not supported for fifo compaction policy ignore the flag 

public CompactionRequestImpl selectCompaction(Collection<HStoreFile> candidateFiles, List<HStoreFile> filesCompacting, boolean isUserCompaction, boolean mayUseOffPeak, boolean forceMajor) throws IOException {	if(forceMajor){	}	boolean isAfterSplit = StoreUtils.hasReferences(candidateFiles);	if(isAfterSplit){	
split detected delegate selection to the parent policy 

public boolean shouldPerformMajorCompaction(Collection<HStoreFile> filesToCompact) throws IOException {	boolean isAfterSplit = StoreUtils.hasReferences(filesToCompact);	if(isAfterSplit){	
split detected delegate to the parent policy 

public boolean needsCompaction(Collection<HStoreFile> storeFiles, List<HStoreFile> filesCompacting) {	boolean isAfterSplit = StoreUtils.hasReferences(storeFiles);	if(isAfterSplit){	
split detected delegate to the parent policy 

========================= hbase sample_2696 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	cluster = null;	admin = null;	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1813 =========================

public void tearDown() throws Exception {	try {	wals.shutdown();	} catch (IOException exception) {	
ignoring failure to close wal factory 

public void tearDown() throws Exception {	try {	wals.shutdown();	} catch (IOException exception) {	
details of failure to close wal factory 

========================= hbase sample_1540 =========================

public BackupInfo getBackupInfo(String backupId) throws IOException {	BackupInfo backupInfo = null;	try (final BackupSystemTable table = new BackupSystemTable(conn)) {	if (backupId == null) {	ArrayList<BackupInfo> recentSessions = table.getBackupInfos(BackupState.RUNNING);	if (recentSessions.isEmpty()) {	
no ongoing sessions found 

public int deleteBackups(String[] backupIds) throws IOException {	int totalDeleted = 0;	Map<String, HashSet<TableName>> allTablesMap = new HashMap<String, HashSet<TableName>>();	boolean deleteSessionStarted = false;	boolean snapshotDone = false;	try (final BackupSystemTable sysTable = new BackupSystemTable(conn)) {	try {	sysTable.startBackupExclusiveOperation();	deleteSessionStarted = true;	} catch (IOException e) {	
you can not run delete command while active backup session is in progress if there is no active backup session running run backup repair utility to restore backup system integrity 

boolean snapshotDone = false;	try (final BackupSystemTable sysTable = new BackupSystemTable(conn)) {	try {	sysTable.startBackupExclusiveOperation();	deleteSessionStarted = true;	} catch (IOException e) {	return -1;	}	List<BackupInfo> list = sysTable.getBackupInfos(BackupState.RUNNING);	if (list.size() != 0) {	
failed backup session found run backup repair tool first 

return -1;	}	List<BackupInfo> list = sysTable.getBackupInfos(BackupState.RUNNING);	if (list.size() != 0) {	return -1;	}	sysTable.startDeleteOperation(backupIds);	if (!BackupSystemTable.snapshotExists(conn)) {	BackupSystemTable.snapshot(conn);	} else {	
backup system table snapshot exists 

}	}	finalizeDelete(allTablesMap, sysTable);	sysTable.finishDeleteOperation();	BackupSystemTable.deleteSnapshot(conn);	} catch (IOException e) {	if (snapshotDone) {	if (BackupSystemTable.snapshotExists(conn)) {	BackupSystemTable.restoreFromSnapshot(conn);	BackupSystemTable.deleteSnapshot(conn);	
delete operation failed please run backup repair utility to restore backup system integrity 

finalizeDelete(allTablesMap, sysTable);	sysTable.finishDeleteOperation();	BackupSystemTable.deleteSnapshot(conn);	} catch (IOException e) {	if (snapshotDone) {	if (BackupSystemTable.snapshotExists(conn)) {	BackupSystemTable.restoreFromSnapshot(conn);	BackupSystemTable.deleteSnapshot(conn);	throw e;	} else {	
delete operation succeeded there were some errors 

private int deleteBackup(String backupId, BackupSystemTable sysTable) throws IOException {	BackupInfo backupInfo = sysTable.readBackupInfo(backupId);	int totalDeleted = 0;	if (backupInfo != null) {	
deleting backup 

removeTableFromBackupImage(info, tn, sysTable);	}	}	Map<byte[], String> map = sysTable.readBulkLoadedFiles(backupId);	FileSystem fs = FileSystem.get(conn.getConfiguration());	boolean success = true;	int numDeleted = 0;	for (String f : map.values()) {	Path p = new Path(f);	try {	
delete backup info for 

}	Map<byte[], String> map = sysTable.readBulkLoadedFiles(backupId);	FileSystem fs = FileSystem.get(conn.getConfiguration());	boolean success = true;	int numDeleted = 0;	for (String f : map.values()) {	Path p = new Path(f);	try {	if (!fs.delete(p)) {	if (fs.exists(p)) {	
was not deleted 

Path p = new Path(f);	try {	if (!fs.delete(p)) {	if (fs.exists(p)) {	success = false;	}	} else {	numDeleted++;	}	} catch (IOException ioe) {	
was not deleted 

success = false;	}	} else {	numDeleted++;	}	} catch (IOException ioe) {	success = false;	}	}	if (LOG.isDebugEnabled()) {	
bulk loaded files out of were deleted 

} catch (IOException ioe) {	success = false;	}	}	if (LOG.isDebugEnabled()) {	}	if (success) {	sysTable.deleteBulkLoadedRows(new ArrayList<byte[]>(map.keySet()));	}	sysTable.deleteBackupInfo(backupInfo.getBackupId());	
delete backup completed 

private void cleanupBackupDir(BackupInfo backupInfo, TableName table, Configuration conf) throws IOException {	try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	
no target directory specified for 

private void cleanupBackupDir(BackupInfo backupInfo, TableName table, Configuration conf) throws IOException {	try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	return;	}	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	Path targetDirPath = new Path(BackupUtils.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	
cleaning up backup data at done 

private void cleanupBackupDir(BackupInfo backupInfo, TableName table, Configuration conf) throws IOException {	try {	String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	return;	}	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	Path targetDirPath = new Path(BackupUtils.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	
no data has been found in 

String targetDir = backupInfo.getBackupRootDir();	if (targetDir == null) {	return;	}	FileSystem outputFs = FileSystem.get(new Path(backupInfo.getBackupRootDir()).toUri(), conf);	Path targetDirPath = new Path(BackupUtils.getTableBackupDir(backupInfo.getBackupRootDir(), backupInfo.getBackupId(), table));	if (outputFs.delete(targetDirPath, true)) {	} else {	}	} catch (IOException e1) {	
cleaning up backup data of for table at failed due to 

String[] tableNames = new String[tables.length];	try (final BackupSystemTable table = new BackupSystemTable(conn);	final Admin admin = conn.getAdmin()) {	for (int i = 0; i < tables.length; i++) {	tableNames[i] = tables[i].getNameAsString();	if (!admin.tableExists(TableName.valueOf(tableNames[i]))) {	throw new IOException("Cannot add " + tableNames[i] + " because it doesn't exist");	}	}	table.addToBackupSet(name, tableNames);	
added tables to backup set 

public void removeFromBackupSet(String name, TableName[] tables) throws IOException {	
removing tables from 

public void removeFromBackupSet(String name, TableName[] tables) throws IOException {	try (final BackupSystemTable table = new BackupSystemTable(conn)) {	table.removeFromBackupSet(name, toStringArray(tables));	
removing tables from completed 

throw new IOException("Non-existing tables found in the table list: " + nonExistingTableList);	}	}	}	BackupRequest.Builder builder = new BackupRequest.Builder();	request = builder.withBackupType(request.getBackupType()).withTableList(tableList) .withTargetRootDir(request.getTargetRootDir()) .withBackupSetName(request.getBackupSetName()).withTotalTasks(request.getTotalTasks()) .withBandwidthPerTasks((int) request.getBandwidth()).build();	TableBackupClient client = null;	try {	client = BackupClientFactory.create(conn, backupId, request);	} catch (IOException e) {	
there is an active session already running 

========================= hbase sample_562 =========================

public void process() throws IOException {	long startTime = System.currentTimeMillis();	Status status = null;	try {	status = this.splitTaskExecutor.exec(splitTaskDetails.getWALFile(), reporter);	switch (status) {	case DONE: coordination.endTask(new SplitLogTask.Done(this.serverName), SplitLogCounters.tot_wkr_task_done, splitTaskDetails);	break;	case PREEMPTED: SplitLogCounters.tot_wkr_preempt_task.increment();	
task execution preempted 

switch (status) {	case DONE: coordination.endTask(new SplitLogTask.Done(this.serverName), SplitLogCounters.tot_wkr_task_done, splitTaskDetails);	break;	case PREEMPTED: SplitLogCounters.tot_wkr_preempt_task.increment();	break;	case ERR: if (server != null && !server.isStopped()) {	coordination.endTask(new SplitLogTask.Err(this.serverName), SplitLogCounters.tot_wkr_task_err, splitTaskDetails);	break;	}	case RESIGNED: if (server != null && server.isStopped()) {	
task execution interrupted because worker is exiting 

========================= hbase sample_2507 =========================

}	assertTrue(fs.exists(workingDir));	SnapshotDescriptionUtils.writeSnapshotInfo(snapshot, workingDir, fs);	doAnswer(__ -> {	addRegionToSnapshot(snapshot, region, manifest);	return null;	}).when(region).addRegionToSnapshot(snapshot, monitor);	FlushSnapshotSubprocedure.RegionSnapshotTask snapshotTask = new FlushSnapshotSubprocedure.RegionSnapshotTask(region, snapshot, true, monitor);	ExecutorService executor = Executors.newFixedThreadPool(1);	Future f = executor.submit(snapshotTask);	
starting major compaction 

assertTrue(fs.exists(workingDir));	SnapshotDescriptionUtils.writeSnapshotInfo(snapshot, workingDir, fs);	doAnswer(__ -> {	addRegionToSnapshot(snapshot, region, manifest);	return null;	}).when(region).addRegionToSnapshot(snapshot, monitor);	FlushSnapshotSubprocedure.RegionSnapshotTask snapshotTask = new FlushSnapshotSubprocedure.RegionSnapshotTask(region, snapshot, true, monitor);	ExecutorService executor = Executors.newFixedThreadPool(1);	Future f = executor.submit(snapshotTask);	region.compact(true);	
finished major compaction 

private void addRegionToSnapshot(SnapshotProtos.SnapshotDescription snapshot, HRegion region, SnapshotManifest manifest) throws Exception {	
adding region to snapshot 

private void addRegionToSnapshot(SnapshotProtos.SnapshotDescription snapshot, HRegion region, SnapshotManifest manifest) throws Exception {	Path workingDir = SnapshotDescriptionUtils.getWorkingSnapshotDir(snapshot, rootDir);	SnapshotManifest.RegionVisitor visitor = createRegionVisitorWithDelay(snapshot, workingDir);	manifest.addRegion(region, visitor);	
added the region to snapshot 

private SnapshotManifest.RegionVisitor createRegionVisitorWithDelay( SnapshotProtos.SnapshotDescription desc, Path workingDir) {	return new SnapshotManifestV2.ManifestBuilder(conf, fs, workingDir) {	public void storeFile(final SnapshotProtos.SnapshotRegionManifest.Builder region, final SnapshotProtos.SnapshotRegionManifest.FamilyFiles.Builder family, final StoreFileInfo storeFile) throws IOException {	try {	
introducing delay before adding store file to manifest 

private SnapshotManifest.RegionVisitor createRegionVisitorWithDelay( SnapshotProtos.SnapshotDescription desc, Path workingDir) {	return new SnapshotManifestV2.ManifestBuilder(conf, fs, workingDir) {	public void storeFile(final SnapshotProtos.SnapshotRegionManifest.Builder region, final SnapshotProtos.SnapshotRegionManifest.FamilyFiles.Builder family, final StoreFileInfo storeFile) throws IOException {	try {	Thread.sleep(2000);	} catch (InterruptedException ex) {	
interrupted due to error 

========================= hbase sample_1281 =========================

protected void postPeerModification(MasterProcedureEnv env) throws IOException {	
successfully added peer config ENABLED DISABLED 

========================= hbase sample_2854 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	
performing action split random region of table 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	
table doesn t have regions to split 

HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	if (context.isStopping()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	
splitting region 

if (regions == null || regions.isEmpty()) {	return;	}	if (context.isStopping()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	try {	admin.splitRegion(region.getRegionName());	} catch (Exception ex) {	
split failed might be caused by other chaos 

========================= hbase sample_3316 =========================

public abstract void setUpCluster() throws Exception;	public void cleanUpCluster() throws Exception {	if (util.isDistributedCluster() &&  (monkey == null || !monkey.isDestructive())) {	noClusterCleanUp = true;	}	if (noClusterCleanUp) {	
noclustercleanup is set skip restoring the cluster 

public abstract void setUpCluster() throws Exception;	public void cleanUpCluster() throws Exception {	if (util.isDistributedCluster() &&  (monkey == null || !monkey.isDestructive())) {	noClusterCleanUp = true;	}	if (noClusterCleanUp) {	return;	}	
restoring the cluster 

public abstract void setUpCluster() throws Exception;	public void cleanUpCluster() throws Exception {	if (util.isDistributedCluster() &&  (monkey == null || !monkey.isDestructive())) {	noClusterCleanUp = true;	}	if (noClusterCleanUp) {	return;	}	util.restoreCluster();	
done restoring the cluster 

========================= hbase sample_3253 =========================

public void testClusterRestart() throws Exception {	UTIL.startMiniCluster(3);	while (!UTIL.getMiniHBaseCluster().getMaster().isInitialized()) {	Threads.sleep(1);	}	
creating tables 

Threads.sleep(1);	}	for(TableName TABLE : TABLES) {	UTIL.createTable(TABLE, FAMILY);	}	for(TableName TABLE : TABLES) {	UTIL.waitTableEnabled(TABLE);	}	List<RegionInfo> allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	
shutting down cluster 

}	for(TableName TABLE : TABLES) {	UTIL.createTable(TABLE, FAMILY);	}	for(TableName TABLE : TABLES) {	UTIL.waitTableEnabled(TABLE);	}	List<RegionInfo> allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	UTIL.shutdownMiniHBaseCluster();	
sleeping a bit 

for(TableName TABLE : TABLES) {	UTIL.createTable(TABLE, FAMILY);	}	for(TableName TABLE : TABLES) {	UTIL.waitTableEnabled(TABLE);	}	List<RegionInfo> allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	UTIL.shutdownMiniHBaseCluster();	Thread.sleep(2000);	
starting cluster the second time 

for(TableName TABLE : TABLES) {	UTIL.waitTableEnabled(TABLE);	}	List<RegionInfo> allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	UTIL.shutdownMiniHBaseCluster();	Thread.sleep(2000);	UTIL.restartHBaseCluster(3);	allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	
waiting for tables to be available 

UTIL.shutdownMiniHBaseCluster();	Thread.sleep(2000);	UTIL.restartHBaseCluster(3);	allRegions = MetaTableAccessor.getAllRegions(UTIL.getConnection(), false);	assertEquals(4, allRegions.size());	for(TableName TABLE: TABLES) {	try {	UTIL.createTable(TABLE, FAMILY);	assertTrue("Able to create table that should already exist", false);	} catch(TableExistsException tee) {	
table already exists as expected 

public void testRetainAssignmentOnRestart() throws Exception {	UTIL.startMiniCluster(2);	while (!UTIL.getMiniHBaseCluster().getMaster().isInitialized()) {	Threads.sleep(1);	}	UTIL.getMiniHBaseCluster().getMaster(). getMasterRpcServices().synchronousBalanceSwitch(false);	
creating tables 

rsPorts[i] = threads.get(i).getRegionServer().getServerName().getPort();	}	rsPorts[2] = cluster.getMaster().getServerName().getPort();	for (ServerName serverName: regionToRegionServerMap.values()) {	boolean found = false;	for (int k = 0; k < 3 && !found; k++) {	found = serverName.getPort() == rsPorts[k];	}	assertTrue(found);	}	
shutting down hbase cluster 

rsPorts[2] = cluster.getMaster().getServerName().getPort();	for (ServerName serverName: regionToRegionServerMap.values()) {	boolean found = false;	for (int k = 0; k < 3 && !found; k++) {	found = serverName.getPort() == rsPorts[k];	}	assertTrue(found);	}	cluster.shutdown();	cluster.waitUntilShutDown();	
sleeping a bit 

for (ServerName serverName: regionToRegionServerMap.values()) {	boolean found = false;	for (int k = 0; k < 3 && !found; k++) {	found = serverName.getPort() == rsPorts[k];	}	assertTrue(found);	}	cluster.shutdown();	cluster.waitUntilShutDown();	Thread.sleep(2000);	
starting cluster the second time with the same ports 

========================= hbase sample_1794 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testModifyNonExistNamespace() throws Exception {	final String namespaceName = "testModifyNonExistNamespace";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	try {	NamespaceDescriptor nsDescriptor = UTIL.getAdmin().getNamespaceDescriptor(namespaceName);	assertNull(nsDescriptor);	} catch (NamespaceNotFoundException nsnfe) {	
the namespace does not exist this is expected 

try {	NamespaceDescriptor nsDescriptor = UTIL.getAdmin().getNamespaceDescriptor(namespaceName);	assertNull(nsDescriptor);	} catch (NamespaceNotFoundException nsnfe) {	}	final NamespaceDescriptor nsd = NamespaceDescriptor.create(namespaceName).build();	long procId = procExec.submitProcedure( new ModifyNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
modify namespace failed with exception 

final NamespaceDescriptor nsd = NamespaceDescriptor.create("testModifyNamespaceWithInvalidRegionCount").build();	final String nsKey = "hbase.namespace.quota.maxregions";	final String nsValue = "-1";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	createNamespaceForTesting(nsd);	nsd.setConfiguration(nsKey, nsValue);	long procId = procExec.submitProcedure( new ModifyNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
modify namespace failed with exception 

final NamespaceDescriptor nsd = NamespaceDescriptor.create("testModifyNamespaceWithInvalidTableCount").build();	final String nsKey = "hbase.namespace.quota.maxtables";	final String nsValue = "-1";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	createNamespaceForTesting(nsd);	nsd.setConfiguration(nsKey, nsValue);	long procId = procExec.submitProcedure( new ModifyNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
modify namespace failed with exception 

========================= hbase sample_1844 =========================

public void run(String[] backupIds) throws IOException {	String bulkOutputConfKey;	player = new MapReduceHFileSplitterJob();	bulkOutputConfKey = MapReduceHFileSplitterJob.BULK_OUTPUT_CONF_KEY;	String bids = StringUtils.join(backupIds, ",");	if (LOG.isDebugEnabled()) {	
merge backup images 

try {	table.startBackupExclusiveOperation();	table.startMergeOperation(backupIds);	String mergedBackupId = findMostRecentBackupId(backupIds);	TableName[] tableNames = getTableNamesInBackupImages(backupIds);	String backupRoot = null;	BackupInfo bInfo = table.readBackupInfo(backupIds[0]);	backupRoot = bInfo.getBackupRootDir();	checkFailure(FailurePhase.PHASE1);	for (int i = 0; i < tableNames.length; i++) {	
merge backup images for 

String backupRoot = null;	BackupInfo bInfo = table.readBackupInfo(backupIds[0]);	backupRoot = bInfo.getBackupRootDir();	checkFailure(FailurePhase.PHASE1);	for (int i = 0; i < tableNames.length; i++) {	Path[] dirPaths = findInputDirectories(fs, backupRoot, tableNames[i], backupIds);	String dirs = StringUtils.join(dirPaths, ",");	Path bulkOutputPath = BackupUtils.getBulkOutputDir(BackupUtils.getFileNameCompatibleString(tableNames[i]), getConf(), false);	if (fs.exists(bulkOutputPath)) {	if (!fs.delete(bulkOutputPath, true)) {	
can not delete 

String[] playerArgs = { dirs, tableNames[i].getNameAsString() };	int result = 0;	checkFailure(FailurePhase.PHASE2);	player.setConf(getConf());	result = player.run(playerArgs);	if (succeeded(result)) {	processedTableList.add(new Pair<TableName, Path>(tableNames[i], bulkOutputPath));	} else {	throw new IOException("Can not merge backup images for " + dirs + " (check Hadoop/MR and HBase logs). Player return code =" + result);	}	
merge job finished 

public void TestIncBackupMergeRestore() throws Exception {	int ADD_ROWS = 99;	
create full backup image for all tables 

List<TableName> tables = Lists.newArrayList(table1, table2);	conf1.setClass(BackupRestoreFactory.HBASE_BACKUP_MERGE_IMPL_CLASS, BackupMergeJobWithFailures.class, BackupMergeJob.class);	Connection conn = ConnectionFactory.createConnection(conf1);	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	
writing rows to 

Connection conn = ConnectionFactory.createConnection(conf1);	HBaseAdmin admin = null;	admin = (HBaseAdmin) conn.getAdmin();	BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH + ADD_ROWS);	t1.close();	
written rows to 

BackupAdminImpl client = new BackupAdminImpl(conn);	BackupRequest request = createBackupRequest(BackupType.FULL, tables, BACKUP_ROOT_DIR);	String backupIdFull = client.backupTables(request);	assertTrue(checkSucceeded(backupIdFull));	HTable t1 = insertIntoTable(conn, table1, famName, 1, ADD_ROWS);	Assert.assertEquals(TEST_UTIL.countRows(t1), NB_ROWS_IN_BATCH + ADD_ROWS);	t1.close();	HTable t2 = insertIntoTable(conn, table2, famName, 1, ADD_ROWS);	Assert.assertEquals(TEST_UTIL.countRows(t2), NB_ROWS_IN_BATCH + ADD_ROWS);	t2.close();	
written rows to 

assertTrue(table.isMergeInProgress());	try {	table.startBackupExclusiveOperation();	Assert.fail("IOException is expected");	} catch(IOException ee) {	table.finishMergeOperation();	table.finishBackupExclusiveOperation();	}	}	table.close();	
expected 

conf.unset(FAILURE_PHASE_KEY);	conf.unset(BackupRestoreFactory.HBASE_BACKUP_MERGE_IMPL_CLASS);	try (BackupAdmin bAdmin = new BackupAdminImpl(conn)) {	String[] backups = new String[] { backupIdIncMultiple, backupIdIncMultiple2 };	bAdmin.mergeBackups(backups);	}	TableName[] tablesRestoreIncMultiple = new TableName[] { table1, table2 };	TableName[] tablesMapIncMultiple = new TableName[] { table1_restore, table2_restore };	client.restore(BackupUtils.createRestoreRequest(BACKUP_ROOT_DIR, backupIdIncMultiple2, false, tablesRestoreIncMultiple, tablesMapIncMultiple, true));	Table hTable = conn.getTable(table1_restore);	
after incremental restore 

conf.unset(FAILURE_PHASE_KEY);	conf.unset(BackupRestoreFactory.HBASE_BACKUP_MERGE_IMPL_CLASS);	try (BackupAdmin bAdmin = new BackupAdminImpl(conn)) {	String[] backups = new String[] { backupIdIncMultiple, backupIdIncMultiple2 };	bAdmin.mergeBackups(backups);	}	TableName[] tablesRestoreIncMultiple = new TableName[] { table1, table2 };	TableName[] tablesMapIncMultiple = new TableName[] { table1_restore, table2_restore };	client.restore(BackupUtils.createRestoreRequest(BACKUP_ROOT_DIR, backupIdIncMultiple2, false, tablesRestoreIncMultiple, tablesMapIncMultiple, true));	Table hTable = conn.getTable(table1_restore);	
has rows 

========================= hbase sample_535 =========================

public ServerName setRegionLocation(final ServerName serverName) {	ServerName lastRegionLocation = this.regionLocation;	if (LOG.isTraceEnabled() && serverName == null) {	
tracking when we are set to null TRACE 

public void deleteRegion(final RegionInfo regionInfo) {	regionsMap.remove(regionInfo.getRegionName());	if (this.regionOffline.containsKey(regionInfo)) {	
removing from regionoffline map 

public Map<TableName, Map<ServerName, List<RegionInfo>>> getAssignmentsByTable() {	final Map<TableName, Map<ServerName, List<RegionInfo>>> result = new HashMap<>();	for (RegionStateNode node: regionsMap.values()) {	Map<ServerName, List<RegionInfo>> tableResult = result.get(node.getTable());	if (tableResult == null) {	tableResult = new HashMap<ServerName, List<RegionInfo>>();	result.put(node.getTable(), tableResult);	}	final ServerName serverName = node.getRegionLocation();	if (serverName == null) {	
skipping no server for 

public void addToOfflineRegions(final RegionStateNode regionNode) {	
added to offline currently never cleared 

========================= hbase sample_2784 =========================

zk.addAuthInfo("digest", "hbase:rox".getBytes());	Stat s = null;	List<ACL> oldACL = null;	while (true) {	try {	s = new Stat();	oldACL = zk.getACL("/", s);	break;	} catch (KeeperException e) {	switch (e.code()) {	
possibly transient zookeeper exception 

default: throw e;	}	}	}	while (true) {	try {	zk.setACL("/", ZooDefs.Ids.CREATOR_ALL_ACL, -1);	break;	} catch (KeeperException e) {	switch (e.code()) {	
possibly transient zookeeper exception 

default: throw e;	}	}	}	while (true) {	try {	zk.create(aclZnode, null, ZooDefs.Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);	break;	} catch (KeeperException e) {	switch (e.code()) {	
possibly transient zookeeper exception 

public void abort(String why, Throwable e) {	
zkwatcher received abort ignoring reason 

========================= hbase sample_722 =========================

public void chore() {	if (regionServerServices == null) return;	List<HRegion> onlineRegions = (List<HRegion>) regionServerServices.getRegions();	if (onlineRegions == null) return;	for (HRegion region : onlineRegions) {	if (LOG.isTraceEnabled()) {	
started compacted hfiles cleaner on 

}	for (HStore store : region.getStores()) {	try {	if (useExecutor && regionServerServices != null) {	CompactedHFilesDischargeHandler handler = new CompactedHFilesDischargeHandler( (Server) regionServerServices, EventType.RS_COMPACTED_FILES_DISCHARGER, store);	regionServerServices.getExecutorService().submit(handler);	} else {	store.closeAndArchiveCompactedFiles();	}	if (LOG.isTraceEnabled()) {	
completed archiving the compacted files for the region under the store 

try {	if (useExecutor && regionServerServices != null) {	CompactedHFilesDischargeHandler handler = new CompactedHFilesDischargeHandler( (Server) regionServerServices, EventType.RS_COMPACTED_FILES_DISCHARGER, store);	regionServerServices.getExecutorService().submit(handler);	} else {	store.closeAndArchiveCompactedFiles();	}	if (LOG.isTraceEnabled()) {	}	} catch (Exception e) {	
exception while trying to close and archive the compacted store files of the store in the region 

regionServerServices.getExecutorService().submit(handler);	} else {	store.closeAndArchiveCompactedFiles();	}	if (LOG.isTraceEnabled()) {	}	} catch (Exception e) {	}	}	if (LOG.isTraceEnabled()) {	
completed the compacted hfiles cleaner for the region 

========================= hbase sample_2593 =========================

public void deregister(MetricsRegionSource toRemove) {	try {	regionSources.remove(toRemove);	} catch (Exception e) {	
error trying to remove from 

========================= hbase sample_688 =========================

byte[] prevRow = null;	for (byte[] row : rows) {	if (prevRow == null || !Bytes.equals(prevRow, row)) {	qm.setToNewRow(KeyValueUtil.createFirstOnRow(row));	prevRow = row;	}	actual.add(qm.match(new KeyValue(row, fam2, null, now, Type.Delete)));	}	assertEquals(expected.length, actual.size());	for (int i = 0; i < expected.length; i++) {	
expected actual 

========================= hbase sample_1700 =========================

public Collection<HStoreFile> getUnneededFiles(long maxTs, List<HStoreFile> filesCompacting) {	ImmutableList<HStoreFile> files = storefiles;	return files.stream().limit(Math.max(0, files.size() - 1)).filter(sf -> {	long fileTs = sf.getReader().getMaxTimestamp();	if (fileTs < maxTs && !filesCompacting.contains(sf)) {	
found an expired store file whose maxtimestamp is which is below 

========================= hbase sample_2655 =========================

public static BloomFilterWriter createGeneralBloomAtWrite(Configuration conf, CacheConfig cacheConf, BloomType bloomType, int maxKeys, HFile.Writer writer) {	if (!isGeneralBloomEnabled(conf)) {	LOG.trace("Bloom filters are disabled by configuration for " + writer.getPath() + (conf == null ? " (configuration is null)" : ""));	return null;	} else if (bloomType == BloomType.NONE) {	
bloom filter is turned off for the column family 

========================= hbase sample_2205 =========================

private Path getOutputPath(final SnapshotFileInfo inputInfo) throws IOException {	Path path = null;	switch (inputInfo.getType()) {	case HFILE: Path inputPath = new Path(inputInfo.getHfile());	String family = inputPath.getParent().getName();	TableName table =HFileLink.getReferencedTableName(inputPath.getName());	String region = HFileLink.getReferencedRegionName(inputPath.getName());	String hfile = HFileLink.getReferencedHFileName(inputPath.getName());	path = new Path(FSUtils.getTableDir(new Path("./"), table), new Path(region, new Path(family, hfile)));	break;	
snapshot does not keeps wals 

private void injectTestFailure(final Context context, final SnapshotFileInfo inputInfo) throws IOException {	if (!context.getConfiguration().getBoolean(Testing.CONF_TEST_FAILURE, false)) return;	if (testing.injectedFailureCount >= testing.failuresCountToInject) return;	testing.injectedFailureCount++;	context.getCounter(Counter.COPY_FAILED).increment(1);	
injecting failure count 

private void copyFile(final Context context, final SnapshotFileInfo inputInfo, final Path outputPath) throws IOException {	FileStatus inputStat = getSourceFileStatus(context, inputInfo);	if (outputFs.exists(outputPath)) {	FileStatus outputStat = outputFs.getFileStatus(outputPath);	if (outputStat != null && sameFile(inputStat, outputStat)) {	
skip copy to same file 

try {	context.getCounter(Counter.BYTES_EXPECTED).increment(inputStat.getLen());	createOutputPath(outputPath.getParent());	FSDataOutputStream out = outputFs.create(outputPath, true);	try {	copyData(context, inputStat.getPath(), in, outputPath, out, inputStat.getLen());	} finally {	out.close();	}	if (!preserveAttributes(outputPath, inputStat)) {	
you may have to run manually chown on 

context.getCounter(Counter.BYTES_COPIED).increment(reportBytes);	context.setStatus(String.format(statusMessage, StringUtils.humanReadableInt(totalBytesWritten), (totalBytesWritten/(float)inputFileSize) * 100.0f) + " from " + inputPath + " to " + outputPath);	if (totalBytesWritten != inputFileSize) {	String msg = "number of bytes copied not matching copied=" + totalBytesWritten + " expected=" + inputFileSize + " for file=" + inputPath;	throw new IOException(msg);	}	LOG.info("copy completed for input=" + inputPath + " output=" + outputPath);	LOG.info("size=" + totalBytesWritten + " (" + StringUtils.humanReadableInt(totalBytesWritten) + ")" + " time=" + StringUtils.formatTimeDiff(etime, stime) + String.format(" %.3fM/sec", (totalBytesWritten / ((etime - stime)/1000.0))/1048576.0));	context.getCounter(Counter.FILES_COPIED).increment(1);	} catch (IOException e) {	
error copying to 

private static List<Pair<SnapshotFileInfo, Long>> getSnapshotFiles(final Configuration conf, final FileSystem fs, final Path snapshotDir) throws IOException {	SnapshotDescription snapshotDesc = SnapshotDescriptionUtils.readSnapshotInfo(fs, snapshotDir);	final List<Pair<SnapshotFileInfo, Long>> files = new ArrayList<>();	final TableName table = TableName.valueOf(snapshotDesc.getTable());	
loading snapshot hfile list 

public int doWork() throws IOException {	Configuration conf = getConf();	if (snapshotName == null) {	System.err.println("Snapshot name not provided.");	
use h or help for usage instructions 

public int doWork() throws IOException {	Configuration conf = getConf();	if (snapshotName == null) {	System.err.println("Snapshot name not provided.");	return 0;	}	if (outputRoot == null) {	System.err.println("Destination file-system (--" + Options.COPY_TO.getLongOpt() + ") not provided.");	
use h or help for usage instructions 

}	} else {	System.err.println("A snapshot with the same name '"+ targetName +"' may be in-progress");	System.err.println("Please check "+snapshotTmpDir+". If the snapshot has completed, ");	System.err.println("consider removing "+snapshotTmpDir+" by using the -overwrite option");	return 1;	}	}	}	try {	
copy snapshot manifest 

try {	FileUtil.copy(inputFs, snapshotDir, outputFs, initialOutputSnapshotDir, false, false, conf);	} catch (IOException e) {	throw new ExportSnapshotException("Failed to copy the snapshot directory: from=" + snapshotDir + " to=" + initialOutputSnapshotDir, e);	} finally {	if (filesUser != null || filesGroup != null) {	LOG.warn((filesUser == null ? "" : "Change the owner of " + needSetOwnerDir + " to " + filesUser) + (filesGroup == null ? "" : ", Change the group of " + needSetOwnerDir + " to " + filesGroup));	setOwner(outputFs, needSetOwnerDir, filesUser, filesGroup, true);	}	if (filesMode > 0) {	
change the permission of to 

SnapshotDescriptionUtils.writeSnapshotInfo(snapshotDesc, initialOutputSnapshotDir, outputFs);	if (filesUser != null || filesGroup != null) {	outputFs.setOwner(new Path(initialOutputSnapshotDir, SnapshotDescriptionUtils.SNAPSHOTINFO_FILE), filesUser, filesGroup);	}	if (filesMode > 0) {	outputFs.setPermission(new Path(initialOutputSnapshotDir, SnapshotDescriptionUtils.SNAPSHOTINFO_FILE), new FsPermission((short)filesMode));	}	}	try {	runCopyJob(inputRoot, outputRoot, snapshotName, snapshotDir, verifyChecksum, filesUser, filesGroup, filesMode, mappers, bandwidthMB);	
finalize the snapshot export 

}	}	try {	runCopyJob(inputRoot, outputRoot, snapshotName, snapshotDir, verifyChecksum, filesUser, filesGroup, filesMode, mappers, bandwidthMB);	if (!skipTmp) {	if (!outputFs.rename(snapshotTmpDir, outputSnapshotDir)) {	throw new ExportSnapshotException("Unable to rename snapshot directory from=" + snapshotTmpDir + " to=" + outputSnapshotDir);	}	}	if (verifyTarget) {	
verify snapshot integrity 

try {	runCopyJob(inputRoot, outputRoot, snapshotName, snapshotDir, verifyChecksum, filesUser, filesGroup, filesMode, mappers, bandwidthMB);	if (!skipTmp) {	if (!outputFs.rename(snapshotTmpDir, outputSnapshotDir)) {	throw new ExportSnapshotException("Unable to rename snapshot directory from=" + snapshotTmpDir + " to=" + outputSnapshotDir);	}	}	if (verifyTarget) {	verifySnapshot(destConf, outputFs, outputRoot, outputSnapshotDir);	}	
export completed 

if (!skipTmp) {	if (!outputFs.rename(snapshotTmpDir, outputSnapshotDir)) {	throw new ExportSnapshotException("Unable to rename snapshot directory from=" + snapshotTmpDir + " to=" + outputSnapshotDir);	}	}	if (verifyTarget) {	verifySnapshot(destConf, outputFs, outputRoot, outputSnapshotDir);	}	return 0;	} catch (Exception e) {	
snapshot export failed 

========================= hbase sample_3414 =========================

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	
refreshing space quotas in regionserver 

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	}	long start = System.nanoTime();	_chore();	if (metrics != null) {	metrics.incrementQuotaObserverTime((System.nanoTime() - start) / 1_000_000);	}	} catch (IOException e) {	
failed to process quota reports and update quota state will retry 

public Set<TableName> filterInsufficientlyReportedTables( QuotaSnapshotStore<TableName> tableStore) throws IOException {	final double percentRegionsReportedThreshold = getRegionReportPercent(getConfiguration());	Set<TableName> tablesToRemove = new HashSet<>();	for (TableName table : Iterables.concat(tablesWithTableQuotas, tablesWithNamespaceQuotas)) {	if (tablesToRemove.contains(table)) {	continue;	}	final int numRegionsInTable = getNumRegions(table);	if (numRegionsInTable == 0) {	if (LOG.isTraceEnabled()) {	
filtering because no regions were reported 

if (numRegionsInTable == 0) {	if (LOG.isTraceEnabled()) {	}	tablesToRemove.add(table);	continue;	}	final int reportedRegionsInQuota = getNumReportedRegions(table, tableStore);	final double ratioReported = ((double) reportedRegionsInQuota) / numRegionsInTable;	if (ratioReported < percentRegionsReportedThreshold) {	if (LOG.isTraceEnabled()) {	
filtering because of regions were reported 

tablesToRemove.add(table);	continue;	}	final int reportedRegionsInQuota = getNumReportedRegions(table, tableStore);	final double ratioReported = ((double) reportedRegionsInQuota) / numRegionsInTable;	if (ratioReported < percentRegionsReportedThreshold) {	if (LOG.isTraceEnabled()) {	}	tablesToRemove.add(table);	} else if (LOG.isTraceEnabled()) {	
retaining because of regions were reported 

========================= hbase sample_2340 =========================

CoprocessorRpcChannel channel = table.coprocessorService(ROW);	RowProcessorEndpoint.FriendsOfFriendsProcessor processor = new RowProcessorEndpoint.FriendsOfFriendsProcessor(ROW, A);	RowProcessorService.BlockingInterface service = RowProcessorService.newBlockingStub(channel);	ProcessRequest request = RowProcessorClient.getRowProcessorPB(processor);	ProcessResponse protoResult = service.process(null, request);	FriendsOfFriendsProcessorResponse response = FriendsOfFriendsProcessorResponse.parseFrom(protoResult.getRowProcessorResult());	Set<String> result = new HashSet<>();	result.addAll(response.getResultList());	Set<String> expected = new HashSet<>(Arrays.asList(new String[]{"d", "e", "f", "g"}));	Get get = new Get(ROW);	
row keyvalues 

public void testReadModifyWrite() throws Throwable {	prepareTestData();	failures.set(0);	int numThreads = 100;	concurrentExec(new IncrementRunner(), numThreads);	Get get = new Get(ROW);	
row keyvalues 

public void testReadModifyWrite() throws Throwable {	prepareTestData();	failures.set(0);	int numThreads = 100;	concurrentExec(new IncrementRunner(), numThreads);	Get get = new Get(ROW);	int finalCounter = incrementCounter(table);	int failureNumber = failures.get();	if (failureNumber > 0) {	
we failed times during test 

public void testMultipleRows() throws Throwable {	prepareTestData();	failures.set(0);	int numThreads = 100;	concurrentExec(new SwapRowsRunner(), numThreads);	
row keyvalues 

public void testMultipleRows() throws Throwable {	prepareTestData();	failures.set(0);	int numThreads = 100;	concurrentExec(new SwapRowsRunner(), numThreads);	
keyvalues 

public void testMultipleRows() throws Throwable {	prepareTestData();	failures.set(0);	int numThreads = 100;	concurrentExec(new SwapRowsRunner(), numThreads);	int failureNumber = failures.get();	if (failureNumber > 0) {	
we failed times during test 

========================= hbase sample_1242 =========================

public void testGetLastGCInfo() {	List<GarbageCollectorMXBean> gcBeans = ManagementFactory.getGarbageCollectorMXBeans();	for(GarbageCollectorMXBean bean:gcBeans) {	ObjectName on = bean.getObjectName();	Object value = JSONMetricUtil.getValueFromMBean(on, "LastGcInfo");	
collector info 

========================= hbase sample_1307 =========================

public boolean isFileDeletable(FileStatus fStat) {	if (!MasterProcedureUtil.validateProcedureWALFilename(fStat.getPath().getName())) {	return true;	}	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	
procedure log life ttl current from 

public boolean isFileDeletable(FileStatus fStat) {	if (!MasterProcedureUtil.validateProcedureWALFilename(fStat.getPath().getName())) {	return true;	}	long currentTime = EnvironmentEdgeManager.currentTime();	long time = fStat.getModificationTime();	long life = currentTime - time;	if (LOG.isTraceEnabled()) {	}	if (life < 0) {	
found a procedure log newer than current time probably a clock skew 

========================= hbase sample_2878 =========================

try {	final TableName tableName = TableName.valueOf(name.getMethodName());	final byte[] FAMILY = Bytes.toBytes("family");	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster master = cluster.getMaster();	HTableDescriptor desc = new HTableDescriptor(tableName);	desc.addFamily(new HColumnDescriptor(FAMILY));	hbaseAdmin = master.getConnection().getAdmin();	hbaseAdmin.createTable(desc);	assertTrue(hbaseAdmin.isTableAvailable(tableName));	
loading to into 

HRegionInfo regionInfo;	try (RegionLocator locator = TEST_UTIL.getConnection().getRegionLocator(tableName)) {	regionInfo = locator.getRegionLocation(Bytes.toBytes("r1")).getRegionInfo();	}	int originServerNum = cluster.getServerWith(regionInfo.getRegionName());	HRegionServer originServer = cluster.getRegionServer(originServerNum);	int targetServerNum = (originServerNum + 1) % NUM_RS;	HRegionServer targetServer = cluster.getRegionServer(targetServerNum);	assertFalse(originServer.equals(targetServer));	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	
moving to 

int originServerNum = cluster.getServerWith(regionInfo.getRegionName());	HRegionServer originServer = cluster.getRegionServer(originServerNum);	int targetServerNum = (originServerNum + 1) % NUM_RS;	HRegionServer targetServer = cluster.getRegionServer(targetServerNum);	assertFalse(originServer.equals(targetServer));	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(targetServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == originServerNum);	
loading to into 

int targetServerNum = (originServerNum + 1) % NUM_RS;	HRegionServer targetServer = cluster.getRegionServer(targetServerNum);	assertFalse(originServer.equals(targetServer));	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(targetServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == originServerNum);	putDataAndVerify(table, "r2", FAMILY, "v2", 2);	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	
moving to 

hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(targetServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == originServerNum);	putDataAndVerify(table, "r2", FAMILY, "v2", 2);	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(originServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == targetServerNum);	
loading to into 

do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == originServerNum);	putDataAndVerify(table, "r2", FAMILY, "v2", 2);	TEST_UTIL.waitUntilAllRegionsAssigned(table.getName());	hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(originServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == targetServerNum);	putDataAndVerify(table, "r3", FAMILY, "v3", 3);	
killing target server 

hbaseAdmin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(originServer.getServerName().getServerName()));	do {	Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == targetServerNum);	putDataAndVerify(table, "r3", FAMILY, "v3", 3);	targetServer.kill();	cluster.getRegionServerThreads().get(targetServerNum).join();	while (master.getServerManager().areDeadServersInProgress()) {	Thread.sleep(5);	}	
killing origin server 

Thread.sleep(1);	} while (cluster.getServerWith(regionInfo.getRegionName()) == targetServerNum);	putDataAndVerify(table, "r3", FAMILY, "v3", 3);	targetServer.kill();	cluster.getRegionServerThreads().get(targetServerNum).join();	while (master.getServerManager().areDeadServersInProgress()) {	Thread.sleep(5);	}	originServer.kill();	cluster.getRegionServerThreads().get(originServerNum).join();	
loading to into 

========================= hbase sample_1757 =========================

public void abortProcedure(String procName, ForeignException reason) {	
abort procedure 

public Procedure startProcedure(ForeignExceptionDispatcher fed, String procName, byte[] procArgs, List<String> expectedMembers) {	Procedure proc = createProcedure(fed, procName, procArgs, expectedMembers);	if (!this.submitProcedure(proc)) {	
failed to submit procedure 

========================= hbase sample_2481 =========================

protected void periodicExecute(final TestProcEnv env) {	
periodic execute 

========================= hbase sample_1184 =========================

public void testClockSkewDetection() throws Exception {	final Configuration conf = HBaseConfiguration.create();	ServerManager sm = new ServerManager(new MockNoopMasterServices(conf) {	public ClusterConnection getClusterConnection() {	ClusterConnection conn = mock(ClusterConnection.class);	when(conn.getRpcControllerFactory()).thenReturn(mock(RpcControllerFactory.class));	return conn;	}	}, true);	
regionserverstartup 

InetAddress ia1 = InetAddress.getLocalHost();	RegionServerStartupRequest.Builder request = RegionServerStartupRequest.newBuilder();	request.setPort(1234);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis());	sm.regionServerStartup(request.build(), ia1);	final Configuration c = HBaseConfiguration.create();	long maxSkew = c.getLong("hbase.master.maxclockskew", 30000);	long warningSkew = c.getLong("hbase.master.warningclockskew", 1000);	try {	
test master time region server time 

InetAddress ia1 = InetAddress.getLocalHost();	RegionServerStartupRequest.Builder request = RegionServerStartupRequest.newBuilder();	request.setPort(1234);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis());	sm.regionServerStartup(request.build(), ia1);	final Configuration c = HBaseConfiguration.create();	long maxSkew = c.getLong("hbase.master.maxclockskew", 30000);	long warningSkew = c.getLong("hbase.master.warningclockskew", 1000);	try {	
regionserverstartup 

long warningSkew = c.getLong("hbase.master.warningclockskew", 1000);	try {	InetAddress ia2 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1235);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() - maxSkew * 2);	sm.regionServerStartup(request.build(), ia2);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch(ClockOutOfSyncException e) {	
received expected exception 

InetAddress ia2 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1235);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() - maxSkew * 2);	sm.regionServerStartup(request.build(), ia2);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch(ClockOutOfSyncException e) {	}	try {	
test master time region server time 

InetAddress ia2 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1235);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() - maxSkew * 2);	sm.regionServerStartup(request.build(), ia2);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch(ClockOutOfSyncException e) {	}	try {	
regionserverstartup 

}	try {	InetAddress ia3 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1236);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() + maxSkew * 2);	sm.regionServerStartup(request.build(), ia3);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch (ClockOutOfSyncException e) {	
received expected exception 

try {	InetAddress ia3 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1236);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() + maxSkew * 2);	sm.regionServerStartup(request.build(), ia3);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch (ClockOutOfSyncException e) {	}	
regionserverstartup 

sm.regionServerStartup(request.build(), ia3);	fail("HMaster should have thrown a ClockOutOfSyncException but didn't.");	} catch (ClockOutOfSyncException e) {	}	InetAddress ia4 = InetAddress.getLocalHost();	request = RegionServerStartupRequest.newBuilder();	request.setPort(1237);	request.setServerStartCode(-1);	request.setServerCurrentTime(System.currentTimeMillis() - warningSkew * 2);	sm.regionServerStartup(request.build(), ia4);	
regionserverstartup 

========================= hbase sample_1887 =========================

public void run() {	for (RegionScanner scanner : scanners) {	try {	scanner.close();	} catch (IOException e) {	
exception while closing the scanner 

public void leaseExpired() {	RegionScannerHolder rsh = scanners.remove(this.scannerName);	if (rsh != null) {	RegionScanner s = rsh.s;	
scanner lease expired on region 

RegionScannerHolder rsh = scanners.remove(this.scannerName);	if (rsh != null) {	RegionScanner s = rsh.s;	HRegion region = null;	try {	region = regionServer.getRegion(s.getRegionInfo().getRegionName());	if (region != null && region.getCoprocessorHost() != null) {	region.getCoprocessorHost().preScannerClose(s);	}	} catch (IOException e) {	
closing scanner for 

region.getCoprocessorHost().preScannerClose(s);	}	} catch (IOException e) {	} finally {	try {	s.close();	if (region != null && region.getCoprocessorHost() != null) {	region.getCoprocessorHost().postScannerClose(s);	}	} catch (IOException e) {	
closing scanner for 

} finally {	try {	s.close();	if (region != null && region.getCoprocessorHost() != null) {	region.getCoprocessorHost().postScannerClose(s);	}	} catch (IOException e) {	}	}	} else {	
scanner lease expired but no related scanner found hence no chance to close that related scanner 

private void closeAllScanners() {	for (Map.Entry<String, RegionScannerHolder> e : scanners.entrySet()) {	try {	e.getValue().s.close();	} catch (IOException ioe) {	
closing scanner 

public static String getHostname(Configuration conf, boolean isMaster) throws UnknownHostException {	String hostname = conf.get(isMaster? HRegionServer.MASTER_HOSTNAME_KEY : HRegionServer.RS_HOSTNAME_KEY);	if (hostname == null || hostname.isEmpty()) {	String masterOrRS = isMaster ? "master" : "regionserver";	return Strings.domainNamePointerToHostName(DNS.getDefaultHost( conf.get("hbase." + masterOrRS + ".dns.interface", "default"), conf.get("hbase." + masterOrRS + ".dns.nameserver", "default")));	} else {	
hostname is configured to be 

public static boolean exitIfOOME(final Throwable e ){	boolean stop = false;	try {	if (e instanceof OutOfMemoryError || (e.getCause() != null && e.getCause() instanceof OutOfMemoryError) || (e.getMessage() != null && e.getMessage().contains( "java.lang.OutOfMemoryError"))) {	stop = true;	
run out of memory will abort itself immediately 

checkOpen();	if (request.hasServerStartCode()) {	long serverStartCode = request.getServerStartCode();	if (regionServer.serverName.getStartcode() !=  serverStartCode) {	throw new ServiceException(new DoNotRetryIOException("This RPC was intended for a " + "different server with startCode: " + serverStartCode + ", this server is: " + regionServer.serverName));	}	}	final String encodedRegionName = ProtobufUtil.getRegionEncodedName(request.getRegion());	requestCount.increment();	if (sn == null) {	
close without moving 

if (request.hasServerStartCode()) {	long serverStartCode = request.getServerStartCode();	if (regionServer.serverName.getStartcode() !=  serverStartCode) {	throw new ServiceException(new DoNotRetryIOException("This RPC was intended for a " + "different server with startCode: " + serverStartCode + ", this server is: " + regionServer.serverName));	}	}	final String encodedRegionName = ProtobufUtil.getRegionEncodedName(request.getRegion());	requestCount.increment();	if (sn == null) {	} else {	
close moving to 

public CompactRegionResponse compactRegion(final RpcController controller, final CompactRegionRequest request) throws ServiceException {	try {	checkOpen();	requestCount.increment();	HRegion region = getRegion(request.getRegion());	if (QuotaUtil.isQuotaEnabled(getConfiguration()) && !Superusers.isSuperUser(RpcServer.getRequestUser().orElse(null)) && this.regionServer.getRegionServerSpaceQuotaManager() .areCompactionsDisabled(region.getTableDescriptor().getTableName())) {	throw new DoNotRetryIOException( "Compactions on this region are " + "disabled due to a space quota violation.");	}	region.startRegionOperation(Operation.COMPACT_REGION);	
compacting 

public FlushRegionResponse flushRegion(final RpcController controller, final FlushRegionRequest request) throws ServiceException {	try {	checkOpen();	requestCount.increment();	HRegion region = getRegion(request.getRegion());	
flushing 

public ClearCompactionQueuesResponse clearCompactionQueues(RpcController controller, ClearCompactionQueuesRequest request) throws ServiceException {	LOG.debug("Client=" + RpcServer.getRequestUserName().orElse(null) + "/" + RpcServer.getRemoteAddress().orElse(null) + " clear compactions queue");	ClearCompactionQueuesResponse.Builder respBuilder = ClearCompactionQueuesResponse.newBuilder();	requestCount.increment();	if (clearCompactionQueues.compareAndSet(false,true)) {	try {	checkOpen();	regionServer.getRegionServerCoprocessorHost().preClearCompactionQueues();	for (String queueName : request.getQueueNameList()) {	
clear compaction queue 

if (clearCompactionQueues.compareAndSet(false,true)) {	try {	checkOpen();	regionServer.getRegionServerCoprocessorHost().preClearCompactionQueues();	for (String queueName : request.getQueueNameList()) {	switch (queueName) {	case "long": regionServer.compactSplitThread.clearLongCompactionsQueue();	break;	case "short": regionServer.compactSplitThread.clearShortCompactionsQueue();	break;	
unknown queue name 

throw new IOException("Unknown queue name " + queueName);	}	}	regionServer.getRegionServerCoprocessorHost().postClearCompactionQueues();	} catch (IOException ie) {	throw new ServiceException(ie);	} finally {	clearCompactionQueues.set(false);	}	} else {	
clear compactions queue is executing by other admin 

try {	String encodedName = region.getEncodedName();	byte[] encodedNameBytes = region.getEncodedNameAsBytes();	final HRegion onlineRegion = regionServer.getRegion(encodedName);	if (onlineRegion != null) {	String error = "Received OPEN for the region:" + region.getRegionNameAsString() + ", which is already online";	LOG.warn(error);	builder.addOpeningState(RegionOpeningState.OPENED);	continue;	}	
open 

final Boolean previous = regionServer.regionsInTransitionInRS.putIfAbsent( encodedNameBytes, Boolean.TRUE);	if (Boolean.FALSE.equals(previous)) {	if (regionServer.getRegion(encodedName) != null) {	String error = "Received OPEN for the region:" + region.getRegionNameAsString() + ", which we are already trying to CLOSE";	regionServer.abort(error);	throw new IOException(error);	}	regionServer.regionsInTransitionInRS.put(encodedNameBytes, Boolean.TRUE);	}	if (Boolean.TRUE.equals(previous)) {	
receiving open for the region which we are already trying to open ignoring this new request for this region 

if (previous == null || !previous.booleanValue()) {	htd = htds.get(region.getTable());	if (htd == null) {	htd = regionServer.tableDescriptors.get(region.getTable());	htds.put(region.getTable(), htd);	}	if (htd == null) {	throw new IOException("Missing table descriptor for " + region.getEncodedName());	}	if (regionServer.executorService == null) {	
no executor executorservice skipping open request 

if (htd.getPriority() >= HConstants.ADMIN_QOS || region.getTable().isSystemTable()) {	regionServer.executorService.submit(new OpenPriorityRegionHandler( regionServer, regionServer, region, htd, masterSystemTime));	} else {	regionServer.executorService.submit(new OpenRegionHandler( regionServer, regionServer, region, htd, masterSystemTime));	}	}	}	}	builder.addOpeningState(RegionOpeningState.OPENED);	} catch (IOException ie) {	
failed opening region 

public WarmupRegionResponse warmupRegion(final RpcController controller, final WarmupRegionRequest request) throws ServiceException {	final RegionInfo region = ProtobufUtil.toRegionInfo(request.getRegionInfo());	TableDescriptor htd;	WarmupRegionResponse response = WarmupRegionResponse.getDefaultInstance();	try {	checkOpen();	String encodedName = region.getEncodedName();	byte[] encodedNameBytes = region.getEncodedNameAsBytes();	final HRegion onlineRegion = regionServer.getRegion(encodedName);	if (onlineRegion != null) {	
region already online skipping warming up 

WarmupRegionResponse response = WarmupRegionResponse.getDefaultInstance();	try {	checkOpen();	String encodedName = region.getEncodedName();	byte[] encodedNameBytes = region.getEncodedNameAsBytes();	final HRegion onlineRegion = regionServer.getRegion(encodedName);	if (onlineRegion != null) {	return response;	}	if (LOG.isDebugEnabled()) {	
warming up region 

String encodedName = region.getEncodedName();	byte[] encodedNameBytes = region.getEncodedNameAsBytes();	final HRegion onlineRegion = regionServer.getRegion(encodedName);	if (onlineRegion != null) {	return response;	}	if (LOG.isDebugEnabled()) {	}	htd = regionServer.tableDescriptors.get(region.getTable());	if (regionServer.getRegionsInTransitionInRS().containsKey(encodedNameBytes)) {	
region is in transition skipping warmup 

return response;	}	if (LOG.isDebugEnabled()) {	}	htd = regionServer.tableDescriptors.get(region.getTable());	if (regionServer.getRegionsInTransitionInRS().containsKey(encodedNameBytes)) {	return response;	}	HRegion.warmupHRegion(region, htd, regionServer.getWAL(region), regionServer.getConfiguration(), regionServer, null);	} catch (IOException ie) {	
failed warming up region 

try {	if (action.hasMutation()) {	MutationProto m = action.getMutation();	if (m.hasAssociatedCellCount()) {	for (int i = 0; i < m.getAssociatedCellCount(); i++) {	cellScanner.advance();	}	}	}	} catch (IOException e) {	
error while skipping cells in cellscanner for invalid region mutations 

private RegionScannerHolder getRegionScanner(ScanRequest request) throws IOException {	String scannerName = Long.toString(request.getScannerId());	RegionScannerHolder rsh = scanners.get(scannerName);	if (rsh == null) {	if (closedScanners.getIfPresent(scannerName) != null) {	throw SCANNER_ALREADY_CLOSED;	} else {	
client tried to access missing scanner 

if (rsh == null) {	if (closedScanners.getIfPresent(scannerName) != null) {	throw SCANNER_ALREADY_CLOSED;	} else {	throw new UnknownScannerException( "Unknown scanner '" + scannerName + "'. This can happen due to any of the following " + "reasons: a) Scanner id given is wrong, b) Scanner lease expired because of " + "long wait between consecutive client checkins, c) Server may be closing down, " + "d) RegionServer restart during upgrade.\nIf the issue is due to reason (b), a " + "possible fix would be increasing the value of" + "'hbase.client.scanner.timeout.period' configuration.");	}	}	RegionInfo hri = rsh.s.getRegionInfo();	if (regionServer.getOnlineRegion(hri.getRegionName()) != rsh.r) {	String msg = "Region has changed on the scanner " + scannerName + ": regionName=" + hri.getRegionNameAsString() + ", scannerRegionName=" + rsh.r;	
closing 

throw new UnknownScannerException( "Unknown scanner '" + scannerName + "'. This can happen due to any of the following " + "reasons: a) Scanner id given is wrong, b) Scanner lease expired because of " + "long wait between consecutive client checkins, c) Server may be closing down, " + "d) RegionServer restart during upgrade.\nIf the issue is due to reason (b), a " + "possible fix would be increasing the value of" + "'hbase.client.scanner.timeout.period' configuration.");	}	}	RegionInfo hri = rsh.s.getRegionInfo();	if (regionServer.getOnlineRegion(hri.getRegionName()) != rsh.r) {	String msg = "Region has changed on the scanner " + scannerName + ": regionName=" + hri.getRegionNameAsString() + ", scannerRegionName=" + rsh.r;	scanners.remove(scannerName);	try {	rsh.s.close();	} catch (IOException e) {	
getting exception closing 

if (regionServer.getOnlineRegion(hri.getRegionName()) != rsh.r) {	String msg = "Region has changed on the scanner " + scannerName + ": regionName=" + hri.getRegionNameAsString() + ", scannerRegionName=" + rsh.r;	scanners.remove(scannerName);	try {	rsh.s.close();	} catch (IOException e) {	} finally {	try {	regionServer.leases.cancelLease(scannerName);	} catch (LeaseException e) {	
getting exception closing 

private void checkLimitOfRows(int numOfCompleteRows, int limitOfRows, boolean moreRows, ScannerContext scannerContext, ScanResponse.Builder builder) {	if (numOfCompleteRows >= limitOfRows) {	if (LOG.isTraceEnabled()) {	
done scanning limit of rows reached morerows scannercontext 

break;	}	}	}	boolean sizeLimitReached = scannerContext.checkSizeLimit(LimitScope.BETWEEN_ROWS);	boolean timeLimitReached = scannerContext.checkTimeLimit(LimitScope.BETWEEN_ROWS);	boolean resultsLimitReached = numOfResults >= maxResults;	limitReached = sizeLimitReached || timeLimitReached || resultsLimitReached;	if (limitReached || !moreRows) {	if (LOG.isTraceEnabled()) {	
done scanning limitreached morerows scannercontext 

}	if (!request.hasScannerId() && !request.hasScan()) {	throw new ServiceException( new DoNotRetryIOException("Missing required input: scannerId or scan"));	}	try {	checkOpen();	} catch (IOException e) {	if (request.hasScannerId()) {	String scannerName = Long.toString(request.getScannerId());	if (LOG.isDebugEnabled()) {	
server shutting down and client tried to access missing scanner 

} catch (IOException e) {	if (request.hasScannerId()) {	String scannerName = Long.toString(request.getScannerId());	if (LOG.isDebugEnabled()) {	}	if (regionServer.leases != null) {	try {	regionServer.leases.cancelLease(scannerName);	} catch (LeaseException le) {	if (LOG.isTraceEnabled()) {	
un able to cancel lease of scanner it could already be closed 

========================= hbase sample_2602 =========================

public void complete() {	synchronized (this.timerTask) {	if (this.complete) {	
timer already marked completed ignoring 

public void complete() {	synchronized (this.timerTask) {	if (this.complete) {	return;	}	if (LOG.isDebugEnabled()) {	
marking timer as complete no error notifications will be received for this timer 

public synchronized void start() throws IllegalStateException {	if (this.start >= 0) {	
timer already started can t be started again ignoring second request 

public synchronized void start() throws IllegalStateException {	if (this.start >= 0) {	return;	}	
scheduling process timer to run in ms 

public void trigger() {	synchronized (timerTask) {	if (this.complete) {	
timer already completed not triggering 

public void trigger() {	synchronized (timerTask) {	if (this.complete) {	return;	}	
triggering timer immediately 

========================= hbase sample_2317 =========================

protected int doWork() throws Exception {	IntegrationTestingUtility.setUseDistributedCluster(conf);	Class<?>[] classes = findIntegrationTestClasses();	
found integration tests to run 

========================= hbase sample_3269 =========================

public void testAggregation() throws Throwable {	Table table = util.getConnection().getTable(TEST_TABLE);	Map<byte[], Long> results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[0], ROWS[ROWS.length-1]);	int sumResult = 0;	int expectedResult = 0;	for (Map.Entry<byte[], Long> e : results.entrySet()) {	
got value for region 

}	for (int i = 0; i < ROWSIZE; i++) {	expectedResult += i;	}	assertEquals("Invalid result", expectedResult, sumResult);	results.clear();	results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[rowSeperator1], ROWS[ROWS.length-1]);	sumResult = 0;	expectedResult = 0;	for (Map.Entry<byte[], Long> e : results.entrySet()) {	
got value for region 

List<HRegionLocation> regions;	try(RegionLocator rl = util.getConnection().getRegionLocator(TEST_TABLE)) {	regions = rl.getAllRegionLocations();	}	final TestProtos.EchoRequestProto request = TestProtos.EchoRequestProto.newBuilder().setMessage("hello").build();	final Map<byte[], String> results = Collections.synchronizedMap( new TreeMap<byte[], String>(Bytes.BYTES_COMPARATOR));	try {	final RpcController controller = new ServerRpcController();	table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[0], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, TestProtos.EchoResponseProto>() {	public TestProtos.EchoResponseProto call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	
default response is 

}	final TestProtos.EchoRequestProto request = TestProtos.EchoRequestProto.newBuilder().setMessage("hello").build();	final Map<byte[], String> results = Collections.synchronizedMap( new TreeMap<byte[], String>(Bytes.BYTES_COMPARATOR));	try {	final RpcController controller = new ServerRpcController();	table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[0], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, TestProtos.EchoResponseProto>() {	public TestProtos.EchoResponseProto call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	CoprocessorRpcUtils.BlockingRpcCallback<TestProtos.EchoResponseProto> callback = new CoprocessorRpcUtils.BlockingRpcCallback<>();	instance.echo(controller, request, callback);	TestProtos.EchoResponseProto response = callback.get();	
batch call returning result 

}	}, new Batch.Callback<TestProtos.EchoResponseProto>() {	public void update(byte[] region, byte[] row, TestProtos.EchoResponseProto result) {	assertNotNull(result);	assertEquals("hello", result.getMessage());	results.put(region, result.getMessage());	}	}	);	for (Map.Entry<byte[], String> e : results.entrySet()) {	
got value for region 

assertNotNull(result);	assertEquals("hello", result.getMessage());	results.put(region, result.getMessage());	}	}	);	for (Map.Entry<byte[], String> e : results.entrySet()) {	}	assertEquals(3, results.size());	for (HRegionLocation info : regions) {	
region info is 

);	for (Map.Entry<byte[], String> e : results.entrySet()) {	}	assertEquals(3, results.size());	for (HRegionLocation info : regions) {	assertTrue(results.containsKey(info.getRegionInfo().getRegionName()));	}	results.clear();	table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[rowSeperator1], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, TestProtos.EchoResponseProto>() {	public TestProtos.EchoResponseProto call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	
default response is 

assertEquals(3, results.size());	for (HRegionLocation info : regions) {	assertTrue(results.containsKey(info.getRegionInfo().getRegionName()));	}	results.clear();	table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[rowSeperator1], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, TestProtos.EchoResponseProto>() {	public TestProtos.EchoResponseProto call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	CoprocessorRpcUtils.BlockingRpcCallback<TestProtos.EchoResponseProto> callback = new CoprocessorRpcUtils.BlockingRpcCallback<>();	instance.echo(controller, request, callback);	TestProtos.EchoResponseProto response = callback.get();	
batch call returning result 

}	}, new Batch.Callback<TestProtos.EchoResponseProto>() {	public void update(byte[] region, byte[] row, TestProtos.EchoResponseProto result) {	assertNotNull(result);	assertEquals("hello", result.getMessage());	results.put(region, result.getMessage());	}	}	);	for (Map.Entry<byte[], String> e : results.entrySet()) {	
got value for region 

regions = rl.getAllRegionLocations();	}	final TestProtos.EchoRequestProto request = TestProtos.EchoRequestProto.newBuilder().setMessage("hello").build();	try {	final RpcController controller = new ServerRpcController();	Map<byte[], String> results = table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[0], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, String>() {	public String call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	CoprocessorRpcUtils.BlockingRpcCallback<TestProtos.EchoResponseProto> callback = new CoprocessorRpcUtils.BlockingRpcCallback<>();	instance.echo(controller, request, callback);	TestProtos.EchoResponseProto response = callback.get();	
batch call got result 

Map<byte[], String> results = table.coprocessorService(TestRpcServiceProtos.TestProtobufRpcProto.class, ROWS[0], ROWS[ROWS.length - 1], new Batch.Call<TestRpcServiceProtos.TestProtobufRpcProto, String>() {	public String call(TestRpcServiceProtos.TestProtobufRpcProto instance) throws IOException {	CoprocessorRpcUtils.BlockingRpcCallback<TestProtos.EchoResponseProto> callback = new CoprocessorRpcUtils.BlockingRpcCallback<>();	instance.echo(controller, request, callback);	TestProtos.EchoResponseProto response = callback.get();	return null;	}	}	);	for (Map.Entry<byte[], String> e : results.entrySet()) {	
got value for region 

TestProtos.EchoResponseProto response = callback.get();	return null;	}	}	);	for (Map.Entry<byte[], String> e : results.entrySet()) {	}	assertEquals(3, results.size());	for (HRegionLocation region : regions) {	HRegionInfo info = region.getRegionInfo();	
region info is 

========================= hbase sample_1254 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_2028 =========================

public static SnapshotDescription validate(SnapshotDescription snapshot, Configuration conf) throws IllegalArgumentException, IOException {	if (!snapshot.hasTable()) {	throw new IllegalArgumentException( "Descriptor doesn't apply to a table, so we can't build it.");	}	long time = snapshot.getCreationTime();	if (time == SnapshotDescriptionUtils.NO_SNAPSHOT_START_TIME_SPECIFIED) {	time = EnvironmentEdgeManager.currentTime();	
creation time not specified setting to current time 

public static void completeSnapshot(SnapshotDescription snapshot, Path rootdir, Path workingDir, FileSystem fs) throws SnapshotCreationException, IOException {	Path finishedDir = getCompletedSnapshotDir(snapshot, rootdir);	
snapshot is done just moving the snapshot from to 

========================= hbase sample_2182 =========================

public Status exec(String filename, CancelableProgressable p) {	Path walDir;	FileSystem fs;	try {	walDir = FSUtils.getWALRootDir(conf);	fs = walDir.getFileSystem(conf);	} catch (IOException e) {	
could not find root dir or fs 

walDir = FSUtils.getWALRootDir(conf);	fs = walDir.getFileSystem(conf);	} catch (IOException e) {	return Status.RESIGNED;	}	try {	if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, filename)), fs, conf, p, sequenceIdChecker, server.getCoordinatedStateManager().getSplitLogWorkerCoordination(), factory)) {	return Status.PREEMPTED;	}	} catch (InterruptedIOException iioe) {	
log splitting of interrupted resigning 

}	try {	if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, filename)), fs, conf, p, sequenceIdChecker, server.getCoordinatedStateManager().getSplitLogWorkerCoordination(), factory)) {	return Status.PREEMPTED;	}	} catch (InterruptedIOException iioe) {	return Status.RESIGNED;	} catch (IOException e) {	Throwable cause = e.getCause();	if (e instanceof RetriesExhaustedException && (cause instanceof NotServingRegionException || cause instanceof ConnectException || cause instanceof SocketTimeoutException)) {	
log replaying of can t connect to the target regionserver resigning 

if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, filename)), fs, conf, p, sequenceIdChecker, server.getCoordinatedStateManager().getSplitLogWorkerCoordination(), factory)) {	return Status.PREEMPTED;	}	} catch (InterruptedIOException iioe) {	return Status.RESIGNED;	} catch (IOException e) {	Throwable cause = e.getCause();	if (e instanceof RetriesExhaustedException && (cause instanceof NotServingRegionException || cause instanceof ConnectException || cause instanceof SocketTimeoutException)) {	return Status.RESIGNED;	} else if (cause instanceof InterruptedException) {	
log splitting of interrupted resigning 

}	} catch (InterruptedIOException iioe) {	return Status.RESIGNED;	} catch (IOException e) {	Throwable cause = e.getCause();	if (e instanceof RetriesExhaustedException && (cause instanceof NotServingRegionException || cause instanceof ConnectException || cause instanceof SocketTimeoutException)) {	return Status.RESIGNED;	} else if (cause instanceof InterruptedException) {	return Status.RESIGNED;	}	
log splitting of failed returning error 

public void run() {	try {	
splitlogworker starting 

coordination.registerListener();	boolean res = false;	while (!res && !coordination.isStop()) {	res = coordination.isReady();	}	if (!coordination.isStop()) {	coordination.taskLoop();	}	} catch (Throwable t) {	if (ExceptionUtil.isInterrupt(t)) {	
splitlogworker interrupted exiting error exitworker is not set exiting anyway 

boolean res = false;	while (!res && !coordination.isStop()) {	res = coordination.isReady();	}	if (!coordination.isStop()) {	coordination.taskLoop();	}	} catch (Throwable t) {	if (ExceptionUtil.isInterrupt(t)) {	} else {	
unexpected error 

}	if (!coordination.isStop()) {	coordination.taskLoop();	}	} catch (Throwable t) {	if (ExceptionUtil.isInterrupt(t)) {	} else {	}	} finally {	coordination.removeListener();	
splitlogworker exiting 

public void stopTask() {	
sending interrupt to stop the worker thread 

========================= hbase sample_2497 =========================

protected void undeployRegion(Connection conn, ServerName sn, RegionInfo hri) throws IOException, InterruptedException {	try {	HBaseFsckRepair.closeRegionSilentlyAndWait(conn, sn, hri);	if (!hri.isMetaRegion()) {	admin.offline(hri.getRegionName());	}	} catch (IOException ioe) {	
got exception when attempting to offline region 

protected void deleteRegion(Configuration conf, final HTableDescriptor htd, byte[] startKey, byte[] endKey, boolean unassign, boolean metaRow, boolean hdfs, boolean regionInfoOnly, int replicaId) throws IOException, InterruptedException {	
before delete 

protected void deleteRegion(Configuration conf, final HTableDescriptor htd, byte[] startKey, byte[] endKey, boolean unassign, boolean metaRow, boolean hdfs, boolean regionInfoOnly, int replicaId) throws IOException, InterruptedException {	dumpMeta(htd.getTableName());	List<HRegionLocation> locations;	try(RegionLocator rl = connection.getRegionLocator(tbl.getName())) {	locations = rl.getAllRegionLocations();	}	for (HRegionLocation location : locations) {	RegionInfo hri = location.getRegionInfo();	ServerName hsa = location.getServerName();	if (Bytes.compareTo(hri.getStartKey(), startKey) == 0 && Bytes.compareTo(hri.getEndKey(), endKey) == 0 && hri.getReplicaId() == replicaId) {	
regionname 

List<HRegionLocation> locations;	try(RegionLocator rl = connection.getRegionLocator(tbl.getName())) {	locations = rl.getAllRegionLocations();	}	for (HRegionLocation location : locations) {	RegionInfo hri = location.getRegionInfo();	ServerName hsa = location.getServerName();	if (Bytes.compareTo(hri.getStartKey(), startKey) == 0 && Bytes.compareTo(hri.getEndKey(), endKey) == 0 && hri.getReplicaId() == replicaId) {	byte[] deleteRow = hri.getRegionName();	if (unassign) {	
undeploying region from server 

}	for (HRegionLocation location : locations) {	RegionInfo hri = location.getRegionInfo();	ServerName hsa = location.getServerName();	if (Bytes.compareTo(hri.getStartKey(), startKey) == 0 && Bytes.compareTo(hri.getEndKey(), endKey) == 0 && hri.getReplicaId() == replicaId) {	byte[] deleteRow = hri.getRegionName();	if (unassign) {	undeployRegion(connection, hsa, hri);	}	if (regionInfoOnly) {	
deleting hdfs regioninfo data 

undeployRegion(connection, hsa, hri);	}	if (regionInfoOnly) {	Path rootDir = FSUtils.getRootDir(conf);	FileSystem fs = rootDir.getFileSystem(conf);	Path p = new Path(FSUtils.getTableDir(rootDir, htd.getTableName()), hri.getEncodedName());	Path hriPath = new Path(p, HRegionFileSystem.REGION_INFO_FILE);	fs.delete(hriPath, true);	}	if (hdfs) {	
deleting hdfs data 

Path p = new Path(FSUtils.getTableDir(rootDir, htd.getTableName()), hri.getEncodedName());	Path hriPath = new Path(p, HRegionFileSystem.REGION_INFO_FILE);	fs.delete(hriPath, true);	}	if (hdfs) {	Path rootDir = FSUtils.getRootDir(conf);	FileSystem fs = rootDir.getFileSystem(conf);	Path p = new Path(FSUtils.getTableDir(rootDir, htd.getTableName()), hri.getEncodedName());	HBaseFsck.debugLsr(conf, p);	boolean success = fs.delete(p, true);	
deleted sucessfully 

if (metaRow) {	try (Table meta = connection.getTable(TableName.META_TABLE_NAME, tableExecutorService)) {	Delete delete = new Delete(deleteRow);	meta.delete(delete);	}	}	}	LOG.info(hri.toString() + hsa.toString());	}	TEST_UTIL.getMetaTableRows(htd.getTableName());	
after delete 

public void deleteTableDir(TableName table) throws IOException {	Path rootDir = FSUtils.getRootDir(conf);	FileSystem fs = rootDir.getFileSystem(conf);	Path p = FSUtils.getTableDir(rootDir, table);	HBaseFsck.debugLsr(conf, p);	boolean success = fs.delete(p, true);	
deleted sucessfully 

protected void deleteMetaRegion(Configuration conf, boolean unassign, boolean hdfs, boolean regionInfoOnly) throws IOException, InterruptedException {	HRegionLocation metaLocation = connection.getRegionLocator(TableName.META_TABLE_NAME) .getRegionLocation(HConstants.EMPTY_START_ROW);	ServerName hsa = metaLocation.getServerName();	RegionInfo hri = metaLocation.getRegionInfo();	if (unassign) {	
undeploying meta region from server 

protected void deleteMetaRegion(Configuration conf, boolean unassign, boolean hdfs, boolean regionInfoOnly) throws IOException, InterruptedException {	HRegionLocation metaLocation = connection.getRegionLocator(TableName.META_TABLE_NAME) .getRegionLocation(HConstants.EMPTY_START_ROW);	ServerName hsa = metaLocation.getServerName();	RegionInfo hri = metaLocation.getRegionInfo();	if (unassign) {	try (Connection unmanagedConnection = ConnectionFactory.createConnection(conf)) {	undeployRegion(unmanagedConnection, hsa, hri);	}	}	if (regionInfoOnly) {	
deleting hdfs regioninfo data 

}	}	if (regionInfoOnly) {	Path rootDir = FSUtils.getRootDir(conf);	FileSystem fs = rootDir.getFileSystem(conf);	Path p = new Path(rootDir + "/" + TableName.META_TABLE_NAME.getNameAsString(), hri.getEncodedName());	Path hriPath = new Path(p, HRegionFileSystem.REGION_INFO_FILE);	fs.delete(hriPath, true);	}	if (hdfs) {	
deleting hdfs data 

Path p = new Path(rootDir + "/" + TableName.META_TABLE_NAME.getNameAsString(), hri.getEncodedName());	Path hriPath = new Path(p, HRegionFileSystem.REGION_INFO_FILE);	fs.delete(hriPath, true);	}	if (hdfs) {	Path rootDir = FSUtils.getRootDir(conf);	FileSystem fs = rootDir.getFileSystem(conf);	Path p = new Path(rootDir + "/" + TableName.META_TABLE_NAME.getNameAsString(), hri.getEncodedName());	HBaseFsck.debugLsr(conf, p);	boolean success = fs.delete(p, true);	
deleted sucessfully 

public static void deleteTable(HBaseTestingUtility testUtil, TableName tableName) throws Exception {	MasterSyncCoprocessor coproc = testUtil.getHBaseCluster().getMaster() .getMasterCoprocessorHost().findCoprocessor(MasterSyncCoprocessor.class);	coproc.tableDeletionLatch = new CountDownLatch(1);	try {	admin.disableTable(tableName);	} catch (Exception e) {	
table already disabled so just deleting it 

========================= hbase sample_1311 =========================

public void run() {	try {	this.user.runAs(new PrivilegedAction<Object>(){	public Object run() {	runRegionServer();	return null;	}	});	} catch (Throwable t) {	
exception in run 

public void run() {	try {	LOG.info("Hook closing fs=" + this.fs);	this.fs.close();	} catch (NullPointerException npe) {	
need to fix these 

public void run() {	try {	LOG.info("Hook closing fs=" + this.fs);	this.fs.close();	} catch (NullPointerException npe) {	} catch (IOException e) {	
running hook 

rsConf.setInt(HConstants.REGIONSERVER_PORT, rsPorts.get(i));	}	User user = HBaseTestingUtility.getDifferentUser(rsConf, ".hfs."+index++);	hbaseCluster.addRegionServer(rsConf, i, user);	}	hbaseCluster.startup();	} catch (IOException e) {	shutdown();	throw e;	} catch (Throwable t) {	
error starting cluster 

public void killRegionServer(ServerName serverName) throws IOException {	HRegionServer server = getRegionServer(getRegionServerIndex(serverName));	if (server instanceof MiniHBaseClusterRegionServer) {	
killing 

public void startZkNode(String hostname, int port) throws IOException {	
starting zookeeper nodes on mini cluster is not supported 

public void killZkNode(ServerName serverName) throws IOException {	
aborting zookeeper nodes on mini cluster is not supported 

public void stopZkNode(ServerName serverName) throws IOException {	
stopping zookeeper nodes on mini cluster is not supported 

public void waitForZkNodeToStart(ServerName serverName, long timeout) throws IOException {	
waiting for zookeeper nodes to start on mini cluster is not supported 

public void waitForZkNodeToStop(ServerName serverName, long timeout) throws IOException {	
waiting for zookeeper nodes to stop on mini cluster is not supported 

public void startDataNode(ServerName serverName) throws IOException {	
starting datanodes on mini cluster is not supported 

public void killDataNode(ServerName serverName) throws IOException {	
aborting datanodes on mini cluster is not supported 

public void stopDataNode(ServerName serverName) throws IOException {	
stopping datanodes on mini cluster is not supported 

public void waitForDataNodeToStart(ServerName serverName, long timeout) throws IOException {	
waiting for datanodes to start on mini cluster is not supported 

public void waitForDataNodeToStop(ServerName serverName, long timeout) throws IOException {	
waiting for datanodes to stop on mini cluster is not supported 

public String abortRegionServer(int serverNumber) {	HRegionServer server = getRegionServer(serverNumber);	
aborting 

public JVMClusterUtil.RegionServerThread stopRegionServer(int serverNumber, final boolean shutdownFS) {	JVMClusterUtil.RegionServerThread server = hbaseCluster.getRegionServers().get(serverNumber);	
stopping 

public String abortMaster(int serverNumber) {	HMaster server = getMaster(serverNumber);	
aborting 

public JVMClusterUtil.MasterThread stopMaster(int serverNumber, final boolean shutdownFS) {	JVMClusterUtil.MasterThread server = hbaseCluster.getMasters().get(serverNumber);	
stopping 

========================= hbase sample_1891 =========================

};	for (int i = 1; i < threads.length; ++i) {	threads[i] = new Thread() {	public void run() {	while (true) {	TestProcedureWithEvent proc = (TestProcedureWithEvent)sched.poll();	if (proc == null) continue;	proc.getEvent().suspend();	waitQueue.add(proc);	proc.getEvent().suspendIfNotReady(proc);	
wait 

========================= hbase sample_1192 =========================

public void testHFileEncryption() throws Exception {	RedundantKVGenerator generator = new RedundantKVGenerator();	List<KeyValue> testKvs = generator.generateTestKeyValues(1000);	Configuration conf = TEST_UTIL.getConfiguration();	CacheConfig cacheConf = new CacheConfig(conf);	for (DataBlockEncoding encoding: DataBlockEncoding.values()) {	for (Compression.Algorithm compression: TestHFileBlock.COMPRESSION_ALGORITHMS) {	HFileContext fileContext = new HFileContextBuilder() .withBlockSize(4096) .withEncryptionContext(cryptoContext) .withCompression(compression) .withDataBlockEncoding(encoding) .build();	
writing with 

FSDataOutputStream out = fs.create(path);	HFile.Writer writer = HFile.getWriterFactory(conf, cacheConf) .withOutputStream(out) .withFileContext(fileContext) .create();	try {	for (KeyValue kv: testKvs) {	writer.append(kv);	}	} finally {	writer.close();	out.close();	}	
reading with 

do {	Cell kv = scanner.getCell();	assertTrue("Read back an unexpected or invalid KV", testKvs.contains(KeyValueUtil.ensureKeyValue(kv)));	i++;	} while (scanner.next());	} finally {	reader.close();	scanner.close();	}	assertEquals("Did not read back as many KVs as written", i, testKvs.size());	
random seeking with 

========================= hbase sample_1487 =========================

try {	lock.acquire();	cleaner.cleanExpiredMobFiles(htd.getTableName().getNameAsString(), hcd);	} finally {	lock.release();	}	}	}	}	} catch (Exception e) {	
fail to clean the expired mob files 

========================= hbase sample_2751 =========================

private void refreshVisibilityLabelsCache(byte[] data) {	try {	this.labelsCache.refreshLabelsCache(data);	} catch (IOException ioe) {	
failed parsing data from labels table from zk 

private void refreshUserAuthsCache(byte[] data) {	try {	this.labelsCache.refreshUserAuthsCache(data);	} catch (IOException ioe) {	
failed parsing data from labels table from zk 

public void nodeCreated(String path) {	if (path.equals(labelZnode) || path.equals(userAuthsZnode)) {	try {	ZKUtil.watchAndCheckExists(watcher, path);	} catch (KeeperException ke) {	
error setting watcher on node 

if (path.equals(labelZnode) || path.equals(userAuthsZnode)) {	try {	watcher.sync(path);	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	if (path.equals(labelZnode)) {	refreshVisibilityLabelsCache(data);	} else {	refreshUserAuthsCache(data);	}	} catch (KeeperException ke) {	
error reading data from zookeeper for node 

public void writeToZookeeper(byte[] data, boolean labelsOrUserAuths) {	String znode = this.labelZnode;	if (!labelsOrUserAuths) {	znode = this.userAuthsZnode;	}	try {	ZKUtil.updateExistingNodeData(watcher, znode, data, -1);	} catch (KeeperException e) {	
failed writing to 

========================= hbase sample_2301 =========================

private void validateMobFile(Path path) throws IOException {	HStoreFile storeFile = null;	try {	storeFile = new HStoreFile(region.getFilesystem(), path, conf, this.mobCacheConfig, BloomType.NONE, isPrimaryReplicaStore());	storeFile.initReader();	} catch (IOException e) {	
fail to open mob file keep it in temp directory 

map.put(tableNameString, locations);	}	} finally {	keyLock.releaseLockEntry(lockEntry);	}	}	result = readCell(locations, fileName, reference, cacheBlocks, readPt, readEmptyValueOnMobCellMiss);	}	}	if (result == null) {	
the cell result is null assemble a new cell with the same row family qualifier timestamp type and tags but with an empty value to return 

for (Path location : locations) {	MobFile file = null;	Path path = new Path(location, fileName);	try {	file = mobCacheConfig.getMobFileCache().openFile(fs, path, mobCacheConfig);	return readPt != -1 ? file.readCell(search, cacheMobBlocks, readPt) : file.readCell(search, cacheMobBlocks);	} catch (IOException e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	throwable = e;	if ((e instanceof FileNotFoundException) || (e.getCause() instanceof FileNotFoundException)) {	
fail to read the cell the mob file doesn t exist 

MobFile file = null;	Path path = new Path(location, fileName);	try {	file = mobCacheConfig.getMobFileCache().openFile(fs, path, mobCacheConfig);	return readPt != -1 ? file.readCell(search, cacheMobBlocks, readPt) : file.readCell(search, cacheMobBlocks);	} catch (IOException e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	throwable = e;	if ((e instanceof FileNotFoundException) || (e.getCause() instanceof FileNotFoundException)) {	} else if (e instanceof CorruptHFileException) {	
the mob file is corrupt 

mobCacheConfig.getMobFileCache().evictFile(fileName);	throwable = e;	if ((e instanceof FileNotFoundException) || (e.getCause() instanceof FileNotFoundException)) {	} else if (e instanceof CorruptHFileException) {	break;	} else {	throw e;	}	} catch (NullPointerException e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	
fail to read the cell 

} else if (e instanceof CorruptHFileException) {	break;	} else {	throw e;	}	} catch (NullPointerException e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	throwable = e;	} catch (AssertionError e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	
fail to read the cell 

throwable = e;	} catch (AssertionError e) {	mobCacheConfig.getMobFileCache().evictFile(fileName);	throwable = e;	} finally {	if (file != null) {	mobCacheConfig.getMobFileCache().closeFile(file);	}	}	}	
the mob file could not be found in the locations or it is corrupt 

========================= hbase sample_2585 =========================

private Tool doMROnTableTest(HBaseTestingUtility util, String family, String data, String[] args, int valueMultiplier, boolean dataAvailable) throws Exception {	String table = args[args.length - 1];	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util.getDataTestDirOnTestFS(table), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	
wrote test data to file s 

private Tool doMROnTableTest(HBaseTestingUtility util, String family, String data, String[] args, int valueMultiplier, boolean dataAvailable) throws Exception {	String table = args[args.length - 1];	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified(new Path(util.getDataTestDirOnTestFS(table), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	
forcing combiner 

Path inputPath = fs.makeQualified(new Path(util.getDataTestDirOnTestFS(table), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	conf.setInt("mapreduce.map.combine.minspills", 1);	}	List<String> argv = new ArrayList<>(Arrays.asList(args));	argv.add(inputPath.toString());	Tool tool = new ImportTsv();	
running importtsv with arguments 

op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	conf.setInt("mapreduce.map.combine.minspills", 1);	}	List<String> argv = new ArrayList<>(Arrays.asList(args));	argv.add(inputPath.toString());	Tool tool = new ImportTsv();	assertEquals(0, ToolRunner.run(conf, tool, argv.toArray(args)));	validateTable(conf, TableName.valueOf(table), family, valueMultiplier, dataAvailable);	if (conf.getBoolean(DELETE_AFTER_LOAD_CONF, true)) {	
deleting test subdirectory 

private static void validateTable(Configuration conf, TableName tableName, String family, int valueMultiplier, boolean dataAvailable) throws IOException {	
validating table 

boolean verified = false;	long pause = conf.getLong("hbase.client.pause", 5 * 1000);	int numRetries = conf.getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	Scan scan = new Scan();	scan.addFamily(Bytes.toBytes(family));	if (dataAvailable) {	ResultScanner resScanner = table.getScanner(scan);	for (Result res : resScanner) {	
getting results 

public void prePut(ObserverContext<RegionCoprocessorEnvironment> e, Put put, WALEdit edit, Durability durability) throws IOException {	Region region = e.getEnvironment().getRegion();	if (!region.getRegionInfo().isMetaRegion() && !region.getRegionInfo().getTable().isSystemTable()) {	if (put.getAttribute(TEST_ATR_KEY) != null) {	
allow any put to happen 

========================= hbase sample_3394 =========================

public void testMultiColumnScanner() throws IOException {	HRegion region = TEST_UTIL.createTestRegion(TABLE_NAME, new HColumnDescriptor(FAMILY) .setCompressionType(comprAlgo) .setBloomFilterType(bloomType) .setMaxVersions(MAX_VERSIONS) .setDataBlockEncoding(dataBlockEncoding) );	List<String> rows = sequentialStrings("row", NUM_ROWS);	List<String> qualifiers = sequentialStrings("qual", NUM_COLUMNS);	List<KeyValue> kvs = new ArrayList<>();	Set<String> keySet = new HashSet<>();	Map<String, Long> lastDelTimeMap = new HashMap<>();	Random rand = new Random(29372937L);	Set<String> rowQualSkip = new HashSet<>();	for (String row : rows) for (String qual : qualifiers) if (rand.nextDouble() < COLUMN_SKIP_IN_ROW_PROB) {	
skipping in row 

List<String> qualifiers = sequentialStrings("qual", NUM_COLUMNS);	List<KeyValue> kvs = new ArrayList<>();	Set<String> keySet = new HashSet<>();	Map<String, Long> lastDelTimeMap = new HashMap<>();	Random rand = new Random(29372937L);	Set<String> rowQualSkip = new HashSet<>();	for (String row : rows) for (String qual : qualifiers) if (rand.nextDouble() < COLUMN_SKIP_IN_ROW_PROB) {	rowQualSkip.add(rowQualKey(row, qual));	}	for (String qual : qualifiers) if (rand.nextDouble() < COLUMN_SKIP_EVERYWHERE_PROB) {	
skipping in all rows 

}	results.clear();	}	for (; kvPos < kvs.size(); ++kvPos) {	KeyValue remainingKV = kvs.get(kvPos);	assertFalse("Matching column not returned by scanner: " + remainingKV + ", " + queryInfo + ", results returned: " + numResults, matchesQuery(remainingKV, qualSet, maxVersions, lastDelTimeMap));	}	}	}	assertTrue("This test is supposed to delete at least some row/column " + "pairs", lastDelTimeMap.size() > 0);	
number of row col pairs deleted at least once 

========================= hbase sample_1716 =========================

protected static Tool doMROnTableTest(HBaseTestingUtility util, TableName table, String family, String data, Map<String, String> args, int valueMultiplier,int expectedKVCount) throws Exception {	Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified( new Path(util.getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	if (data == null) {	data = "KEY\u001bVALUE1\u001bVALUE2\n";	}	op.write(Bytes.toBytes(data));	op.close();	
wrote test data to file s 

Configuration conf = new Configuration(util.getConfiguration());	FileSystem fs = FileSystem.get(conf);	Path inputPath = fs.makeQualified( new Path(util.getDataTestDirOnTestFS(table.getNameAsString()), "input.dat"));	FSDataOutputStream op = fs.create(inputPath, true);	if (data == null) {	data = "KEY\u001bVALUE1\u001bVALUE2\n";	}	op.write(Bytes.toBytes(data));	op.close();	if (conf.getBoolean(FORCE_COMBINER_CONF, true)) {	
forcing combiner 

Iterator it = args.entrySet().iterator();	int i = 0;	while (it.hasNext()) {	Map.Entry pair = (Map.Entry) it.next();	argsArray[i] = "-D" + pair.getKey() + "=" + pair.getValue();	i++;	}	argsArray[i] = table.getNameAsString();	argsArray[i + 1] = inputPath.toString();	Tool tool = new ImportTsv();	
running importtsv with arguments 

if (args.containsKey(ImportTsv.BULK_OUTPUT_CONF_KEY)) {	if (isDryRun) {	assertFalse(String.format("Dry run mode, %s should not have been created.", ImportTsv.BULK_OUTPUT_CONF_KEY), fs.exists(new Path(ImportTsv.BULK_OUTPUT_CONF_KEY)));	} else {	validateHFiles(fs, args.get(ImportTsv.BULK_OUTPUT_CONF_KEY), family,expectedKVCount);	}	} else {	validateTable(conf, table, family, valueMultiplier, isDryRun);	}	if (conf.getBoolean(DELETE_AFTER_LOAD_CONF, true)) {	
deleting test subdirectory 

private static void validateTable(Configuration conf, TableName tableName, String family, int valueMultiplier, boolean isDryRun) throws IOException {	
validating table 

private static void validateHFiles(FileSystem fs, String outputPath, String family, int expectedKVCount) throws IOException {	
validating hfiles 

========================= hbase sample_3402 =========================

private FSDataOutputStream createFileWithRetries(final FileSystem fs, final Path hbckLockFilePath, final FsPermission defaultPerms) throws IOException {	IOException exception = null;	do {	try {	return FSUtils.create(fs, hbckLockFilePath, defaultPerms, false);	} catch (IOException ioe) {	LOG.info("Failed to create lock file " + hbckLockFilePath.getName() + ", try=" + (retryCounter.getAttemptTimes() + 1) + " of " + retryCounter.getMaxAttempts());	
failed to create lock file 

RetryCounter retryCounter = lockFileRetryCounterFactory.create();	FileLockCallable callable = new FileLockCallable(retryCounter);	ExecutorService executor = Executors.newFixedThreadPool(1);	FutureTask<FSDataOutputStream> futureTask = new FutureTask<>(callable);	executor.execute(futureTask);	final int timeoutInSeconds = getConf().getInt( "hbase.hbck.lockfile.maxwaittime", DEFAULT_WAIT_FOR_LOCK_TIMEOUT);	FSDataOutputStream stream = null;	try {	stream = futureTask.get(timeoutInSeconds, TimeUnit.SECONDS);	} catch (ExecutionException ee) {	
encountered exception when opening lock file 

FileLockCallable callable = new FileLockCallable(retryCounter);	ExecutorService executor = Executors.newFixedThreadPool(1);	FutureTask<FSDataOutputStream> futureTask = new FutureTask<>(callable);	executor.execute(futureTask);	final int timeoutInSeconds = getConf().getInt( "hbase.hbck.lockfile.maxwaittime", DEFAULT_WAIT_FOR_LOCK_TIMEOUT);	FSDataOutputStream stream = null;	try {	stream = futureTask.get(timeoutInSeconds, TimeUnit.SECONDS);	} catch (ExecutionException ee) {	} catch (InterruptedException ie) {	
interrupted when opening lock file 

FutureTask<FSDataOutputStream> futureTask = new FutureTask<>(callable);	executor.execute(futureTask);	final int timeoutInSeconds = getConf().getInt( "hbase.hbck.lockfile.maxwaittime", DEFAULT_WAIT_FOR_LOCK_TIMEOUT);	FSDataOutputStream stream = null;	try {	stream = futureTask.get(timeoutInSeconds, TimeUnit.SECONDS);	} catch (ExecutionException ee) {	} catch (InterruptedException ie) {	Thread.currentThread().interrupt();	} catch (TimeoutException exception) {	
took more than seconds in obtaining lock 

private void unlockHbck() {	if (isExclusive() && hbckLockCleanup.compareAndSet(true, false)) {	RetryCounter retryCounter = lockFileRetryCounterFactory.create();	do {	try {	IOUtils.closeQuietly(hbckOutFd);	FSUtils.delete(FSUtils.getCurrentFileSystem(getConf()), HBCK_LOCK_PATH, true);	
finishing hbck 

private void unlockHbck() {	if (isExclusive() && hbckLockCleanup.compareAndSet(true, false)) {	RetryCounter retryCounter = lockFileRetryCounterFactory.create();	do {	try {	IOUtils.closeQuietly(hbckOutFd);	FSUtils.delete(FSUtils.getCurrentFileSystem(getConf()), HBCK_LOCK_PATH, true);	return;	} catch (IOException ioe) {	LOG.info("Failed to delete " + HBCK_LOCK_PATH + ", try=" + (retryCounter.getAttemptTimes() + 1) + " of " + retryCounter.getMaxAttempts());	
failed to delete 

try {	IOUtils.closeQuietly(hbckOutFd);	FSUtils.delete(FSUtils.getCurrentFileSystem(getConf()), HBCK_LOCK_PATH, true);	return;	} catch (IOException ioe) {	LOG.info("Failed to delete " + HBCK_LOCK_PATH + ", try=" + (retryCounter.getAttemptTimes() + 1) + " of " + retryCounter.getMaxAttempts());	try {	retryCounter.sleepUntilNextRetry();	} catch (InterruptedException ie) {	Thread.currentThread().interrupt();	
interrupted while deleting lock file 

public void connect() throws IOException {	if (isExclusive()) {	hbckOutFd = checkAndMarkRunningHbck();	if (hbckOutFd == null) {	setRetCode(-1);	
another instance of hbck is fixing hbase exiting this instance if you are sure no other instance is running delete the lock file and rerun the tool 

}	hbckLockCleanup.set(true);	}	Runtime.getRuntime().addShutdownHook(new Thread() {	public void run() {	IOUtils.closeQuietly(HBaseFsck.this);	cleanupHbckZnode();	unlockHbck();	}	});	
launching hbck 

public void offlineHdfsIntegrityRepair() throws IOException, InterruptedException {	if (shouldCheckHdfs() && (shouldFixHdfsOrphans() || shouldFixHdfsHoles() || shouldFixHdfsOverlaps() || shouldFixTableOrphans())) {	
loading regioninfos hdfs 

if (shouldCheckHdfs() && (shouldFixHdfsOrphans() || shouldFixHdfsHoles() || shouldFixHdfsOverlaps() || shouldFixTableOrphans())) {	int maxIterations = getConf().getInt("hbase.hbck.integrityrepair.iterations.max", 3);	int curIter = 0;	do {	clearState();	restoreHdfsIntegrity();	curIter++;	} while (fixes > 0 && curIter <= maxIterations);	if (curIter > 2) {	if (curIter == maxIterations) {	
exiting integrity repairs after max iterations tables integrity may not be fully repaired 

int maxIterations = getConf().getInt("hbase.hbck.integrityrepair.iterations.max", 3);	int curIter = 0;	do {	clearState();	restoreHdfsIntegrity();	curIter++;	} while (fixes > 0 && curIter <= maxIterations);	if (curIter > 2) {	if (curIter == maxIterations) {	} else {	
successfully exiting integrity repairs after iterations 

if (!checkMetaRegion()) {	String errorMsg = "hbase:meta table is not consistent. ";	if (shouldFixAssignments()) {	errorMsg += "HBCK will try fixing it. Rerun once hbase:meta is back to consistent state.";	} else {	errorMsg += "Run HBCK with proper fix options to fix hbase:meta inconsistency.";	}	errors.reportError(errorMsg + " Exiting...");	return -2;	}	
loading regionsinfo from the hbase meta table 

if (!success) return -1;	reportEmptyMetaCells();	if (shouldFixEmptyMetaCells()) {	fixEmptyMetaCells();	}	if (!checkMetaOnly) {	reportTablesInFlux();	}	loadTableStates();	if (shouldCheckHdfs()) {	
loading region directories from hdfs 

reportEmptyMetaCells();	if (shouldFixEmptyMetaCells()) {	fixEmptyMetaCells();	}	if (!checkMetaOnly) {	reportTablesInFlux();	}	loadTableStates();	if (shouldCheckHdfs()) {	loadHdfsRegionDirs();	
loading region information from hdfs 

}	if (!checkMetaOnly) {	reportTablesInFlux();	}	loadTableStates();	if (shouldCheckHdfs()) {	loadHdfsRegionDirs();	loadHdfsRegionInfos();	}	fixOrphanTables();	
checking and fixing region consistency 

private void cleanupHbckZnode() {	try {	if (zkw != null && hbckZodeCreated) {	ZKUtil.deleteNode(zkw, hbckEphemeralNodePath);	hbckZodeCreated = false;	}	} catch (KeeperException e) {	if (!e.code().equals(KeeperException.Code.NONODE)) {	
delete hbck znode failed 

public int onlineHbck() throws IOException, KeeperException, InterruptedException, ReplicationException {	errors.print("Version: " + status.getHBaseVersion());	clearState();	offlineHdfsIntegrityRepair();	offlineReferenceFileRepair();	offlineHLinkFileRepair();	if (!setMasterInMaintenanceMode()) {	
hbck is running while master is not in maintenance mode you might see transient error please run hbck multiple times to reduce the chance of transient error 

if (currentRegionBoundariesInformation.metaLastKey.length == 0) currentRegionBoundariesInformation.metaLastKey = null;	boolean valid = true;	if ((currentRegionBoundariesInformation.storesFirstKey != null) && (currentRegionBoundariesInformation.metaFirstKey != null)) {	valid = valid && comparator.compare(currentRegionBoundariesInformation.storesFirstKey, currentRegionBoundariesInformation.metaFirstKey) >= 0;	}	if ((currentRegionBoundariesInformation.storesLastKey != null) && (currentRegionBoundariesInformation.metaLastKey != null)) {	valid = valid && comparator.compare(currentRegionBoundariesInformation.storesLastKey, currentRegionBoundariesInformation.metaLastKey) < 0;	}	if (!valid) {	errors.reportError(ERROR_CODE.BOUNDARIES_ERROR, "Found issues with regions boundaries", tablesInfo.get(regionInfo.getTable()));	
region s boundaries not aligned between stores and meta for 

private void adoptHdfsOrphans(Collection<HbckInfo> orphanHdfsDirs) throws IOException {	for (HbckInfo hi : orphanHdfsDirs) {	
attempting to handle orphan hdfs dir 

private void adoptHdfsOrphan(HbckInfo hi) throws IOException {	Path p = hi.getHdfsRegionDir();	FileSystem fs = p.getFileSystem(getConf());	FileStatus[] dirs = fs.listStatus(p);	if (dirs == null) {	
attempt to adopt orphan hdfs region skipped because no files present in this dir could probably be deleted 

HFile.Reader hf = null;	try {	CacheConfig cacheConf = new CacheConfig(getConf());	hf = HFile.createReader(fs, hfile.getPath(), cacheConf, true, getConf());	hf.loadFileInfo();	Optional<Cell> startKv = hf.getFirstKey();	start = CellUtil.cloneRow(startKv.get());	Optional<Cell> endKv = hf.getLastKey();	end = CellUtil.cloneRow(endKv.get());	} catch (IOException ioe) {	
problem reading orphan file skipping 

CacheConfig cacheConf = new CacheConfig(getConf());	hf = HFile.createReader(fs, hfile.getPath(), cacheConf, true, getConf());	hf.loadFileInfo();	Optional<Cell> startKv = hf.getFirstKey();	start = CellUtil.cloneRow(startKv.get());	Optional<Cell> endKv = hf.getLastKey();	end = CellUtil.cloneRow(endKv.get());	} catch (IOException ioe) {	continue;	} catch (NullPointerException ioe) {	
orphan file is possibly corrupted hfile skipping 

if (Bytes.compareTo(orphanRegionRange.getFirst(), start) > 0) {	orphanRegionRange.setFirst(start);	}	if (Bytes.compareTo(orphanRegionRange.getSecond(), end) < 0 ) {	orphanRegionRange.setSecond(end);	}	}	}	}	if (orphanRegionRange == null) {	
no data in dir sidelining data 

orphanRegionRange.setSecond(end);	}	}	}	}	if (orphanRegionRange == null) {	fixes++;	sidelineRegionDir(fs, hi);	return;	}	
min max keys are 

}	}	}	}	if (orphanRegionRange == null) {	fixes++;	sidelineRegionDir(fs, hi);	return;	}	RegionInfo regionInfo = RegionInfoBuilder.newBuilder(template.getTableName()) .setStartKey(orphanRegionRange.getFirst()) .setEndKey(Bytes.add(orphanRegionRange.getSecond(), new byte[1])) .build();	
creating new region 

private int restoreHdfsIntegrity() throws IOException, InterruptedException {	
loading hbase regioninfo from hdfs 

private int restoreHdfsIntegrity() throws IOException, InterruptedException {	loadHdfsRegionDirs();	int errs = errors.getErrorList().size();	tablesInfo = loadHdfsRegionInfos();	checkHdfsIntegrity(false, false);	if (errors.getErrorList().size() == errs) {	
no integrity errors we are done with this phase glorious 

private void offlineReferenceFileRepair() throws IOException, InterruptedException {	clearState();	Configuration conf = getConf();	Path hbaseRoot = FSUtils.getRootDir(conf);	FileSystem fs = hbaseRoot.getFileSystem(conf);	
computing mapping of all store files 

private void offlineReferenceFileRepair() throws IOException, InterruptedException {	clearState();	Configuration conf = getConf();	Path hbaseRoot = FSUtils.getRootDir(conf);	FileSystem fs = hbaseRoot.getFileSystem(conf);	Map<String, Path> allFiles = FSUtils.getTableStoreFilePathMap(fs, hbaseRoot, new FSUtils.ReferenceFileFilter(fs), executor, errors);	errors.print("");	
validating mapping using hdfs state 

boolean success = false;	String pathStr = path.toString();	int index = pathStr.lastIndexOf(Path.SEPARATOR_CHAR);	for (int i = 0; index > 0 && i < 5; i++) {	index = pathStr.lastIndexOf(Path.SEPARATOR_CHAR, index - 1);	}	if (index > 0) {	Path rootDir = getSidelineDir();	Path dst = new Path(rootDir, pathStr.substring(index + 1));	fs.mkdirs(dst.getParent());	
trying to sideline reference file to 

}	if (index > 0) {	Path rootDir = getSidelineDir();	Path dst = new Path(rootDir, pathStr.substring(index + 1));	fs.mkdirs(dst.getParent());	setShouldRerun();	success = fs.rename(path, dst);	debugLsr(dst);	}	if (!success) {	
failed to sideline reference file 

private void offlineHLinkFileRepair() throws IOException, InterruptedException {	Configuration conf = getConf();	Path hbaseRoot = FSUtils.getRootDir(conf);	FileSystem fs = hbaseRoot.getFileSystem(conf);	
computing mapping of all link files 

private void offlineHLinkFileRepair() throws IOException, InterruptedException {	Configuration conf = getConf();	Path hbaseRoot = FSUtils.getRootDir(conf);	FileSystem fs = hbaseRoot.getFileSystem(conf);	Map<String, Path> allFiles = FSUtils .getTableStoreFilePathMap(fs, hbaseRoot, new FSUtils.HFileLinkFilter(), executor, errors);	errors.print("");	
validating mapping using hdfs state 

Map<String, Path> allFiles = FSUtils .getTableStoreFilePathMap(fs, hbaseRoot, new FSUtils.HFileLinkFilter(), executor, errors);	errors.print("");	for (Path path : allFiles.values()) {	HFileLink actualLink = HFileLink.buildFromHFileLinkPattern(conf, path);	if (actualLink.exists(fs)) continue;	errors.reportError(ERROR_CODE.LINGERING_HFILELINK, "Found lingering HFileLink " + path);	if (!shouldFixHFileLinks()) continue;	setShouldRerun();	boolean success = sidelineFile(fs, hbaseRoot, path);	if (!success) {	
failed to sideline hfilelink file 

if (actualLink.exists(fs)) continue;	errors.reportError(ERROR_CODE.LINGERING_HFILELINK, "Found lingering HFileLink " + path);	if (!shouldFixHFileLinks()) continue;	setShouldRerun();	boolean success = sidelineFile(fs, hbaseRoot, path);	if (!success) {	}	Path backRefPath = FileLink.getBackReferencesDir(HFileArchiveUtil .getStoreArchivePath(conf, HFileLink.getReferencedTableName(path.getName().toString()), HFileLink.getReferencedRegionName(path.getName().toString()), path.getParent().getName()), HFileLink.getReferencedHFileName(path.getName().toString()));	success = sidelineFile(fs, hbaseRoot, backRefPath);	if (!success) {	
failed to sideline hfilelink backreference file 

private boolean sidelineFile(FileSystem fs, Path hbaseRoot, Path path) throws IOException {	URI uri = hbaseRoot.toUri().relativize(path.toUri());	if (uri.isAbsolute()) return false;	String relativePath = uri.getPath();	Path rootDir = getSidelineDir();	Path dst = new Path(rootDir, relativePath);	boolean pathCreated = fs.mkdirs(dst.getParent());	if (!pathCreated) {	
failed to create path 

private boolean sidelineFile(FileSystem fs, Path hbaseRoot, Path path) throws IOException {	URI uri = hbaseRoot.toUri().relativize(path.toUri());	if (uri.isAbsolute()) return false;	String relativePath = uri.getPath();	Path rootDir = getSidelineDir();	Path dst = new Path(rootDir, relativePath);	boolean pathCreated = fs.mkdirs(dst.getParent());	if (!pathCreated) {	return false;	}	
trying to sideline file to 

if (hbi.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	LOG.warn("No HDFS region dir found: " + hbi + " meta=" + hbi.metaEntry);	}	return;	}	if (hbi.hdfsEntry.hri != null) {	return;	}	FileSystem fs = FileSystem.get(getConf());	RegionInfo hri = HRegionFileSystem.loadRegionInfoFileContent(fs, regionDir);	
regioninfo read 

WorkItemHdfsRegionInfo work = new WorkItemHdfsRegionInfo(hbi, this, errors);	hbis.add(work);	}	hbiFutures = executor.invokeAll(hbis);	for(int i=0; i<hbiFutures.size(); i++) {	WorkItemHdfsRegionInfo work = hbis.get(i);	Future<Void> f = hbiFutures.get(i);	try {	f.get();	} catch(ExecutionException e) {	
failed to read regioninfo file for region 

}	}	Path hbaseRoot = FSUtils.getRootDir(getConf());	FileSystem fs = hbaseRoot.getFileSystem(getConf());	for (HbckInfo hbi: hbckInfos) {	if (hbi.getHdfsHRI() == null) {	continue;	}	TableName tableName = hbi.getTableName();	if (tableName == null) {	
tablename was null for 

}	TableInfo modTInfo = tablesInfo.get(tableName);	if (modTInfo == null) {	modTInfo = new TableInfo(tableName);	tablesInfo.put(tableName, modTInfo);	try {	TableDescriptor htd = FSTableDescriptors.getTableDescriptorFromFs(fs, hbaseRoot, tableName);	modTInfo.htds.add(htd);	} catch (IOException ioe) {	if (!orphanTableDirs.containsKey(tableName)) {	
unable to read tableinfo from 

public void fixEmptyMetaCells() throws IOException {	if (shouldFixEmptyMetaCells() && !emptyRegionInfoQualifiers.isEmpty()) {	
trying to fix empty regioninfo qualifier hbase meta rows 

List<TableName> tmpList = new ArrayList<>(orphanTableDirs.keySet().size());	tmpList.addAll(orphanTableDirs.keySet());	TableDescriptor[] htds = getTableDescriptors(tmpList);	Iterator<Entry<TableName, Set<String>>> iter = orphanTableDirs.entrySet().iterator();	int j = 0;	int numFailedCase = 0;	FSTableDescriptors fstd = new FSTableDescriptors(getConf());	while (iter.hasNext()) {	Entry<TableName, Set<String>> entry = iter.next();	TableName tableName = entry.getKey();	
trying to fix orphan table error 

Iterator<Entry<TableName, Set<String>>> iter = orphanTableDirs.entrySet().iterator();	int j = 0;	int numFailedCase = 0;	FSTableDescriptors fstd = new FSTableDescriptors(getConf());	while (iter.hasNext()) {	Entry<TableName, Set<String>> entry = iter.next();	TableName tableName = entry.getKey();	if (j < htds.length) {	if (tableName.equals(htds[j].getTableName())) {	TableDescriptor htd = htds[j];	
fixing orphan table from cache 

TableName tableName = entry.getKey();	if (j < htds.length) {	if (tableName.equals(htds[j].getTableName())) {	TableDescriptor htd = htds[j];	fstd.createTableDescriptor(htd, true);	j++;	iter.remove();	}	} else {	if (fabricateTableInfo(fstd, tableName, entry.getValue())) {	
fixing orphan table with a default tableinfo file 

TableName tableName = entry.getKey();	if (j < htds.length) {	if (tableName.equals(htds[j].getTableName())) {	TableDescriptor htd = htds[j];	fstd.createTableDescriptor(htd, true);	j++;	iter.remove();	}	} else {	if (fabricateTableInfo(fstd, tableName, entry.getValue())) {	
strongly recommend to modify the tabledescriptor if necessary for 

if (tableName.equals(htds[j].getTableName())) {	TableDescriptor htd = htds[j];	fstd.createTableDescriptor(htd, true);	j++;	iter.remove();	}	} else {	if (fabricateTableInfo(fstd, tableName, entry.getValue())) {	iter.remove();	} else {	
unable to create default tableinfo for while missing column family information 

if (fabricateTableInfo(fstd, tableName, entry.getValue())) {	iter.remove();	} else {	numFailedCase++;	}	}	fixes++;	}	if (orphanTableDirs.isEmpty()) {	setShouldRerun();	
strongly recommend to re run manually hfsck after all orphantabledirs being fixed 

iter.remove();	} else {	numFailedCase++;	}	}	fixes++;	}	if (orphanTableDirs.isEmpty()) {	setShouldRerun();	} else if (numFailedCase > 0) {	
failed to fix orphantables with default tableinfo files 

TableName name = e.getKey();	if (name.compareTo(TableName.META_TABLE_NAME) == 0) {	continue;	}	TableInfo ti = e.getValue();	puts.add(MetaTableAccessor .makePutFromTableState(new TableState(ti.tableName, TableState.State.ENABLED)));	for (Entry<byte[], Collection<HbckInfo>> spl : ti.sc.getStarts().asMap() .entrySet()) {	Collection<HbckInfo> his = spl.getValue();	int sz = his.size();	if (sz != 1) {	
split starting at had regions instead of exactly 

public boolean rebuildMeta(boolean fix) throws IOException, InterruptedException {	
loading hbase regioninfo from hdfs 

int errCount = errors.getErrorList().size();	if (fixes == 0) {	if (errCount > 0) {	return false;	} else {	break;	}	}	}	}	
hdfs regioninfo s seems good sidelining old hbase meta 

if (fixes == 0) {	if (errCount > 0) {	return false;	} else {	break;	}	}	}	}	Path backupDir = sidelineOldMeta();	
creating new hbase meta 

break;	}	}	}	}	Path backupDir = sidelineOldMeta();	String walFactoryId = "hbck-meta-recovery-" + RandomStringUtils.randomNumeric(8);	HRegion meta = createNewMeta(walFactoryId);	List<Put> puts = generatePuts(tablesInfo);	if (puts == null) {	
problem encountered when creating new hbase meta entries you may need to restore the previously sidelined hbase meta 

List<Put> puts = generatePuts(tablesInfo);	if (puts == null) {	return false;	}	meta.batchMutate(puts.toArray(new Put[puts.size()]), HConstants.NO_NONCE, HConstants.NO_NONCE);	meta.close();	if (meta.getWAL() != null) {	meta.getWAL().close();	}	removeHBCKMetaRecoveryWALDir(walFactoryId);	
success hbase meta table rebuilt 

List<Put> puts = generatePuts(tablesInfo);	if (puts == null) {	return false;	}	meta.batchMutate(puts.toArray(new Put[puts.size()]), HConstants.NO_NONCE, HConstants.NO_NONCE);	meta.close();	if (meta.getWAL() != null) {	meta.getWAL().close();	}	removeHBCKMetaRecoveryWALDir(walFactoryId);	
old hbase meta is moved into 

private void removeHBCKMetaRecoveryWALDir(String walFactoryId) throws IOException {	Path rootdir = FSUtils.getRootDir(getConf());	Path walLogDir = new Path(new Path(rootdir, HConstants.HREGION_LOGDIR_NAME), walFactoryId);	FileSystem fs = FSUtils.getCurrentFileSystem(getConf());	FileStatus[] walFiles = FSUtils.listStatus(fs, walLogDir, null);	if (walFiles == null || walFiles.length == 0) {	
hbck meta recovery wal directory is empty removing it now 

private void removeHBCKMetaRecoveryWALDir(String walFactoryId) throws IOException {	Path rootdir = FSUtils.getRootDir(getConf());	Path walLogDir = new Path(new Path(rootdir, HConstants.HREGION_LOGDIR_NAME), walFactoryId);	FileSystem fs = FSUtils.getCurrentFileSystem(getConf());	FileStatus[] walFiles = FSUtils.listStatus(fs, walLogDir, null);	if (walFiles == null || walFiles.length == 0) {	if (!FSUtils.deleteDirectory(fs, walLogDir)) {	
couldn t clear the hbck meta recovery wal directory 

private SortedMap<TableName, TableInfo> checkHdfsIntegrity(boolean fixHoles, boolean fixOverlaps) throws IOException {	
checking hbase region split map from hdfs data 

List<Path> paths = FSUtils.getTableDirs(fs, rootDir);	for (Path path : paths) {	TableName tableName = FSUtils.getTableName(path);	if ((!checkMetaOnly && isTableIncluded(tableName)) || tableName.equals(TableName.META_TABLE_NAME)) {	tableDirs.add(fs.getFileStatus(path));	}	}	if (!foundVersionFile) {	errors.reportError(ERROR_CODE.NO_VERSION_FILE, "Version file does not exist in root dir " + rootDir);	if (shouldFixVersionFile()) {	
trying to create a new file 

}	}	if (!foundVersionFile) {	errors.reportError(ERROR_CODE.NO_VERSION_FILE, "Version file does not exist in root dir " + rootDir);	if (shouldFixVersionFile()) {	setShouldRerun();	FSUtils.setVersion(fs, rootDir, getConf().getInt( HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000), getConf().getInt( HConstants.VERSION_FILE_WRITE_ATTEMPTS, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS));	}	}	for (FileStatus tableDir : tableDirs) {	
loading region dirs from 

if (shouldFixVersionFile()) {	setShouldRerun();	FSUtils.setVersion(fs, rootDir, getConf().getInt( HConstants.THREAD_WAKE_FREQUENCY, 10 * 1000), getConf().getInt( HConstants.VERSION_FILE_WRITE_ATTEMPTS, HConstants.DEFAULT_VERSION_FILE_WRITE_ATTEMPTS));	}	}	for (FileStatus tableDir : tableDirs) {	WorkItemHdfsDir item = new WorkItemHdfsDir(fs, errors, tableDir);	try {	item.call();	} catch (ExecutionException e) {	
could not completely load table dir 

private void checkRegionConsistencyConcurrently( final List<CheckRegionConsistencyWorkItem> workItems) throws IOException, KeeperException, InterruptedException {	if (workItems.isEmpty()) {	return;	}	List<Future<Void>> workFutures = executor.invokeAll(workItems);	for(Future<Void> f: workFutures) {	try {	f.get();	} catch(ExecutionException e1) {	
could not check region consistency 

public synchronized Void call() throws Exception {	try {	checkRegionConsistency(key, hbi);	} catch (Exception e) {	
unable to complete check or repair the region 

public synchronized Void call() throws Exception {	try {	checkRegionConsistency(key, hbi);	} catch (Exception e) {	if (hbi.getHdfsHRI().isMetaRegion()) {	throw e;	}	
skip region 

}	Path hbaseDir = FSUtils.getRootDir(getConf());	FileSystem fs = hbaseDir.getFileSystem(getConf());	UserProvider userProvider = UserProvider.instantiate(getConf());	UserGroupInformation ugi = userProvider.getCurrent().getUGI();	FileStatus[] files = fs.listStatus(hbaseDir);	for (FileStatus file : files) {	try {	FSUtils.checkAccess(ugi, file, FsAction.WRITE);	} catch (AccessDeniedException ace) {	
got accessdeniedexception when precheckpermission 

private void deleteMetaRegion(byte[] metaKey) throws IOException {	Delete d = new Delete(metaKey);	meta.delete(d);	
deleted from meta 

private void resetSplitParent(HbckInfo hi) throws IOException {	RowMutations mutations = new RowMutations(hi.metaEntry.getRegionName());	Delete d = new Delete(hi.metaEntry.getRegionName());	d.addColumn(HConstants.CATALOG_FAMILY, HConstants.SPLITA_QUALIFIER);	d.addColumn(HConstants.CATALOG_FAMILY, HConstants.SPLITB_QUALIFIER);	mutations.add(d);	RegionInfo hri = RegionInfoBuilder.newBuilder(hi.metaEntry) .setOffline(false) .setSplit(false) .build();	Put p = MetaTableAccessor.makePutFromRegionInfo(hri);	mutations.add(p);	meta.mutateRow(mutations);	
reset split parent in meta 

private void offline(byte[] regionName) throws IOException {	String regionString = Bytes.toStringBinary(regionName);	if (!rsSupportsOffline) {	
using unassign region instead of using offline method you should restart hmaster after these repairs 

private void offline(byte[] regionName) throws IOException {	String regionString = Bytes.toStringBinary(regionName);	if (!rsSupportsOffline) {	admin.unassign(regionName, true);	return;	}	try {	
offlining region 

String regionString = Bytes.toStringBinary(regionName);	if (!rsSupportsOffline) {	admin.unassign(regionName, true);	return;	}	try {	admin.offline(regionName);	} catch (IOException ioe) {	String notFoundMsg = "java.lang.NoSuchMethodException: " + "org.apache.hadoop.hbase.master.HMaster.offline([B)";	if (ioe.getMessage().contains(notFoundMsg)) {	
using unassign region instead of using offline method you should restart hmaster after these repairs 

private void undeployRegionsForHbi(HbckInfo hi) throws IOException, InterruptedException {	for (OnlineEntry rse : hi.deployedEntries) {	
undeploy region from 

private void undeployRegionsForHbi(HbckInfo hi) throws IOException, InterruptedException {	for (OnlineEntry rse : hi.deployedEntries) {	try {	HBaseFsckRepair.closeRegionSilentlyAndWait(connection, rse.hsa, rse.hri);	offline(rse.hri.getRegionName());	} catch (IOException ioe) {	
got exception when attempting to offline region 

if (hi.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	int numReplicas = admin.getTableDescriptor(hi.getTableName()).getRegionReplication();	for (int i = 0; i < numReplicas; i++) {	get.addColumn(HConstants.CATALOG_FAMILY, MetaTableAccessor.getServerColumn(i));	get.addColumn(HConstants.CATALOG_FAMILY, MetaTableAccessor.getStartCodeColumn(i));	}	}	Result r = meta.get(get);	RegionLocations rl = MetaTableAccessor.getRegionLocations(r);	if (rl == null) {	
unable to close region since meta does not have handle to reach it 

return;	}	for (HRegionLocation h : rl.getRegionLocations()) {	ServerName serverName = h.getServerName();	if (serverName == null) {	errors.reportError("Unable to close region " + hi.getRegionNameAsString() +  " because meta does not " + "have handle to reach it.");	continue;	}	RegionInfo hri = h.getRegionInfo();	if (hri == null) {	
unable to close region because hbase meta had invalid or missing qualifier value 

boolean deploymentMatchesMeta = hasMetaAssignment && isDeployed && !isMultiplyDeployed && hbi.metaEntry.regionServer.equals(hbi.deployedOn.get(0));	boolean splitParent = inMeta && hbi.metaEntry.isSplit() && hbi.metaEntry.isOffline();	boolean shouldBeDeployed = inMeta && !isTableDisabled(hbi.metaEntry.getTable());	boolean recentlyModified = inHdfs && hbi.getModTime() + timelag > EnvironmentEdgeManager.currentTime();	if (hbi.containsOnlyHdfsEdits()) {	return;	}	if (inMeta && inHdfs && isDeployed && deploymentMatchesMeta && shouldBeDeployed) {	return;	} else if (inMeta && inHdfs && !shouldBeDeployed && !isDeployed) {	
region is in meta and in a disabled tabled that is not deployed 

boolean shouldBeDeployed = inMeta && !isTableDisabled(hbi.metaEntry.getTable());	boolean recentlyModified = inHdfs && hbi.getModTime() + timelag > EnvironmentEdgeManager.currentTime();	if (hbi.containsOnlyHdfsEdits()) {	return;	}	if (inMeta && inHdfs && isDeployed && deploymentMatchesMeta && shouldBeDeployed) {	return;	} else if (inMeta && inHdfs && !shouldBeDeployed && !isDeployed) {	return;	} else if (recentlyModified) {	
region was recently modified skipping 

else if (!inMeta && !inHdfs && !isDeployed) {	assert false : "Entry for region with no data";	} else if (!inMeta && !inHdfs && isDeployed) {	errors.reportError(ERROR_CODE.NOT_IN_META_HDFS, "Region " + descriptiveName + ", key=" + key + ", not on HDFS or in hbase:meta but " + "deployed on " + Joiner.on(", ").join(hbi.deployedOn));	if (shouldFixAssignments()) {	undeployRegions(hbi);	}	} else if (!inMeta && inHdfs && !isDeployed) {	if (hbi.isMerged()) {	hbi.setSkipChecks(true);	
region got merge recently its file s will be cleaned by catalogjanitor later 

undeployRegions(hbi);	}	} else if (!inMeta && inHdfs && !isDeployed) {	if (hbi.isMerged()) {	hbi.setSkipChecks(true);	return;	}	errors.reportError(ERROR_CODE.NOT_IN_META_OR_DEPLOYED, "Region " + descriptiveName + " on HDFS, but not listed in hbase:meta " + "or deployed on any region server");	if (shouldFixMeta()) {	if (!hbi.isHdfsRegioninfoPresent()) {	
region could have been repaired in table integrity repair phase if fixhdfsorphans was used 

if (Bytes.compareTo(region.getStartKey(), hri.getStartKey()) <= 0 && (region.getEndKey().length == 0 || Bytes.compareTo(region.getEndKey(), hri.getEndKey()) >= 0) && Bytes.compareTo(region.getStartKey(), hri.getEndKey()) <= 0) {	if(region.isSplit() || region.isOffline()) continue;	Path regionDir = hbi.getHdfsRegionDir();	FileSystem fs = regionDir.getFileSystem(getConf());	List<Path> familyDirs = FSUtils.getFamilyDirs(fs, regionDir);	for (Path familyDir : familyDirs) {	List<Path> referenceFilePaths = FSUtils.getReferenceFilePaths(fs, familyDir);	for (Path referenceFilePath : referenceFilePaths) {	Path parentRegionDir = StoreFileInfo.getReferredToFile(referenceFilePath).getParent().getParent();	if (parentRegionDir.toString().endsWith(region.getEncodedName())) {	
start and stop keys are in the range of the region might not be cleaned up from hdfs when region split failed hence deleting from hdfs 

for (Path referenceFilePath : referenceFilePaths) {	Path parentRegionDir = StoreFileInfo.getReferredToFile(referenceFilePath).getParent().getParent();	if (parentRegionDir.toString().endsWith(region.getEncodedName())) {	HRegionFileSystem.deleteRegionFromFileSystem(getConf(), fs, regionDir.getParent(), hri);	return;	}	}	}	}	}	
patching hbase meta with regioninfo 

} else if (!inMeta && inHdfs && isDeployed) {	errors.reportError(ERROR_CODE.NOT_IN_META, "Region " + descriptiveName + " not in META, but deployed on " + Joiner.on(", ").join(hbi.deployedOn));	debugLsr(hbi.getHdfsRegionDir());	if (hbi.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) {	if (shouldFixAssignments()) {	undeployRegionsForHbi(hbi);	}	}	if (shouldFixMeta() && hbi.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	if (!hbi.isHdfsRegioninfoPresent()) {	
this should have been repaired in table integrity repair phase 

debugLsr(hbi.getHdfsRegionDir());	if (hbi.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) {	if (shouldFixAssignments()) {	undeployRegionsForHbi(hbi);	}	}	if (shouldFixMeta() && hbi.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID) {	if (!hbi.isHdfsRegioninfoPresent()) {	return;	}	
patching hbase meta with with regioninfo 

} else if (inMeta && inHdfs && !isDeployed && splitParent) {	if (hbi.metaEntry.splitA != null && hbi.metaEntry.splitB != null) {	HbckInfo infoA = this.regionInfoMap.get(hbi.metaEntry.splitA.getEncodedName());	HbckInfo infoB = this.regionInfoMap.get(hbi.metaEntry.splitB.getEncodedName());	if (infoA != null && infoB != null) {	hbi.setSkipChecks(true);	return;	}	}	if (hbi.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) {	
region is a split parent in meta in hdfs and not deployed on any region server this may be transient 

public int mergeRegionDirs(Path targetRegionDir, HbckInfo contained) throws IOException {	int fileMoves = 0;	String thread = Thread.currentThread().getName();	
contained region dir after close and pause 

public int mergeRegionDirs(Path targetRegionDir, HbckInfo contained) throws IOException {	int fileMoves = 0;	String thread = Thread.currentThread().getName();	debugLsr(contained.getHdfsRegionDir());	FileSystem fs = targetRegionDir.getFileSystem(getConf());	FileStatus[] dirs = null;	try {	dirs = fs.listStatus(contained.getHdfsRegionDir());	} catch (FileNotFoundException fnfe) {	if (!fs.exists(contained.getHdfsRegionDir())) {	
hdfs region dir is missing assuming already sidelined or moved 

dirs = fs.listStatus(contained.getHdfsRegionDir());	} catch (FileNotFoundException fnfe) {	if (!fs.exists(contained.getHdfsRegionDir())) {	} else {	sidelineRegionDir(fs, contained);	}	return fileMoves;	}	if (dirs == null) {	if (!fs.exists(contained.getHdfsRegionDir())) {	
hdfs region dir already sidelined 

}	for (FileStatus cf : dirs) {	Path src = cf.getPath();	Path dst =  new Path(targetRegionDir, src.getName());	if (src.getName().equals(HRegionFileSystem.REGION_INFO_FILE)) {	continue;	}	if (src.getName().equals(HConstants.HREGION_OLDLOGDIR_NAME)) {	continue;	}	
moving files from into containing region 

}	if (src.getName().equals(HConstants.HREGION_OLDLOGDIR_NAME)) {	continue;	}	for (FileStatus hfile : fs.listStatus(src)) {	boolean success = fs.rename(hfile.getPath(), dst);	if (success) {	fileMoves++;	}	}	
sideline directory contents 

}	for (FileStatus hfile : fs.listStatus(src)) {	boolean success = fs.rename(hfile.getPath(), dst);	if (success) {	fileMoves++;	}	}	debugLsr(targetRegionDir);	}	sidelineRegionDir(fs, contained);	
sidelined region dir into 

private TableDescriptor getHTD() {	if (htds.size() == 1) {	return (TableDescriptor)htds.toArray()[0];	} else {	
none multiple table descriptors found for table regions 

public void handleRegionStartKeyNotEmpty(HbckInfo next) throws IOException {	errors.reportError(ERROR_CODE.FIRST_REGION_STARTKEY_NOT_EMPTY, "First region should start with an empty key.  Creating a new " + "region and regioninfo in HDFS to plug the hole.", getTableInfo(), next);	TableDescriptor htd = getTableInfo().getHTD();	RegionInfo newRegion = RegionInfoBuilder.newBuilder(htd.getTableName()) .setStartKey(HConstants.EMPTY_START_ROW) .setEndKey(next.getStartKey()) .build();	HRegion region = HBaseFsckRepair.createHDFSRegionDir(conf, newRegion, htd);	
table region start key was not empty created new empty region 

public void handleRegionEndKeyNotEmpty(byte[] curEndKey) throws IOException {	errors.reportError(ERROR_CODE.LAST_REGION_ENDKEY_NOT_EMPTY, "Last region should end with an empty key.  Creating a new " + "region and regioninfo in HDFS to plug the hole.", getTableInfo());	TableDescriptor htd = getTableInfo().getHTD();	RegionInfo newRegion = RegionInfoBuilder.newBuilder(htd.getTableName()) .setStartKey(curEndKey) .setEndKey(HConstants.EMPTY_START_ROW) .build();	HRegion region = HBaseFsckRepair.createHDFSRegionDir(conf, newRegion, htd);	
table region end key was not empty created new empty region 

public void handleHoleInRegionChain(byte[] holeStartKey, byte[] holeStopKey) throws IOException {	errors.reportError( ERROR_CODE.HOLE_IN_REGION_CHAIN, "There is a hole in the region chain between " + Bytes.toStringBinary(holeStartKey) + " and " + Bytes.toStringBinary(holeStopKey) + ".  Creating a new regioninfo and region " + "dir in hdfs to plug the hole.");	TableDescriptor htd = getTableInfo().getHTD();	RegionInfo newRegion = RegionInfoBuilder.newBuilder(htd.getTableName()) .setStartKey(holeStartKey) .setEndKey(holeStopKey) .build();	HRegion region = HBaseFsckRepair.createHDFSRegionDir(conf, newRegion, htd);	
plugged hole by creating new empty region 

public void handleOverlapGroup(Collection<HbckInfo> overlap) throws IOException {	Preconditions.checkNotNull(overlap);	Preconditions.checkArgument(overlap.size() >0);	if (!this.fixOverlaps) {	
not attempting to repair overlaps 

public void handleOverlapGroup(Collection<HbckInfo> overlap) throws IOException {	Preconditions.checkNotNull(overlap);	Preconditions.checkArgument(overlap.size() >0);	if (!this.fixOverlaps) {	return;	}	if (overlap.size() > maxMerge) {	
overlap group has overlapping regions which is greater than the max number of regions to merge 

}	for (HbckInfo rng : ranges) {	byte[] endKey = rng.getEndKey();	endKey = (endKey.length == 0) ? null : endKey;	if (Bytes.equals(rng.getStartKey(),endKey)) {	handler.handleDegenerateRegion(rng);	}	}	if (ranges.size() == 1) {	if (problemKey != null) {	
reached end of problem group 

if (Bytes.equals(rng.getStartKey(),endKey)) {	handler.handleDegenerateRegion(rng);	}	}	if (ranges.size() == 1) {	if (problemKey != null) {	}	problemKey = null;	} else if (ranges.size() > 1) {	if (problemKey == null) {	
naming new problem group 

overlapGroups.putAll(problemKey, ranges);	ArrayList<HbckInfo> subRange = new ArrayList<>(ranges);	for (HbckInfo r1 : ranges) {	if (r1.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) continue;	subRange.remove(r1);	for (HbckInfo r2 : subRange) {	if (r2.getReplicaId() != RegionInfo.DEFAULT_REPLICA_ID) continue;	if (Bytes.compareTo(r1.getStartKey(), r2.getStartKey())==0) {	handler.handleDuplicateStartKeys(r1,r2);	} else if (Bytes.compareTo(r1.getEndKey(), r2.getStartKey())==0 && r1.getHdfsHRI().getRegionId() == r2.getHdfsHRI().getRegionId()) {	
this is a split log to splits 

handler.handleDuplicateStartKeys(r1,r2);	} else if (Bytes.compareTo(r1.getEndKey(), r2.getStartKey())==0 && r1.getHdfsHRI().getRegionId() == r2.getHdfsHRI().getRegionId()) {	handler.handleSplit(r1, r2);	} else {	handler.handleOverlapInRegionChain(r1, r2);	}	}	}	} else if (ranges.isEmpty()) {	if (problemKey != null) {	
reached end of problem group 

}	}	if (details) {	errors.print("---- Table '"  +  this.tableName + "': region split map");	dump(splits, regions);	errors.print("---- Table '"  +  this.tableName + "': overlap groups");	dumpOverlapProblems(overlapGroups);	errors.print("There are " + overlapGroups.keySet().size() + " overlap groups with " + overlapGroups.size() + " overlapping regions");	}	if (!sidelinedRegions.isEmpty()) {	
sidelined big overlapped regions please bulk load them 

private boolean handleOverlapsParallel(TableIntegrityErrorHandler handler, byte[] prevKey) throws IOException {	List<WorkItemOverlapMerge> merges = new ArrayList<>(overlapGroups.size());	List<Future<Void>> rets;	for (Collection<HbckInfo> overlap : overlapGroups.asMap().values()) {	merges.add(new WorkItemOverlapMerge(overlap, handler));	}	try {	rets = executor.invokeAll(merges);	} catch (InterruptedException e) {	
overlap merges were interrupted 

rets = executor.invokeAll(merges);	} catch (InterruptedException e) {	return false;	}	for(int i=0; i<merges.size(); i++) {	WorkItemOverlapMerge work = merges.get(i);	Future<Void> f = rets.get(i);	try {	f.get();	} catch(ExecutionException e) {	
failed to merge overlap group 

} catch (InterruptedException e) {	return false;	}	for(int i=0; i<merges.size(); i++) {	WorkItemOverlapMerge work = merges.get(i);	Future<Void> f = rets.get(i);	try {	f.get();	} catch(ExecutionException e) {	} catch (InterruptedException e) {	
waiting for overlap merges was interrupted 

public byte[] getStartKey() {	if (this.metaEntry != null) {	return this.metaEntry.getStartKey();	} else if (this.hdfsEntry != null) {	return this.hdfsEntry.hri.getStartKey();	} else {	
entry has no meta or hdfs region start key 

public byte[] getEndKey() {	if (this.metaEntry != null) {	return this.metaEntry.getEndKey();	} else if (this.hdfsEntry != null) {	return this.hdfsEntry.hri.getEndKey();	} else {	
entry has no meta or hdfs region start key 

final String encodedName = regionDir.getPath().getName();	if (!encodedName.toLowerCase(Locale.ROOT).matches("[0-9a-f]+")) {	continue;	}	if (!exceptions.isEmpty()) {	break;	}	futures.add(executor.submit(new Runnable() {	public void run() {	try {	
loading region info from hdfs 

if (!exceptions.isEmpty()) {	break;	}	futures.add(executor.submit(new Runnable() {	public void run() {	try {	Path regioninfoFile = new Path(regionDir.getPath(), HRegionFileSystem.REGION_INFO_FILE);	boolean regioninfoFileExists = fs.exists(regioninfoFile);	if (!regioninfoFileExists) {	if (!fs.exists(regionDir.getPath())) {	
by the time we tried to process this region dir it was already gone 

errors.progress();	String sdName = subDir.getPath().getName();	if (!sdName.startsWith(".") && !sdName.equals(ePath.getName())) {	he.hdfsOnlyEdits = false;	break;	}	}	hbi.hdfsEntry = he;	}	} catch (Exception e) {	
could not load region dir 

}	}));	}	for (Future<?> f : futures) {	if (!exceptions.isEmpty()) {	break;	}	try {	f.get();	} catch (ExecutionException e) {	
unexpected exec exception should ve been caught already bug 

for (Future<?> f : futures) {	if (!exceptions.isEmpty()) {	break;	}	try {	f.get();	} catch (ExecutionException e) {	}	}	} catch (IOException e) {	
cannot execute workitemhdfsdir for 

if (hbi.getHdfsHRI() == null) {	try {	errors.progress();	hbck.loadHdfsRegioninfo(hbi);	} catch (IOException ioe) {	String msg = "Orphan region in HDFS: Unable to load .regioninfo from table " + hbi.getTableName() + " in hdfs dir " + hbi.getHdfsRegionDir() + "!  It may be an invalid format or version file.  Treating as " + "an orphaned regiondir.";	errors.reportError(ERROR_CODE.ORPHAN_HDFS_REGION, msg);	try {	hbck.debugLsr(hbi.getHdfsRegionDir());	} catch (IOException ioe2) {	
unable to read directory 

try {	preCheckPermission();	} catch (AccessDeniedException ace) {	Runtime.getRuntime().exit(-1);	} catch (IOException ioe) {	Runtime.getRuntime().exit(-1);	}	connect();	try {	if (checkCorruptHFiles || sidelineCorruptHFiles) {	
checking all hfiles for corruption 

} else {	tableDirs = FSUtils.getTableDirs(FSUtils.getCurrentFileSystem(getConf()), rootdir);	}	hfcc.checkTables(tableDirs);	hfcc.report(errors);	}	int code = onlineHbck();	setRetCode(code);	if (shouldRerun()) {	try {	
sleeping ms before re checking after fix 

}	hfcc.checkTables(tableDirs);	hfcc.report(errors);	}	int code = onlineHbck();	setRetCode(code);	if (shouldRerun()) {	try {	Thread.sleep(sleepBeforeRerun);	} catch (InterruptedException ie) {	
interrupted while sleeping 

========================= hbase sample_2213 =========================

protected void configureForRegion(HRegion region) {	super.configureForRegion(region);	prefixLength = 0;	String prefixLengthString = region.getTableDescriptor().getValue( PREFIX_LENGTH_KEY);	if (prefixLengthString == null) {	prefixLengthString = region.getTableDescriptor().getValue(PREFIX_LENGTH_KEY_DEPRECATED);	if (prefixLengthString == null) {	
not specified for table using default regionsplitpolicy 

String prefixLengthString = region.getTableDescriptor().getValue( PREFIX_LENGTH_KEY);	if (prefixLengthString == null) {	prefixLengthString = region.getTableDescriptor().getValue(PREFIX_LENGTH_KEY_DEPRECATED);	if (prefixLengthString == null) {	return;	}	}	try {	prefixLength = Integer.parseInt(prefixLengthString);	} catch (NumberFormatException nfe) {	
number format exception when parsing for table 

if (prefixLengthString == null) {	return;	}	}	try {	prefixLength = Integer.parseInt(prefixLengthString);	} catch (NumberFormatException nfe) {	return;	}	if (prefixLength <= 0) {	
invalid value for for table using default regionsplitpolicy 

========================= hbase sample_2643 =========================

SingleColumnValueFilter scvf = new SingleColumnValueFilter( family, qualifier, CompareOperator.EQUAL, Bytes.toBytes("113"));	FilterList filterList = new FilterList(Operator.MUST_PASS_ONE, pf, scvf);	Scan s1 = new Scan();	s1.setFilter(filterList);	InternalScanner scanner = testRegion.getScanner(s1);	List<Cell> results = new ArrayList<>();	int resultCount = 0;	while (scanner.next(results)) {	resultCount++;	byte[] row =  CellUtil.cloneRow(results.get(0));	
found row 

for (Cell kv : results) {	LOG.info("row=" + row + ", result=" + kv.toString() + ", match=" + kvs[idx].toString());	assertTrue("Row mismatch", CellUtil.matchingRows(kv, kvs[idx]));	assertTrue("Family mismatch", CellUtil.matchingFamily(kv, kvs[idx]));	assertTrue("Qualifier mismatch", CellUtil.matchingQualifier(kv, kvs[idx]));	assertTrue("Value mismatch", CellUtil.matchingValue(kv, kvs[idx]));	idx++;	}	results.clear();	}	
looked at rows with keys 

for(Cell kv : results) {	LOG.info("row=" + row + ", result=" + kv.toString() + ", match=" + kvs[idx].toString());	assertTrue("Row mismatch", CellUtil.matchingRows(kv, kvs[idx]));	assertTrue("Family mismatch", CellUtil.matchingFamily(kv, kvs[idx]));	assertTrue("Qualifier mismatch", CellUtil.matchingQualifier(kv, kvs[idx]));	assertFalse("Should not have returned whole value", CellUtil.matchingValue(kv, kvs[idx]));	if (useLen) {	assertEquals("Value in result is not SIZEOF_INT", kv.getValueLength(), Bytes.SIZEOF_INT);	LOG.info("idx = "  + idx + ", len=" + kvs[idx].getValueLength() + ", actual=" +  Bytes.toInt(CellUtil.cloneValue(kv)));	assertEquals("Scan value should be the length of the actual value. ", kvs[idx].getValueLength(), Bytes.toInt(CellUtil.cloneValue(kv)) );	
good 

assertEquals("Value in result is not SIZEOF_INT", kv.getValueLength(), Bytes.SIZEOF_INT);	LOG.info("idx = "  + idx + ", len=" + kvs[idx].getValueLength() + ", actual=" +  Bytes.toInt(CellUtil.cloneValue(kv)));	assertEquals("Scan value should be the length of the actual value. ", kvs[idx].getValueLength(), Bytes.toInt(CellUtil.cloneValue(kv)) );	} else {	assertEquals("Value in result is not empty", kv.getValueLength(), 0);	}	idx++;	}	results.clear();	}	
looked at rows with keys 

public boolean filterRow() throws IOException {	ipcHandlerThread = Thread.currentThread();	try {	
handler thread sleeping in filter 

========================= hbase sample_1983 =========================

final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	MasterProcedureTestingUtility.createTable(procExec, tableName, null, "f1", "f2");	long procId1 = procExec.submitProcedure(new DisableTableProcedure( procExec.getEnvironment(), tableName, false));	ProcedureTestingUtility.waitProcedure(procExec, procId1);	ProcedureTestingUtility.assertProcNotFailed(procExec, procId1);	MasterProcedureTestingUtility.validateTableIsDisabled(getMaster(), tableName);	long procId2 = procExec.submitProcedure(new DisableTableProcedure( procExec.getEnvironment(), tableName, false));	ProcedureTestingUtility.waitProcedure(procExec, procId2);	Procedure<?> result = procExec.getResult(procId2);	assertTrue(result.isFailed());	
disable failed with exception 

ProcedureTestingUtility.waitProcedure(procExec, procId2);	Procedure<?> result = procExec.getResult(procId2);	assertTrue(result.isFailed());	assertTrue( ProcedureTestingUtility.getExceptionCause(result) instanceof TableNotEnabledException);	try {	final ProcedurePrepareLatch prepareLatch = new ProcedurePrepareLatch.CompatibilityLatch();	long procId3 = procExec.submitProcedure(new DisableTableProcedure( procExec.getEnvironment(), tableName, false, prepareLatch));	prepareLatch.await();	Assert.fail("Disable should throw exception through latch.");	} catch (TableNotEnabledException tnee) {	
disable failed with expected exception 

========================= hbase sample_1829 =========================

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	
running ingest 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	
cluster size 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	Threads.sleep( getConf().getInt("hbase.region.replica.replication.cache.disabledAndDroppedTables.expiryMs", 5000) + 1000);	long start = System.currentTimeMillis();	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	while (System.currentTimeMillis() - start < 0.9 * runtime) {	
intended run time min left min 

========================= hbase sample_3235 =========================

public void before() throws IOException {	
before 

public void before() throws IOException {	UTIL.ensureSomeRegionServersAvailable(1);	
before done 

public void testExtensionOfTableInputFormatBase() throws IOException {	
testing use of an inputformat taht extends inputformatbase 

public void testDeprecatedExtensionOfTableInputFormatBase() throws IOException {	
testing use of an inputformat taht extends inputformatbase as it was given in 

public void testJobConfigurableExtensionOfTableInputFormatBase() throws IOException {	
testing use of an inputformat taht extends inputformatbase using jobconfigurable 

========================= hbase sample_3370 =========================

public void notifyAllObservers(Configuration conf) {	
starting to notify all observers that config changed 

public void notifyAllObservers(Configuration conf) {	synchronized (configurationObservers) {	for (ConfigurationObserver observer : configurationObservers) {	try {	if (observer != null) {	observer.onConfigurationChange(conf);	}	} catch (Throwable t) {	
encountered a throwable while notifying observers of type 

========================= hbase sample_2998 =========================

}	Table table = null;	try {	table = handler.getTable(row.getTable());	if (failures > 2) {	throw new IOException("Auto-Fail rest of ICVs");	}	table.incrementColumnValue(row.getRowKey(), row.getFamily(), row.getQualifier(), counter);	} catch (IOException e) {	failures++;	
failed icv 

========================= hbase sample_800 =========================

public void doMain(String args[]) {	try {	int ret = ToolRunner.run(HBaseConfiguration.create(), this, args);	if (ret != 0) {	System.exit(ret);	}	} catch (Exception e) {	
failed to run 

========================= hbase sample_2218 =========================

public void testIncBackupDeleteTable() throws Exception {	
create full backup image for all tables 

========================= hbase sample_553 =========================

controller.sendMemberCompleted(sub, memberData);	committed.countDown();	return null;	}	}).when(member).receivedReachedGlobalBarrier(operationName);	controller.start(COHORT_NODE_NAME, member);	String prepare = ZKProcedureUtil.getAcquireBarrierNode(controller.getZkController(), operationName);	ZKUtil.createSetData(watcher, prepare, ProtobufUtil.prependPBMagic(data));	prepared.await();	String commit = ZKProcedureUtil.getReachedBarrierNode(controller.getZkController(), operationName);	
found prepared posting commit node 

committed.countDown();	return null;	}	}).when(member).receivedReachedGlobalBarrier(operationName);	controller.start(COHORT_NODE_NAME, member);	String prepare = ZKProcedureUtil.getAcquireBarrierNode(controller.getZkController(), operationName);	ZKUtil.createSetData(watcher, prepare, ProtobufUtil.prependPBMagic(data));	prepared.await();	String commit = ZKProcedureUtil.getReachedBarrierNode(controller.getZkController(), operationName);	ZKUtil.createAndFailSilent(watcher, commit);	
commit node exists 

========================= hbase sample_1571 =========================

public static RpcServer createRpcServer(final Server server, final String name, final List<BlockingServiceAndInterface> services, final InetSocketAddress bindAddress, Configuration conf, RpcScheduler scheduler, boolean reservoirEnabled) throws IOException {	String rpcServerClass = conf.get(CUSTOM_RPC_SERVER_IMPL_CONF_KEY, NettyRpcServer.class.getName());	StringBuilder servicesList = new StringBuilder();	for (BlockingServiceAndInterface s: services) {	ServiceDescriptor sd = s.getBlockingService().getDescriptorForType();	if (sd == null) continue;	if (servicesList.length() > 0) servicesList.append(", ");	servicesList.append(sd.getFullName());	}	
creating hosting 

========================= hbase sample_2920 =========================

static String getStubKey(String serviceName, ServerName serverName, boolean hostnameCanChange) {	String hostname = serverName.getHostname();	int port = serverName.getPort();	if (hostnameCanChange) {	try {	InetAddress ip = InetAddress.getByName(hostname);	return serviceName + "@" + hostname + "-" + ip.getHostAddress() + ":" + port;	} catch (UnknownHostException e) {	
can not resolve please check your network 

private static String getMyAddress() {	try {	return DNS.getDefaultHost("default", "default");	} catch (UnknownHostException uhe) {	
cannot determine my address 

========================= hbase sample_338 =========================

public void perform() throws Exception {	
performing action restart random region server 

========================= hbase sample_3327 =========================

private void putAndReplicateRows() throws Exception {	
putAndReplicateRows 

private void mimicSyncUpAfterDelete() throws Exception {	
mimicSyncUpAfterDelete 

assertEquals("@Peer1 t1_syncup should still have 100 rows", 100, rowCount_ht1TargetAtPeer1);	assertEquals("@Peer1 t2_syncup should still have 200 rows", 200, rowCount_ht2TargetAtPeer1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 50 || rowCount_ht2TargetAtPeer1 != 100) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	
syncup should have rows at source and it is 

assertEquals("@Peer1 t2_syncup should still have 200 rows", 200, rowCount_ht2TargetAtPeer1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 50 || rowCount_ht2TargetAtPeer1 != 100) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	rowCount_ht2Source = utility1.countRows(ht2Source);	
syncup should have rows at source and it is 

private void mimicSyncUpAfterPut() throws Exception {	
mimicSyncUpAfterPut 

assertEquals("@Peer1 t1_syncup should be NOT sync up and have 50 rows", 50, rowCount_ht1TargetAtPeer1);	assertEquals("@Peer1 t2_syncup should be NOT sync up and have 100 rows", 100, rowCount_ht2TargetAtPeer1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 100 || rowCount_ht2TargetAtPeer1 != 200) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	
syncup should have rows at source and it is 

assertEquals("@Peer1 t2_syncup should be NOT sync up and have 100 rows", 100, rowCount_ht2TargetAtPeer1);	for (int i = 0; i < NB_RETRIES; i++) {	syncUp(utility1);	rowCount_ht1TargetAtPeer1 = utility2.countRows(ht1TargetAtPeer1);	rowCount_ht2TargetAtPeer1 = utility2.countRows(ht2TargetAtPeer1);	if (i == NB_RETRIES - 1) {	if (rowCount_ht1TargetAtPeer1 != 100 || rowCount_ht2TargetAtPeer1 != 200) {	utility1.restartHBaseCluster(1);	rowCount_ht1Source = utility1.countRows(ht1Source);	rowCount_ht2Source = utility1.countRows(ht2Source);	
syncup should have rows at source and it is 

========================= hbase sample_1930 =========================

private Set<Class<?>> findClassesFromJar(String jarFileName, String packageName, boolean proceedOnExceptions) throws IOException, ClassNotFoundException, LinkageError {	JarInputStream jarFile = null;	try {	jarFile = new JarInputStream(new FileInputStream(jarFileName));	} catch (IOException ioEx) {	
failed to look for classes in 

Set<Class<?>> classes = new HashSet<>();	JarEntry entry = null;	try {	while (true) {	try {	entry = jarFile.getNextJarEntry();	} catch (IOException ioEx) {	if (!proceedOnExceptions) {	throw ioEx;	}	
failed to get next entry from 

if (null != this.fileNameFilter && !this.fileNameFilter.isCandidateFile(fileName, className)) {	continue;	}	className = className.substring(0, className.length() - CLASS_EXT.length()).replace('/', '.');	if (!className.startsWith(packageName)) {	continue;	}	Class<?> c = makeClass(className, proceedOnExceptions);	if (c != null) {	if (!classes.add(c)) {	
ignoring duplicate class 

private Set<Class<?>> findClassesFromFiles(File baseDirectory, String packageName, boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {	Set<Class<?>> classes = new HashSet<>();	if (!baseDirectory.exists()) {	
does not exist 

private Set<Class<?>> findClassesFromFiles(File baseDirectory, String packageName, boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {	Set<Class<?>> classes = new HashSet<>();	if (!baseDirectory.exists()) {	return classes;	}	File[] files = baseDirectory.listFiles(this.fileFilter);	if (files == null) {	
failed to get files from 

}	for (File file : files) {	final String fileName = file.getName();	if (file.isDirectory()) {	classes.addAll(findClassesFromFiles(file, packageName + "." + fileName, proceedOnExceptions));	} else {	String className = packageName + '.' + fileName.substring(0, fileName.length() - CLASS_EXT.length());	Class<?> c = makeClass(className, proceedOnExceptions);	if (c != null) {	if (!classes.add(c)) {	
ignoring duplicate class 

private Class<?> makeClass(String className, boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {	try {	Class<?> c = Class.forName(className, false, this.getClass().getClassLoader());	boolean isCandidateClass = null == classFilter || classFilter.isCandidateClass(c);	return isCandidateClass ? c : null;	} catch (NoClassDefFoundError|ClassNotFoundException classNotFoundEx) {	if (!proceedOnExceptions) {	throw classNotFoundEx;	}	
failed to instantiate or check 

boolean isCandidateClass = null == classFilter || classFilter.isCandidateClass(c);	return isCandidateClass ? c : null;	} catch (NoClassDefFoundError|ClassNotFoundException classNotFoundEx) {	if (!proceedOnExceptions) {	throw classNotFoundEx;	}	} catch (LinkageError linkageEx) {	if (!proceedOnExceptions) {	throw linkageEx;	}	
failed to instantiate or check 

========================= hbase sample_857 =========================

EvenOnlyCompactor compactor = (EvenOnlyCompactor) cp;	long ts = System.currentTimeMillis();	admin.flush(compactTable);	for (int i = 0; i < 10; i++) {	if (compactor.lastFlush >= ts) {	break;	}	Thread.sleep(1000);	}	assertTrue("Flush didn't complete", compactor.lastFlush >= ts);	
flush complete 

}	assertTrue("Flush didn't complete", compactor.lastFlush >= ts);	ts = compactor.lastFlush;	admin.majorCompact(compactTable);	for (int i = 0; i < 30; i++) {	if (compactor.lastCompaction >= ts) {	break;	}	Thread.sleep(1000);	}	
last compaction was at 

put.addColumn(A, A, A);	put.addColumn(B, B, B);	put.addColumn(C, C, C);	table.put(put);	table.put(put);	verifyMethodResult(SimpleRegionObserver.class, new String[] { "hadPreGet", "hadPostGet", "hadPrePut", "hadPostPut", "hadPreBatchMutate", "hadPostBatchMutate", "hadDelete" }, tableName, new Boolean[] { false, false, true, true, true, true, false });	verifyMethodResult(SimpleRegionObserver.class, new String[] { "getCtPreReplayWALs", "getCtPostReplayWALs", "getCtPreWALRestore", "getCtPostWALRestore", "getCtPrePut", "getCtPostPut" }, tableName, new Integer[] { 0, 0, 0, 0, 2, 2 });	cluster.killRegionServer(rs1.getRegionServer().getServerName());	Threads.sleep(1000);	util.waitUntilAllRegionsAssigned(tableName);	
all regions assigned 

========================= hbase sample_1526 =========================

return -1;	}	TableName tableName = TableName.valueOf(args[0]);	int numOps = args.length > 1 ? Integer.parseInt(args[1]) : DEFAULT_NUM_OPS;	ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_POOL_SIZE, Threads.newDaemonThreadFactory("AsyncClientExample"));	CountDownLatch latch = new CountDownLatch(numOps);	IntStream.range(0, numOps).forEach(i -> {	CompletableFuture<AsyncConnection> future = getConn();	future.whenComplete((conn, error) -> {	if (error != null) {	
failed to get async connection for 

IntStream.range(0, numOps).forEach(i -> {	CompletableFuture<AsyncConnection> future = getConn();	future.whenComplete((conn, error) -> {	if (error != null) {	latch.countDown();	return;	}	AsyncTable<?> table = conn.getTable(tableName, threadPool);	table.put(new Put(getKey(i)).addColumn(FAMILY, QUAL, Bytes.toBytes(i))) .whenComplete((putResp, putErr) -> {	if (putErr != null) {	
put failed for 

if (error != null) {	latch.countDown();	return;	}	AsyncTable<?> table = conn.getTable(tableName, threadPool);	table.put(new Put(getKey(i)).addColumn(FAMILY, QUAL, Bytes.toBytes(i))) .whenComplete((putResp, putErr) -> {	if (putErr != null) {	latch.countDown();	return;	}	
put for succeeded try getting 

return;	}	AsyncTable<?> table = conn.getTable(tableName, threadPool);	table.put(new Put(getKey(i)).addColumn(FAMILY, QUAL, Bytes.toBytes(i))) .whenComplete((putResp, putErr) -> {	if (putErr != null) {	latch.countDown();	return;	}	table.get(new Get(getKey(i))).whenComplete((result, getErr) -> {	if (getErr != null) {	
get failed for 

if (putErr != null) {	latch.countDown();	return;	}	table.get(new Get(getKey(i))).whenComplete((result, getErr) -> {	if (getErr != null) {	latch.countDown();	return;	}	if (result.isEmpty()) {	
get failed for server returns empty result 

latch.countDown();	return;	}	table.get(new Get(getKey(i))).whenComplete((result, getErr) -> {	if (getErr != null) {	latch.countDown();	return;	}	if (result.isEmpty()) {	} else if (!result.containsColumn(FAMILY, QUAL)) {	
get failed for the result does not contain 

table.get(new Get(getKey(i))).whenComplete((result, getErr) -> {	if (getErr != null) {	latch.countDown();	return;	}	if (result.isEmpty()) {	} else if (!result.containsColumn(FAMILY, QUAL)) {	} else {	int v = Bytes.toInt(result.getValue(FAMILY, QUAL));	if (v != i) {	
get failed for the value of is exected 

if (getErr != null) {	latch.countDown();	return;	}	if (result.isEmpty()) {	} else if (!result.containsColumn(FAMILY, QUAL)) {	} else {	int v = Bytes.toInt(result.getValue(FAMILY, QUAL));	if (v != i) {	} else {	
get for succeeded 

========================= hbase sample_1176 =========================

region.flush(true);	}	HTableDescriptor htd = new HTableDescriptor(admin.getTableDescriptor(tableName));	htd.setNormalizationEnabled(true);	admin.modifyTable(tableName, htd);	admin.flush(tableName);	assertEquals(5, MetaTableAccessor.getRegionCount(TEST_UTIL.getConnection(), tableName));	Thread.sleep(5000);	m.normalizeRegions();	while (MetaTableAccessor.getRegionCount(TEST_UTIL.getConnection(), tableName) > 4) {	
waiting for normalization merge to complete 

========================= hbase sample_1875 =========================

}	while (entryReader == null) {	if (source.sleepForRetries("Replication WAL entry reader thread not initialized", sleepMultiplier)) {	sleepMultiplier++;	}	}	try {	WALEntryBatch entryBatch = entryReader.take();	shipEdits(entryBatch);	if (entryBatch.getWalEntries().isEmpty() && entryBatch.getLastSeqIds().isEmpty()) {	
finished recovering queue for group of peer 

}	try {	WALEntryBatch entryBatch = entryReader.take();	shipEdits(entryBatch);	if (entryBatch.getWalEntries().isEmpty() && entryBatch.getLastSeqIds().isEmpty()) {	source.getSourceMetrics().incrCompletedRecoveryQueue();	setWorkerState(WorkerState.FINISHED);	continue;	}	} catch (InterruptedException e) {	
interrupted while waiting for next replication entry batch 

public long getStartPosition() {	long startPosition = getRecoveredQueueStartPos();	int numRetries = 0;	while (numRetries <= maxRetriesMultiplier) {	try {	source.locateRecoveredPaths(queue);	break;	} catch (IOException e) {	
error while locating recovered queue paths attempt 

private long getRecoveredQueueStartPos() {	long startPosition = 0;	String peerClusterZnode = source.getQueueId();	try {	startPosition = this.replicationQueues.getWALPosition(source.getServerWALsBelongTo(), peerClusterZnode, this.queue.peek().getName());	if (LOG.isTraceEnabled()) {	
recovered queue started with log at position 

private void terminate(String reason, Exception cause) {	if (cause == null) {	
closing worker for wal group because 

private void terminate(String reason, Exception cause) {	if (cause == null) {	} else {	
closing worker for wal group because an error occurred 

private void terminate(String reason, Exception cause) {	if (cause == null) {	} else {	}	entryReader.interrupt();	Threads.shutdown(entryReader, sleepForRetries);	this.interrupt();	Threads.shutdown(this, sleepForRetries);	
replicationsourceworker terminated 

========================= hbase sample_2936 =========================

public Void call() throws Exception {	
starting snapshot operation on 

public Void call() throws Exception {	region.startRegionOperation(Operation.SNAPSHOT);	try {	if (skipFlush) {	
take snapshot without flush memstore first 

public Void call() throws Exception {	region.startRegionOperation(Operation.SNAPSHOT);	try {	if (skipFlush) {	} else {	
flush snapshotting region started 

succeeded = true;	break;	}	}	if (!succeeded) {	throw new IOException("Unable to complete flush after " + MAX_RETRIES + " attempts");	}	}	region.addRegionToSnapshot(snapshotDesc, monitor);	if (skipFlush) {	
skipflush snapshotting region completed 

break;	}	}	if (!succeeded) {	throw new IOException("Unable to complete flush after " + MAX_RETRIES + " attempts");	}	}	region.addRegionToSnapshot(snapshotDesc, monitor);	if (skipFlush) {	} else {	
flush snapshotting region completed 

}	if (!succeeded) {	throw new IOException("Unable to complete flush after " + MAX_RETRIES + " attempts");	}	}	region.addRegionToSnapshot(snapshotDesc, monitor);	if (skipFlush) {	} else {	}	} finally {	
closing snapshot operation on 

return;	}	monitor.rethrowException();	if (taskManager.hasTasks()) {	throw new IllegalStateException("Attempting to take snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " but we currently have outstanding tasks");	}	for (HRegion region : regions) {	taskManager.submitTask(new RegionSnapshotTask(region, snapshot, snapshotSkipFlush, monitor));	monitor.rethrowException();	}	
flush snapshot tasks submitted for regions 

if (taskManager.hasTasks()) {	throw new IllegalStateException("Attempting to take snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " but we currently have outstanding tasks");	}	for (HRegion region : regions) {	taskManager.submitTask(new RegionSnapshotTask(region, snapshot, snapshotSkipFlush, monitor));	monitor.rethrowException();	}	try {	taskManager.waitForOutstandingTasks();	} catch (InterruptedException e) {	
got interrupted exception for 

public void cleanup(Exception e) {	
aborting all online flush snapshot subprocedure task threads for due to error 

========================= hbase sample_2520 =========================

}	if (wl == null || wl.writer == null) {	if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {	HRegionLocation loc = null;	String tableName = Bytes.toString(tableNameBytes);	if (tableName != null) {	try (Connection connection = ConnectionFactory.createConnection(conf);	RegionLocator locator = connection.getRegionLocator(TableName.valueOf(tableName))) {	loc = locator.getRegionLocation(rowKey);	} catch (Throwable e) {	
there s something wrong when locating rowkey for tablename 

String tableName = Bytes.toString(tableNameBytes);	if (tableName != null) {	try (Connection connection = ConnectionFactory.createConnection(conf);	RegionLocator locator = connection.getRegionLocator(TableName.valueOf(tableName))) {	loc = locator.getRegionLocation(rowKey);	} catch (Throwable e) {	loc = null;	} }	if (null == loc) {	if (LOG.isTraceEnabled()) {	
failed to get region location so use default writer for rowkey 

loc = locator.getRegionLocation(rowKey);	} catch (Throwable e) {	loc = null;	} }	if (null == loc) {	if (LOG.isTraceEnabled()) {	}	wl = getNewWriter(tableNameBytes, family, conf, null);	} else {	if (LOG.isDebugEnabled()) {	
first rowkey 

if (null == loc) {	if (LOG.isTraceEnabled()) {	}	wl = getNewWriter(tableNameBytes, family, conf, null);	} else {	if (LOG.isDebugEnabled()) {	}	InetSocketAddress initialIsa = new InetSocketAddress(loc.getHostname(), loc.getPort());	if (initialIsa.isUnresolved()) {	if (LOG.isTraceEnabled()) {	
failed to resolve bind address so use default writer 

} else {	if (LOG.isDebugEnabled()) {	}	InetSocketAddress initialIsa = new InetSocketAddress(loc.getHostname(), loc.getPort());	if (initialIsa.isUnresolved()) {	if (LOG.isTraceEnabled()) {	}	wl = getNewWriter(tableNameBytes, family, conf, null);	} else {	if (LOG.isDebugEnabled()) {	
use favored nodes writer 

private static List<ImmutableBytesWritable> getRegionStartKeys(List<RegionLocator> regionLocators, boolean writeMultipleTables) throws IOException {	ArrayList<ImmutableBytesWritable> ret = new ArrayList<>();	for(RegionLocator regionLocator : regionLocators) {	TableName tableName = regionLocator.getName();	
looking up current regions for table 

ArrayList<ImmutableBytesWritable> ret = new ArrayList<>();	for(RegionLocator regionLocator : regionLocators) {	TableName tableName = regionLocator.getName();	byte[][] byteKeys = regionLocator.getStartKeys();	for (byte[] byteKey : byteKeys) {	byte[] fullKey = byteKey;	if (writeMultipleTables) {	fullKey = combineTableNameSuffix(tableName.getName(), byteKey);	}	if (LOG.isDebugEnabled()) {	
splitpoint startkey for table 

private static void writePartitions(Configuration conf, Path partitionsPath, List<ImmutableBytesWritable> startKeys, boolean writeMultipleTables) throws IOException {	
writing partition information to 

writeMultipleTables = true;	conf.setBoolean(MULTI_TABLE_HFILEOUTPUTFORMAT_CONF_KEY, true);	}	if (KeyValue.class.equals(job.getMapOutputValueClass()) || MapReduceExtendedCell.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(CellSortReducer.class);	} else if (Put.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(PutSortReducer.class);	} else if (Text.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(TextSortReducer.class);	} else {	
unknown map output value type 

if (KeyValue.class.equals(job.getMapOutputValueClass()) || MapReduceExtendedCell.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(CellSortReducer.class);	} else if (Put.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(PutSortReducer.class);	} else if (Text.class.equals(job.getMapOutputValueClass())) {	job.setReducerClass(TextSortReducer.class);	} else {	}	conf.setStrings("io.serializations", conf.get("io.serializations"), MutationSerialization.class.getName(), ResultSerialization.class.getName(), CellSerialization.class.getName());	if (conf.getBoolean(LOCALITY_SENSITIVE_CONF_KEY, DEFAULT_LOCALITY_SENSITIVE)) {	
bulkload locality sensitive enabled 

List<String> allTableNames = new ArrayList<>(multiTableInfo.size());	List<RegionLocator> regionLocators = new ArrayList<>( multiTableInfo.size());	List<TableDescriptor> tableDescriptors = new ArrayList<>( multiTableInfo.size());	for( TableInfo tableInfo : multiTableInfo ) {	regionLocators.add(tableInfo.getRegionLocator());	allTableNames.add(tableInfo.getRegionLocator().getName().getNameAsString());	tableDescriptors.add(tableInfo.getTableDescriptor());	}	conf.set(OUTPUT_TABLE_NAME_CONF_KEY, StringUtils.join(allTableNames, Bytes .toString(tableSeparator)));	List<ImmutableBytesWritable> startKeys = getRegionStartKeys(regionLocators, writeMultipleTables);	
configuring reduce partitions to match current region count for all tables 

conf.set(OUTPUT_TABLE_NAME_CONF_KEY, StringUtils.join(allTableNames, Bytes .toString(tableSeparator)));	List<ImmutableBytesWritable> startKeys = getRegionStartKeys(regionLocators, writeMultipleTables);	job.setNumReduceTasks(startKeys.size());	configurePartitioner(job, startKeys, writeMultipleTables);	conf.set(COMPRESSION_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(compressionDetails, tableDescriptors));	conf.set(BLOCK_SIZE_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(blockSizeDetails, tableDescriptors));	conf.set(BLOOM_TYPE_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(bloomTypeDetails, tableDescriptors));	conf.set(DATABLOCK_ENCODING_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(dataBlockEncodingDetails, tableDescriptors));	TableMapReduceUtil.addDependencyJars(job);	TableMapReduceUtil.initCredentials(job);	
incremental output configured for tables 

job.setOutputFormatClass(HFileOutputFormat2.class);	ArrayList<TableDescriptor> singleTableDescriptor = new ArrayList<>(1);	singleTableDescriptor.add(tableDescriptor);	conf.set(OUTPUT_TABLE_NAME_CONF_KEY, tableDescriptor.getTableName().getNameAsString());	conf.set(COMPRESSION_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(compressionDetails, singleTableDescriptor));	conf.set(BLOCK_SIZE_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(blockSizeDetails, singleTableDescriptor));	conf.set(BLOOM_TYPE_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(bloomTypeDetails, singleTableDescriptor));	conf.set(DATABLOCK_ENCODING_FAMILIES_CONF_KEY, serializeColumnFamilyAttribute(dataBlockEncodingDetails, singleTableDescriptor));	TableMapReduceUtil.addDependencyJars(job);	TableMapReduceUtil.initCredentials(job);	
incremental table output configured 

========================= hbase sample_3448 =========================

public void testReplicationEndpointReturnsFalseOnReplicate() throws Exception {	Assert.assertEquals(0, ReplicationEndpointForTest.replicateCount.get());	Assert.assertTrue(!ReplicationEndpointReturningFalse.replicated.get());	int peerCount = admin.getPeersCount();	final String id = "testReplicationEndpointReturnsFalseOnReplicate";	admin.addPeer(id, new ReplicationPeerConfig().setClusterKey(ZKConfig.getZooKeeperClusterKey(conf1)) .setReplicationEndpointImpl(ReplicationEndpointReturningFalse.class.getName()), null);	if (admin.getPeersCount() <= peerCount) {	
waiting on peercount to go up from 

========================= hbase sample_1926 =========================

public void shutdown() throws IOException {	IOException failure = null;	for (WALProvider provider: cached.values()) {	try {	provider.shutdown();	} catch (IOException e) {	
problem shutting down wal provider 

public void shutdown() throws IOException {	IOException failure = null;	for (WALProvider provider: cached.values()) {	try {	provider.shutdown();	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
details of problem shutting down wal provider 

public void close() throws IOException {	IOException failure = null;	for (WALProvider provider : cached.values()) {	try {	provider.close();	} catch (IOException e) {	
problem closing wal provider 

public void close() throws IOException {	IOException failure = null;	for (WALProvider provider : cached.values()) {	try {	provider.close();	} catch (IOException e) {	if (LOG.isDebugEnabled()) {	
details of problem closing wal provider 

========================= hbase sample_2259 =========================

int numRegions = getTableRegionsFromServer(tableName, mostLoadedServer).size();	excludedServers.add(mostLoadedServer);	ServerName source = getRSWithMaxRegions(tableName, excludedServers);	assertNotNull(source);	int regionsToMove = getTableRegionsFromServer(tableName, source).size()/2;	List<RegionInfo> hris = getRegionsThatCanBeMoved(tableName, mostLoadedServer);	RegionStates rst = master.getAssignmentManager().getRegionStates();	for (int i = 0; i < regionsToMove; i++) {	final RegionInfo regionInfo = hris.get(i);	admin.move(regionInfo.getEncodedNameAsBytes(), Bytes.toBytes(mostLoadedServer.getServerName()));	
moving region to 

}	}	RegionLocationFinder regionFinder = new RegionLocationFinder();	regionFinder.setClusterMetrics(admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)));	regionFinder.setConf(conf);	regionFinder.setServices(TEST_UTIL.getMiniHBaseCluster().getMaster());	Cluster cluster = new Cluster(serverAssignments, null, regionFinder, new RackManager(conf));	LoadOnlyFavoredStochasticBalancer balancer = (LoadOnlyFavoredStochasticBalancer) TEST_UTIL .getMiniHBaseCluster().getMaster().getLoadBalancer();	cluster.sortServersByRegionCount();	Integer[] servers = cluster.serverIndicesSortedByRegionCount;	
servers sorted by region count 

}	}	RegionLocationFinder regionFinder = new RegionLocationFinder();	regionFinder.setClusterMetrics(admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)));	regionFinder.setConf(conf);	regionFinder.setServices(TEST_UTIL.getMiniHBaseCluster().getMaster());	Cluster cluster = new Cluster(serverAssignments, null, regionFinder, new RackManager(conf));	LoadOnlyFavoredStochasticBalancer balancer = (LoadOnlyFavoredStochasticBalancer) TEST_UTIL .getMiniHBaseCluster().getMaster().getLoadBalancer();	cluster.sortServersByRegionCount();	Integer[] servers = cluster.serverIndicesSortedByRegionCount;	
cluster dump 

}	RegionLocationFinder regionFinder = new RegionLocationFinder();	regionFinder.setClusterMetrics(admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)));	regionFinder.setConf(conf);	regionFinder.setServices(TEST_UTIL.getMiniHBaseCluster().getMaster());	Cluster cluster = new Cluster(serverAssignments, null, regionFinder, new RackManager(conf));	LoadOnlyFavoredStochasticBalancer balancer = (LoadOnlyFavoredStochasticBalancer) TEST_UTIL .getMiniHBaseCluster().getMaster().getLoadBalancer();	cluster.sortServersByRegionCount();	Integer[] servers = cluster.serverIndicesSortedByRegionCount;	if (!mostLoadedServer.equals(cluster.servers[servers[servers.length -1]])) {	
most loaded server does not match 

private ServerName getRSWithMaxRegions(TableName tableName, List<ServerName> excludeNodes) throws IOException {	int maxRegions = 0;	ServerName maxLoadedServer = null;	for (JVMClusterUtil.RegionServerThread rst : cluster.getLiveRegionServerThreads()) {	List<HRegion> regions = rst.getRegionServer().getRegions(tableName);	
server regions 

========================= hbase sample_1863 =========================

public void refreshHFiles(RpcController controller, RefreshHFilesProtos.RefreshHFilesRequest request, RpcCallback<RefreshHFilesProtos.RefreshHFilesResponse> done) {	try {	for (Store store : env.getRegion().getStores()) {	
refreshing hfiles for region and store class 

public void refreshHFiles(RpcController controller, RefreshHFilesProtos.RefreshHFilesRequest request, RpcCallback<RefreshHFilesProtos.RefreshHFilesResponse> done) {	try {	for (Store store : env.getRegion().getStores()) {	store.refreshStoreFiles();	}	} catch (IOException ioe) {	
exception while trying to refresh store files 

========================= hbase sample_1160 =========================

int code = hashTable.run(new String[] {	"--batchsize=" + batchSize, "--numhashfiles=" + numHashFiles, "--scanbatch=2", tableName.getNameAsString(), testDir.toString()});	assertEquals("test job failed", 0, code);	FileSystem fs = TEST_UTIL.getTestFileSystem();	HashTable.TableHash tableHash = HashTable.TableHash.read(fs.getConf(), testDir);	assertEquals(tableName.getNameAsString(), tableHash.tableName);	assertEquals(batchSize, tableHash.batchSize);	assertEquals(numHashFiles, tableHash.numHashFiles);	assertEquals(numHashFiles - 1, tableHash.partitions.size());	for (ImmutableBytesWritable bytes : tableHash.partitions) {	
partition 

ImmutableMap<Integer, ImmutableBytesWritable> expectedHashes = ImmutableMap.<Integer, ImmutableBytesWritable>builder() .put(-1, new ImmutableBytesWritable(Bytes.fromHex("714cb10a9e3b5569852980edd8c6ca2f"))) .put(5, new ImmutableBytesWritable(Bytes.fromHex("28d961d9252ce8f8d44a07b38d3e1d96"))) .put(10, new ImmutableBytesWritable(Bytes.fromHex("f6bbc4a224d8fd929b783a92599eaffa"))) .put(15, new ImmutableBytesWritable(Bytes.fromHex("522deb5d97f73a414ecc11457be46881"))) .put(20, new ImmutableBytesWritable(Bytes.fromHex("b026f2611aaa46f7110116d807545352"))) .put(25, new ImmutableBytesWritable(Bytes.fromHex("39ffc1a3094aa12a2e90ffd9cef2ce93"))) .put(30, new ImmutableBytesWritable(Bytes.fromHex("f6b4d75727ce9a30ac29e4f08f601666"))) .put(35, new ImmutableBytesWritable(Bytes.fromHex("422e2d2f1eb79a8f02171a705a42c090"))) .put(40, new ImmutableBytesWritable(Bytes.fromHex("559ad61c900fffefea0a15abf8a97bc3"))) .put(45, new ImmutableBytesWritable(Bytes.fromHex("23019084513eca41cee436b2a29611cb"))) .put(50, new ImmutableBytesWritable(Bytes.fromHex("b40467d222ddb4949b142fe145ee9edc"))) .put(55, new ImmutableBytesWritable(Bytes.fromHex("372bf89fcd8ca4b7ab3c1add9d07f7e4"))) .put(60, new ImmutableBytesWritable(Bytes.fromHex("69ae0585e6255de27dce974e332b8f8b"))) .put(65, new ImmutableBytesWritable(Bytes.fromHex("8029610044297aad0abdbecd485d8e59"))) .put(70, new ImmutableBytesWritable(Bytes.fromHex("de5f784f7f78987b6e57ecfd81c8646f"))) .put(75, new ImmutableBytesWritable(Bytes.fromHex("1cd757cc4e1715c8c3b1c24447a1ec56"))) .put(80, new ImmutableBytesWritable(Bytes.fromHex("f9a53aacfeb6142b08066615e7038095"))) .put(85, new ImmutableBytesWritable(Bytes.fromHex("89b872b7e639df32d3276b33928c0c91"))) .put(90, new ImmutableBytesWritable(Bytes.fromHex("45eeac0646d46a474ea0484175faed38"))) .put(95, new ImmutableBytesWritable(Bytes.fromHex("f57c447e32a08f4bf1abb2892839ac56"))) .build();	Map<Integer, ImmutableBytesWritable> actualHashes = new HashMap<>();	Path dataDir = new Path(testDir, HashTable.HASH_DATA_DIR);	for (int i = 0; i < numHashFiles; i++) {	Path hashPath = new Path(dataDir, HashTable.TableHash.getDataFileName(i));	MapFile.Reader reader = new MapFile.Reader(hashPath, fs.getConf());	ImmutableBytesWritable key = new ImmutableBytesWritable();	ImmutableBytesWritable hash = new ImmutableBytesWritable();	while(reader.next(key, hash)) {	String keyString = Bytes.toHex(key.get(), key.getOffset(), key.getLength());	
key hash 

}	if (actualHashes.containsKey(intKey)) {	Assert.fail("duplicate key in data files: " + intKey);	}	actualHashes.put(intKey, new ImmutableBytesWritable(hash.copyBytes()));	}	reader.close();	}	FileStatus[] files = fs.listStatus(testDir);	for (FileStatus file : files) {	
output file 

}	actualHashes.put(intKey, new ImmutableBytesWritable(hash.copyBytes()));	}	reader.close();	}	FileStatus[] files = fs.listStatus(testDir);	for (FileStatus file : files) {	}	files = fs.listStatus(dataDir);	for (FileStatus file : files) {	
data file 

}	reader.close();	}	FileStatus[] files = fs.listStatus(testDir);	for (FileStatus file : files) {	}	files = fs.listStatus(dataDir);	for (FileStatus file : files) {	}	if (!expectedHashes.equals(actualHashes)) {	
diff 

========================= hbase sample_3389 =========================

public synchronized void start() {	this.watcher.registerListener(this);	try {	if(ZKUtil.watchAndCheckExists(watcher, node)) {	byte [] data = ZKUtil.getDataAndWatch(watcher, node);	if(data != null) {	this.data = data;	} else {	
try starting again because there is no data from 

if (timeout < 0) {	throw new IllegalArgumentException();	}	boolean notimeout = timeout == 0;	long startTime = System.currentTimeMillis();	long remaining = timeout;	if (refresh) {	try {	this.data = ZKUtil.getDataAndWatch(watcher, node);	} catch(KeeperException e) {	
unexpected exception handling blockuntilavailable 

} catch(KeeperException e) {	abortable.abort("Unexpected exception handling blockUntilAvailable", e);	}	}	boolean nodeExistsChecked = (!refresh ||data!=null);	while (!this.stopped && (notimeout || remaining > 0) && this.data == null) {	if (!nodeExistsChecked) {	try {	nodeExistsChecked = (ZKUtil.checkExists(watcher, node) != -1);	} catch (KeeperException e) {	
got exception while trying to check existence in zookeeper of the node retrying if timeout not reached 

}	}	boolean nodeExistsChecked = (!refresh ||data!=null);	while (!this.stopped && (notimeout || remaining > 0) && this.data == null) {	if (!nodeExistsChecked) {	try {	nodeExistsChecked = (ZKUtil.checkExists(watcher, node) != -1);	} catch (KeeperException e) {	}	if (nodeExistsChecked){	
node now exists resetting a watcher 

while (!this.stopped && (notimeout || remaining > 0) && this.data == null) {	if (!nodeExistsChecked) {	try {	nodeExistsChecked = (ZKUtil.checkExists(watcher, node) != -1);	} catch (KeeperException e) {	}	if (nodeExistsChecked){	try {	this.data = ZKUtil.getDataAndWatch(watcher, node);	} catch (KeeperException e) {	
unexpected exception handling blockuntilavailable 

========================= hbase sample_729 =========================

private void testBackupDeleteWithFailuresAfter(int expected, Failure ...failures) throws Exception {	
test repair backup delete on a single table with data and failures 

private void testBackupDeleteWithFailuresAfter(int expected, Failure ...failures) throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	
backup complete 

========================= hbase sample_545 =========================

private boolean checkDuplicates(Collection<HRegion> onlineRegions3) throws Exception {	ArrayList<Region> copyOfRegion = new ArrayList<Region>(onlineRegions3);	for (Region region : copyOfRegion) {	RegionInfo regionInfo = region.getRegionInfo();	RegionInfo regionInfoForReplica = RegionReplicaUtil.getRegionInfoForDefaultReplica(regionInfo);	int i = 0;	for (Region actualRegion : onlineRegions3) {	if (regionInfoForReplica.equals( RegionReplicaUtil.getRegionInfoForDefaultReplica(actualRegion.getRegionInfo()))) {	i++;	if (i > 1) {	
duplicate found 

========================= hbase sample_1588 =========================

public void testTruncateNotExistentTable() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	long procId = ProcedureTestingUtility.submitAndWait(procExec, new TruncateTableProcedure(procExec.getEnvironment(), tableName, true));	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
truncate failed with exception 

public void testTruncateNotDisabledTable() throws Exception {	final TableName tableName = TableName.valueOf(name.getMethodName());	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	MasterProcedureTestingUtility.createTable(procExec, tableName, null, "f");	long procId = ProcedureTestingUtility.submitAndWait(procExec, new TruncateTableProcedure(procExec.getEnvironment(), tableName, false));	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
truncate failed with exception 

========================= hbase sample_1834 =========================

rs = Mockito.mock(HRegionServer.class);	rpcServices = Mockito.mock(RSRpcServices.class);	rpcServer = Mockito.mock(RpcServerInterface.class);	Mockito.doReturn(HBaseConfiguration.create()) .when(rs).getConfiguration();	Mockito.doReturn(rpcServices).when(rs).getRSRpcServices();	Mockito.doReturn(rpcServer).when(rs).getRpcServer();	Mockito.doReturn(fakeResponse).when(rpcServices).getServerInfo( (RpcController)Mockito.any(), (GetServerInfoRequest)Mockito.any());	ZKWatcher zkw = Mockito.mock(ZKWatcher.class);	Mockito.doReturn("fakequorum").when(zkw).getQuorum();	Mockito.doReturn(zkw).when(rs).getZooKeeper();	
the is set to 

========================= hbase sample_1770 =========================

public void startRegionServer(String hostname, int port) throws IOException {	
starting rs on 

public void killRegionServer(ServerName serverName) throws IOException {	
aborting rs 

public void stopRegionServer(ServerName serverName) throws IOException {	
stopping rs 

public void startZkNode(String hostname, int port) throws IOException {	
starting zookeeper node on 

public void killZkNode(ServerName serverName) throws IOException {	
aborting zookeeper node on 

public void stopZkNode(ServerName serverName) throws IOException {	
stopping zookeeper node 

public void startDataNode(ServerName serverName) throws IOException {	
starting data node on 

public void killDataNode(ServerName serverName) throws IOException {	
aborting data node on 

public void stopDataNode(ServerName serverName) throws IOException {	
stopping data node on 

private void waitForServiceToStop(ServiceType service, ServerName serverName, long timeout) throws IOException {	
waiting for service to stop 

private void waitForServiceToStart(ServiceType service, ServerName serverName, long timeout) throws IOException {	
waiting for service to start 

public void startMaster(String hostname, int port) throws IOException {	
starting master on 

public void killMaster(ServerName serverName) throws IOException {	
aborting master 

public void stopMaster(ServerName serverName) throws IOException {	
stopping master 

public boolean waitForActiveAndReadyMaster(long timeout) throws IOException {	long start = System.currentTimeMillis();	while (System.currentTimeMillis() - start < timeout) {	try {	getMasterAdminService();	return true;	} catch (MasterNotRunningException m) {	
master not started yet 

public boolean waitForActiveAndReadyMaster(long timeout) throws IOException {	long start = System.currentTimeMillis();	while (System.currentTimeMillis() - start < timeout) {	try {	getMasterAdminService();	return true;	} catch (MasterNotRunningException m) {	} catch (ZooKeeperConnectionException e) {	
failed to connect to zk 

public ServerName getServerHoldingRegion(TableName tn, byte[] regionName) throws IOException {	HRegionLocation regionLoc = null;	try (RegionLocator locator = connection.getRegionLocator(tn)) {	regionLoc = locator.getRegionLocation(regionName, true);	}	if (regionLoc == null) {	
cannot find region server holding region start key 

public boolean restoreClusterMetrics(ClusterMetrics initial) throws IOException {	ClusterMetrics current = getClusterMetrics();	
restoring cluster started 

public boolean restoreClusterMetrics(ClusterMetrics initial) throws IOException {	ClusterMetrics current = getClusterMetrics();	boolean success = true;	success = restoreMasters(initial, current) & success;	success = restoreRegionServers(initial, current) & success;	success = restoreAdmin() & success;	
restoring cluster done 

protected boolean restoreMasters(ClusterMetrics initial, ClusterMetrics current) {	List<IOException> deferred = new ArrayList<>();	final ServerName initMaster = initial.getMasterName();	if (!ServerName.isSameAddress(initMaster, current.getMasterName())) {	
restoring cluster initial active master has changed to 

protected boolean restoreMasters(ClusterMetrics initial, ClusterMetrics current) {	List<IOException> deferred = new ArrayList<>();	final ServerName initMaster = initial.getMasterName();	if (!ServerName.isSameAddress(initMaster, current.getMasterName())) {	try {	if (!clusterManager.isRunning(ServiceType.HBASE_MASTER, initMaster.getHostname(), initMaster.getPort())) {	
restoring cluster starting initial active master at 

protected boolean restoreMasters(ClusterMetrics initial, ClusterMetrics current) {	List<IOException> deferred = new ArrayList<>();	final ServerName initMaster = initial.getMasterName();	if (!ServerName.isSameAddress(initMaster, current.getMasterName())) {	try {	if (!clusterManager.isRunning(ServiceType.HBASE_MASTER, initMaster.getHostname(), initMaster.getPort())) {	startMaster(initMaster.getHostname(), initMaster.getPort());	}	for (ServerName currentBackup : current.getBackupMasterNames()) {	if (!ServerName.isSameAddress(currentBackup, initMaster)) {	
restoring cluster stopping backup master 

if (!ServerName.isSameAddress(initMaster, current.getMasterName())) {	try {	if (!clusterManager.isRunning(ServiceType.HBASE_MASTER, initMaster.getHostname(), initMaster.getPort())) {	startMaster(initMaster.getHostname(), initMaster.getPort());	}	for (ServerName currentBackup : current.getBackupMasterNames()) {	if (!ServerName.isSameAddress(currentBackup, initMaster)) {	stopMaster(currentBackup);	}	}	
restoring cluster stopping active master 

}	}	stopMaster(current.getMasterName());	waitForActiveAndReadyMaster();	} catch (IOException ex) {	deferred.add(ex);	}	for (ServerName backup : initial.getBackupMasterNames()) {	try {	if (!clusterManager.isRunning(ServiceType.HBASE_MASTER, backup.getHostname(), backup.getPort())) {	
restoring cluster starting initial backup master 

toKill.addAll(current.getBackupMasterNames());	for (ServerName server : current.getBackupMasterNames()) {	toStart.remove(server);	}	for (ServerName server: initial.getBackupMasterNames()) {	toKill.remove(server);	}	for (ServerName sn:toStart) {	try {	if(!clusterManager.isRunning(ServiceType.HBASE_MASTER, sn.getHostname(), sn.getPort())) {	
restoring cluster starting initial backup master 

if(!clusterManager.isRunning(ServiceType.HBASE_MASTER, sn.getHostname(), sn.getPort())) {	startMaster(sn.getHostname(), sn.getPort());	}	} catch (IOException ex) {	deferred.add(ex);	}	}	for (ServerName sn:toKill) {	try {	if(clusterManager.isRunning(ServiceType.HBASE_MASTER, sn.getHostname(), sn.getPort())) {	
restoring cluster stopping backup master 

try {	if(clusterManager.isRunning(ServiceType.HBASE_MASTER, sn.getHostname(), sn.getPort())) {	stopMaster(sn);	}	} catch (IOException ex) {	deferred.add(ex);	}	}	}	if (!deferred.isEmpty()) {	
restoring cluster restoring region servers reported errors 

for (ServerName server : current.getLiveServerMetrics().keySet()) {	toStart.remove(server);	}	for (ServerName server: initial.getLiveServerMetrics().keySet()) {	toKill.remove(server);	}	List<IOException> deferred = new ArrayList<>();	for(ServerName sn:toStart) {	try {	if (!clusterManager.isRunning(ServiceType.HBASE_REGIONSERVER, sn.getHostname(), sn.getPort()) && master.getPort() != sn.getPort()) {	
restoring cluster starting initial region server 

if (!clusterManager.isRunning(ServiceType.HBASE_REGIONSERVER, sn.getHostname(), sn.getPort()) && master.getPort() != sn.getPort()) {	startRegionServer(sn.getHostname(), sn.getPort());	}	} catch (IOException ex) {	deferred.add(ex);	}	}	for(ServerName sn:toKill) {	try {	if (clusterManager.isRunning(ServiceType.HBASE_REGIONSERVER, sn.getHostname(), sn.getPort()) && master.getPort() != sn.getPort()){	
restoring cluster stopping initial region server 

for(ServerName sn:toKill) {	try {	if (clusterManager.isRunning(ServiceType.HBASE_REGIONSERVER, sn.getHostname(), sn.getPort()) && master.getPort() != sn.getPort()){	stopRegionServer(sn);	}	} catch (IOException ex) {	deferred.add(ex);	}	}	if (!deferred.isEmpty()) {	
restoring cluster restoring region servers reported errors 

protected boolean restoreAdmin() throws IOException {	try {	admin.close();	} catch (IOException ioe) {	
while closing the old connection 

protected boolean restoreAdmin() throws IOException {	try {	admin.close();	} catch (IOException ioe) {	}	this.admin = this.connection.getAdmin();	
added new hbaseadmin 

========================= hbase sample_3258 =========================

public void export(RpcController controller, ExportProtos.ExportRequest request, RpcCallback<ExportProtos.ExportResponse> done) {	Region region = env.getRegion();	Configuration conf = HBaseConfiguration.create(env.getConfiguration());	conf.setStrings("io.serializations", conf.get("io.serializations"), ResultSerialization.class.getName());	try {	Scan scan = validateKey(region.getRegionInfo(), request);	Token userToken = null;	if (userProvider.isHadoopSecurityEnabled() && !request.hasFsToken()) {	
hadoop security is enable but no found of user token 

private static User getActiveUser(final UserProvider userProvider, final Token userToken) throws IOException {	User user = RpcServer.getRequestUser().orElse(userProvider.getCurrent());	if (user == null && userToken != null) {	
no found of user credentials but a token was got from user request 

========================= hbase sample_1265 =========================

public void start() {	if (ras.isEmpty()) {	
no resource analyzer 

public void end() {	if (ras.isEmpty()) {	
no resource analyzer 

public void end() {	if (ras.isEmpty()) {	return;	}	if (initialValues == null) {	
no initial values 

========================= hbase sample_882 =========================

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	
reading current quota snapshots from hbase quota 

protected void chore() {	try {	if (LOG.isTraceEnabled()) {	}	final Map<TableName, SpaceQuotaSnapshot> currentSnapshots = getManager().copyQuotaSnapshots();	final Map<TableName, SpaceQuotaSnapshot> newSnapshots = fetchSnapshotsFromQuotaTable();	if (LOG.isTraceEnabled()) {	
table quota snapshots are collected read from the quota table 

for (Entry<TableName, SpaceQuotaSnapshot> entry : newSnapshots.entrySet()) {	final TableName tableName = entry.getKey();	final SpaceQuotaSnapshot newSnapshot = entry.getValue();	final SpaceQuotaSnapshot currentSnapshot = currentSnapshots.get(tableName);	if (LOG.isTraceEnabled()) {	LOG.trace(tableName + ": current=" + currentSnapshot + ", new=" + newSnapshot);	}	if (!newSnapshot.equals(currentSnapshot)) {	if (!isInViolation(currentSnapshot) && newSnapshot.getQuotaStatus().isInViolation()) {	if (LOG.isTraceEnabled()) {	
enabling on 

LOG.trace(tableName + ": current=" + currentSnapshot + ", new=" + newSnapshot);	}	if (!newSnapshot.equals(currentSnapshot)) {	if (!isInViolation(currentSnapshot) && newSnapshot.getQuotaStatus().isInViolation()) {	if (LOG.isTraceEnabled()) {	}	getManager().enforceViolationPolicy(tableName, newSnapshot);	}	if (isInViolation(currentSnapshot) && !newSnapshot.getQuotaStatus().isInViolation()) {	if (LOG.isTraceEnabled()) {	
removing quota violation policy on 

}	if (isInViolation(currentSnapshot) && !newSnapshot.getQuotaStatus().isInViolation()) {	if (LOG.isTraceEnabled()) {	}	getManager().disableViolationPolicyEnforcement(tableName);	}	}	}	getManager().updateQuotaSnapshot(newSnapshots);	} catch (IOException e) {	
caught exception while refreshing enforced quota violation policies will retry 

========================= hbase sample_2330 =========================

LOG.info(msg);	metricsSnapshot.addSnapshot(status.getCompletionTimestamp() - status.getStartTime());	} catch (Exception e) {	status.abort("Failed to complete snapshot " + snapshot.getName() + " on table " + snapshotTable + " because " + e.getMessage());	String reason = "Failed taking snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " due to exception:" + e.getMessage();	LOG.error(reason, e);	ForeignException ee = new ForeignException(reason, e);	monitor.receive(ee);	cancel(reason);	} finally {	
launching cleanup of working dir 

} catch (Exception e) {	status.abort("Failed to complete snapshot " + snapshot.getName() + " on table " + snapshotTable + " because " + e.getMessage());	String reason = "Failed taking snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " due to exception:" + e.getMessage();	LOG.error(reason, e);	ForeignException ee = new ForeignException(reason, e);	monitor.receive(ee);	cancel(reason);	} finally {	try {	if (fs.exists(workingDir) && !this.fs.delete(workingDir, true)) {	
couldn t delete snapshot working directory 

String reason = "Failed taking snapshot " + ClientSnapshotDescriptionUtils.toString(snapshot) + " due to exception:" + e.getMessage();	LOG.error(reason, e);	ForeignException ee = new ForeignException(reason, e);	monitor.receive(ee);	cancel(reason);	} finally {	try {	if (fs.exists(workingDir) && !this.fs.delete(workingDir, true)) {	}	} catch (IOException e) {	
couldn t delete snapshot working directory 

public void completeSnapshot(Path snapshotDir, Path workingDir, FileSystem fs) throws SnapshotCreationException, IOException {	
sentinel is done just moving the snapshot from to 

========================= hbase sample_2760 =========================

public void acquireDelegationToken(final FileSystem fs) throws IOException {	if (userProvider.isHadoopSecurityEnabled()) {	this.fs = fs;	userToken = userProvider.getCurrent().getToken("HDFS_DELEGATION_TOKEN", fs.getCanonicalServiceName());	if (userToken == null) {	hasForwardedToken = false;	try {	userToken = fs.getDelegationToken(renewer);	} catch (NullPointerException npe) {	
failed to get token for 

this.fs = fs;	userToken = userProvider.getCurrent().getToken("HDFS_DELEGATION_TOKEN", fs.getCanonicalServiceName());	if (userToken == null) {	hasForwardedToken = false;	try {	userToken = fs.getDelegationToken(renewer);	} catch (NullPointerException npe) {	}	} else {	hasForwardedToken = true;	
use the existing token 

public void releaseDelegationToken() {	if (userProvider.isHadoopSecurityEnabled()) {	if (userToken != null && !hasForwardedToken) {	try {	userToken.cancel(this.fs.getConf());	} catch (Exception e) {	
failed to cancel hdfs delegation token 

========================= hbase sample_2275 =========================

public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {	WALSplit hsplit = (WALSplit)split;	logFile = new Path(hsplit.getLogFileName());	conf = context.getConfiguration();	
opening reader for 

if (reader == null) return false;	this.currentPos = reader.getPosition();	Entry temp;	long i = -1;	try {	do {	try {	temp = reader.next(currentEntry);	i++;	} catch (EOFException x) {	
corrupted entry detected ignoring the rest of the file this is normal when a regionserver crashed 

try {	do {	try {	temp = reader.next(currentEntry);	i++;	} catch (EOFException x) {	return false;	}	} while (temp != null && temp.getKey().getWriteTime() < startTime);	if (temp == null) {	
skipped entries 

try {	do {	try {	temp = reader.next(currentEntry);	i++;	} catch (EOFException x) {	return false;	}	} while (temp != null && temp.getKey().getWriteTime() < startTime);	if (temp == null) {	
reached end of file 

try {	temp = reader.next(currentEntry);	i++;	} catch (EOFException x) {	return false;	}	} while (temp != null && temp.getKey().getWriteTime() < startTime);	if (temp == null) {	return false;	} else if (i > 0) {	
skipped entries until ts 

} catch (EOFException x) {	return false;	}	} while (temp != null && temp.getKey().getWriteTime() < startTime);	if (temp == null) {	return false;	} else if (i > 0) {	}	boolean res = temp.getKey().getWriteTime() <= endTime;	if (!res) {	
reached ts ignoring the rest of the file 

public void close() throws IOException {	
closing reader 

private List<FileStatus> getFiles(FileSystem fs, Path dir, long startTime, long endTime) throws IOException {	List<FileStatus> result = new ArrayList<>();	
scanning for wal files 

LocatedFileStatus file = iter.next();	if (file.isDirectory()) {	result.addAll(getFiles(fs, file.getPath(), startTime, endTime));	} else {	String name = file.getPath().toString();	int idx = name.lastIndexOf('.');	if (idx > 0) {	try {	long fileStartTime = Long.parseLong(name.substring(idx+1));	if (fileStartTime <= endTime) {	
found 

try {	long fileStartTime = Long.parseLong(name.substring(idx+1));	if (fileStartTime <= endTime) {	result.add(file);	}	} catch (NumberFormatException x) {	idx = 0;	}	}	if (idx == 0) {	
file does not appear to be an wal file skipping 

========================= hbase sample_3464 =========================

public int run(String[] args) throws IOException {	cmdLineArgs = args;	if (conf == null) {	
tool configuration is not initialized 

addOptions();	if (isHelpCommand(args)) {	printUsage();	return EXIT_SUCCESS;	}	String[] remainingArgs = new String[argsList.size()];	argsList.toArray(remainingArgs);	cmd = new DefaultParser().parse(options, remainingArgs);	} catch (MissingOptionException e) {	LOG.error(e.getMessage());	
use h or help for usage instructions 

printUsage();	return EXIT_SUCCESS;	}	String[] remainingArgs = new String[argsList.size()];	argsList.toArray(remainingArgs);	cmd = new DefaultParser().parse(options, remainingArgs);	} catch (MissingOptionException e) {	LOG.error(e.getMessage());	return EXIT_FAILURE;	} catch (ParseException e) {	
error when parsing command line arguments 

printUsage();	return EXIT_SUCCESS;	}	String[] remainingArgs = new String[argsList.size()];	argsList.toArray(remainingArgs);	cmd = new DefaultParser().parse(options, remainingArgs);	} catch (MissingOptionException e) {	LOG.error(e.getMessage());	return EXIT_FAILURE;	} catch (ParseException e) {	
use h or help for usage instructions 

LOG.error(e.getMessage());	return EXIT_FAILURE;	} catch (ParseException e) {	return EXIT_FAILURE;	}	processOptions(cmd);	int ret;	try {	ret = doWork();	} catch (Exception e) {	
error running command line tool 

protected void doStaticMain(String args[]) {	int ret;	try {	ret = ToolRunner.run(HBaseConfiguration.create(), this, args);	} catch (Exception ex) {	
error running command line tool 

========================= hbase sample_1009 =========================

public Scan setTimeStamp(long timestamp) throws IOException {	try {	tr = new TimeRange(timestamp, timestamp+1);	} catch(Exception e) {	
timerange failed likely caused by integer overflow 

========================= hbase sample_355 =========================

public static void stopMasterAndAssignMeta(HBaseTestingUtility HTU) throws IOException, InterruptedException {	HMaster master = HTU.getHBaseCluster().getMaster();	Thread masterThread = HTU.getHBaseCluster().getMasterThread();	ServerName masterAddr = master.getServerName();	master.stopMaster();	
waiting until master thread exits 

========================= hbase sample_1662 =========================

public static Class<? extends FlushPolicy> getFlushPolicyClass(TableDescriptor htd, Configuration conf) throws IOException {	String className = htd.getFlushPolicyClassName();	if (className == null) {	className = conf.get(HBASE_FLUSH_POLICY_KEY, DEFAULT_FLUSH_POLICY_CLASS.getName());	}	try {	Class<? extends FlushPolicy> clazz = Class.forName(className).asSubclass(FlushPolicy.class);	return clazz;	} catch (Exception e) {	
unable to load configured flush policy for table load default flush policy instead 

========================= hbase sample_2737 =========================

public void serverAdded(final ServerName serverName) {	
server added 

public void serverRemoved(final ServerName serverName) {	
server removed 

public void testAssignmentListener() throws IOException, InterruptedException {	AssignmentManager am = TEST_UTIL.getHBaseCluster().getMaster().getAssignmentManager();	Admin admin = TEST_UTIL.getAdmin();	DummyAssignmentListener listener = new DummyAssignmentListener();	am.registerListener(listener);	try {	final TableName tableName = TableName.valueOf(name.getMethodName());	final byte[] FAMILY = Bytes.toBytes("cf");	
create table 

try {	for (int i = 0; i < 10; ++i) {	byte[] key = Bytes.toBytes("row-" + i);	Put put = new Put(key);	put.addColumn(FAMILY, null, key);	table.put(put);	}	} finally {	table.close();	}	
split table 

while (mergeable < 2) {	Thread.sleep(100);	admin.majorCompact(tableName);	mergeable = 0;	for (JVMClusterUtil.RegionServerThread regionThread: miniCluster.getRegionServerThreads()) {	for (Region region: regionThread.getRegionServer().getRegions(tableName)) {	mergeable += ((HRegion)region).isMergeable() ? 1 : 0;	}	}	}	
merge regions 

assertEquals(2, regions.size());	boolean sameServer = areAllRegionsLocatedOnSameServer(tableName);	final int expectedModifications = sameServer ? 3 : 5;	final int expectedLoadCount = sameServer ? 1 : 2;	final int expectedCloseCount = sameServer ? 2 : 3;	admin.mergeRegionsAsync(regions.get(0).getEncodedNameAsBytes(), regions.get(1).getEncodedNameAsBytes(), true);	listener.awaitModifications(expectedModifications);	assertEquals(1, admin.getTableRegions(tableName).size());	assertEquals(expectedLoadCount, listener.getLoadCount());	assertEquals(expectedCloseCount, listener.getCloseCount());	
drop table 

========================= hbase sample_1818 =========================

public Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	if (this.getConf() == null || !BackupManager.isBackupEnabled(getConf())) {	if (LOG.isDebugEnabled()) {	
backup is not enabled check your setting 

public Iterable<FileStatus> getDeletableFiles(Iterable<FileStatus> files) {	if (this.getConf() == null || !BackupManager.isBackupEnabled(getConf())) {	if (LOG.isDebugEnabled()) {	}	return files;	}	List<FileStatus> list = new ArrayList<FileStatus>();	try (final BackupSystemTable table = new BackupSystemTable(conn)) {	try {	if (!table.hasBackupSessions()) {	
backuplogcleaner has no backup sessions 

}	return files;	}	List<FileStatus> list = new ArrayList<FileStatus>();	try (final BackupSystemTable table = new BackupSystemTable(conn)) {	try {	if (!table.hasBackupSessions()) {	return files;	}	} catch (TableNotFoundException tnfe) {	
backup system table is not available 

} catch (TableNotFoundException tnfe) {	return files;	}	Map<FileStatus, Boolean> walFilesDeletableMap = table.areWALFilesDeletable(files);	for (Map.Entry<FileStatus, Boolean> entry: walFilesDeletableMap.entrySet()) {	FileStatus file = entry.getKey();	String wal = file.getPath().toString();	boolean deletable = entry.getValue();	if (deletable) {	if (LOG.isDebugEnabled()) {	
found log file in backup system table deleting 

for (Map.Entry<FileStatus, Boolean> entry: walFilesDeletableMap.entrySet()) {	FileStatus file = entry.getKey();	String wal = file.getPath().toString();	boolean deletable = entry.getValue();	if (deletable) {	if (LOG.isDebugEnabled()) {	}	list.add(file);	} else {	if (LOG.isDebugEnabled()) {	
didn t find this log in backup system table keeping 

if (LOG.isDebugEnabled()) {	}	list.add(file);	} else {	if (LOG.isDebugEnabled()) {	}	}	}	return list;	} catch (IOException e) {	
failed to get backup system table table therefore will keep all files 

public void setConf(Configuration config) {	super.setConf(config);	if (!config.getBoolean(BackupRestoreConstants.BACKUP_ENABLE_KEY, BackupRestoreConstants.BACKUP_ENABLE_DEFAULT)) {	
backup is disabled allowing all wals to be deleted 

public void stop(String why) {	if (this.stopped) {	return;	}	this.stopped = true;	
stopping backuplogcleaner 

========================= hbase sample_586 =========================

public void start() throws IOException {	if (!QuotaUtil.isQuotaEnabled(masterServices.getConfiguration())) {	
quota support disabled 

public void start() throws IOException {	if (!QuotaUtil.isQuotaEnabled(masterServices.getConfiguration())) {	return;	}	if (!MetaTableAccessor.tableExists(masterServices.getConnection(), QuotaUtil.QUOTA_TABLE_NAME)) {	
quota table not found creating 

public void start() throws IOException {	if (!QuotaUtil.isQuotaEnabled(masterServices.getConfiguration())) {	return;	}	if (!MetaTableAccessor.tableExists(masterServices.getConnection(), QuotaUtil.QUOTA_TABLE_NAME)) {	createQuotaTable();	}	
initializing quota support 

private void setQuota(final SetQuotaRequest req, final SetQuotaOperations quotaOps) throws IOException, InterruptedException {	if (req.hasRemoveAll() && req.getRemoveAll() == true) {	quotaOps.preApply(null);	quotaOps.delete();	quotaOps.postApply(null);	return;	}	GlobalQuotaSettingsImpl currentQuota = quotaOps.fetch();	if (LOG.isTraceEnabled()) {	
current quota for request 

quotaOps.delete();	quotaOps.postApply(null);	return;	}	GlobalQuotaSettingsImpl currentQuota = quotaOps.fetch();	if (LOG.isTraceEnabled()) {	}	quotaOps.preApply(currentQuota);	QuotaSettings newQuota = QuotaSettings.buildFromProto(req);	if (LOG.isTraceEnabled()) {	
deserialized quota from request 

}	GlobalQuotaSettingsImpl currentQuota = quotaOps.fetch();	if (LOG.isTraceEnabled()) {	}	quotaOps.preApply(currentQuota);	QuotaSettings newQuota = QuotaSettings.buildFromProto(req);	if (LOG.isTraceEnabled()) {	}	GlobalQuotaSettingsImpl mergedQuota = currentQuota.merge(newQuota);	if (LOG.isTraceEnabled()) {	
computed merged quota from current quota and user request 

if (!QuotaUtil.isQuotaEnabled(masterServices.getConfiguration())) {	throw new DoNotRetryIOException( new UnsupportedOperationException("quota support disabled"));	}	if (!initialized) {	long maxWaitTime = masterServices.getConfiguration().getLong( "hbase.master.wait.for.quota.manager.init", 30000);	long startTime = EnvironmentEdgeManager.currentTime();	do {	try {	Thread.sleep(100);	} catch (InterruptedException e) {	
interrupted while waiting for quota manager to be initialized 

========================= hbase sample_2367 =========================

public byte[] getBody() {	if (body == null) {	try {	body = Client.getResponseBody(resp);	} catch (IOException ioe) {	
encountered ioe when obtaining body 

========================= hbase sample_3126 =========================

ArrayList<TableName> existTableList = new ArrayList<>();	ArrayList<TableName> disabledTableList = new ArrayList<>();	try (Admin admin = conn.getAdmin()) {	for (TableName tableName : tTableArray) {	if (admin.tableExists(tableName)) {	existTableList.add(tableName);	if (admin.isTableDisabled(tableName)) {	disabledTableList.add(tableName);	}	} else {	
hbase table does not exist it will be created during restore process 

existTableList.add(tableName);	if (admin.isTableDisabled(tableName)) {	disabledTableList.add(tableName);	}	} else {	}	}	}	if (existTableList.size() > 0) {	if (!isOverwrite) {	
existing table found in the restore target please add as overwrite option in the command if you mean to restore to these existing tables 

}	} else {	}	}	}	if (existTableList.size() > 0) {	if (!isOverwrite) {	throw new IOException("Existing table found in target while no \"-o\" " + "as overwrite option found");	} else {	if (disabledTableList.size() > 0) {	
found offline table in the restore target please enable them before restore with option 

}	} else {	}	}	}	if (existTableList.size() > 0) {	if (!isOverwrite) {	throw new IOException("Existing table found in target while no \"-o\" " + "as overwrite option found");	} else {	if (disabledTableList.size() > 0) {	
offline table list in restore target 

private void restoreImages(BackupImage[] images, TableName sTable, TableName tTable, boolean truncateIfExists) throws IOException {	BackupImage image = images[0];	String rootDir = image.getRootDir();	String backupId = image.getBackupId();	Path backupRoot = new Path(rootDir);	RestoreTool restoreTool = new RestoreTool(conf, backupRoot, backupId);	Path tableBackupPath = HBackupFileSystem.getTableBackupPath(sTable, backupRoot, backupId);	String lastIncrBackupId = images.length == 1 ? null : images[images.length - 1].getBackupId();	BackupManifest manifest = HBackupFileSystem.getManifest(conf, backupRoot, backupId);	if (manifest.getType() == BackupType.FULL) {	
restoring to from full backup image 

return;	}	List<Path> dirList = new ArrayList<Path>();	for (int i = 1; i < images.length; i++) {	BackupImage im = images[i];	String fileBackupDir = HBackupFileSystem.getTableBackupDir(im.getRootDir(), im.getBackupId(), sTable);	List<Path> list = getFilesRecursively(fileBackupDir);	dirList.addAll(list);	}	String dirs = StringUtils.join(dirList, ",");	
restoring to from log dirs 

BackupImage im = images[i];	String fileBackupDir = HBackupFileSystem.getTableBackupDir(im.getRootDir(), im.getBackupId(), sTable);	List<Path> list = getFilesRecursively(fileBackupDir);	dirList.addAll(list);	}	String dirs = StringUtils.join(dirList, ",");	Path[] paths = new Path[dirList.size()];	dirList.toArray(paths);	conf.set(JOB_NAME_CONF_KEY, "Incremental_Restore-" + backupId + "-" + tTable);	restoreTool.incrementalRestoreTable(conn, tableBackupPath, paths, new TableName[] { sTable }, new TableName[] { tTable }, lastIncrBackupId);	
has been successfully restored to 

List<BackupImage> list = new ArrayList<BackupImage>();	list.add(manifest.getBackupImage());	TreeSet<BackupImage> set = new TreeSet<BackupImage>(list);	List<BackupImage> depList = manifest.getDependentListByTable(table);	set.addAll(depList);	BackupImage[] arr = new BackupImage[set.size()];	set.toArray(arr);	restoreImages(arr, table, tTableArray[i], truncateIfExists);	restoreImageSet.addAll(list);	if (restoreImageSet != null && !restoreImageSet.isEmpty()) {	
restore includes the following image s 

list.add(manifest.getBackupImage());	TreeSet<BackupImage> set = new TreeSet<BackupImage>(list);	List<BackupImage> depList = manifest.getDependentListByTable(table);	set.addAll(depList);	BackupImage[] arr = new BackupImage[set.size()];	set.toArray(arr);	restoreImages(arr, table, tTableArray[i], truncateIfExists);	restoreImageSet.addAll(list);	if (restoreImageSet != null && !restoreImageSet.isEmpty()) {	for (BackupImage image : restoreImageSet) {	
backup 

List<BackupImage> depList = manifest.getDependentListByTable(table);	set.addAll(depList);	BackupImage[] arr = new BackupImage[set.size()];	set.toArray(arr);	restoreImages(arr, table, tTableArray[i], truncateIfExists);	restoreImageSet.addAll(list);	if (restoreImageSet != null && !restoreImageSet.isEmpty()) {	for (BackupImage image : restoreImageSet) {	if (image.getType() == BackupType.INCREMENTAL) {	backupIdSet.add(image.getBackupId());	
adding for bulk load 

restoreImages(arr, table, tTableArray[i], truncateIfExists);	restoreImageSet.addAll(list);	if (restoreImageSet != null && !restoreImageSet.isEmpty()) {	for (BackupImage image : restoreImageSet) {	if (image.getType() == BackupType.INCREMENTAL) {	backupIdSet.add(image.getBackupId());	}	}	}	}	
restorestage finished 

========================= hbase sample_569 =========================

public void tearDown() throws Exception {	try {	wals.close();	} catch (IOException exception) {	
encountered exception while closing wal factory if you have other errors this may be the cause message 

public void tearDown() throws Exception {	try {	wals.close();	} catch (IOException exception) {	
exception details for failure to close wal factory 

final TableName tableName = TableName.valueOf(currentTest.getMethodName());	final byte [] rowName = tableName.getName();	final MultiVersionConcurrencyControl mvcc = new MultiVersionConcurrencyControl(1);	final int howmany = 3;	RegionInfo[] infos = new RegionInfo[3];	Path tabledir = FSUtils.getTableDir(hbaseWALDir, tableName);	fs.mkdirs(tabledir);	for (int i = 0; i < howmany; i++) {	infos[i] = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes("" + i)) .setEndKey(Bytes.toBytes("" + (i + 1))).build();	fs.mkdirs(new Path(tabledir, infos[i].getEncodedName()));	
allo 

scopes.put(Bytes.toBytes("column"), 0);	for (int ii = 0; ii < howmany; ii++) {	for (int i = 0; i < howmany; i++) {	final WAL log = wals.getWAL(infos[i]);	for (int j = 0; j < howmany; j++) {	WALEdit edit = new WALEdit();	byte [] family = Bytes.toBytes("column");	byte [] qualifier = Bytes.toBytes(Integer.toString(j));	byte [] column = Bytes.toBytes("column:" + Integer.toString(j));	edit.add(new KeyValue(rowName, family, qualifier, System.currentTimeMillis(), column));	
region 

try {	DistributedFileSystem dfs = cluster.getFileSystem();	dfs.setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_ENTER);	TEST_UTIL.shutdownMiniDFSCluster();	try {	wal.shutdown();	} catch (IOException e) {	LOG.info(e.toString(), e);	}	fs.close();	
stopped first instance of the cluster 

dfs.setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_ENTER);	TEST_UTIL.shutdownMiniDFSCluster();	try {	wal.shutdown();	} catch (IOException e) {	LOG.info(e.toString(), e);	}	fs.close();	} finally {	while (cluster.isClusterUp()){	
waiting for cluster to go down 

while (cluster.isClusterUp()){	Thread.sleep(1000);	}	assertFalse(cluster.isClusterUp());	cluster = null;	for (int i = 0; i < 100; i++) {	try {	cluster = TEST_UTIL.startMiniDFSClusterForTestWAL(namenodePort);	break;	} catch (BindException e) {	
sleeping bindexception bringing up new cluster 

for (int i = 0; i < 100; i++) {	try {	cluster = TEST_UTIL.startMiniDFSClusterForTestWAL(namenodePort);	break;	} catch (BindException e) {	Threads.sleep(1000);	}	}	cluster.waitActive();	fs = cluster.getFileSystem();	
started second instance 

========================= hbase sample_1361 =========================

public boolean start() {	if (running.getAndSet(true)) {	
already running 

public boolean stop() {	if (!running.getAndSet(false)) {	return false;	}	
stopping procedure remote dispatcher 

public void join() {	assert !running.get() : "expected not running";	timeoutExecutor.awaitTermination();	timeoutExecutor = null;	threadPool.shutdownNow();	try {	while (!threadPool.awaitTermination(60, TimeUnit.SECONDS)) {	
waiting for thread pool to terminate 

public void join() {	assert !running.get() : "expected not running";	timeoutExecutor.awaitTermination();	timeoutExecutor = null;	threadPool.shutdownNow();	try {	while (!threadPool.awaitTermination(60, TimeUnit.SECONDS)) {	}	} catch (InterruptedException e) {	
interrupted while waiting for thread pool termination 

protected UncaughtExceptionHandler getUncaughtExceptionHandler() {	return new UncaughtExceptionHandler() {	public void uncaughtException(Thread t, Throwable e) {	
failed to execute remote procedures 

public void awaitTermination() {	try {	final long startTime = EnvironmentEdgeManager.currentTime();	for (int i = 0; isAlive(); ++i) {	sendStopSignal();	join(250);	if (i > 0 && (i % 8) == 0) {	
waiting termination of thread 

public void awaitTermination() {	try {	final long startTime = EnvironmentEdgeManager.currentTime();	for (int i = 0; isAlive(); ++i) {	sendStopSignal();	join(250);	if (i > 0 && (i % 8) == 0) {	}	}	} catch (InterruptedException e) {	
join wait got interrupted 

========================= hbase sample_1224 =========================

} finally {	if (beanWriter != null) beanWriter.close();	if (jsonpcb != null) {	writer.write(");");	}	if (writer != null) {	writer.close();	}	}	} catch (IOException e) {	
caught an exception while processing jmx request 

if (jsonpcb != null) {	writer.write(");");	}	if (writer != null) {	writer.close();	}	}	} catch (IOException e) {	response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);	} catch (MalformedObjectNameException e) {	
caught an exception while processing jmx request 

========================= hbase sample_3219 =========================

public boolean flattenOneSegment(long requesterVersion, CompactingMemStore.IndexType idxType, MemStoreCompactionStrategy.Action action) {	if(requesterVersion != version) {	
segment flattening failed because versions do not match requester version actual version 

public boolean flattenOneSegment(long requesterVersion, CompactingMemStore.IndexType idxType, MemStoreCompactionStrategy.Action action) {	if(requesterVersion != version) {	return false;	}	synchronized (pipeline){	if(requesterVersion != version) {	
segment flattening failed because versions do not match 

}	int i = 0;	for (ImmutableSegment s : pipeline) {	if ( s.canBeFlattened() ) {	MemStoreSizing newMemstoreAccounting = new MemStoreSizing();	ImmutableSegment newS = SegmentFactory.instance().createImmutableSegmentByFlattening( (CSLMImmutableSegment)s,idxType,newMemstoreAccounting,action);	replaceAtIndex(i,newS);	if(region != null) {	region.addMemStoreSize(new MemStoreSize(0, newMemstoreAccounting.getHeapSize()));	}	
compaction pipeline segment flattened 

========================= hbase sample_2721 =========================

public void sleepUntilNextRetry() throws InterruptedException {	int attempts = getAttemptTimes();	long sleepTime = retryConfig.backoffPolicy.getBackoffTime(retryConfig, attempts);	if (LOG.isTraceEnabled()) {	
sleeping ms before retry 

========================= hbase sample_986 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

public Response put(final TableSchemaModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
put 

public Response post(final TableSchemaModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
put 

public Response delete(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
delete 

========================= hbase sample_3075 =========================

public void testRegionReplicasCreatedAreDistributed() throws Exception {	try {	checkAndAssertRegionDistribution(false);	HTU.getAdmin().disableTable(table.getName());	
disabled the table 

public void testRegionReplicasCreatedAreDistributed() throws Exception {	try {	checkAndAssertRegionDistribution(false);	HTU.getAdmin().disableTable(table.getName());	
enabling the table 

public void testRegionReplicasCreatedAreDistributed() throws Exception {	try {	checkAndAssertRegionDistribution(false);	HTU.getAdmin().disableTable(table.getName());	HTU.getAdmin().enableTable(table.getName());	
enabled the table 

private boolean checkAndAssertRegionDistribution(boolean checkfourth) throws Exception {	Collection<RegionInfo> onlineRegions = new ArrayList<RegionInfo>(getRS().getOnlineRegionsLocalContext().size());	for (HRegion region : getRS().getOnlineRegionsLocalContext()) {	onlineRegions.add(region.getRegionInfo());	}	if (this.serverVsOnlineRegions == null) {	this.serverVsOnlineRegions = new HashMap<ServerName, Collection<RegionInfo>>();	this.serverVsOnlineRegions.put(getRS().getServerName(), onlineRegions);	} else {	Collection<RegionInfo> existingRegions = new ArrayList<RegionInfo>(this.serverVsOnlineRegions.get(getRS().getServerName()));	
count is 

}	Collection<RegionInfo> onlineRegions2 = new ArrayList<RegionInfo>(getSecondaryRS().getOnlineRegionsLocalContext().size());	for (HRegion region : getSecondaryRS().getOnlineRegionsLocalContext()) {	onlineRegions2.add(region.getRegionInfo());	}	if (this.serverVsOnlineRegions2 == null) {	this.serverVsOnlineRegions2 = new HashMap<ServerName, Collection<RegionInfo>>();	this.serverVsOnlineRegions2.put(getSecondaryRS().getServerName(), onlineRegions2);	} else {	Collection<RegionInfo> existingRegions = new ArrayList<RegionInfo>( this.serverVsOnlineRegions2.get(getSecondaryRS().getServerName()));	
count is 

}	Collection<RegionInfo> onlineRegions3 = new ArrayList<RegionInfo>(getTertiaryRS().getOnlineRegionsLocalContext().size());	for (HRegion region : getTertiaryRS().getOnlineRegionsLocalContext()) {	onlineRegions3.add(region.getRegionInfo());	}	if (this.serverVsOnlineRegions3 == null) {	this.serverVsOnlineRegions3 = new HashMap<ServerName, Collection<RegionInfo>>();	this.serverVsOnlineRegions3.put(getTertiaryRS().getServerName(), onlineRegions3);	} else {	Collection<RegionInfo> existingRegions = new ArrayList<RegionInfo>( this.serverVsOnlineRegions3.get(getTertiaryRS().getServerName()));	
count is 

========================= hbase sample_1766 =========================

public void testTestCompression() {	assertTrue(CompressionTest.testCompression("NONE"));	assertTrue(CompressionTest.testCompression("GZ"));	if (NativeCodeLoader.isNativeCodeLoaded()) {	nativeCodecTest("LZO", "lzo2", "com.hadoop.compression.lzo.LzoCodec");	nativeCodecTest("LZ4", null, "org.apache.hadoop.io.compress.Lz4Codec");	nativeCodecTest("SNAPPY", "snappy", "org.apache.hadoop.io.compress.SnappyCodec");	nativeCodecTest("BZIP2", "bzip2", "org.apache.hadoop.io.compress.BZip2Codec");	nativeCodecTest("ZSTD", "zstd", "org.apache.hadoop.io.compress.ZStandardCodec");	} else {	
native code not loaded 

CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(conf.getClassByName(codecClassName), conf);	DataOutputBuffer compressedDataBuffer = new DataOutputBuffer();	CompressionOutputStream deflateFilter = codec.createOutputStream(compressedDataBuffer);	byte[] data = new byte[1024];	DataOutputStream deflateOut = new DataOutputStream(new BufferedOutputStream(deflateFilter));	deflateOut.write(data, 0, data.length);	deflateOut.flush();	deflateFilter.finish();	assertTrue(CompressionTest.testCompression(codecName));	} catch (UnsatisfiedLinkError e) {	
no jni for codec 

DataOutputStream deflateOut = new DataOutputStream(new BufferedOutputStream(deflateFilter));	deflateOut.write(data, 0, data.length);	deflateOut.flush();	deflateFilter.finish();	assertTrue(CompressionTest.testCompression(codecName));	} catch (UnsatisfiedLinkError e) {	} catch (Exception e) {	LOG.error(codecName, e);	}	} catch (UnsatisfiedLinkError e) {	
native lib not available 

deflateFilter.finish();	assertTrue(CompressionTest.testCompression(codecName));	} catch (UnsatisfiedLinkError e) {	} catch (Exception e) {	LOG.error(codecName, e);	}	} catch (UnsatisfiedLinkError e) {	assertFalse(CompressionTest.testCompression(codecName));	}	} else {	
codec class not available 

========================= hbase sample_1336 =========================

}	ZooKeeperServer server = new ZooKeeperServer(dir, dir, tickTimeToUse);	server.setMinSessionTimeout(configuration.getInt( "hbase.zookeeper.property.minSessionTimeout", -1));	server.setMaxSessionTimeout(configuration.getInt( "hbase.zookeeper.property.maxSessionTimeout", -1));	NIOServerCnxnFactory standaloneServerFactory;	while (true) {	try {	standaloneServerFactory = new NIOServerCnxnFactory();	standaloneServerFactory.configure( new InetSocketAddress(currentClientPort), configuration.getInt(HConstants.ZOOKEEPER_MAX_CLIENT_CNXNS, HConstants.DEFAULT_ZOOKEPER_MAX_CLIENT_CNXNS));	} catch (BindException e) {	
failed binding zk server to client port 

}	standaloneServerFactoryList.clear();	for (ZooKeeperServer zkServer: zooKeeperServers) {	zkServer.getZKDatabase().close();	}	zooKeeperServers.clear();	if (started) {	started = false;	activeZKServerIndex = 0;	clientPortList.clear();	
shutdown minizk cluster with all zk servers 

NIOServerCnxnFactory standaloneServerFactory = standaloneServerFactoryList.get(activeZKServerIndex);	int clientPort = clientPortList.get(activeZKServerIndex);	standaloneServerFactory.shutdown();	if (!waitForServerDown(clientPort, connectionTimeout)) {	throw new IOException("Waiting for shutdown of standalone server");	}	zooKeeperServers.get(activeZKServerIndex).getZKDatabase().close();	standaloneServerFactoryList.remove(activeZKServerIndex);	clientPortList.remove(activeZKServerIndex);	zooKeeperServers.remove(activeZKServerIndex);	
kill the current active zk servers in the cluster on client port 

throw new IOException("Waiting for shutdown of standalone server");	}	zooKeeperServers.get(activeZKServerIndex).getZKDatabase().close();	standaloneServerFactoryList.remove(activeZKServerIndex);	clientPortList.remove(activeZKServerIndex);	zooKeeperServers.remove(activeZKServerIndex);	if (standaloneServerFactoryList.isEmpty()) {	return -1;	}	clientPort = clientPortList.get(activeZKServerIndex);	
activate a backup zk server in the cluster on client port 

NIOServerCnxnFactory standaloneServerFactory = standaloneServerFactoryList.get(backupZKServerIndex);	int clientPort = clientPortList.get(backupZKServerIndex);	standaloneServerFactory.shutdown();	if (!waitForServerDown(clientPort, connectionTimeout)) {	throw new IOException("Waiting for shutdown of standalone server");	}	zooKeeperServers.get(backupZKServerIndex).getZKDatabase().close();	standaloneServerFactoryList.remove(backupZKServerIndex);	clientPortList.remove(backupZKServerIndex);	zooKeeperServers.remove(backupZKServerIndex);	
kill one backup zk servers in the cluster on client port 

if (line != null && line.startsWith("Zookeeper version:")) {	return true;	}	} finally {	sock.close();	if (reader != null) {	reader.close();	}	}	} catch (IOException e) {	
server localhost not up 

========================= hbase sample_744 =========================

public void testCorruptedRegionManifest() throws IOException {	SnapshotTestingUtils.SnapshotMock snapshotMock = new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);	SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2( SNAPSHOT_NAME_STR, TABLE_NAME_STR);	builder.addRegionV2();	builder.corruptOneRegionManifest();	long period = Long.MAX_VALUE;	SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000, "test-snapshot-file-cache-refresh", new SnapshotFiles());	try {	cache.getSnapshotsInProgress(null);	} catch (CorruptedSnapshotException cse) {	
expected exception 

SnapshotTestingUtils.SnapshotMock snapshotMock = new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);	SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2( SNAPSHOT_NAME_STR, TABLE_NAME_STR);	builder.addRegionV2();	builder.consolidate();	builder.corruptDataManifest();	long period = Long.MAX_VALUE;	SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000, "test-snapshot-file-cache-refresh", new SnapshotFiles());	try {	cache.getSnapshotsInProgress(null);	} catch (CorruptedSnapshotException cse) {	
expected exception 

========================= hbase sample_1789 =========================

public void testBalancerWithoutFavoredNodes() throws Exception {	TableName tableName = TableName.valueOf("testBalancerWithoutFavoredNodes");	HTableDescriptor desc = new HTableDescriptor(tableName);	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("aaa"), Bytes.toBytes("zzz"), REGION_NUM);	TEST_UTIL.waitTableAvailable(tableName);	final RegionInfo region = admin.getTableRegions(tableName).get(0);	
region thats supposed to be in transition 

public void test2FavoredNodesDead() throws Exception {	TableName tableName = TableName.valueOf("testAllFavoredNodesDead");	HTableDescriptor desc = new HTableDescriptor(tableName);	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("aaa"), Bytes.toBytes("zzz"), REGION_NUM);	TEST_UTIL.waitTableAvailable(tableName);	final RegionInfo region = admin.getTableRegions(tableName).get(0);	
region that s supposed to be in transition 

public void testAllFavoredNodesDead() throws Exception {	TableName tableName = TableName.valueOf("testAllFavoredNodesDead");	HTableDescriptor desc = new HTableDescriptor(tableName);	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("aaa"), Bytes.toBytes("zzz"), REGION_NUM);	TEST_UTIL.waitTableAvailable(tableName);	final RegionInfo region = admin.getTableRegions(tableName).get(0);	
region that s supposed to be in transition 

for (ServerName sn : admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().keySet()) {	serversForNewFN.add(ServerName.valueOf(sn.getHostname(), sn.getPort(), NON_STARTCODE));	}	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(serversForNewFN, conf);	helper.initialize();	for (RegionStateNode regionState: regionStates.getRegionsInTransition()) {	RegionInfo regionInfo = regionState.getRegionInfo();	List<ServerName> newFavoredNodes = helper.generateFavoredNodes(regionInfo);	assertNotNull(newFavoredNodes);	assertEquals(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM, newFavoredNodes.size());	
region fn 

FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(serversForNewFN, conf);	helper.initialize();	for (RegionStateNode regionState: regionStates.getRegionsInTransition()) {	RegionInfo regionInfo = regionState.getRegionInfo();	List<ServerName> newFavoredNodes = helper.generateFavoredNodes(regionInfo);	assertNotNull(newFavoredNodes);	assertEquals(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM, newFavoredNodes.size());	Map<RegionInfo, List<ServerName>> regionFNMap = Maps.newHashMap();	regionFNMap.put(regionInfo, newFavoredNodes);	fnm.updateFavoredNodes(regionFNMap);	
assigning region 

public void testAllFavoredNodesDeadMasterRestarted() throws Exception {	TableName tableName = TableName.valueOf("testAllFavoredNodesDeadMasterRestarted");	HTableDescriptor desc = new HTableDescriptor(tableName);	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("aaa"), Bytes.toBytes("zzz"), REGION_NUM);	TEST_UTIL.waitTableAvailable(tableName);	final RegionInfo region = admin.getTableRegions(tableName).get(0);	
region that s supposed to be in transition 

final RegionStates regionStatesBeforeMaster = master.getAssignmentManager().getRegionStates();	TEST_UTIL.waitFor(10000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return regionStatesBeforeMaster.getRegionState(region).isFailedOpen();	}	});	assertTrue("Region: " + region + " should be RIT", regionStatesBeforeMaster.getRegionState(region).isFailedOpen());	List<RegionInfo> rit = Lists.newArrayList();	for (RegionStateNode regionState: regionStatesBeforeMaster.getRegionsInTransition()) {	RegionInfo regionInfo = regionState.getRegionInfo();	
region in transition after stopping fn s 

List<ServerName> serversForNewFN = Lists.newArrayList();	for (ServerName sn : admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().keySet()) {	serversForNewFN.add(ServerName.valueOf(sn.getHostname(), sn.getPort(), NON_STARTCODE));	}	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(serversForNewFN, conf);	helper.initialize();	for (RegionInfo regionInfo : rit) {	List<ServerName> newFavoredNodes = helper.generateFavoredNodes(regionInfo);	assertNotNull(newFavoredNodes);	assertEquals(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM, newFavoredNodes.size());	
region fn 

}	FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(serversForNewFN, conf);	helper.initialize();	for (RegionInfo regionInfo : rit) {	List<ServerName> newFavoredNodes = helper.generateFavoredNodes(regionInfo);	assertNotNull(newFavoredNodes);	assertEquals(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM, newFavoredNodes.size());	Map<RegionInfo, List<ServerName>> regionFNMap = Maps.newHashMap();	regionFNMap.put(regionInfo, newFavoredNodes);	fnm.updateFavoredNodes(regionFNMap);	
assigning region 

private void stopServersAndWaitUntilProcessed(List<ServerName> currentFN) throws Exception {	for (ServerName sn : currentFN) {	for (JVMClusterUtil.RegionServerThread rst : cluster.getLiveRegionServerThreads()) {	if (ServerName.isSameAddress(sn, rst.getRegionServer().getServerName())) {	
shutting down server 

========================= hbase sample_1859 =========================

public ReadOnlyZKClient(Configuration conf) {	this.connectString = ZKConfig.getZKQuorumServersString(conf);	this.sessionTimeoutMs = conf.getInt(ZK_SESSION_TIMEOUT, DEFAULT_ZK_SESSION_TIMEOUT);	this.maxRetries = conf.getInt(RECOVERY_RETRY, DEFAULT_RECOVERY_RETRY);	this.retryIntervalMs = conf.getInt(RECOVERY_RETRY_INTERVAL_MILLIS, DEFAULT_RECOVERY_RETRY_INTERVAL_MILLIS);	this.keepAliveTimeMs = conf.getInt(KEEPALIVE_MILLIS, DEFAULT_KEEPALIVE_MILLIS);	
start read only zookeeper connection to session timeout ms retries retry interval ms keep alive ms 

} else if (code == Code.NONODE) {	if (errorIfNoNode) {	future.completeExceptionally(KeeperException.create(code, path));	} else {	future.complete(ret);	}	} else if (FAIL_FAST_CODES.contains(code)) {	future.completeExceptionally(KeeperException.create(code, path));	} else {	if (code == Code.SESSIONEXPIRED) {	
to session expired close and reconnect 

Task task;	try {	task = tasks.poll(keepAliveTimeMs, TimeUnit.MILLISECONDS);	} catch (InterruptedException e) {	continue;	}	if (task == CLOSE) {	break;	}	if (task == null && pendingRequests == 0) {	
to no activities for ms close active connection will reconnect next time when there are new requests 

public void close() {	if (closed.compareAndSet(false, true)) {	
close zookeeper connection to 

========================= hbase sample_197 =========================

public static void updateMetaWithFavoredNodesInfo( Map<RegionInfo, List<ServerName>> regionToFavoredNodes, Connection connection) throws IOException {	List<Put> puts = new ArrayList<>();	for (Map.Entry<RegionInfo, List<ServerName>> entry : regionToFavoredNodes.entrySet()) {	Put put = makePutFromRegionInfo(entry.getKey(), entry.getValue());	if (put != null) {	puts.add(put);	}	}	MetaTableAccessor.putsToMetaTable(connection, puts);	
added regions in meta 

Put put = makePutFromRegionInfo(entry.getKey(), entry.getValue());	if (put != null) {	puts.add(put);	}	}	try (Connection connection = ConnectionFactory.createConnection(conf)) {	try (Table metaTable = connection.getTable(TableName.META_TABLE_NAME)) {	metaTable.put(puts);	}	}	
added regions in meta 

static Put makePutFromRegionInfo(RegionInfo regionInfo, List<ServerName>favoredNodeList) throws IOException {	Put put = null;	if (favoredNodeList != null) {	put = MetaTableAccessor.makePutFromRegionInfo(regionInfo);	byte[] favoredNodes = getFavoredNodes(favoredNodeList);	put.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY) .setRow(put.getRow()) .setFamily(HConstants.CATALOG_FAMILY) .setQualifier(FAVOREDNODES_QUALIFIER) .setTimestamp(EnvironmentEdgeManager.currentTime()) .setType(Type.Put) .setValue(favoredNodes) .build());	
create the region with favored nodes 

public Map<RegionInfo, ServerName[]> placeSecondaryAndTertiaryRS( Map<RegionInfo, ServerName> primaryRSMap) {	Map<RegionInfo, ServerName[]> secondaryAndTertiaryMap = new HashMap<>();	for (Map.Entry<RegionInfo, ServerName> entry : primaryRSMap.entrySet()) {	RegionInfo regionInfo = entry.getKey();	ServerName primaryRS = entry.getValue();	try {	ServerName[] favoredNodes = getSecondaryAndTertiary(regionInfo, primaryRS);	if (favoredNodes != null) {	secondaryAndTertiaryMap.put(regionInfo, favoredNodes);	
place the secondary and tertiary region server for region 

Map<RegionInfo, ServerName[]> secondaryAndTertiaryMap = new HashMap<>();	for (Map.Entry<RegionInfo, ServerName> entry : primaryRSMap.entrySet()) {	RegionInfo regionInfo = entry.getKey();	ServerName primaryRS = entry.getValue();	try {	ServerName[] favoredNodes = getSecondaryAndTertiary(regionInfo, primaryRS);	if (favoredNodes != null) {	secondaryAndTertiaryMap.put(regionInfo, favoredNodes);	}	} catch (Exception e) {	
cannot place the favored nodes for region because 

try {	String primaryRack = getRackOfServer(primaryRS);	ServerName[] favoredNodes = null;	if (getTotalNumberOfRacks() == 1) {	favoredNodes = singleRackCase(regionInfo, primaryRS, primaryRack);	} else {	favoredNodes = multiRackCaseWithRestrictions(serverToPrimaries, secondaryAndTertiaryMap, primaryRack, primaryRS, regionInfo);	}	if (favoredNodes != null) {	secondaryAndTertiaryMap.put(regionInfo, favoredNodes);	
place the secondary and tertiary region server for region 

ServerName[] favoredNodes = null;	if (getTotalNumberOfRacks() == 1) {	favoredNodes = singleRackCase(regionInfo, primaryRS, primaryRack);	} else {	favoredNodes = multiRackCaseWithRestrictions(serverToPrimaries, secondaryAndTertiaryMap, primaryRack, primaryRS, regionInfo);	}	if (favoredNodes != null) {	secondaryAndTertiaryMap.put(regionInfo, favoredNodes);	}	} catch (Exception e) {	
cannot place the favored nodes for region because 

}	secondaryRack = getOneRandomRack(rackSkipSet);	serverList = getServersFromRack(secondaryRack);	serverSet = new HashSet<>();	serverSet.addAll(serverList);	}	ServerName secondaryRS = getOneRandomServer(secondaryRack, skipServerSet);	skipServerSet.add(secondaryRS);	ServerName tertiaryRS = getOneRandomServer(secondaryRack, skipServerSet);	if (secondaryRS == null || tertiaryRS == null) {	
cannot place the secondary and tertiary region server for region 

List<ServerName> serverList = getServersFromRack(primaryRack);	if ((serverList == null) || (serverList.size() <= 2)) {	return null;	} else {	Set<ServerName> serverSkipSet = new HashSet<>();	serverSkipSet.add(primaryRS);	ServerName secondaryRS = getOneRandomServer(primaryRack, serverSkipSet);	serverSkipSet.add(secondaryRS);	ServerName tertiaryRS = getOneRandomServer(primaryRack, serverSkipSet);	if (secondaryRS == null || tertiaryRS == null) {	
cannot place the secondary tertiary favored node for region 

Set<String> randomRacks = Sets.newHashSet();	ServerName newServer = null;	do {	String randomRack = this.getOneRandomRack(skipRackSet);	newServer = this.getOneRandomServer(randomRack, favoredNodeSet);	randomRacks.add(randomRack);	i++;	} while ((i < MAX_ATTEMPTS_FN_GENERATION) && (newServer == null));	if (newServer == null) {	if (LOG.isTraceEnabled()) {	
unable to generate additional favored nodes for s after considering racks s and skip rack s with a unique rack list of s and rack to rs map of s and rs to rack map of s 

========================= hbase sample_2326 =========================

for(String fam : fams) {	scan.addFamily(Bytes.toBytes(fam));	}	}	boolean includeDeletedCells = conf.getBoolean(NAME + ".includeDeletedCells", false);	scan.setRaw(includeDeletedCells);	String rowPrefixes = conf.get(NAME + ".rowPrefixes", null);	setRowPrefixFilter(scan, rowPrefixes);	scan.setTimeRange(startTime, endTime);	int versions = conf.getInt(NAME+".versions", -1);	
setting number of version inside map as 

endRow = ((TableSplit) tableSplit).getEndRow();	}	scan.setStopRow(endRow);	String peerSnapshotName = conf.get(NAME + ".peerSnapshotName", null);	if (peerSnapshotName != null) {	String peerSnapshotTmpDir = conf.get(NAME + ".peerSnapshotTmpDir", null);	String peerFSAddress = conf.get(NAME + ".peerFSAddress", null);	String peerHBaseRootAddress = conf.get(NAME + ".peerHBaseRootAddress", null);	FileSystem.setDefaultUri(peerConf, peerFSAddress);	FSUtils.setRootDir(peerConf, new Path(peerHBaseRootAddress));	
using peer snapshot with temp dir peer root uri peerfsaddress 

if (currentCompareRowInPeerTable == null) {	logFailRowAndIncreaseCounter(context, Counters.ONLY_IN_SOURCE_TABLE_ROWS, value);	break;	}	int rowCmpRet = Bytes.compareTo(value.getRow(), currentCompareRowInPeerTable.getRow());	if (rowCmpRet == 0) {	try {	Result.compareResults(value, currentCompareRowInPeerTable);	context.getCounter(Counters.GOODROWS).increment(1);	if (verbose) {	
good row key 

protected void cleanup(Context context) {	if (replicatedScanner != null) {	try {	while (currentCompareRowInPeerTable != null) {	logFailRowAndIncreaseCounter(context, Counters.ONLY_IN_PEER_TABLE_ROWS, currentCompareRowInPeerTable);	currentCompareRowInPeerTable = replicatedScanner.next();	}	} catch (Exception e) {	
fail to scan peer table in cleanup 

} catch (Exception e) {	} finally {	replicatedScanner.close();	replicatedScanner = null;	}	}	if (sourceTable != null) {	try {	sourceTable.close();	} catch (IOException e) {	
fail to close source table in cleanup 

if (sourceTable != null) {	try {	sourceTable.close();	} catch (IOException e) {	}	}	if(sourceConnection != null){	try {	sourceConnection.close();	} catch (Exception e) {	
fail to close source connection in cleanup 

if(sourceConnection != null){	try {	sourceConnection.close();	} catch (Exception e) {	}	}	if(replicatedTable != null){	try{	replicatedTable.close();	} catch (Exception e) {	
fail to close replicated table in cleanup 

if(replicatedTable != null){	try{	replicatedTable.close();	} catch (Exception e) {	}	}	if(replicatedConnection != null){	try {	replicatedConnection.close();	} catch (Exception e) {	
fail to close replicated connection in cleanup 

conf.setBoolean(NAME +".includeDeletedCells", includeDeletedCells);	if (families != null) {	conf.set(NAME+".families", families);	}	if (rowPrefixes != null){	conf.set(NAME+".rowPrefixes", rowPrefixes);	}	Pair<ReplicationPeerConfig, Configuration> peerConfigPair = getPeerQuorumConfig(conf, peerId);	ReplicationPeerConfig peerConfig = peerConfigPair.getFirst();	String peerQuorumAddress = peerConfig.getClusterKey();	
peer quorum address peer configuration 

}	if (rowPrefixes != null){	conf.set(NAME+".rowPrefixes", rowPrefixes);	}	Pair<ReplicationPeerConfig, Configuration> peerConfigPair = getPeerQuorumConfig(conf, peerId);	ReplicationPeerConfig peerConfig = peerConfigPair.getFirst();	String peerQuorumAddress = peerConfig.getClusterKey();	conf.set(NAME + ".peerQuorumAddress", peerQuorumAddress);	HBaseConfiguration.setWithPrefix(conf, PEER_CONFIG_PREFIX, peerConfig.getConfiguration().entrySet());	conf.setInt(NAME + ".versions", versions);	
number of version 

job.setJarByClass(VerifyReplication.class);	Scan scan = new Scan();	scan.setTimeRange(startTime, endTime);	scan.setRaw(includeDeletedCells);	scan.setCacheBlocks(false);	if (batch > 0) {	scan.setBatch(batch);	}	if (versions >= 0) {	scan.setMaxVersions(versions);	
number of versions set to 

}	if(families != null) {	String[] fams = families.split(",");	for(String fam : fams) {	scan.addFamily(Bytes.toBytes(fam));	}	}	setRowPrefixFilter(scan, rowPrefixes);	if (sourceSnapshotName != null) {	Path snapshotTempPath = new Path(sourceSnapshotTmpDir);	
using source snapshot with temp dir 

========================= hbase sample_3472 =========================

public byte[][] rollWriter() {	if (!listeners.isEmpty()) {	for (WALActionsListener listener : listeners) {	listener.logRollRequested(false);	}	for (WALActionsListener listener : listeners) {	try {	listener.preLogRoll(path, path);	} catch (IOException exception) {	
ignoring exception from listener 

for (WALActionsListener listener : listeners) {	try {	listener.preLogRoll(path, path);	} catch (IOException exception) {	}	}	for (WALActionsListener listener : listeners) {	try {	listener.postLogRoll(path, path);	} catch (IOException exception) {	
ignoring exception from listener 

========================= hbase sample_2263 =========================

public void testReportExpiration() throws Exception {	Configuration conf = TEST_UTIL.getConfiguration();	conf.setInt(FileSystemUtilizationChore.FS_UTILIZATION_CHORE_PERIOD_KEY, 25000);	conf.setInt(QuotaObserverChore.REGION_REPORT_RETENTION_DURATION_KEY, 5000);	TEST_UTIL.startMiniCluster(1);	final String FAM1 = "f1";	final HMaster master = TEST_UTIL.getMiniHBaseCluster().getMaster();	while (master.getMasterQuotaManager() == null) {	
masterquotamanager is null waiting 

tableDesc.addFamily(new HColumnDescriptor(FAM1));	TEST_UTIL.getAdmin().createTable(tableDesc);	assertEquals(0, getRegionReportsForTable(quotaManager.snapshotRegionSizes(), tn));	final long sizeLimit = 100L * SpaceQuotaHelperForTests.ONE_MEGABYTE;	final SpaceViolationPolicy violationPolicy = SpaceViolationPolicy.NO_INSERTS;	QuotaSettings settings = QuotaSettingsFactory.limitTableSpace(tn, sizeLimit, violationPolicy);	TEST_UTIL.getAdmin().setQuota(settings);	Waiter.waitFor(TEST_UTIL.getConfiguration(), 45000, 1000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	int numReports = getRegionReportsForTable(quotaManager.snapshotRegionSizes(), tn);	
saw reports for while waiting for 

TEST_UTIL.getAdmin().setQuota(settings);	Waiter.waitFor(TEST_UTIL.getConfiguration(), 45000, 1000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	int numReports = getRegionReportsForTable(quotaManager.snapshotRegionSizes(), tn);	return numReports == 1;	}	});	Waiter.waitFor(TEST_UTIL.getConfiguration(), 15000, 1000, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	int numReports = getRegionReportsForTable(quotaManager.snapshotRegionSizes(), tn);	
saw reports for while waiting for none 

========================= hbase sample_1438 =========================

private void registerCustomFilter(Configuration conf) {	String[] filterList = conf.getStrings(Constants.CUSTOM_FILTERS);	if (filterList != null) {	for (String filterClass : filterList) {	String[] filterPart = filterClass.split(":");	if (filterPart.length != 2) {	
invalid filter specification skipping 

========================= hbase sample_3110 =========================

public synchronized void suspend() {	ready = false;	if (LOG.isTraceEnabled()) {	
suspend 

========================= hbase sample_1204 =========================

public int run(String[] args) {	if (getConf() == null) {	throw new RuntimeException("A Configuration instance must be provided.");	}	try {	FSUtils.setFsDefault(getConf(), FSUtils.getRootDir(getConf()));	if (!parseOptions(args)) return 1;	} catch (IOException ex) {	
error parsing command line options 

public int run(String[] args) {	if (getConf() == null) {	throw new RuntimeException("A Configuration instance must be provided.");	}	try {	FSUtils.setFsDefault(getConf(), FSUtils.getRootDir(getConf()));	if (!parseOptions(args)) return 1;	} catch (IOException ex) {	return 1;	} catch (ParseException ex) {	
error parsing command line options 

} catch (ParseException ex) {	return 1;	}	for (Path fileName : files) {	try {	int exitCode = processFile(fileName);	if (exitCode != 0) {	return exitCode;	}	} catch (IOException ex) {	
error reading 

========================= hbase sample_2428 =========================

public boolean isBalancerOn() {	byte [] upData = super.getData(false);	try {	return upData == null || parseFrom(upData).getBalancerOn();	} catch (DeserializationException dex) {	
zk state for loadbalancer could not be parsed 

========================= hbase sample_733 =========================

addGauge(name, (Gauge<?>) metric, builder);	} else if (metric instanceof Counter) {	addCounter(name, (Counter)metric, builder);	} else if (metric instanceof Histogram) {	addHistogram(name, (Histogram)metric, builder);	} else if (metric instanceof Meter) {	addMeter(name, (Meter)metric, builder);	} else if (metric instanceof Timer) {	addTimer(name, (Timer)metric, builder);	} else {	
ignoring unknown metric class 

final Object o = gauge.getValue();	if (o instanceof Integer) {	builder.addGauge(info, (int) o);	} else if (o instanceof Long) {	builder.addGauge(info, (long) o);	} else if (o instanceof Float) {	builder.addGauge(info, (float) o);	} else if (o instanceof Double) {	builder.addGauge(info, (double) o);	} else {	
ignoring gauge with unhandled type 

========================= hbase sample_676 =========================

public static boolean archiveRegion(FileSystem fs, Path rootdir, Path tableDir, Path regionDir) throws IOException {	if (LOG.isDebugEnabled()) {	
archiving 

public static boolean archiveRegion(FileSystem fs, Path rootdir, Path tableDir, Path regionDir) throws IOException {	if (LOG.isDebugEnabled()) {	}	if (tableDir == null || regionDir == null) {	
no archive directory could be found because tabledir or regiondir was null deleting files instead 

FileStatusConverter getAsFile = new FileStatusConverter(fs);	Collection<File> toArchive = new ArrayList<>();	final PathFilter dirFilter = new FSUtils.DirFilter(fs);	PathFilter nonHidden = new PathFilter() {	public boolean accept(Path file) {	return dirFilter.accept(file) && !file.getName().toString().startsWith(".");	}	};	FileStatus[] storeDirs = FSUtils.listStatus(fs, regionDir, nonHidden);	if (storeDirs == null) {	
region directory empty 

PathFilter nonHidden = new PathFilter() {	public boolean accept(Path file) {	return dirFilter.accept(file) && !file.getName().toString().startsWith(".");	}	};	FileStatus[] storeDirs = FSUtils.listStatus(fs, regionDir, nonHidden);	if (storeDirs == null) {	return deleteRegionWithoutArchiving(fs, regionDir);	}	toArchive.addAll(Lists.transform(Arrays.asList(storeDirs), getAsFile));	
archiving 

public static void archiveStoreFiles(Configuration conf, FileSystem fs, RegionInfo regionInfo, Path tableDir, byte[] family, Collection<HStoreFile> compactedFiles) throws IOException, FailedArchiveException {	if (fs == null) {	
passed filesystem is null so just deleting the files without archiving for region family 

public static void archiveStoreFiles(Configuration conf, FileSystem fs, RegionInfo regionInfo, Path tableDir, byte[] family, Collection<HStoreFile> compactedFiles) throws IOException, FailedArchiveException {	if (fs == null) {	deleteStoreFilesWithoutArchiving(compactedFiles);	return;	}	if (compactedFiles.isEmpty()) {	
no store files to dispose done 

return;	}	if (compactedFiles.isEmpty()) {	return;	}	if (regionInfo == null || family == null) throw new IOException( "Need to have a region and a family to archive from.");	Path storeArchiveDir = HFileArchiveUtil.getStoreArchivePath(conf, regionInfo, tableDir, family);	if (!fs.mkdirs(storeArchiveDir)) {	throw new IOException("Could not make archive directory (" + storeArchiveDir + ") for store:" + Bytes.toString(family) + ", deleting compacted files instead.");	}	
archiving compacted store files 

private static List<File> resolveAndArchive(FileSystem fs, Path baseArchiveDir, Collection<File> toArchive, long start) throws IOException {	if (toArchive.isEmpty()) return Collections.emptyList();	
moving files to the archive directory 

private static List<File> resolveAndArchive(FileSystem fs, Path baseArchiveDir, Collection<File> toArchive, long start) throws IOException {	if (toArchive.isEmpty()) return Collections.emptyList();	if (!fs.exists(baseArchiveDir)) {	if (!fs.mkdirs(baseArchiveDir)) {	throw new IOException("Failed to create the archive directory:" + baseArchiveDir + ", quitting archive attempt.");	}	
created archive directory 

if (toArchive.isEmpty()) return Collections.emptyList();	if (!fs.exists(baseArchiveDir)) {	if (!fs.mkdirs(baseArchiveDir)) {	throw new IOException("Failed to create the archive directory:" + baseArchiveDir + ", quitting archive attempt.");	}	}	List<File> failures = new ArrayList<>();	String startTime = Long.toString(start);	for (File file : toArchive) {	try {	
archiving 

if (!fs.mkdirs(baseArchiveDir)) {	throw new IOException("Failed to create the archive directory:" + baseArchiveDir + ", quitting archive attempt.");	}	}	List<File> failures = new ArrayList<>();	String startTime = Long.toString(start);	for (File file : toArchive) {	try {	if (file.isFile()) {	if (!resolveAndArchiveFile(baseArchiveDir, file, startTime)) {	
couldn t archive into backup directory 

}	List<File> failures = new ArrayList<>();	String startTime = Long.toString(start);	for (File file : toArchive) {	try {	if (file.isFile()) {	if (!resolveAndArchiveFile(baseArchiveDir, file, startTime)) {	failures.add(file);	}	} else {	
is a directory archiving children files 

if (file.isFile()) {	if (!resolveAndArchiveFile(baseArchiveDir, file, startTime)) {	failures.add(file);	}	} else {	Path parentArchiveDir = new Path(baseArchiveDir, file.getName());	Collection<File> children = file.getChildren();	failures.addAll(resolveAndArchive(fs, parentArchiveDir, children, start));	}	} catch (IOException e) {	
failed to archive 

private static boolean resolveAndArchiveFile(Path archiveDir, File currentFile, String archiveStartTime) throws IOException {	String filename = currentFile.getName();	Path archiveFile = new Path(archiveDir, filename);	FileSystem fs = currentFile.getFileSystem();	if (fs.exists(archiveFile)) {	if (LOG.isDebugEnabled()) {	
file already exists in archive moving to timestamped backup and overwriting current 

private static boolean resolveAndArchiveFile(Path archiveDir, File currentFile, String archiveStartTime) throws IOException {	String filename = currentFile.getName();	Path archiveFile = new Path(archiveDir, filename);	FileSystem fs = currentFile.getFileSystem();	if (fs.exists(archiveFile)) {	if (LOG.isDebugEnabled()) {	}	Path backedupArchiveFile = new Path(archiveDir, filename + SEPARATOR + archiveStartTime);	if (!fs.rename(archiveFile, backedupArchiveFile)) {	
could not rename archive file to backup deleting existing file in favor of newer 

FileSystem fs = currentFile.getFileSystem();	if (fs.exists(archiveFile)) {	if (LOG.isDebugEnabled()) {	}	Path backedupArchiveFile = new Path(archiveDir, filename + SEPARATOR + archiveStartTime);	if (!fs.rename(archiveFile, backedupArchiveFile)) {	if (!fs.delete(archiveFile, false)) {	throw new IOException("Couldn't delete existing archive file (" + archiveFile + ") or rename it to the backup file (" + backedupArchiveFile + ") to make room for similarly named file.");	}	}	
backed up archive file from 

if (LOG.isDebugEnabled()) {	}	Path backedupArchiveFile = new Path(archiveDir, filename + SEPARATOR + archiveStartTime);	if (!fs.rename(archiveFile, backedupArchiveFile)) {	if (!fs.delete(archiveFile, false)) {	throw new IOException("Couldn't delete existing archive file (" + archiveFile + ") or rename it to the backup file (" + backedupArchiveFile + ") to make room for similarly named file.");	}	}	}	if (LOG.isTraceEnabled()) {	
no existing file in archive for free to archive original file 

}	}	if (LOG.isTraceEnabled()) {	}	boolean success = false;	for (int i = 0; !success && i < DEFAULT_RETRIES_NUMBER; ++i) {	if (i > 0) {	try {	if (!fs.exists(archiveDir)) {	if (fs.mkdirs(archiveDir)) {	
created archive directory 

}	boolean success = false;	for (int i = 0; !success && i < DEFAULT_RETRIES_NUMBER; ++i) {	if (i > 0) {	try {	if (!fs.exists(archiveDir)) {	if (fs.mkdirs(archiveDir)) {	}	}	} catch (IOException e) {	
failed to create directory 

if (!fs.exists(archiveDir)) {	if (fs.mkdirs(archiveDir)) {	}	}	} catch (IOException e) {	}	}	try {	success = currentFile.moveAndClose(archiveFile);	} catch (FileNotFoundException fnfe) {	
failed to archive because it does not exist skipping and continuing on 

}	}	} catch (IOException e) {	}	}	try {	success = currentFile.moveAndClose(archiveFile);	} catch (FileNotFoundException fnfe) {	success = true;	} catch (IOException e) {	
failed to archive on try 

}	try {	success = currentFile.moveAndClose(archiveFile);	} catch (FileNotFoundException fnfe) {	success = true;	} catch (IOException e) {	success = false;	}	}	if (!success) {	
failed to archive 

} catch (FileNotFoundException fnfe) {	success = true;	} catch (IOException e) {	success = false;	}	}	if (!success) {	return false;	}	if (LOG.isDebugEnabled()) {	
finished archiving from to 

private static boolean deleteRegionWithoutArchiving(FileSystem fs, Path regionDir) throws IOException {	if (fs.delete(regionDir, true)) {	
deleted 

private static boolean deleteRegionWithoutArchiving(FileSystem fs, Path regionDir) throws IOException {	if (fs.delete(regionDir, true)) {	return true;	}	
failed to delete region directory 

private static void deleteStoreFilesWithoutArchiving(Collection<HStoreFile> compactedFiles) throws IOException {	
deleting store files without archiving 

private static void deleteStoreFilesWithoutArchiving(Collection<HStoreFile> compactedFiles) throws IOException {	List<IOException> errors = new ArrayList<>(0);	for (HStoreFile hsf : compactedFiles) {	try {	hsf.deleteStoreFile();	} catch (IOException e) {	
failed to delete store file 

========================= hbase sample_2994 =========================

public void setConf(Configuration configuration) {	this.conf = configuration;	Scan scan = null;	if (conf.get(SCAN) != null) {	try {	scan = TableMapReduceUtil.convertStringToScan(conf.get(SCAN));	} catch (IOException e) {	
an error occurred 

========================= hbase sample_3452 =========================

try {	RegionInfo parsedRegionInfo = MetaTableAccessor.parseRegionInfoFromRegionName(regionName);	metaTable.get( new Get(MetaTableAccessor.getMetaKeyForRegion(parsedRegionInfo)) .addFamily(HConstants.CATALOG_FAMILY)).whenComplete( (r, err) -> {	if (err != null) {	future.completeExceptionally(err);	return;	}	future.complete(getRegionLocations(r).map( locations -> locations.getRegionLocation(parsedRegionInfo.getReplicaId())));	});	} catch (IOException parseEx) {	
failed to parse the passed region name 

private static CompletableFuture<List<Pair<RegionInfo, ServerName>>> getTableRegionsAndLocations( AsyncTable<AdvancedScanResultConsumer> metaTable, final Optional<TableName> tableName, final boolean excludeOfflinedSplitParents) {	CompletableFuture<List<Pair<RegionInfo, ServerName>>> future = new CompletableFuture<>();	if (tableName.filter((t) -> t.equals(TableName.META_TABLE_NAME)).isPresent()) {	future.completeExceptionally(new IOException( "This method can't be used to locate meta regions;" + " use MetaTableLocator instead"));	}	CollectingVisitor<Pair<RegionInfo, ServerName>> visitor = new CollectingVisitor<Pair<RegionInfo, ServerName>>() {	private Optional<RegionLocations> current = null;	public boolean visit(Result r) throws IOException {	current = getRegionLocations(r);	if (!current.isPresent() || current.get().getRegionLocation().getRegion() == null) {	
no serialized regioninfo in 

========================= hbase sample_158 =========================

public void testGlobalMemStore() throws Exception {	
starting cluster 

public void testGlobalMemStore() throws Exception {	Configuration conf = HBaseConfiguration.create();	TEST_UTIL = new HBaseTestingUtility(conf);	TEST_UTIL.startMiniCluster(1, regionServerNum);	cluster = TEST_UTIL.getHBaseCluster();	
waiting for active ready master 

public void testGlobalMemStore() throws Exception {	Configuration conf = HBaseConfiguration.create();	TEST_UTIL = new HBaseTestingUtility(conf);	TEST_UTIL.startMiniCluster(1, regionServerNum);	cluster = TEST_UTIL.getHBaseCluster();	cluster.waitForActiveAndReadyMaster();	final TableName table = TableName.valueOf(name.getMethodName());	byte [] family = Bytes.toBytes("family");	
creating table with regions 

}	assertEquals(server.getRegionServerAccounting().getGlobalMemStoreDataSize(), globalMemStoreSize);	}	int i = 0;	for (HRegionServer server : getOnlineRegionServers()) {	LOG.info("Starting flushes on " + server.getServerName() + ", size=" + server.getRegionServerAccounting().getGlobalMemStoreDataSize());	for (RegionInfo regionInfo : ProtobufUtil.getOnlineRegions(null, server.getRSRpcServices())) {	HRegion r = server.getRegion(regionInfo.getEncodedName());	flush(r, server);	}	
post flush on 

while(server.getRegionServerAccounting().getGlobalMemStoreDataSize() != 0 && timeout < System.currentTimeMillis()) {	Threads.sleep(10);	}	long size = server.getRegionServerAccounting().getGlobalMemStoreDataSize();	if (size > 0) {	for (RegionInfo regionInfo : ProtobufUtil.getOnlineRegions(null, server.getRSRpcServices())) {	HRegion r = server.getRegion(regionInfo.getEncodedName());	long l = r.getMemStoreSize();	if (l > 0) {	assertTrue(regionInfo.isMetaRegion());	
reflushing 

private void waitForAllRegionsAssigned() throws IOException {	while (true) {	int regionCount = HBaseTestingUtility.getAllOnlineRegions(cluster).size();	if (regionCount >= totalRegionNum) break;	
waiting for there to be regions but there are right now 

========================= hbase sample_1896 =========================

public Get setTimeStamp(long timestamp) throws IOException {	try {	tr = new TimeRange(timestamp, timestamp+1);	} catch(Exception e) {	
timerange failed likely caused by integer overflow 

========================= hbase sample_508 =========================

conf.set(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, "org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner");	conf.setLong(TimeToLiveHFileCleaner.TTL_CONF_KEY, ttl);	Server server = new DummyServer();	Path archivedHfileDir = new Path(UTIL.getDataTestDirOnTestFS(), HConstants.HFILE_ARCHIVE_DIRECTORY);	FileSystem fs = FileSystem.get(conf);	HFileCleaner cleaner = new HFileCleaner(1000, server, conf, fs, archivedHfileDir);	final long createTime = System.currentTimeMillis();	fs.delete(archivedHfileDir, true);	fs.mkdirs(archivedHfileDir);	fs.createNewFile(new Path(archivedHfileDir, "dfd-dfd"));	
now is 

FileSystem fs = FileSystem.get(conf);	HFileCleaner cleaner = new HFileCleaner(1000, server, conf, fs, archivedHfileDir);	final long createTime = System.currentTimeMillis();	fs.delete(archivedHfileDir, true);	fs.mkdirs(archivedHfileDir);	fs.createNewFile(new Path(archivedHfileDir, "dfd-dfd"));	for (int i = 1; i < 32; i++) {	Path fileName = new Path(archivedHfileDir, (prefix + "." + (createTime + i)));	fs.createNewFile(fileName);	fs.setTimes(fileName, createTime - ttl - 1, -1);	
creating 

fs.mkdirs(archivedHfileDir);	fs.createNewFile(new Path(archivedHfileDir, "dfd-dfd"));	for (int i = 1; i < 32; i++) {	Path fileName = new Path(archivedHfileDir, (prefix + "." + (createTime + i)));	fs.createNewFile(fileName);	fs.setTimes(fileName, createTime - ttl - 1, -1);	}	Path saved = new Path(archivedHfileDir, prefix + ".00000000000");	fs.createNewFile(saved);	fs.setTimes(saved, createTime - ttl / 2, -1);	
creating 

assertEquals(33, fs.listStatus(archivedHfileDir).length);	EnvironmentEdge setTime = new EnvironmentEdge() {	public long currentTime() {	return createTime;	}	};	EnvironmentEdgeManager.injectEdge(setTime);	cleaner.chore();	assertEquals(1, fs.listStatus(archivedHfileDir).length);	for (FileStatus file : fs.listStatus(archivedHfileDir)) {	
kept hfiles 

t.start();	while (cleaner.getNumOfDeletedSmallFiles() == 0) {	Thread.yield();	}	Configuration newConf = new Configuration(conf);	newConf.setInt(HFileCleaner.HFILE_DELETE_THROTTLE_THRESHOLD, UPDATE_THROTTLE_POINT);	newConf.setInt(HFileCleaner.LARGE_HFILE_QUEUE_INIT_SIZE, UPDATE_QUEUE_INIT_SIZE);	newConf.setInt(HFileCleaner.SMALL_HFILE_QUEUE_INIT_SIZE, UPDATE_QUEUE_INIT_SIZE);	newConf.setInt(HFileCleaner.LARGE_HFILE_DELETE_THREAD_NUMBER, LARGE_THREAD_NUM);	newConf.setInt(HFileCleaner.SMALL_HFILE_DELETE_THREAD_NUMBER, SMALL_THREAD_NUM);	
file deleted from large queue from small queue 

cleaner.onConfigurationChange(newConf);	Assert.assertEquals(UPDATE_THROTTLE_POINT, cleaner.getThrottlePoint());	Assert.assertEquals(UPDATE_QUEUE_INIT_SIZE, cleaner.getLargeQueueInitSize());	Assert.assertEquals(UPDATE_QUEUE_INIT_SIZE, cleaner.getSmallQueueInitSize());	Assert.assertEquals(LARGE_THREAD_NUM + SMALL_THREAD_NUM, cleaner.getCleanerThreads().size());	List<Thread> oldThreads = cleaner.getCleanerThreads();	cleaner.onConfigurationChange(newConf);	List<Thread> newThreads = cleaner.getCleanerThreads();	Assert.assertArrayEquals(oldThreads.toArray(), newThreads.toArray());	t.join();	
file deleted from large queue from small queue 

========================= hbase sample_1879 =========================

}	}	Procedure proc = coordinator.startProcedure(this.monitor, this.snapshot.getName(), this.snapshot.toByteArray(), Lists.newArrayList(regionServers));	if (proc == null) {	String msg = "Failed to submit distributed procedure for snapshot '" + snapshot.getName() + "'";	LOG.error(msg);	throw new HBaseSnapshotException(msg);	}	try {	proc.waitForCompleted();	
done waiting online snapshot for 

proc.waitForCompleted();	for (Pair<RegionInfo, ServerName> region : regions) {	RegionInfo regionInfo = region.getFirst();	if (regionInfo.isOffline() && (regionInfo.isSplit() || regionInfo.isSplitParent())) {	LOG.info("Take disabled snapshot of offline region=" + regionInfo);	snapshotDisabledRegion(regionInfo);	}	}	boolean mobEnabled = MobUtils.hasMobColumns(htd);	if (mobEnabled) {	
taking snapshot for mob files in table 

========================= hbase sample_2756 =========================

}	Scan scan = new Scan();	scan.setMaxVersions(Integer.MAX_VALUE);	CacheConfig cacheConf = new CacheConfig(conf);	LruBlockCache cache = (LruBlockCache) cacheConf.getBlockCache();	cache.clearCache();	InternalScanner scanner = region.getScanner(scan);	List<Cell> results = new ArrayList<>();	final int expectedKVsPerRow = numFreshFiles * NUM_COLS_PER_ROW;	int numReturnedRows = 0;	
scanning the entire table 

List<Cell> results = new ArrayList<>();	final int expectedKVsPerRow = numFreshFiles * NUM_COLS_PER_ROW;	int numReturnedRows = 0;	while (scanner.next(results) || results.size() > 0) {	assertEquals(expectedKVsPerRow, results.size());	++numReturnedRows;	results.clear();	}	assertEquals(NUM_ROWS, numReturnedRows);	Set<String> accessedFiles = cache.getCachedFileNamesForTest();	
files accessed during scan 

========================= hbase sample_1480 =========================

static void visitTableStoreFiles(final Configuration conf, final FileSystem fs, final Path snapshotDir, final SnapshotDescription desc, final StoreFileVisitor visitor) throws IOException {	SnapshotManifest manifest = SnapshotManifest.open(conf, fs, snapshotDir, desc);	List<SnapshotRegionManifest> regionManifests = manifest.getRegionManifests();	if (regionManifests == null || regionManifests.isEmpty()) {	
no manifest files present 

public static void concurrentVisitReferencedFiles(final Configuration conf, final FileSystem fs, final SnapshotManifest manifest, final String desc, final StoreFileVisitor visitor) throws IOException {	final Path snapshotDir = manifest.getSnapshotDir();	List<SnapshotRegionManifest> regionManifests = manifest.getRegionManifests();	if (regionManifests == null || regionManifests.isEmpty()) {	
no manifest files present 

public static void concurrentVisitReferencedFiles(final Configuration conf, final FileSystem fs, final SnapshotManifest manifest, final ExecutorService exec, final StoreFileVisitor visitor) throws IOException {	final SnapshotDescription snapshotDesc = manifest.getSnapshotDescription();	final Path snapshotDir = manifest.getSnapshotDir();	List<SnapshotRegionManifest> regionManifests = manifest.getRegionManifests();	if (regionManifests == null || regionManifests.isEmpty()) {	
no manifest files present 

========================= hbase sample_2185 =========================

public void testWholesomeMerge() throws Exception {	
starting 

public void testCleanMergeReference() throws Exception {	
starting 

newcount1 += hrfs.getStoreFiles(colFamily.getName()).size();	}	if(newcount1 <= 1) {	break;	}	Thread.sleep(50);	}	int cleaned = 0;	while (cleaned == 0) {	cleaned = ADMIN.runCatalogScan();	
catalog janitor returned 

public void testMerge() throws Exception {	
starting 

LOG.info(Objects.toString(tableRegionsInMaster));	LOG.info(Objects.toString(tableRegionsInMeta));	int tableRegionsInMetaSize = tableRegionsInMeta.size();	int tableRegionsInMasterSize = tableRegionsInMaster.size();	if (tableRegionsInMetaSize == expectedRegionNum && tableRegionsInMasterSize == expectedRegionNum) {	break;	}	Thread.sleep(250);	}	tableRegionsInMeta = MetaTableAccessor.getTableRegionsAndLocations( TEST_UTIL.getConnection(), tablename);	
regions after merge 

private Table createTableAndLoadData(HMaster master, TableName tablename, int numRegions, int replication) throws Exception {	assertTrue("ROWSIZE must > numregions:" + numRegions, ROWSIZE > numRegions);	byte[][] splitRows = new byte[numRegions - 1][];	for (int i = 0; i < splitRows.length; i++) {	splitRows[i] = ROWS[(i + 1) * ROWSIZE / numRegions];	}	Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	
created 

private Table createTableAndLoadData(HMaster master, TableName tablename, int numRegions, int replication) throws Exception {	assertTrue("ROWSIZE must > numregions:" + numRegions, ROWSIZE > numRegions);	byte[][] splitRows = new byte[numRegions - 1][];	for (int i = 0; i < splitRows.length; i++) {	splitRows[i] = ROWS[(i + 1) * ROWSIZE / numRegions];	}	Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	if (replication > 1) {	HBaseTestingUtility.setReplicas(ADMIN, tablename, replication);	
set replication of on 

assertTrue("ROWSIZE must > numregions:" + numRegions, ROWSIZE > numRegions);	byte[][] splitRows = new byte[numRegions - 1][];	for (int i = 0; i < splitRows.length; i++) {	splitRows[i] = ROWS[(i + 1) * ROWSIZE / numRegions];	}	Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	if (replication > 1) {	HBaseTestingUtility.setReplicas(ADMIN, tablename, replication);	}	loadData(table);	
loaded 

byte[][] splitRows = new byte[numRegions - 1][];	for (int i = 0; i < splitRows.length; i++) {	splitRows[i] = ROWS[(i + 1) * ROWSIZE / numRegions];	}	Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	if (replication > 1) {	HBaseTestingUtility.setReplicas(ADMIN, tablename, replication);	}	loadData(table);	verifyRowCount(table, ROWSIZE);	
verified 

splitRows[i] = ROWS[(i + 1) * ROWSIZE / numRegions];	}	Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	if (replication > 1) {	HBaseTestingUtility.setReplicas(ADMIN, tablename, replication);	}	loadData(table);	verifyRowCount(table, ROWSIZE);	List<Pair<RegionInfo, ServerName>> tableRegions;	TEST_UTIL.waitUntilAllRegionsAssigned(tablename);	
all regions assigned for table 

Table table = TEST_UTIL.createTable(tablename, FAMILYNAME, splitRows);	if (replication > 1) {	HBaseTestingUtility.setReplicas(ADMIN, tablename, replication);	}	loadData(table);	verifyRowCount(table, ROWSIZE);	List<Pair<RegionInfo, ServerName>> tableRegions;	TEST_UTIL.waitUntilAllRegionsAssigned(tablename);	tableRegions = MetaTableAccessor.getTableRegionsAndLocations( TEST_UTIL.getConnection(), tablename);	assertEquals("Wrong number of regions in table " + tablename, numRegions * replication, tableRegions.size());	
regions after load 

========================= hbase sample_1603 =========================

private void add(final List<String> servers) throws IOException {	synchronized(this.drainingServers) {	this.drainingServers.clear();	for (String n: servers) {	final ServerName sn = ServerName.valueOf(ZKUtil.getNodeName(n));	this.drainingServers.add(sn);	this.serverManager.addServerToDrainList(sn);	
draining rs node created adding to list 

public void nodeDeleted(final String path) {	if(path.startsWith(watcher.znodePaths.drainingZNode)) {	final ServerName sn = ServerName.valueOf(ZKUtil.getNodeName(path));	
draining rs node deleted removing from list 

========================= hbase sample_2886 =========================

public void testClassLoadingFromHDFS() throws Exception {	FileSystem fs = cluster.getFileSystem();	File jarFile1 = buildCoprocessorJar(cpName1);	File jarFile2 = buildCoprocessorJar(cpName2);	fs.copyFromLocalFile(new Path(jarFile1.getPath()), new Path(fs.getUri().toString() + Path.SEPARATOR));	String jarFileOnHDFS1 = fs.getUri().toString() + Path.SEPARATOR + jarFile1.getName();	Path pathOnHDFS1 = new Path(jarFileOnHDFS1);	assertTrue("Copy jar file to HDFS failed.", fs.exists(pathOnHDFS1));	
copied jar file to hdfs 

File jarFile1 = buildCoprocessorJar(cpName1);	File jarFile2 = buildCoprocessorJar(cpName2);	fs.copyFromLocalFile(new Path(jarFile1.getPath()), new Path(fs.getUri().toString() + Path.SEPARATOR));	String jarFileOnHDFS1 = fs.getUri().toString() + Path.SEPARATOR + jarFile1.getName();	Path pathOnHDFS1 = new Path(jarFileOnHDFS1);	assertTrue("Copy jar file to HDFS failed.", fs.exists(pathOnHDFS1));	fs.copyFromLocalFile(new Path(jarFile2.getPath()), new Path(fs.getUri().toString() + Path.SEPARATOR));	String jarFileOnHDFS2 = fs.getUri().toString() + Path.SEPARATOR + jarFile2.getName();	Path pathOnHDFS2 = new Path(jarFileOnHDFS2);	assertTrue("Copy jar file to HDFS failed.", fs.exists(pathOnHDFS2));	
copied jar file to hdfs 

========================= hbase sample_1253 =========================

this.fs = fs;	this.oldFileDir = oldFileDir;	this.conf = conf;	this.params = params;	initCleanerChain(confKey);	if (chorePool == null) {	String poolSize = conf.get(CHORE_POOL_SIZE, DEFAULT_CHORE_POOL_SIZE);	chorePoolSize = calculatePoolSize(poolSize);	chorePoolSize = chorePoolSize == 0 ? calculatePoolSize(DEFAULT_CHORE_POOL_SIZE) : chorePoolSize;	this.chorePool = new ForkJoinPool(chorePoolSize);	
cleaner pool size is 

private void updateChorePoolSize(int updatedSize) {	chorePool.shutdownNow();	
update chore s pool size from to 

protected void chore() {	if (getEnabled()) {	if (runCleaner()) {	
cleaned old files dirs under successfully 

protected void chore() {	if (getEnabled()) {	if (runCleaner()) {	} else {	
failed to fully clean old files dirs under 

protected void chore() {	if (getEnabled()) {	if (runCleaner()) {	} else {	}	if (reconfig.compareAndSet(true, false)) {	updateChorePoolSize(chorePoolSize);	}	} else {	
cleaner chore disabled not cleaning 

private boolean checkAndDeleteFiles(List<FileStatus> files) {	if (files == null) {	return true;	}	List<FileStatus> validFiles = Lists.newArrayListWithCapacity(files.size());	List<FileStatus> invalidFiles = Lists.newArrayList();	for (FileStatus file : files) {	if (validate(file.getPath())) {	validFiles.add(file);	} else {	
found a wrongly formatted file will delete it 

for (FileStatus file : files) {	if (validate(file.getPath())) {	validFiles.add(file);	} else {	invalidFiles.add(file);	}	}	Iterable<FileStatus> deletableValidFiles = validFiles;	for (T cleaner : cleanersChain) {	if (cleaner.isStopped() || this.getStopper().isStopped()) {	
a file cleaner is stopped won t delete any more files in 

Iterable<FileStatus> deletableValidFiles = validFiles;	for (T cleaner : cleanersChain) {	if (cleaner.isStopped() || this.getStopper().isStopped()) {	return false;	}	Iterable<FileStatus> filteredFiles = cleaner.getDeletableFiles(deletableValidFiles);	if (LOG.isTraceEnabled()) {	ImmutableSet<FileStatus> filteredFileSet = ImmutableSet.copyOf(filteredFiles);	for (FileStatus file : deletableValidFiles) {	if (!filteredFileSet.contains(file)) {	
is not deletable according to 

protected int deleteFiles(Iterable<FileStatus> filesToDelete) {	int deletedFileCount = 0;	for (FileStatus file : filesToDelete) {	Path filePath = file.getPath();	
removing from archive 

protected int deleteFiles(Iterable<FileStatus> filesToDelete) {	int deletedFileCount = 0;	for (FileStatus file : filesToDelete) {	Path filePath = file.getPath();	try {	boolean success = this.fs.delete(filePath, false);	if (success) {	deletedFileCount++;	} else {	
attempted to delete but couldn t run cleaner chain and attempt to delete on next pass 

for (FileStatus file : filesToDelete) {	Path filePath = file.getPath();	try {	boolean success = this.fs.delete(filePath, false);	if (success) {	deletedFileCount++;	} else {	}	} catch (IOException e) {	e = e instanceof RemoteException ? ((RemoteException)e).unwrapRemoteException() : e;	
error while deleting 

public void cleanup() {	for (T lc : this.cleanersChain) {	try {	lc.stop("Exiting");	} catch (Throwable t) {	
Stopping 

protected Boolean compute() {	if (LOG.isDebugEnabled()) {	
cleanertask starts cleaning dirs and files under and itself 

protected Boolean compute() {	if (LOG.isDebugEnabled()) {	}	List<FileStatus> subDirs;	List<FileStatus> files;	try {	subDirs = getFilteredStatus(status -> status.isDirectory());	files = getFilteredStatus(status -> status.isFile());	} catch (IOException ioe) {	
doesn t exist just skip it 

List<FileStatus> subDirs;	List<FileStatus> files;	try {	subDirs = getFilteredStatus(status -> status.isDirectory());	files = getFilteredStatus(status -> status.isFile());	} catch (IOException ioe) {	return true;	}	boolean nullSubDirs = subDirs == null;	if (nullSubDirs) {	
there is no subdir under 

try {	subDirs = getFilteredStatus(status -> status.isDirectory());	files = getFilteredStatus(status -> status.isFile());	} catch (IOException ioe) {	return true;	}	boolean nullSubDirs = subDirs == null;	if (nullSubDirs) {	}	if (files == null) {	
there is no file under 

private boolean deleteAction(Action<Boolean> deletion, String type) {	boolean deleted;	String errorMsg = null;	try {	
start deleting under 

private boolean deleteAction(Action<Boolean> deletion, String type) {	boolean deleted;	String errorMsg = null;	try {	deleted = deletion.act();	} catch (IOException ioe) {	errorMsg = ioe.getMessage();	
could not delete under 

========================= hbase sample_2869 =========================

public void setUp() {	jsc = new JavaSparkContext("local", "JavaHBaseContextSuite");	File tempDir = Files.createTempDir();	tempDir.deleteOnExit();	htu = new HBaseTestingUtility();	try {	
cleaning up test dir 

public void setUp() {	jsc = new JavaSparkContext("local", "JavaHBaseContextSuite");	File tempDir = Files.createTempDir();	tempDir.deleteOnExit();	htu = new HBaseTestingUtility();	try {	htu.cleanupTestDir();	
starting minicluster 

public void setUp() {	jsc = new JavaSparkContext("local", "JavaHBaseContextSuite");	File tempDir = Files.createTempDir();	tempDir.deleteOnExit();	htu = new HBaseTestingUtility();	try {	htu.cleanupTestDir();	htu.startMiniZKCluster();	htu.startMiniHBaseCluster(1, 1);	
minicluster started 

File tempDir = Files.createTempDir();	tempDir.deleteOnExit();	htu = new HBaseTestingUtility();	try {	htu.cleanupTestDir();	htu.startMiniZKCluster();	htu.startMiniHBaseCluster(1, 1);	try {	htu.deleteTable(TableName.valueOf(tableName));	} catch (Exception e) {	
no table found 

tempDir.deleteOnExit();	htu = new HBaseTestingUtility();	try {	htu.cleanupTestDir();	htu.startMiniZKCluster();	htu.startMiniHBaseCluster(1, 1);	try {	htu.deleteTable(TableName.valueOf(tableName));	} catch (Exception e) {	}	
creating table 

htu = new HBaseTestingUtility();	try {	htu.cleanupTestDir();	htu.startMiniZKCluster();	htu.startMiniHBaseCluster(1, 1);	try {	htu.deleteTable(TableName.valueOf(tableName));	} catch (Exception e) {	}	htu.createTable(TableName.valueOf(tableName), new byte[][]{columnFamily, columnFamily1});	
created table 

public void tearDown() {	try {	htu.deleteTable(TableName.valueOf(tableName));	
shuting down minicluster 

public void tearDown() {	try {	htu.deleteTable(TableName.valueOf(tableName));	htu.shutdownMiniHBaseCluster();	htu.shutdownMiniZKCluster();	
minicluster shut down 

========================= hbase sample_621 =========================

public void initialize(RegionServerServices rss) throws KeeperException {	for (RegionServerProcedureManager proc : procedures) {	
procedure is initializing 

public void initialize(RegionServerServices rss) throws KeeperException {	for (RegionServerProcedureManager proc : procedures) {	proc.initialize(rss);	
procedure is initialized 

public void start() {	for (RegionServerProcedureManager proc : procedures) {	
procedure is starting 

public void start() {	for (RegionServerProcedureManager proc : procedures) {	proc.start();	
procedure is started 

public void stop(boolean force) {	for (RegionServerProcedureManager proc : procedures) {	try {	proc.stop(force);	} catch (IOException e) {	
failed to close procedure cleanly 

========================= hbase sample_2490 =========================

TableDescriptor td = TableDescriptorBuilder.newBuilder(TABLE_NAME) .addColumnFamily(ColumnFamilyDescriptorBuilder.of(TEST_FAM)) .setCompactionEnabled(false) .build();	UTIL.getAdmin().createTable(td);	for (int i = 0; i < blockingStoreFiles / 2; i ++) {	UTIL.loadTable(UTIL.getConnection().getTable(TABLE_NAME), TEST_FAM);	UTIL.flush(TABLE_NAME);	}	admin.disableTable(TABLE_NAME);	String snapshotName = "snapshot";	byte[] snapshotNameBytes = Bytes.toBytes(snapshotName);	admin.snapshot(snapshotNameBytes, TABLE_NAME);	
after snapshot file system state 

List<RegionServerThread> regionServerThreads = UTIL.getMiniHBaseCluster() .getRegionServerThreads();	HRegionServer hrs = null;	for (RegionServerThread rs : regionServerThreads) {	if (!rs.getRegionServer().getRegions(TABLE_NAME).isEmpty()) {	hrs = rs.getRegionServer();	break;	}	}	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, hrs, false);	cleaner.chore();	
after compaction file system state 

HRegionServer hrs = null;	for (RegionServerThread rs : regionServerThreads) {	if (!rs.getRegionServer().getRegions(TABLE_NAME).isEmpty()) {	hrs = rs.getRegionServer();	break;	}	}	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, hrs, false);	cleaner.chore();	FSUtils.logFileSystemState(fs, rootDir, LOG);	
running hfile cleaners 

for (RegionServerThread rs : regionServerThreads) {	if (!rs.getRegionServer().getRegions(TABLE_NAME).isEmpty()) {	hrs = rs.getRegionServer();	break;	}	}	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, hrs, false);	cleaner.chore();	FSUtils.logFileSystemState(fs, rootDir, LOG);	ensureHFileCleanersRun();	
after cleaners file system state 

break;	}	}	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, hrs, false);	cleaner.chore();	FSUtils.logFileSystemState(fs, rootDir, LOG);	ensureHFileCleanersRun();	FSUtils.logFileSystemState(fs, rootDir, LOG);	Path snapshotTable = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshotName, rootDir);	Set<String> snapshotHFiles = SnapshotReferenceUtil.getHFileNames( UTIL.getConfiguration(), fs, snapshotTable);	
have snapshot hfiles 

assertTrue("Archived hfiles " + archives + " and table hfiles " + hfiles + " is missing snapshot file:" + fileName, exist);	}	admin.deleteSnapshot(snapshotNameBytes);	SnapshotTestingUtils.assertNoSnapshots(admin);	List<BaseHFileCleanerDelegate> delegates = UTIL.getMiniHBaseCluster().getMaster() .getHFileCleaner().cleanersChain;	for (BaseHFileCleanerDelegate delegate: delegates) {	if (delegate instanceof SnapshotHFileCleaner) {	((SnapshotHFileCleaner)delegate).getFileCacheForTesting().triggerCacheRefreshForTesting();	}	}	
running hfile cleaners 

}	admin.deleteSnapshot(snapshotNameBytes);	SnapshotTestingUtils.assertNoSnapshots(admin);	List<BaseHFileCleanerDelegate> delegates = UTIL.getMiniHBaseCluster().getMaster() .getHFileCleaner().cleanersChain;	for (BaseHFileCleanerDelegate delegate: delegates) {	if (delegate instanceof SnapshotHFileCleaner) {	((SnapshotHFileCleaner)delegate).getFileCacheForTesting().triggerCacheRefreshForTesting();	}	}	ensureHFileCleanersRun();	
after delete snapshot cleaners run file system state 

========================= hbase sample_1880 =========================

public Map<String, TableDescriptor> getAllDescriptors() throws IOException {	Map<String, TableDescriptor> tds = new TreeMap<>();	if (fsvisited && usecache) {	for (Map.Entry<TableName, TableDescriptor> entry: this.cache.entrySet()) {	tds.put(entry.getKey().toString(), entry.getValue());	}	tds.put(this.metaTableDescriptor.getTableName().getNameAsString(), metaTableDescriptor);	} else {	
fetching table descriptors from the filesystem 

tds.put(entry.getKey().toString(), entry.getValue());	}	tds.put(this.metaTableDescriptor.getTableName().getNameAsString(), metaTableDescriptor);	} else {	boolean allvisited = true;	for (Path d : FSUtils.getTableDirs(fs, rootdir)) {	TableDescriptor htd = null;	try {	htd = get(FSUtils.getTableName(d));	} catch (FileNotFoundException fnfe) {	
trouble retrieving htd 

public Map<String, TableDescriptor> getByNamespace(String name) throws IOException {	Map<String, TableDescriptor> htds = new TreeMap<>();	List<Path> tableDirs = FSUtils.getLocalTableDirs(fs, FSUtils.getNamespaceDir(rootdir, name));	for (Path d: tableDirs) {	TableDescriptor htd = null;	try {	htd = get(FSUtils.getTableName(d));	} catch (FileNotFoundException fnfe) {	
trouble retrieving htd 

for (FileStatus file : status) {	if (mostCurrent == null || TABLEINFO_FILESTATUS_COMPARATOR.compare(file, mostCurrent) < 0) {	mostCurrent = file;	}	}	if (removeOldFiles && status.length > 1) {	for (FileStatus file : status) {	Path path = file.getPath();	if (file != mostCurrent) {	if (!fs.delete(file.getPath(), false)) {	
failed cleanup of 

if (mostCurrent == null || TABLEINFO_FILESTATUS_COMPARATOR.compare(file, mostCurrent) < 0) {	mostCurrent = file;	}	}	if (removeOldFiles && status.length > 1) {	for (FileStatus file : status) {	Path path = file.getPath();	if (file != mostCurrent) {	if (!fs.delete(file.getPath(), false)) {	} else {	
cleaned up old tableinfo file 

private static void deleteTableDescriptorFiles(FileSystem fs, Path dir, int maxSequenceId) throws IOException {	FileStatus [] status = FSUtils.listStatus(fs, dir, TABLEINFO_PATHFILTER);	for (FileStatus file : status) {	Path path = file.getPath();	int sequenceId = getTableInfoSequenceId(path);	if (sequenceId <= maxSequenceId) {	boolean success = FSUtils.delete(fs, path, false);	if (success) {	
deleted table descriptor at 

private static void deleteTableDescriptorFiles(FileSystem fs, Path dir, int maxSequenceId) throws IOException {	FileStatus [] status = FSUtils.listStatus(fs, dir, TABLEINFO_PATHFILTER);	for (FileStatus file : status) {	Path path = file.getPath();	int sequenceId = getTableInfoSequenceId(path);	if (sequenceId <= maxSequenceId) {	boolean success = FSUtils.delete(fs, path, false);	if (success) {	} else {	
failed to delete descriptor at 

int currentSequenceId = currentDescriptorFile == null ? 0 : getTableInfoSequenceId(currentDescriptorFile.getPath());	int newSequenceId = currentSequenceId;	int retries = 10;	int retrymax = currentSequenceId + retries;	Path tableInfoDirPath = null;	do {	newSequenceId += 1;	String filename = getTableInfoFileName(newSequenceId);	Path tempPath = new Path(tmpTableDir, filename);	if (fs.exists(tempPath)) {	
exists retrying up to times 

if (fs.exists(tempPath)) {	continue;	}	tableInfoDirPath = new Path(tableInfoDir, filename);	try {	writeTD(fs, tempPath, htd);	fs.mkdirs(tableInfoDirPath.getParent());	if (!fs.rename(tempPath, tableInfoDirPath)) {	throw new IOException("Failed rename of " + tempPath + " to " + tableInfoDirPath);	}	
wrote descriptor into 

continue;	}	tableInfoDirPath = new Path(tableInfoDir, filename);	try {	writeTD(fs, tempPath, htd);	fs.mkdirs(tableInfoDirPath.getParent());	if (!fs.rename(tempPath, tableInfoDirPath)) {	throw new IOException("Failed rename of " + tempPath + " to " + tableInfoDirPath);	}	} catch (IOException ioe) {	
failed write and or rename retrying 

}	tableInfoDirPath = new Path(tableInfoDir, filename);	try {	writeTD(fs, tempPath, htd);	fs.mkdirs(tableInfoDirPath.getParent());	if (!fs.rename(tempPath, tableInfoDirPath)) {	throw new IOException("Failed rename of " + tempPath + " to " + tableInfoDirPath);	}	} catch (IOException ioe) {	if (!FSUtils.deleteDirectory(fs, tempPath)) {	
failed cleanup of 

public boolean createTableDescriptorForTableDirectory(Path tableDir, TableDescriptor htd, boolean forceCreation) throws IOException {	if (fsreadonly) {	throw new NotImplementedException("Cannot create a table descriptor - in read only mode");	}	FileStatus status = getTableInfoPath(fs, tableDir);	if (status != null) {	LOG.debug("Current tableInfoPath = " + status.getPath());	if (!forceCreation) {	if (fs.exists(status.getPath()) && status.getLen() > 0) {	if (readTableDescriptor(fs, status).equals(htd)) {	
tableinfo already exists skipping creation 

========================= hbase sample_2255 =========================

public void testSeekingOnSample() throws IOException {	List<KeyValue> sampleKv = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);	List<DataBlockEncoder.EncodedSeeker> encodedSeekers = new ArrayList<>();	for (DataBlockEncoding encoding : DataBlockEncoding.values()) {	
encoding 

public void testSeekingOnSample() throws IOException {	List<KeyValue> sampleKv = generator.generateTestKeyValues(NUMBER_OF_KV, includesTags);	List<DataBlockEncoder.EncodedSeeker> encodedSeekers = new ArrayList<>();	for (DataBlockEncoding encoding : DataBlockEncoding.values()) {	DataBlockEncoder encoder = encoding.getEncoder();	if (encoder == null) {	continue;	}	
encoder 

DataBlockEncoder encoder = encoding.getEncoder();	if (encoder == null) {	continue;	}	ByteBuffer encodedBuffer = encodeKeyValues(encoding, sampleKv, getEncodingContext(Compression.Algorithm.NONE, encoding), this.useOffheapData);	HFileContext meta = new HFileContextBuilder() .withHBaseCheckSum(false) .withIncludesMvcc(includesMemstoreTS) .withIncludesTags(includesTags) .withCompression(Compression.Algorithm.NONE) .build();	DataBlockEncoder.EncodedSeeker seeker = encoder.createSeeker(CellComparatorImpl.COMPARATOR, encoder.newDataBlockDecodingContext(meta));	seeker.setCurrentBuffer(new SingleByteBuff(encodedBuffer));	encodedSeekers.add(seeker);	}	
testing it 

int keyValueId;	if (!seekBefore) {	keyValueId = randomizer.nextInt(sampleKv.size());	} else {	keyValueId = randomizer.nextInt(sampleKv.size() - 1) + 1;	}	KeyValue keyValue = sampleKv.get(keyValueId);	checkSeekingConsistency(encodedSeekers, seekBefore, keyValue);	}	}	
checking edge cases 

checkSeekingConsistency(encodedSeekers, seekBefore, keyValue);	}	}	checkSeekingConsistency(encodedSeekers, false, sampleKv.get(0));	for (boolean seekBefore : new boolean[] { false, true }) {	checkSeekingConsistency(encodedSeekers, seekBefore, sampleKv.get(sampleKv.size() - 1));	KeyValue midKv = sampleKv.get(sampleKv.size() / 2);	Cell lastMidKv =PrivateCellUtil.createLastOnRowCol(midKv);	checkSeekingConsistency(encodedSeekers, seekBefore, lastMidKv);	}	
Done 

========================= hbase sample_1479 =========================

private void clearBlockCache(BlockCache blockCache) throws InterruptedException {	if (blockCache instanceof LruBlockCache) {	((LruBlockCache) blockCache).clearCache();	} else {	for (int clearCount = 0; blockCache.getBlockCount() > 0; clearCount++) {	if (clearCount > 0) {	
clear block cache times blocks remaining 

((LruBlockCache) blockCache).clearCache();	} else {	for (int clearCount = 0; blockCache.getBlockCount() > 0; clearCount++) {	if (clearCount > 0) {	Thread.sleep(10);	}	for (CachedBlock block : Lists.newArrayList(blockCache)) {	BlockCacheKey key = new BlockCacheKey(block.getFilename(), block.getOffset());	for (int evictCount = 0; blockCache.evictBlock(key); evictCount++) {	if (evictCount > 1) {	
evict block in times maybe a bug here 

private void readStoreFile(boolean useTags) throws IOException {	HFile.Reader reader = HFile.createReader(fs, storeFilePath, cacheConf, true, conf);	
hfile information 

assertNotEquals(block.getBlockType(), BlockType.ENCODED_DATA);	assertEquals(block.getOnDiskSizeWithHeader(), fromCache.getOnDiskSizeWithHeader());	assertEquals(block.getOnDiskSizeWithoutHeader(), fromCache.getOnDiskSizeWithoutHeader());	assertEquals( block.getUncompressedSizeWithoutHeader(), fromCache.getUncompressedSizeWithoutHeader());	}	offset += block.getOnDiskSizeWithHeader();	BlockType bt = block.getBlockType();	Integer count = blockCountByType.get(bt);	blockCountByType.put(bt, (count == null ? 0 : count) + 1);	}	
block count by type 

}	}	p.setDurability(Durability.ASYNC_WAL);	region.put(p);	}	region.flush(true);	}	clearBlockCache(blockCache);	assertEquals(0, blockCache.getBlockCount());	region.compact(false);	
compactstores returned 

========================= hbase sample_1496 =========================

private void checkForClusterLevelSingleConf(String vlsClassName) {	assert this.vlsClazzName != null;	if (!this.vlsClazzName.equals(vlsClassName)) {	
trying to use table specific value for config hbase regionserver visibility label service class which is not supported will use the cluster level visibilitylabelservice class 

========================= hbase sample_2310 =========================

this.activeHandlerCount.incrementAndGet();	cr.run();	} catch (Throwable e) {	if (e instanceof Error) {	int failedCount = failedHandlerCount.incrementAndGet();	if (this.handlerFailureThreshhold >= 0 && failedCount > handlerCount * this.handlerFailureThreshhold) {	String message = "Number of failed RpcServer handler runs exceeded threshhold " + this.handlerFailureThreshhold + "; reason: " + StringUtils.stringifyException(e);	if (abortable != null) {	abortable.abort(message, e);	} else {	
error but can t abort because abortable is null 

if (e instanceof Error) {	int failedCount = failedHandlerCount.incrementAndGet();	if (this.handlerFailureThreshhold >= 0 && failedCount > handlerCount * this.handlerFailureThreshhold) {	String message = "Number of failed RpcServer handler runs exceeded threshhold " + this.handlerFailureThreshhold + "; reason: " + StringUtils.stringifyException(e);	if (abortable != null) {	abortable.abort(message, e);	} else {	throw e;	}	} else {	
handler errors 

if (this.handlerFailureThreshhold >= 0 && failedCount > handlerCount * this.handlerFailureThreshhold) {	String message = "Number of failed RpcServer handler runs exceeded threshhold " + this.handlerFailureThreshhold + "; reason: " + StringUtils.stringifyException(e);	if (abortable != null) {	abortable.abort(message, e);	} else {	throw e;	}	} else {	}	} else {	
handler exception 

========================= hbase sample_2890 =========================

public HealthReport checkHealth() {	HealthCheckerExitStatus status = HealthCheckerExitStatus.SUCCESS;	try {	shexec.execute();	} catch (ExitCodeException e) {	
caught exception exit code 

public HealthReport checkHealth() {	HealthCheckerExitStatus status = HealthCheckerExitStatus.SUCCESS;	try {	shexec.execute();	} catch (ExitCodeException e) {	status = HealthCheckerExitStatus.FAILED_WITH_EXIT_CODE;	} catch (IOException e) {	
caught exception 

========================= hbase sample_2193 =========================

try {	setupMobTable(table);	assertEquals(ROWKEYS.length, countRows());	admin.flush(table);	FileSystem fs = FileSystem.get(conf);	Path mobFile = getFlushedMobFile(fs, table);	admin.disableTable(table);	String corruptMobFile = createMobFileName(mobFile.getName());	Path corrupt = new Path(mobFile.getParent(), corruptMobFile);	TestHFile.truncateFile(fs, mobFile, corrupt);	
created corrupted mob file 

========================= hbase sample_1300 =========================

public void tearDown() throws IOException {	IOException ex = null;	try {	region.close();	} catch (IOException e) {	
caught exception 

public void tearDown() throws IOException {	IOException ex = null;	try {	region.close();	} catch (IOException e) {	ex = e;	}	try {	walFactory.close();	} catch (IOException e) {	
caught exception 

ex = e;	}	try {	walFactory.close();	} catch (IOException e) {	ex = e;	}	try {	fs.delete(new Path(DIR), true);	} catch (IOException e) {	
could not delete 

========================= hbase sample_1584 =========================

private List<String> convert(List<FileStatus> walFiles) {	List<String> result = new ArrayList<String>();	for (FileStatus fs : walFiles) {	
wal 

========================= hbase sample_549 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testCreateSameNamespaceTwice() throws Exception {	final NamespaceDescriptor nsd = NamespaceDescriptor.create("testCreateSameNamespaceTwice").build();	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	long procId1 = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId1);	ProcedureTestingUtility.assertProcNotFailed(procExec, procId1);	long procId2 = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId2);	Procedure<?> result = procExec.getResult(procId2);	assertTrue(result.isFailed());	
create namespace failed with exception 

public void testCreateSystemNamespace() throws Exception {	final NamespaceDescriptor nsd = UTIL.getAdmin().getNamespaceDescriptor(NamespaceDescriptor.SYSTEM_NAMESPACE.getName());	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	long procId = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
create namespace failed with exception 

public void testCreateNamespaceWithInvalidRegionCount() throws Exception {	final NamespaceDescriptor nsd = NamespaceDescriptor.create("testCreateNamespaceWithInvalidRegionCount").build();	final String nsKey = "hbase.namespace.quota.maxregions";	final String nsValue = "-1";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	nsd.setConfiguration(nsKey, nsValue);	long procId = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
create namespace failed with exception 

public void testCreateNamespaceWithInvalidTableCount() throws Exception {	final NamespaceDescriptor nsd = NamespaceDescriptor.create("testCreateNamespaceWithInvalidTableCount").build();	final String nsKey = "hbase.namespace.quota.maxtables";	final String nsValue = "-1";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	nsd.setConfiguration(nsKey, nsValue);	long procId = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
create namespace failed with exception 

final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	ProcedureTestingUtility.waitNoProcedureRunning(procExec);	ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);	long procId = procExec.submitProcedure( new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));	int numberOfSteps = 0;	MasterProcedureTestingUtility.testRollbackAndDoubleExecution(procExec, procId, numberOfSteps);	try {	NamespaceDescriptor nsDescriptor = UTIL.getAdmin().getNamespaceDescriptor(nsd.getName());	assertNull(nsDescriptor);	} catch (NamespaceNotFoundException nsnfe) {	
the namespace is not created 

========================= hbase sample_1838 =========================

public void enable() throws IOException {	try {	if (LOG.isTraceEnabled()) {	
starting disable of 

public void enable() throws IOException {	try {	if (LOG.isTraceEnabled()) {	}	getRegionServerServices().getClusterConnection().getAdmin().disableTable(getTableName());	if (LOG.isTraceEnabled()) {	
disable is complete for 

public void disable() throws IOException {	try {	if (LOG.isTraceEnabled()) {	
starting enable of 

public void disable() throws IOException {	try {	if (LOG.isTraceEnabled()) {	}	getRegionServerServices().getClusterConnection().getAdmin().enableTable(getTableName());	if (LOG.isTraceEnabled()) {	
enable is complete for 

========================= hbase sample_2347 =========================

assertEquals(0, zkListener.createdLock.availablePermits());	final ZooKeeper zkconn = ZooKeeperHelper. getConnectedZooKeeper(ZKConfig.getZKQuorumServersString(TEST_UTIL.getConfiguration()), 60000);	zkconn.create(node, dataOne, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);	zkListener.waitForCreation();	thread.join();	assertNotNull(localTracker.getData(false));	assertNotNull(localTracker.blockUntilAvailable());	assertTrue(Bytes.equals(localTracker.getData(false), dataOne));	assertTrue(thread.hasData);	assertTrue(Bytes.equals(thread.tracker.getData(false), dataOne));	
successfully got data one 

zkListener.waitForCreation();	thread.join();	assertNotNull(localTracker.getData(false));	assertNotNull(localTracker.blockUntilAvailable());	assertTrue(Bytes.equals(localTracker.getData(false), dataOne));	assertTrue(thread.hasData);	assertTrue(Bytes.equals(thread.tracker.getData(false), dataOne));	assertNotNull(secondTracker.getData(false));	assertNotNull(secondTracker.blockUntilAvailable());	assertTrue(Bytes.equals(secondTracker.getData(false), dataOne));	
successfully got data one with the second tracker 

assertNotNull(secondTracker.blockUntilAvailable());	assertTrue(Bytes.equals(secondTracker.getData(false), dataOne));	zkconn.delete(node, -1);	zkListener.waitForDeletion();	TestTracker threadTracker = thread.tracker;	thread = new WaitToGetDataThread(zk, node, threadTracker);	thread.start();	assertFalse(thread.hasData);	assertNull(secondTracker.getData(false));	assertNull(localTracker.getData(false));	
successfully made unavailable 

zkListener.waitForCreation();	thread.join();	assertNotNull(localTracker.getData(false));	assertNotNull(localTracker.blockUntilAvailable());	assertTrue(Bytes.equals(localTracker.getData(false), dataTwo));	assertNotNull(secondTracker.getData(false));	assertNotNull(secondTracker.blockUntilAvailable());	assertTrue(Bytes.equals(secondTracker.getData(false), dataTwo));	assertTrue(thread.hasData);	assertTrue(Bytes.equals(thread.tracker.getData(false), dataTwo));	
successfully got data two on all trackers and threads 

zkconn.setData(node, dataOne, -1);	zkListener.waitForDataChange();	assertNotNull(localTracker.getData(false));	assertNotNull(localTracker.blockUntilAvailable());	assertTrue(Bytes.equals(localTracker.getData(false), dataOne));	assertNotNull(secondTracker.getData(false));	assertNotNull(secondTracker.blockUntilAvailable());	assertTrue(Bytes.equals(secondTracker.getData(false), dataOne));	assertTrue(thread.hasData);	assertTrue(Bytes.equals(thread.tracker.getData(false), dataOne));	
successfully got data one following a data change on all trackers and threads 

public void run() {	
waiting for data to be available in waittogetdatathread 

public void run() {	try {	tracker.blockUntilAvailable();	} catch (InterruptedException e) {	e.printStackTrace();	}	
data now available in tracker from waittogetdatathread 

public void nodeDeleted(String path) {	if(path.equals(node)) {	
nodedeleted 

public void nodeCreated(String path) {	if(path.equals(node)) {	
nodecreated 

public void nodeDataChanged(String path) {	if(path.equals(node)) {	
nodedatachanged 

========================= hbase sample_725 =========================

public void run() {	
started 

}	final long txid = wal.append(hri, new WALKeyImpl(hri.getEncodedNameAsBytes(), TableName.META_TABLE_NAME, now, mvcc, scopes), edit, true);	Threads.sleep(ThreadLocalRandom.current().nextInt(5));	wal.sync(txid);	}	String msg = getName() + " finished";	if (isException()) this.log.info(msg, getException());	else this.log.info(msg);	} catch (Exception e) {	this.e = e;	
caught exception from appender 

========================= hbase sample_1642 =========================

visTags.clear();	nonVisTags.clear();	Byte serializationFormat = VisibilityUtils.extractAndPartitionTags(cell, visTags, nonVisTags);	if (!visTags.isEmpty()) {	try {	byte[] modifiedVisExpression = visibilityLabelsService .encodeVisibilityForReplication(visTags, serializationFormat);	if (modifiedVisExpression != null) {	nonVisTags .add(new ArrayBackedTag(TagType.STRING_VIS_TAG_TYPE, modifiedVisExpression));	}	} catch (Exception ioe) {	
exception while reading the visibility labels from the cell the replication would happen as per the existing format and not as string type for the cell 

========================= hbase sample_2296 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

public void testDeleteNonExistNamespace() throws Exception {	final String namespaceName = "testDeleteNonExistNamespace";	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	validateNamespaceNotExist(namespaceName);	long procId = procExec.submitProcedure( new DeleteNamespaceProcedure(procExec.getEnvironment(), namespaceName));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
delete namespace failed with exception 

public void testDeleteSystemNamespace() throws Exception {	final String namespaceName = NamespaceDescriptor.SYSTEM_NAMESPACE.getName();	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	long procId = procExec.submitProcedure( new DeleteNamespaceProcedure(procExec.getEnvironment(), namespaceName));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
delete namespace failed with exception 

public void testDeleteNonEmptyNamespace() throws Exception {	final String namespaceName = "testDeleteNonExistNamespace";	final TableName tableName = TableName.valueOf("testDeleteNonExistNamespace:" + name.getMethodName());	final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();	createNamespaceForTesting(namespaceName);	MasterProcedureTestingUtility.createTable(procExec, tableName, null, "f1");	long procId = procExec.submitProcedure( new DeleteNamespaceProcedure(procExec.getEnvironment(), namespaceName));	ProcedureTestingUtility.waitProcedure(procExec, procId);	Procedure<?> result = procExec.getResult(procId);	assertTrue(result.isFailed());	
delete namespace failed with exception 

========================= hbase sample_1843 =========================

}	boolean raw = Boolean.parseBoolean(conf.get(RAW_SCAN));	if (raw) {	s.setRaw(raw);	}	for (String columnFamily : conf.getTrimmedStrings(TableInputFormat.SCAN_COLUMN_FAMILY)) {	s.addFamily(Bytes.toBytes(columnFamily));	}	Filter exportFilter = getExportFilter(args);	if (exportFilter!= null) {	
setting scan filter for export 

labels = Arrays.asList(conf.getStrings(EXPORT_VISIBILITY_LABELS));	if (!labels.isEmpty()) {	s.setAuthorizations(new Authorizations(labels));	}	}	int batching = conf.getInt(EXPORT_BATCHING, -1);	if (batching != -1) {	try {	s.setBatch(batching);	} catch (IncompatibleFilterException e) {	
batching could not be set 

try {	s.setBatch(batching);	} catch (IncompatibleFilterException e) {	}	}	int caching = conf.getInt(EXPORT_CACHING, 100);	if (caching != -1) {	try {	s.setCaching(caching);	} catch (IncompatibleFilterException e) {	
caching could not be set 

========================= hbase sample_3487 =========================

private static byte[] getKeyFromConf(Configuration conf, String base64Key, String deprecatedKey) {	String encoded = conf.get(base64Key);	if (encoded != null) {	return Base64.decode(encoded);	}	String oldStyleVal = conf.get(deprecatedKey);	if (oldStyleVal == null) {	return null;	}	
using deprecated configuration please use static accessor methods instead 

========================= hbase sample_3468 =========================

public void testBasicRegionSizeReports() throws Exception {	final long bytesWritten = 5L * 1024L * 1024L;	final TableName tn = writeData(bytesWritten);	
data was written to hbase 

public void testBasicRegionSizeReports() throws Exception {	final long bytesWritten = 5L * 1024L * 1024L;	final TableName tn = writeData(bytesWritten);	final Admin admin = TEST_UTIL.getAdmin();	admin.flush(tn);	
data flushed to disk 

final long bytesWritten = 5L * 1024L * 1024L;	final TableName tn = writeData(bytesWritten);	final Admin admin = TEST_UTIL.getAdmin();	admin.flush(tn);	final List<RegionInfo> regions = TEST_UTIL.getAdmin().getRegions(tn);	HMaster master = cluster.getMaster();	MasterQuotaManager quotaManager = master.getMasterQuotaManager();	Map<RegionInfo,Long> regionSizes = quotaManager.snapshotRegionSizes();	int observedRegions = numRegionsForTable(tn, regionSizes);	while (observedRegions < regions.size()) {	
expecting more regions saw region sizes reported expected at least 

final List<RegionInfo> regions = TEST_UTIL.getAdmin().getRegions(tn);	HMaster master = cluster.getMaster();	MasterQuotaManager quotaManager = master.getMasterQuotaManager();	Map<RegionInfo,Long> regionSizes = quotaManager.snapshotRegionSizes();	int observedRegions = numRegionsForTable(tn, regionSizes);	while (observedRegions < regions.size()) {	Thread.sleep(1000);	regionSizes = quotaManager.snapshotRegionSizes();	observedRegions = numRegionsForTable(tn, regionSizes);	}	
observed region sizes by the hmaster 

========================= hbase sample_1455 =========================

try {	Future<Result> f = cs.poll(timeBeforeReplicas, TimeUnit.MICROSECONDS);	if (f != null) {	return f.get();	}	if (cConnection.getConnectionMetrics() != null) {	cConnection.getConnectionMetrics().incrHedgedReadOps();	}	} catch (ExecutionException e) {	if (LOG.isDebugEnabled()) {	
primary replica returns 

return f.get();	} catch (ExecutionException e) {	throwEnrichedException(e, retries);	} catch (CancellationException e) {	throw new InterruptedIOException();	} catch (InterruptedException e) {	throw new InterruptedIOException();	} finally {	cs.cancelAll();	}	
imposible arrive at an unreachable line 

========================= hbase sample_498 =========================

private void waitUntilStarted() {	try {	initialized.await();	} catch (InterruptedException e) {	
interrupted while waiting for start 

public void nodeCreated(String path) {	waitUntilStarted();	if (path.equals(aclZNode)) {	asyncProcessNodeUpdate(new Runnable() {	public void run() {	try {	List<ZKUtil.NodeAndData> nodes = ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);	refreshNodes(nodes);	} catch (KeeperException ke) {	
error reading data from zookeeper 

public void nodeDataChanged(final String path) {	waitUntilStarted();	if (aclZNode.equals(ZKUtil.getParent(path))) {	asyncProcessNodeUpdate(new Runnable() {	public void run() {	String entry = ZKUtil.getNodeName(path);	try {	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	refreshAuthManager(entry, data);	} catch (KeeperException ke) {	
error reading data from zookeeper for node 

if (aclZNode.equals(ZKUtil.getParent(path))) {	asyncProcessNodeUpdate(new Runnable() {	public void run() {	String entry = ZKUtil.getNodeName(path);	try {	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	refreshAuthManager(entry, data);	} catch (KeeperException ke) {	watcher.abort("ZooKeeper error getting data for node " + entry, ke);	} catch (IOException ioe) {	
error reading permissions writables 

public void nodeChildrenChanged(final String path) {	waitUntilStarted();	if (path.equals(aclZNode)) {	try {	final List<ZKUtil.NodeAndData> nodeList = ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);	if (childrenChangedFuture != null && !childrenChangedFuture.isDone()) {	boolean cancelled = childrenChangedFuture.cancel(true);	if (!cancelled) {	if (! childrenChangedFuture.isDone()) {	
could not cancel processing node children changed event please file a jira and attach logs if possible 

final List<ZKUtil.NodeAndData> nodeList = ZKUtil.getChildDataAndWatchForNewChildren(watcher, aclZNode);	if (childrenChangedFuture != null && !childrenChangedFuture.isDone()) {	boolean cancelled = childrenChangedFuture.cancel(true);	if (!cancelled) {	if (! childrenChangedFuture.isDone()) {	}	}	}	childrenChangedFuture = asyncProcessNodeUpdate(() -> refreshNodes(nodeList));	} catch (KeeperException ke) {	
error reading data from zookeeper for path 

private Future<?> asyncProcessNodeUpdate(Runnable runnable) {	if (!executor.isShutdown()) {	try {	return executor.submit(runnable);	} catch (RejectedExecutionException e) {	if (executor.isShutdown()) {	
aclznode changed after zkpermissionwatcher was shutdown 

for (ZKUtil.NodeAndData n : nodes) {	if (Thread.interrupted()) {	break;	}	if (n.isEmpty()) continue;	String path = n.getNode();	String entry = (ZKUtil.getNodeName(path));	try {	refreshAuthManager(entry, n.getData());	} catch (IOException ioe) {	
failed parsing permissions for table from zk 

private void refreshAuthManager(String entry, byte[] nodeData) throws IOException {	if (LOG.isDebugEnabled()) {	
updating permissions cache from node with data 

public void writeToZookeeper(byte[] entry, byte[] permsData) {	String entryName = Bytes.toString(entry);	String zkNode = ZNodePaths.joinZNode(watcher.znodePaths.baseZNode, ACL_NODE);	zkNode = ZNodePaths.joinZNode(zkNode, entryName);	try {	ZKUtil.createWithParents(watcher, zkNode);	ZKUtil.updateExistingNodeData(watcher, zkNode, permsData, -1);	} catch (KeeperException e) {	
failed updating permissions for entry 

public void deleteTableACLNode(final TableName tableName) {	String zkNode = ZNodePaths.joinZNode(watcher.znodePaths.baseZNode, ACL_NODE);	zkNode = ZNodePaths.joinZNode(zkNode, tableName.getNameAsString());	try {	ZKUtil.deleteNode(watcher, zkNode);	} catch (KeeperException.NoNodeException e) {	
no acl notify node of table 

public void deleteTableACLNode(final TableName tableName) {	String zkNode = ZNodePaths.joinZNode(watcher.znodePaths.baseZNode, ACL_NODE);	zkNode = ZNodePaths.joinZNode(zkNode, tableName.getNameAsString());	try {	ZKUtil.deleteNode(watcher, zkNode);	} catch (KeeperException.NoNodeException e) {	} catch (KeeperException e) {	
failed deleting acl node of table 

public void deleteNamespaceACLNode(final String namespace) {	String zkNode = ZNodePaths.joinZNode(watcher.znodePaths.baseZNode, ACL_NODE);	zkNode = ZNodePaths.joinZNode(zkNode, AccessControlLists.NAMESPACE_PREFIX + namespace);	try {	ZKUtil.deleteNode(watcher, zkNode);	} catch (KeeperException.NoNodeException e) {	
no acl notify node of namespace 

public void deleteNamespaceACLNode(final String namespace) {	String zkNode = ZNodePaths.joinZNode(watcher.znodePaths.baseZNode, ACL_NODE);	zkNode = ZNodePaths.joinZNode(zkNode, AccessControlLists.NAMESPACE_PREFIX + namespace);	try {	ZKUtil.deleteNode(watcher, zkNode);	} catch (KeeperException.NoNodeException e) {	} catch (KeeperException e) {	
failed deleting acl node of namespace 

========================= hbase sample_2279 =========================

final boolean isDebugEnabled = LOG.isDebugEnabled();	public boolean visit(final Result r) throws IOException {	if (r !=  null && !r.isEmpty()) {	long st = 0;	if (LOG.isTraceEnabled()) {	st = System.currentTimeMillis();	}	visitMetaEntry(visitor, r);	if (LOG.isTraceEnabled()) {	long et = System.currentTimeMillis();	
t load meta perf 

if (r !=  null && !r.isEmpty()) {	long st = 0;	if (LOG.isTraceEnabled()) {	st = System.currentTimeMillis();	}	visitMetaEntry(visitor, r);	if (LOG.isTraceEnabled()) {	long et = System.currentTimeMillis();	}	} else if (isDebugEnabled) {	
null result from meta ignoring but this is strange 

========================= hbase sample_2783 =========================

protected void postPeerModification(MasterProcedureEnv env) throws IOException, ReplicationException {	env.getReplicationPeerManager().removeAllQueuesAndHFileRefs(peerId);	
successfully removed peer 

========================= hbase sample_2853 =========================

private void assertContainsContent(final URL u, final String expected) throws IOException {	
testing has 

private void assertDoesNotContainContent(final URL u, final String expected) throws IOException {	
testing does not have 

========================= hbase sample_1286 =========================

public void perform() throws IOException {	final int versions =  random.nextInt(3) + 1;	
performing action changing versions on to 

public void perform() throws IOException {	final int versions =  random.nextInt(3) + 1;	modifyAllTableColumns(tableName, columnBuilder -> {	columnBuilder.setMinVersions(versions).setMaxVersions(versions);	});	
performing action just changed versions on 

========================= hbase sample_3311 =========================

public void testRollWALWALWriter() throws Exception {	setUpforLogRolling();	String className = this.getClass().getName();	StringBuilder v = new StringBuilder(className);	while (v.length() < 1000) {	v.append(className);	}	byte[] value = Bytes.toBytes(v.toString());	HRegionServer regionServer = startAndWriteData(tableName, value);	
after writing there are log files 

while (v.length() < 1000) {	v.append(className);	}	byte[] value = Bytes.toBytes(v.toString());	HRegionServer regionServer = startAndWriteData(tableName, value);	for (HRegion r : regionServer.getOnlineRegionsLocalContext()) {	r.flush(true);	}	admin.rollWALWriter(regionServer.getServerName()).join();	int count = AbstractFSWALProvider.getNumRolledLogFiles(regionServer.getWAL(null));	
after flushing all regions and rolling logs there are log files 

========================= hbase sample_2150 =========================

public void testMasterOpsWhileSplitting() throws Exception {	MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster m = cluster.getMaster();	try (Table ht = TEST_UTIL.createTable(TABLENAME, FAMILYNAME)) {	assertTrue(m.getTableStateManager().isTableState(TABLENAME, TableState.State.ENABLED));	TEST_UTIL.loadTable(ht, FAMILYNAME, false);	}	List<Pair<RegionInfo, ServerName>> tableRegions = MetaTableAccessor.getTableRegionsAndLocations( m.getConnection(), TABLENAME);	
regions after load 

MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();	HMaster m = cluster.getMaster();	try (Table ht = TEST_UTIL.createTable(TABLENAME, FAMILYNAME)) {	assertTrue(m.getTableStateManager().isTableState(TABLENAME, TableState.State.ENABLED));	TEST_UTIL.loadTable(ht, FAMILYNAME, false);	}	List<Pair<RegionInfo, ServerName>> tableRegions = MetaTableAccessor.getTableRegionsAndLocations( m.getConnection(), TABLENAME);	assertEquals(1, tableRegions.size());	assertArrayEquals(HConstants.EMPTY_START_ROW, tableRegions.get(0).getFirst().getStartKey());	assertArrayEquals(HConstants.EMPTY_END_ROW, tableRegions.get(0).getFirst().getEndKey());	
splitting table 

HMaster m = cluster.getMaster();	try (Table ht = TEST_UTIL.createTable(TABLENAME, FAMILYNAME)) {	assertTrue(m.getTableStateManager().isTableState(TABLENAME, TableState.State.ENABLED));	TEST_UTIL.loadTable(ht, FAMILYNAME, false);	}	List<Pair<RegionInfo, ServerName>> tableRegions = MetaTableAccessor.getTableRegionsAndLocations( m.getConnection(), TABLENAME);	assertEquals(1, tableRegions.size());	assertArrayEquals(HConstants.EMPTY_START_ROW, tableRegions.get(0).getFirst().getStartKey());	assertArrayEquals(HConstants.EMPTY_END_ROW, tableRegions.get(0).getFirst().getEndKey());	TEST_UTIL.getAdmin().split(TABLENAME);	
making sure we can call gettableregions while opening 

}	List<Pair<RegionInfo, ServerName>> tableRegions = MetaTableAccessor.getTableRegionsAndLocations( m.getConnection(), TABLENAME);	assertEquals(1, tableRegions.size());	assertArrayEquals(HConstants.EMPTY_START_ROW, tableRegions.get(0).getFirst().getStartKey());	assertArrayEquals(HConstants.EMPTY_END_ROW, tableRegions.get(0).getFirst().getEndKey());	TEST_UTIL.getAdmin().split(TABLENAME);	while (tableRegions.size() < 3) {	tableRegions = MetaTableAccessor.getTableRegionsAndLocations(m.getConnection(), TABLENAME, false);	Thread.sleep(100);	}	
regions 

List<Pair<RegionInfo, ServerName>> tableRegions = MetaTableAccessor.getTableRegionsAndLocations( m.getConnection(), TABLENAME);	assertEquals(1, tableRegions.size());	assertArrayEquals(HConstants.EMPTY_START_ROW, tableRegions.get(0).getFirst().getStartKey());	assertArrayEquals(HConstants.EMPTY_END_ROW, tableRegions.get(0).getFirst().getEndKey());	TEST_UTIL.getAdmin().split(TABLENAME);	while (tableRegions.size() < 3) {	tableRegions = MetaTableAccessor.getTableRegionsAndLocations(m.getConnection(), TABLENAME, false);	Thread.sleep(100);	}	assertEquals(3, tableRegions.size());	
making sure we can call gettableregionclosest while opening 

assertEquals(1, tableRegions.size());	assertArrayEquals(HConstants.EMPTY_START_ROW, tableRegions.get(0).getFirst().getStartKey());	assertArrayEquals(HConstants.EMPTY_END_ROW, tableRegions.get(0).getFirst().getEndKey());	TEST_UTIL.getAdmin().split(TABLENAME);	while (tableRegions.size() < 3) {	tableRegions = MetaTableAccessor.getTableRegionsAndLocations(m.getConnection(), TABLENAME, false);	Thread.sleep(100);	}	assertEquals(3, tableRegions.size());	Pair<RegionInfo, ServerName> pair = m.getTableRegionForRow(TABLENAME, Bytes.toBytes("cde"));	
result is 

========================= hbase sample_1793 =========================

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	
initializing checking cluster has servers 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	util.initializeCluster(getMinServerCount());	
done initializing checking cluster 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	
running ingest 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	
cluster size 

protected void runIngestTest(long defaultRunTime, long keysPerServerPerIter, int colsPerKey, int recordSize, int writeThreads, int readThreads) throws Exception {	long start = System.currentTimeMillis();	String runtimeKey = String.format(RUN_TIME_KEY, this.getClass().getSimpleName());	long runtime = util.getConfiguration().getLong(runtimeKey, defaultRunTime);	long startKey = 0;	long numKeys = getNumKeys(keysPerServerPerIter);	while (System.currentTimeMillis() - start < 0.9 * runtime) {	
intended run time min left min 

}	ret = loadTool.run(getArgsForLoadTestTool("-update", String.format("60:%d:1", writeThreads), startKey, numKeys));	if (0 != ret) {	String errorMsg = "Update failed with error code " + ret;	LOG.error(errorMsg);	Assert.fail(errorMsg);	}	ret = loadTool.run(getArgsForLoadTestTool("-read", String.format("100:%d", readThreads) , startKey, numKeys));	if (0 != ret) {	String errorMsg = "Verification failed with error code " + ret;	
rerunning verification after minute for debugging 

String errorMsg = "Update failed with error code " + ret;	LOG.error(errorMsg);	Assert.fail(errorMsg);	}	ret = loadTool.run(getArgsForLoadTestTool("-read", String.format("100:%d", readThreads) , startKey, numKeys));	if (0 != ret) {	String errorMsg = "Verification failed with error code " + ret;	Threads.sleep(1000 * 60);	ret = loadTool.run(getArgsForLoadTestTool("-read", String.format("100:%d", readThreads) , startKey, numKeys));	if (0 != ret) {	
rerun of verification failed with error code 

========================= hbase sample_3254 =========================

conf.set(HConstants.HBASE_MASTER_LOGCLEANER_PLUGINS, plugins + "," + cleanerClass);	}	String classes = conf.get(ProcedureManagerHost.MASTER_PROCEDURE_CONF_KEY);	String masterProcedureClass = LogRollMasterProcedureManager.class.getName();	if (classes == null) {	conf.set(ProcedureManagerHost.MASTER_PROCEDURE_CONF_KEY, masterProcedureClass);	} else if (!classes.contains(masterProcedureClass)) {	conf.set(ProcedureManagerHost.MASTER_PROCEDURE_CONF_KEY, classes + "," + masterProcedureClass);	}	if (LOG.isDebugEnabled()) {	
added log cleaner added master procedure manager 

String regionProcedureClass = LogRollRegionServerProcedureManager.class.getName();	if (classes == null) {	conf.set(ProcedureManagerHost.REGIONSERVER_PROCEDURE_CONF_KEY, regionProcedureClass);	} else if (!classes.contains(regionProcedureClass)) {	conf.set(ProcedureManagerHost.REGIONSERVER_PROCEDURE_CONF_KEY, classes + "," + regionProcedureClass);	}	String coproc = conf.get(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY);	String regionObserverClass = BackupObserver.class.getName();	conf.set(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY, (coproc == null ? "" : coproc + ",") + regionObserverClass);	if (LOG.isDebugEnabled()) {	
added region procedure manager added region observer 

throw new BackupException("No table exists for full backup of all tables.");	} else {	tableList = new ArrayList<>();	for (HTableDescriptor hTableDescriptor : htds) {	TableName tn = hTableDescriptor.getTableName();	if (tn.equals(BackupSystemTable.getTableName(conf))) {	continue;	}	tableList.add(hTableDescriptor.getTableName());	}	
full backup all the tables available in the cluster 

public void initialize() throws IOException {	String ongoingBackupId = this.getOngoingBackupId();	if (ongoingBackupId != null) {	
there is a ongoing backup can not launch new backup until no ongoing backup remains 

public ArrayList<BackupImage> getAncestors(BackupInfo backupInfo) throws IOException, BackupException {	
getting the direct ancestors of the current backup 

public ArrayList<BackupImage> getAncestors(BackupInfo backupInfo) throws IOException, BackupException {	ArrayList<BackupImage> ancestors = new ArrayList<BackupImage>();	if (backupInfo.getType() == BackupType.FULL) {	
current backup is a full backup no direct ancestor for it 

ArrayList<BackupInfo> allHistoryList = getBackupHistory(true);	for (BackupInfo backup : allHistoryList) {	BackupImage.Builder builder = BackupImage.newBuilder();	BackupImage image = builder.withBackupId(backup.getBackupId()).withType(backup.getType()) .withRootDir(backup.getBackupRootDir()).withTableList(backup.getTableNames()) .withStartTime(backup.getStartTs()).withCompleteTime(backup.getCompleteTs()).build();	if (backup.getType().equals(BackupType.FULL)) {	if (!BackupManifest.canCoverImage(ancestors, image)) {	ancestors.add(image);	}	} else {	if (BackupManifest.canCoverImage(ancestors, image)) {	
met the backup boundary of the current table set 

if (!BackupManifest.canCoverImage(ancestors, image)) {	ancestors.add(image);	}	} else {	if (BackupManifest.canCoverImage(ancestors, image)) {	for (BackupImage image1 : ancestors) {	LOG.debug("  BackupID=" + image1.getBackupId() + ", BackupDir=" + image1.getRootDir());	}	} else {	Path logBackupPath = HBackupFileSystem.getBackupPath(backup.getBackupRootDir(), backup.getBackupId());	
current backup has an incremental backup ancestor touching its image manifest in to construct the dependency 

}	} else {	Path logBackupPath = HBackupFileSystem.getBackupPath(backup.getBackupRootDir(), backup.getBackupId());	BackupManifest lastIncrImgManifest = new BackupManifest(conf, logBackupPath);	BackupImage lastIncrImage = lastIncrImgManifest.getBackupImage();	ancestors.add(lastIncrImage);	LOG.debug("Last dependent incremental backup image: " + "{BackupID=" + lastIncrImage.getBackupId() + "," + "BackupDir=" + lastIncrImage.getRootDir() + "}");	}	}	}	
got ancestors for the current backup 

========================= hbase sample_565 =========================

public synchronized void close() throws IOException {	if (this.output == null) {	return;	}	try {	writeWALTrailer();	output.close();	} catch (Exception e) {	
normal close failed try recover 

========================= hbase sample_2557 =========================

public void moveServers(RpcController controller, MoveServersRequest request, RpcCallback<MoveServersResponse> done) {	MoveServersResponse.Builder builder = MoveServersResponse.newBuilder();	Set<Address> hostPorts = Sets.newHashSet();	for (HBaseProtos.ServerName el : request.getServersList()) {	hostPorts.add(Address.fromParts(el.getHostName(), el.getPort()));	}	
move servers to rsgroup 

public void moveTables(RpcController controller, MoveTablesRequest request, RpcCallback<MoveTablesResponse> done) {	MoveTablesResponse.Builder builder = MoveTablesResponse.newBuilder();	Set<TableName> tables = new HashSet<>(request.getTableNameList().size());	for (HBaseProtos.TableName tableName : request.getTableNameList()) {	tables.add(ProtobufUtil.toTableName(tableName));	}	
move tables to rsgroup 

public void addRSGroup(RpcController controller, AddRSGroupRequest request, RpcCallback<AddRSGroupResponse> done) {	AddRSGroupResponse.Builder builder = AddRSGroupResponse.newBuilder();	
add rsgroup 

public void removeRSGroup(RpcController controller, RemoveRSGroupRequest request, RpcCallback<RemoveRSGroupResponse> done) {	RemoveRSGroupResponse.Builder builder = RemoveRSGroupResponse.newBuilder();	
remove rsgroup 

public void listRSGroupInfos(RpcController controller, ListRSGroupInfosRequest request, RpcCallback<ListRSGroupInfosResponse> done) {	ListRSGroupInfosResponse.Builder builder = ListRSGroupInfosResponse.newBuilder();	
list rsgroup 

public void moveServersAndTables(RpcController controller, MoveServersAndTablesRequest request, RpcCallback<MoveServersAndTablesResponse> done) {	MoveServersAndTablesResponse.Builder builder = MoveServersAndTablesResponse.newBuilder();	Set<Address> hostPorts = Sets.newHashSet();	for (HBaseProtos.ServerName el : request.getServersList()) {	hostPorts.add(Address.fromParts(el.getHostName(), el.getPort()));	}	Set<TableName> tables = new HashSet<>(request.getTableNameList().size());	for (HBaseProtos.TableName tableName : request.getTableNameList()) {	tables.add(ProtobufUtil.toTableName(tableName));	}	
move servers and tables to rsgroup 

public void removeServers(RpcController controller, RemoveServersRequest request, RpcCallback<RemoveServersResponse> done) {	RemoveServersResponse.Builder builder = RemoveServersResponse.newBuilder();	Set<Address> servers = Sets.newHashSet();	for (HBaseProtos.ServerName el : request.getServersList()) {	servers.add(Address.fromParts(el.getHostName(), el.getPort()));	}	
remove decommissioned servers from rsgroup 

public void postDeleteTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableName tableName) throws IOException {	try {	RSGroupInfo group = groupAdminServer.getRSGroupInfoOfTable(tableName);	if (group != null) {	
removing deleted table s from rsgroup s 

public void postDeleteTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableName tableName) throws IOException {	try {	RSGroupInfo group = groupAdminServer.getRSGroupInfoOfTable(tableName);	if (group != null) {	groupAdminServer.moveTables(Sets.newHashSet(tableName), null);	}	} catch (IOException ex) {	
failed to perform rsgroup information cleanup for table 

========================= hbase sample_3346 =========================

public void recoverFileLease(final FileSystem fs, final Path path) throws IOException {	final Configuration conf = master.getConfiguration();	final FSUtils fsUtils = FSUtils.getInstance(fs, conf);	fsUtils.recoverFileLease(fs, path, conf, new CancelableProgressable() {	public boolean progress() {	
recover procedure store log lease 

========================= hbase sample_2804 =========================

public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {	if (filterConfig == null) return;	String uri = ((HttpServletRequest)request).getRequestURI();	
filtering 

static void access(String urlstring) throws IOException {	
access 

========================= hbase sample_3203 =========================

boolean fakeZNodeDelete = false;	for (int i = 0; i < 20; i++) {	try {	BlockingRpcChannel channel = rpcClient.createBlockingRpcChannel(sm, User.getCurrent(), 0);	MasterProtos.MasterService.BlockingInterface stub = MasterProtos.MasterService.newBlockingStub(channel);	assertTrue(stub.isMasterRunning(null, IsMasterRunningRequest.getDefaultInstance()) .getIsMasterRunning());	return;	} catch (ServiceException ex) {	IOException ie = ProtobufUtil.handleRemoteException(ex);	assertTrue(ie.getMessage().startsWith( "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet"));	
expected exception 

========================= hbase sample_1802 =========================

public List<Path> compact(final CompactionRequestImpl request, final List<Long> lowerBoundaries, ThroughputController throughputController, User user) throws IOException {	if (LOG.isDebugEnabled()) {	
executing compaction with windows lower boundaries 

========================= hbase sample_2687 =========================

bPaddedAdditional[j] = bPadded[j];	}	aPaddedAdditional[aPadded.length] = 0;	bPaddedAdditional[bPadded.length] = 0;	return iterateOnSplits(aPaddedAdditional, bPaddedAdditional, inclusive,  num);	}	final BigInteger intervalBI;	try {	intervalBI = diffBI.divide(splitsBI);	} catch(Exception e) {	
exception caught during division 

========================= hbase sample_965 =========================

public Response get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

========================= hbase sample_3079 =========================

public void testRegionServerSessionExpired() throws Exception {	
starting 

public void testMasterSessionExpired() throws Exception {	
starting 

public void testMasterZKSessionRecoveryFailure() throws Exception {	
starting 

private void testSanity(final String testName) throws Exception {	String tableName = testName + "_" + System.currentTimeMillis();	TableDescriptor desc = TableDescriptorBuilder.newBuilder(TableName.valueOf(tableName)) .addColumnFamily(ColumnFamilyDescriptorBuilder.of("fam")).build();	
creating table 

TableDescriptor desc = TableDescriptorBuilder.newBuilder(TableName.valueOf(tableName)) .addColumnFamily(ColumnFamilyDescriptorBuilder.of("fam")).build();	Admin admin = TEST_UTIL.getAdmin();	try {	admin.createTable(desc);	} finally {	admin.close();	}	Table table = TEST_UTIL.getConnection().getTable(desc.getTableName());	Put put = new Put(Bytes.toBytes("testrow"));	put.addColumn(Bytes.toBytes("fam"), Bytes.toBytes("col"), Bytes.toBytes("testdata"));	
putting table 

========================= hbase sample_1414 =========================

public static void await() throws InterruptedException {	if (useLatch.get()) {	
waiting on latch 

public static void await() throws InterruptedException {	if (useLatch.get()) {	synchronized(latch) {	latch.wait();	}	
waited on latch now proceeding 

protected void replicateEntries(BlockingInterface rrs, final List<Entry> entries, String replicationClusterId, Path baseNamespaceDir, Path hfileArchiveDir) throws IOException {	try {	long size = 0;	for (Entry e: entries) {	size += e.getKey().estimatedSerializedSizeOf();	size += e.getEdit().estimatedSerializedSizeOf();	}	
replicating batch of entries with total size bytes to 

long size = 0;	for (Entry e: entries) {	size += e.getKey().estimatedSerializedSizeOf();	size += e.getEdit().estimatedSerializedSizeOf();	}	super.replicateEntries(rrs, entries, replicationClusterId, baseNamespaceDir, hfileArchiveDir);	entriesCount += entries.size();	int count = batchCount.incrementAndGet();	LOG.info("Completed replicating batch " + System.identityHashCode(entries) + " count=" + count);	} catch (IOException e) {	
failed to replicate batch 

public boolean replicate(ReplicateContext replicateContext) {	try {	await();	} catch (InterruptedException e) {	
interrupted waiting for latch 

========================= hbase sample_1947 =========================

public Token<AuthenticationTokenIdentifier> selectToken(Text serviceName, Collection<Token<? extends TokenIdentifier>> tokens) {	if (serviceName != null) {	for (Token ident : tokens) {	if (serviceName.equals(ident.getService()) && AuthenticationTokenIdentifier.AUTH_TOKEN_TYPE.equals(ident.getKind())) {	if (LOG.isDebugEnabled()) {	
returning token 

public Token<AuthenticationTokenIdentifier> selectToken(Text serviceName, Collection<Token<? extends TokenIdentifier>> tokens) {	if (serviceName != null) {	for (Token ident : tokens) {	if (serviceName.equals(ident.getService()) && AuthenticationTokenIdentifier.AUTH_TOKEN_TYPE.equals(ident.getKind())) {	if (LOG.isDebugEnabled()) {	}	return (Token<AuthenticationTokenIdentifier>)ident;	}	}	}	
no matching token found 

========================= hbase sample_123 =========================

protected Flow executeFromState(MasterProcedureEnv env, MasterProcedureProtos.RecoverMetaState state) throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {	prepare(env);	if (!isRunRequired()) {	
meta already initialized skipping run 

protected Flow executeFromState(MasterProcedureEnv env, MasterProcedureProtos.RecoverMetaState state) throws ProcedureSuspendedException, ProcedureYieldException, InterruptedException {	prepare(env);	if (!isRunRequired()) {	return Flow.NO_MORE_STATE;	}	try {	switch (state) {	
start 

private void handleRIT(MasterProcedureEnv env, RegionInfo ri, ServerName crashedServerName) {	AssignmentManager am = env.getAssignmentManager();	RegionTransitionProcedure rtp = am.getRegionStates().getRegionTransitionProcedure(ri);	if (rtp == null) {	return;	}	ServerName rtpServerName = rtp.getServer(env);	if (rtpServerName == null) {	
rit with servername null 

========================= hbase sample_2812 =========================

public void setUp() throws Exception {	createNamespace(TEST_UTIL, NamespaceDescriptor.create(namespace).build());	try (Table table = createTable(TEST_UTIL, tableName, new byte[][] { TEST_FAMILY, TEST_FAMILY_2 })) {	TEST_UTIL.waitTableEnabled(tableName);	table.put(Arrays.asList(new Put(TEST_ROW).addColumn(TEST_FAMILY, Q1, value1), new Put(TEST_ROW_2).addColumn(TEST_FAMILY, Q2, value2), new Put(TEST_ROW_3).addColumn(TEST_FAMILY_2, Q1, value1)));	}	assertEquals(1, AccessControlLists.getTablePermissions(conf, tableName).size());	try {	assertEquals(1, AccessControlClient.getUserPermissions(systemUserConnection, tableName.toString()).size());	} catch (Throwable e) {	
error during call of accesscontrolclient getuserpermissions 

public void tearDown() throws Exception {	try {	deleteTable(TEST_UTIL, tableName);	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1382 =========================

int sleepMultiplier = 1;	while (isReaderRunning()) {	try (WALEntryStream entryStream = new WALEntryStream(logQueue, fs, conf, currentPosition, source.getWALFileLengthProvider(), source.getServerWALsBelongTo(), source.getSourceMetrics())) {	while (isReaderRunning()) {	if (!checkQuota()) {	continue;	}	WALEntryBatch batch = readWALEntries(entryStream);	if (batch != null && (!batch.getLastSeqIds().isEmpty() || batch.getNbEntries() > 0)) {	if (LOG.isTraceEnabled()) {	
read s wal entries eligible for replication 

entryBatchQueue.put(batch);	sleepMultiplier = 1;	} else {	handleEmptyWALEntryBatch(batch, entryStream.getCurrentPath());	}	currentPosition = entryStream.getPosition();	entryStream.reset();	}	} catch (IOException e) {	if (sleepMultiplier < maxRetriesMultiplier) {	
failed to read stream of replication entries 

} else {	handleEmptyWALEntryBatch(batch, entryStream.getCurrentPath());	}	currentPosition = entryStream.getPosition();	entryStream.reset();	}	} catch (IOException e) {	if (sleepMultiplier < maxRetriesMultiplier) {	sleepMultiplier++;	} else {	
failed to read stream of replication entries 

entryStream.reset();	}	} catch (IOException e) {	if (sleepMultiplier < maxRetriesMultiplier) {	sleepMultiplier++;	} else {	handleEofException(e);	}	Threads.sleep(sleepForRetries * sleepMultiplier);	} catch (InterruptedException e) {	
interrupted while sleeping between wal reads 

protected void handleEmptyWALEntryBatch(WALEntryBatch batch, Path currentPath) throws InterruptedException {	
didn t read any new entries from wal 

private void handleEofException(IOException e) {	if ((e instanceof EOFException || e.getCause() instanceof EOFException) && logQueue.size() > 1 && this.eofAutoRecovery) {	try {	if (fs.getFileStatus(logQueue.peek()).getLen() == 0) {	
forcing removal of length log in queue 

private void handleEofException(IOException e) {	if ((e instanceof EOFException || e.getCause() instanceof EOFException) && logQueue.size() > 1 && this.eofAutoRecovery) {	try {	if (fs.getFileStatus(logQueue.peek()).getLen() == 0) {	logQueue.remove();	currentPosition = 0;	}	} catch (IOException ioe) {	
couldn t get file length information about log 

for (int i = 0; i < totalCells; i++) {	if (CellUtil.matchingQualifier(cells.get(i), WALEdit.BULK_LOAD)) {	try {	BulkLoadDescriptor bld = WALEdit.getBulkLoadDescriptor(cells.get(i));	List<StoreDescriptor> stores = bld.getStoresList();	int totalStores = stores.size();	for (int j = 0; j < totalStores; j++) {	totalHFileEntries += stores.get(j).getStoreFileList().size();	}	} catch (IOException e) {	
failed to deserialize bulk load entry from wal edit then its hfiles count will not be added into metric 

for (int i = 0; i < totalCells; i++) {	if (CellUtil.matchingQualifier(cells.get(i), WALEdit.BULK_LOAD)) {	try {	BulkLoadDescriptor bld = WALEdit.getBulkLoadDescriptor(cells.get(i));	List<StoreDescriptor> stores = bld.getStoresList();	int totalStores = stores.size();	for (int j = 0; j < totalStores; j++) {	totalStoreFilesSize += stores.get(j).getStoreFileSizeBytes();	}	} catch (IOException e) {	
failed to deserialize bulk load entry from wal edit size of hfiles part of cell will not be considered in replication request size calculation 

========================= hbase sample_2957 =========================

for (int[] mockCluster : clusterStateMocks) {	Map<ServerName, List<RegionInfo>> clusterServers = mockClusterServers(mockCluster, 50);	List<ServerAndLoad> clusterList = convertToList(clusterServers);	clusterLoad.put(TableName.valueOf(name.getMethodName()), clusterServers);	HashMap<TableName, TreeMap<ServerName, List<RegionInfo>>> result = mockClusterServersWithTables(clusterServers);	loadBalancer.setClusterLoad(clusterLoad);	List<RegionPlan> clusterplans = new ArrayList<>();	List<Pair<TableName, Integer>> regionAmountList = new ArrayList<>();	for(TreeMap<ServerName, List<RegionInfo>> servers : result.values()){	List<ServerAndLoad> list = convertToList(servers);	
mock cluster 

clusterLoad.put(TableName.valueOf(name.getMethodName()), clusterServers);	HashMap<TableName, TreeMap<ServerName, List<RegionInfo>>> result = mockClusterServersWithTables(clusterServers);	loadBalancer.setClusterLoad(clusterLoad);	List<RegionPlan> clusterplans = new ArrayList<>();	List<Pair<TableName, Integer>> regionAmountList = new ArrayList<>();	for(TreeMap<ServerName, List<RegionInfo>> servers : result.values()){	List<ServerAndLoad> list = convertToList(servers);	List<RegionPlan> partialplans = loadBalancer.balanceCluster(servers);	if(partialplans != null) clusterplans.addAll(partialplans);	List<ServerAndLoad> balancedClusterPerTable = reconcile(list, partialplans, servers);	
mock balance 

Map<TableName, Map<ServerName, List<RegionInfo>>> clusterLoad = new TreeMap<>();	Map<ServerName, List<RegionInfo>> clusterServers = mockUniformClusterServers(mockUniformCluster);	List<ServerAndLoad> clusterList = convertToList(clusterServers);	clusterLoad.put(TableName.valueOf(name.getMethodName()), clusterServers);	HashMap<TableName, TreeMap<ServerName, List<RegionInfo>>> result1 = mockClusterServersWithTables(clusterServers);	loadBalancer.setClusterLoad(clusterLoad);	List<RegionPlan> clusterplans1 = new ArrayList<RegionPlan>();	List<Pair<TableName, Integer>> regionAmountList = new ArrayList<Pair<TableName, Integer>>();	for(TreeMap<ServerName, List<RegionInfo>> servers : result1.values()){	List<ServerAndLoad> list = convertToList(servers);	
mock cluster 

clusterLoad.put(TableName.valueOf(name.getMethodName()), clusterServers);	HashMap<TableName, TreeMap<ServerName, List<RegionInfo>>> result1 = mockClusterServersWithTables(clusterServers);	loadBalancer.setClusterLoad(clusterLoad);	List<RegionPlan> clusterplans1 = new ArrayList<RegionPlan>();	List<Pair<TableName, Integer>> regionAmountList = new ArrayList<Pair<TableName, Integer>>();	for(TreeMap<ServerName, List<RegionInfo>> servers : result1.values()){	List<ServerAndLoad> list = convertToList(servers);	List<RegionPlan> partialplans = loadBalancer.balanceCluster(servers);	if(partialplans != null) clusterplans1.addAll(partialplans);	List<ServerAndLoad> balancedClusterPerTable = reconcile(list, partialplans, servers);	
mock balance 

========================= hbase sample_1855 =========================

break;	}	Path coprocPath = new Path(coprocPathStr);	String coprocessorClass = matcher.group(2).trim();	boolean foundPathMatch = false;	for (String pathStr : paths) {	Path wlPath = new Path(pathStr);	try {	foundPathMatch = validatePath(coprocPath, wlPath, conf);	if (foundPathMatch == true) {	
coprocessor s found in directory s 

String coprocessorClass = matcher.group(2).trim();	boolean foundPathMatch = false;	for (String pathStr : paths) {	Path wlPath = new Path(pathStr);	try {	foundPathMatch = validatePath(coprocPath, wlPath, conf);	if (foundPathMatch == true) {	break;	}	} catch (IOException e) {	
failed to validate white list path s for coprocessor path s 

========================= hbase sample_2280 =========================

private void undoDeleteFromNSTable(final MasterProcedureEnv env) {	try {	if (nsDescriptor != null) {	CreateNamespaceProcedure.insertIntoNSTable(env, nsDescriptor);	}	} catch (Exception e) {	
rollback of deletefromnstable throws exception 

private void undoRemoveFromZKNamespaceManager(final MasterProcedureEnv env) {	try {	if (nsDescriptor != null) {	CreateNamespaceProcedure.updateZKNamespaceManager(env, nsDescriptor);	}	} catch (Exception e) {	
rollback of removefromzknamespacemanager throws exception 

try {	for(FileStatus status : fs.listStatus(p)) {	if (!HConstants.HBASE_NON_TABLE_DIRS.contains(status.getPath().getName())) {	throw new IOException("Namespace directory contains table dir: " + status.getPath());	}	}	if (!fs.delete(FSUtils.getNamespaceDir(mfs.getRootDir(), namespaceName), true)) {	throw new IOException("Failed to remove namespace: " + namespaceName);	}	} catch (FileNotFoundException e) {	
deletedirectory throws exception 

private void rollbackDeleteDirectory(final MasterProcedureEnv env) throws IOException {	try {	CreateNamespaceProcedure.createDirectory(env, nsDescriptor);	} catch (Exception e) {	
rollback of deletedirectory throws exception 

private void rollbacRemoveNamespaceQuota(final MasterProcedureEnv env) throws IOException {	try {	CreateNamespaceProcedure.setNamespaceQuota(env, nsDescriptor);	} catch (Exception e) {	
rollback of removenamespacequota throws exception 

========================= hbase sample_2795 =========================

TableDescriptor tableDescriptor = admin.getDescriptor(tableName);	ColumnFamilyDescriptor[] columnDescriptors = tableDescriptor.getColumnFamilies();	if (columnDescriptors.length <= (protectedColumns == null ? 1 : protectedColumns.size())) {	return;	}	int index = random.nextInt(columnDescriptors.length);	while(protectedColumns != null && protectedColumns.contains(columnDescriptors[index].getNameAsString())) {	index = random.nextInt(columnDescriptors.length);	}	byte[] colDescName = columnDescriptors[index].getName();	
performing action removing from 

========================= hbase sample_3307 =========================

private void startWalkers(int numWalkers, Configuration conf, Context context) {	
starting concurrent walkers 

public void run(long startKeyIn, long maxQueriesIn) throws IOException {	long maxQueries = maxQueriesIn > 0 ? maxQueriesIn : Long.MAX_VALUE;	byte[] startKey = Bytes.toBytes(startKeyIn);	Connection connection = ConnectionFactory.createConnection(getConf());	Table table = connection.getTable(getTableName(getConf()));	long numQueries = 0;	CINode node = findStartNode(table, startKey);	if (node == null) {	
start node not found 

if (node == null) {	throw new IOException("Start node not found: " + startKeyIn);	}	while (numQueries < maxQueries) {	numQueries++;	byte[] prev = node.prev;	long t1 = System.currentTimeMillis();	node = getNode(prev, table, node);	long t2 = System.currentTimeMillis();	if (node == null) {	
concurrentwalker found undefined node 

}	while (numQueries < maxQueries) {	numQueries++;	byte[] prev = node.prev;	long t1 = System.currentTimeMillis();	node = getNode(prev, table, node);	long t2 = System.currentTimeMillis();	if (node == null) {	context.getCounter(Counts.UNDEFINED).increment(1l);	} else if (node.prev.length == NO_KEY.length) {	
concurrentwalker found terminating node 

hcd.setMobThreshold(4);	}	}	if (conf.getBoolean(HBaseTestingUtility.PRESPLIT_TEST_TABLE_KEY, HBaseTestingUtility.PRESPLIT_TEST_TABLE)) {	int numberOfServers = admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().size();	if (numberOfServers == 0) {	throw new IllegalStateException("No live regionservers");	}	int regionsPerServer = conf.getInt(HBaseTestingUtility.REGIONS_PER_SERVER_KEY, HBaseTestingUtility.DEFAULT_REGIONS_PER_SERVER);	int totalNumberOfRegions = numberOfServers * regionsPerServer;	
number of live regionservers pre splitting table into regions default regions per server 

}	int regionsPerServer = conf.getInt(HBaseTestingUtility.REGIONS_PER_SERVER_KEY, HBaseTestingUtility.DEFAULT_REGIONS_PER_SERVER);	int totalNumberOfRegions = numberOfServers * regionsPerServer;	byte[][] splits = new RegionSplitter.UniformSplit().split(totalNumberOfRegions);	admin.createTable(htd, splits);	} else {	admin.createTable(htd);	}	}	} catch (MasterNotRunningException e) {	
master not running 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	
counters object was null generator verification cannot be performed this is commonly a result of insufficient yarn configuration 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	return false;	}	if (counters.findCounter(Counts.TERMINATING).getValue() > 0 || counters.findCounter(Counts.UNDEFINED).getValue() > 0 || counters.findCounter(Counts.IOEXCEPTION).getValue() > 0) {	
concurrent walker failed to verify during generation phase 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	return false;	}	if (counters.findCounter(Counts.TERMINATING).getValue() > 0 || counters.findCounter(Counts.UNDEFINED).getValue() > 0 || counters.findCounter(Counts.IOEXCEPTION).getValue() > 0) {	
terminating nodes 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	return false;	}	if (counters.findCounter(Counts.TERMINATING).getValue() > 0 || counters.findCounter(Counts.UNDEFINED).getValue() > 0 || counters.findCounter(Counts.IOEXCEPTION).getValue() > 0) {	
undefined nodes 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	return false;	}	if (counters.findCounter(Counts.TERMINATING).getValue() > 0 || counters.findCounter(Counts.UNDEFINED).getValue() > 0 || counters.findCounter(Counts.IOEXCEPTION).getValue() > 0) {	
ioexception nodes 

public boolean verify() {	try {	Counters counters = job.getCounters();	if (counters == null) {	return false;	}	if (counters.findCounter(Counts.TERMINATING).getValue() > 0 || counters.findCounter(Counts.UNDEFINED).getValue() > 0 || counters.findCounter(Counts.IOEXCEPTION).getValue() > 0) {	return false;	}	} catch (IOException e) {	
generator verification could not find counter 

public int run(Path inputDir, int numMappers) throws Exception {	getConf().set(SEARCHER_INPUTDIR_KEY, inputDir.toString());	SortedSet<byte []> keys = readKeysToSearch(getConf());	if (keys.isEmpty()) throw new RuntimeException("No keys to find");	
count of keys to find 

public int run(Path inputDir, int numMappers) throws Exception {	getConf().set(SEARCHER_INPUTDIR_KEY, inputDir.toString());	SortedSet<byte []> keys = readKeysToSearch(getConf());	if (keys.isEmpty()) throw new RuntimeException("No keys to find");	
key 

if (multipleUnevenColumnFamilies && (!value.containsColumn(BIG_FAMILY_NAME, BIG_FAMILY_NAME) || !value.containsColumn( TINY_FAMILY_NAME, TINY_FAMILY_NAME))) {	context.write(row, DEF_LOST_FAMILIES);	} else {	context.write(row, DEF);	}	byte[] prev = value.getValue(FAMILY_NAME, COLUMN_PREV);	if (prev != null && prev.length > 0) {	ref.set(prev, 0, prev.length);	context.write(ref, row);	} else {	
prev is not set for s 

job.getConfiguration().setBoolean("mapreduce.map.speculative", false);	job.setReducerClass(VerifyReducer.class);	job.setOutputFormatClass(SequenceFileAsBinaryOutputFormat.class);	job.setOutputKeyClass(BytesWritable.class);	job.setOutputValueClass(BytesWritable.class);	TextOutputFormat.setOutputPath(job, outputDir);	boolean success = job.waitForCompletion(true);	if (success) {	Counters counters = job.getCounters();	if (null == counters) {	
counters were null cannot verify job completion this is commonly a result of insufficient yarn configuration 

public boolean verify(long expectedReferenced) throws Exception {	if (job == null) {	throw new IllegalStateException("You should call run() first");	}	Counters counters = job.getCounters();	if (counters == null) {	
counters object was null write verification cannot be performed this is commonly a result of insufficient yarn configuration 

Configuration conf = job.getConfiguration();	TableName tableName = getTableName(conf);	try (Connection conn = ConnectionFactory.createConnection(conf)) {	try (RegionLocator rl = conn.getRegionLocator(tableName)) {	CounterGroup g = counters.getGroup("undef");	Iterator<Counter> it = g.iterator();	while (it.hasNext()) {	String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = rl.getRegionLocation(key, true);	
undefined row 

String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = rl.getRegionLocation(key, true);	}	g = counters.getGroup("unref");	it = g.iterator();	while (it.hasNext()) {	String keyString = it.next().getName();	byte[] key = Bytes.toBytes(keyString);	HRegionLocation loc = rl.getRegionLocation(key, true);	
unreferred row 

long numNodes = Long.parseLong(args[2]);	String outputDir = args[3];	int numReducers = Integer.parseInt(args[4]);	Integer width = (args.length < 6) ? null : Integer.parseInt(args[5]);	Integer wrapMultiplier = (args.length < 7) ? null : Integer.parseInt(args[6]);	Integer numWalkers = (args.length < 8) ? 0 : Integer.parseInt(args[7]);	long expectedNumNodes = 0;	if (numIterations < 0) {	numIterations = Integer.MAX_VALUE;	}	
running loop with args 

========================= hbase sample_3242 =========================

public void exceptionCaught(ChannelHandlerContext ctx, Throwable e) {	allChannels.remove(ctx.channel());	
connection caught unexpected downstream exception 

========================= hbase sample_2900 =========================

public void perform() throws Exception {	if (sleepTime > 0) {	Thread.sleep(sleepTime);	}	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	
performing action move random region of table 

public void perform() throws Exception {	if (sleepTime > 0) {	Thread.sleep(sleepTime);	}	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	
table doesn t have regions to move 

if (sleepTime > 0) {	Thread.sleep(sleepTime);	}	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	
unassigning region 

========================= hbase sample_3306 =========================

public int run(String args[]) throws Exception {	Options opt = new Options();	opt.addOption("localRegionServers", true, "RegionServers to start in master process when running standalone");	opt.addOption("masters", true, "Masters to start in this process");	opt.addOption("minRegionServers", true, "Minimum RegionServers needed to host user tables");	opt.addOption("backup", false, "Do not try to become HMaster until the primary fails");	CommandLine cmd;	try {	cmd = new GnuParser().parse(opt, args);	} catch (ParseException e) {	
could not parse 

CommandLine cmd;	try {	cmd = new GnuParser().parse(opt, args);	} catch (ParseException e) {	usage(null);	return 1;	}	if (cmd.hasOption("minRegionServers")) {	String val = cmd.getOptionValue("minRegionServers");	getConf().setInt("hbase.regions.server.count.min", Integer.parseInt(val));	
minregionservers set to 

usage(null);	return 1;	}	if (cmd.hasOption("minRegionServers")) {	String val = cmd.getOptionValue("minRegionServers");	getConf().setInt("hbase.regions.server.count.min", Integer.parseInt(val));	}	if (cmd.hasOption("minServers")) {	String val = cmd.getOptionValue("minServers");	getConf().setInt("hbase.regions.server.count.min", Integer.parseInt(val));	
minservers set to 

if (cmd.hasOption("minServers")) {	String val = cmd.getOptionValue("minServers");	getConf().setInt("hbase.regions.server.count.min", Integer.parseInt(val));	}	if (cmd.hasOption("backup")) {	getConf().setBoolean(HConstants.MASTER_TYPE_BACKUP, true);	}	if (cmd.hasOption("localRegionServers")) {	String val = cmd.getOptionValue("localRegionServers");	getConf().setInt("hbase.regionservers", Integer.parseInt(val));	
localregionservers set to 

if (cmd.hasOption("backup")) {	getConf().setBoolean(HConstants.MASTER_TYPE_BACKUP, true);	}	if (cmd.hasOption("localRegionServers")) {	String val = cmd.getOptionValue("localRegionServers");	getConf().setInt("hbase.regionservers", Integer.parseInt(val));	}	if (cmd.hasOption("masters")) {	String val = cmd.getOptionValue("masters");	getConf().setInt("hbase.masters", Integer.parseInt(val));	
masters set to 

}	}	zooKeeperCluster.setDefaultClientPort(zkClientPort);	int zkTickTime = conf.getInt(HConstants.ZOOKEEPER_TICK_TIME, 0);	if (zkTickTime > 0) {	zooKeeperCluster.setTickTime(zkTickTime);	}	ZKUtil.loginServer(conf, HConstants.ZK_SERVER_KEYTAB_FILE, HConstants.ZK_SERVER_KERBEROS_PRINCIPAL, null);	int localZKClusterSessionTimeout = conf.getInt(HConstants.ZK_SESSION_TIMEOUT + ".localHBaseCluster", 10*1000);	conf.setInt(HConstants.ZK_SESSION_TIMEOUT, localZKClusterSessionTimeout);	
starting a zookeeper cluster 

conf.setIfUnset("hbase.master.start.timeout.localHBaseCluster", "300000");	LOG.info("Starting up instance of localHBaseCluster; master=" + mastersCount + ", regionserversCount=" + regionServersCount);	LocalHBaseCluster cluster = new LocalHBaseCluster(conf, mastersCount, regionServersCount, LocalHMaster.class, HRegionServer.class);	((LocalHMaster)cluster.getMaster(0)).setZKCluster(zooKeeperCluster);	cluster.startup();	waitOnMasterThreads(cluster);	} else {	logProcessInfo(getConf());	HMaster master = HMaster.constructMaster(masterClass, conf);	if (master.isStopped()) {	
won t bring the master up as a shutdown is requested 

logProcessInfo(getConf());	HMaster master = HMaster.constructMaster(masterClass, conf);	if (master.isStopped()) {	return 1;	}	master.start();	master.join();	if(master.isAborted()) throw new RuntimeException("HMaster Aborted");	}	} catch (Throwable t) {	
master exiting 

private int stopMaster() {	Configuration conf = getConf();	conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 0);	try (Connection connection = ConnectionFactory.createConnection(conf)) {	try (Admin admin = connection.getAdmin()) {	admin.shutdown();	} catch (Throwable t) {	
failed to stop master 

private int stopMaster() {	Configuration conf = getConf();	conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 0);	try (Connection connection = ConnectionFactory.createConnection(conf)) {	try (Admin admin = connection.getAdmin()) {	admin.shutdown();	} catch (Throwable t) {	return 1;	}	} catch (MasterNotRunningException e) {	
master not running 

conf.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 0);	try (Connection connection = ConnectionFactory.createConnection(conf)) {	try (Admin admin = connection.getAdmin()) {	admin.shutdown();	} catch (Throwable t) {	return 1;	}	} catch (MasterNotRunningException e) {	return 1;	} catch (ZooKeeperConnectionException e) {	
zookeeper not available 

try (Admin admin = connection.getAdmin()) {	admin.shutdown();	} catch (Throwable t) {	return 1;	}	} catch (MasterNotRunningException e) {	return 1;	} catch (ZooKeeperConnectionException e) {	return 1;	} catch (IOException e) {	
got ioexception 

========================= hbase sample_2844 =========================

private void handleLeaderChange() {	try {	synchronized(lock) {	if (ZKUtil.watchAndCheckExists(watcher, leaderZNode)) {	
found new leader for znode 

private void handleLeaderChange() {	try {	synchronized(lock) {	if (ZKUtil.watchAndCheckExists(watcher, leaderZNode)) {	leaderExists.set(true);	} else {	
leader change but no new leader found 

public void waitToBecomeLeader() {	while (!candidate.isStopped()) {	try {	if (ZKUtil.createEphemeralNodeAndWatch(watcher, leaderZNode, nodeId)) {	leaderExists.set(true);	if (LOG.isDebugEnabled()) {	
claimed the leader znode as 

while (!candidate.isStopped()) {	try {	if (ZKUtil.createEphemeralNodeAndWatch(watcher, leaderZNode, nodeId)) {	leaderExists.set(true);	if (LOG.isDebugEnabled()) {	}	return;	}	byte[] currentId = ZKUtil.getDataAndWatch(watcher, leaderZNode);	if (currentId != null && Bytes.equals(currentId, nodeId)) {	
found existing leader with our id removing 

leaderExists.set(true);	if (LOG.isDebugEnabled()) {	}	return;	}	byte[] currentId = ZKUtil.getDataAndWatch(watcher, leaderZNode);	if (currentId != null && Bytes.equals(currentId, nodeId)) {	ZKUtil.deleteNode(watcher, leaderZNode);	leaderExists.set(false);	} else {	
found existing leader with id 

} catch (KeeperException ke) {	watcher.abort("Unexpected error from ZK, stopping candidate", ke);	candidate.stop("Unexpected error from ZK: "+ke.getMessage());	return;	}	synchronized(lock) {	while (leaderExists.get() && !candidate.isStopped()) {	try {	lock.wait();	} catch (InterruptedException ie) {	
interrupted waiting on leader 

public void stepDownAsLeader() {	try {	synchronized(lock) {	if (!leaderExists.get()) {	return;	}	byte[] leaderId = ZKUtil.getData(watcher, leaderZNode);	if (leaderId != null && Bytes.equals(nodeId, leaderId)) {	
stepping down as leader 

try {	synchronized(lock) {	if (!leaderExists.get()) {	return;	}	byte[] leaderId = ZKUtil.getData(watcher, leaderZNode);	if (leaderId != null && Bytes.equals(nodeId, leaderId)) {	ZKUtil.deleteNodeFailSilent(watcher, leaderZNode);	leaderExists.set(false);	} else {	
not current leader no need to step down 

========================= hbase sample_749 =========================

public void testTableCreation() throws Exception {	conf.set(HConstants.HBASE_MASTER_LOADBALANCER_CLASS, StochasticLoadBalancer.class.getName());	
starting up cluster 

while (!UTIL.getMiniHBaseCluster().getMaster().isInitialized()) {	Threads.sleep(1);	}	Admin admin = UTIL.getAdmin();	admin.setBalancerRunning(false, true);	String tableName = "testFNImport";	HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("a"), Bytes.toBytes("z"), REGION_NUM);	UTIL.waitTableAvailable(desc.getTableName());	
shutting down cluster 

}	Admin admin = UTIL.getAdmin();	admin.setBalancerRunning(false, true);	String tableName = "testFNImport";	HTableDescriptor desc = new HTableDescriptor(TableName.valueOf(tableName));	desc.addFamily(new HColumnDescriptor(HConstants.CATALOG_FAMILY));	admin.createTable(desc, Bytes.toBytes("a"), Bytes.toBytes("z"), REGION_NUM);	UTIL.waitTableAvailable(desc.getTableName());	UTIL.shutdownMiniHBaseCluster();	Thread.sleep(2000);	
starting cluster again with fn balancer 

========================= hbase sample_1854 =========================

private void genAssignmentPlan(TableName tableName, SnapshotOfRegionAssignmentFromMeta assignmentSnapshot, Map<String, Map<String, Float>> regionLocalityMap, FavoredNodesPlan plan, boolean munkresForSecondaryAndTertiary) throws IOException {	List<RegionInfo> regions = assignmentSnapshot.getTableToRegionMap().get(tableName);	int numRegions = regions.size();	Map<RegionInfo, ServerName> currentAssignmentMap = assignmentSnapshot.getRegionToRegionServerMap();	List<ServerName> servers = new ArrayList<>();	try (Admin admin = this.connection.getAdmin()) {	servers.addAll(admin.getClusterMetrics(EnumSet.of(Option.LIVE_SERVERS)) .getLiveServerMetrics().keySet());	}	
start to generate assignment plan for regions from table with region servers 

for (int i = 0; i < numRegions; i++) {	List<ServerName> favoredServers = new ArrayList<>(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM);	ServerName s = servers.get(primaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = servers.get(secondaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = servers.get(tertiaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	plan.updateFavoredNodesMap(regions.get(i), favoredServers);	}	
generated the assignment plan for regions from table with region servers 

for (int i = 0; i < numRegions; i++) {	List<ServerName> favoredServers = new ArrayList<>(FavoredNodeAssignmentHelper.FAVORED_NODES_NUM);	ServerName s = servers.get(primaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = servers.get(secondaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = servers.get(tertiaryAssignment[i] / slotsPerServer);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	plan.updateFavoredNodesMap(regions.get(i), favoredServers);	}	
assignment plan for secondary and tertiary generated using munkresassignment 

RegionInfo currentRegion = regions.get(i);	ServerName s = primaryRSMap.get(currentRegion);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	ServerName[] secondaryAndTertiary = secondaryAndTertiaryMap.get(currentRegion);	s = secondaryAndTertiary[0];	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = secondaryAndTertiary[1];	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	plan.updateFavoredNodesMap(regions.get(i), favoredServers);	}	
generated the assignment plan for regions from table with region servers 

RegionInfo currentRegion = regions.get(i);	ServerName s = primaryRSMap.get(currentRegion);	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	ServerName[] secondaryAndTertiary = secondaryAndTertiaryMap.get(currentRegion);	s = secondaryAndTertiary[0];	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	s = secondaryAndTertiary[1];	favoredServers.add(ServerName.valueOf(s.getHostname(), s.getPort(), ServerName.NON_STARTCODE));	plan.updateFavoredNodesMap(regions.get(i), favoredServers);	}	
assignment plan for secondary and tertiary generated using placesecondaryandtertiarywithrestrictions method 

public FavoredNodesPlan getNewAssignmentPlan() throws IOException {	SnapshotOfRegionAssignmentFromMeta assignmentSnapshot = this.getRegionAssignmentSnapshot();	Map<String, Map<String, Float>> regionLocalityMap = null;	if (this.enforceLocality) {	regionLocalityMap = FSUtils.getRegionDegreeLocalityMappingFromFS(conf);	}	FavoredNodesPlan plan = new FavoredNodesPlan();	Map<TableName, List<RegionInfo>> tableToRegionMap = assignmentSnapshot.getTableToRegionMap();	
start to generate the new assignment plan for the tables 

}	FavoredNodesPlan plan = new FavoredNodesPlan();	Map<TableName, List<RegionInfo>> tableToRegionMap = assignmentSnapshot.getTableToRegionMap();	for (TableName table : tableToRegionMap.keySet()) {	try {	if (!this.targetTableSet.isEmpty() && !this.targetTableSet.contains(table)) {	continue;	}	genAssignmentPlan(table, assignmentSnapshot, regionLocalityMap, plan, USE_MUNKRES_FOR_PLACING_SECONDARY_AND_TERTIARY);	} catch (Exception e) {	
get some exceptions for placing primary region server for table because 

Map<TableName, List<RegionInfo>> tableToRegionMap = assignmentSnapshot.getTableToRegionMap();	for (TableName table : tableToRegionMap.keySet()) {	try {	if (!this.targetTableSet.isEmpty() && !this.targetTableSet.contains(table)) {	continue;	}	genAssignmentPlan(table, assignmentSnapshot, regionLocalityMap, plan, USE_MUNKRES_FOR_PLACING_SECONDARY_AND_TERTIARY);	} catch (Exception e) {	}	}	
finish to generate the new assignment plan for the tables 

public static void printAssignmentPlan(FavoredNodesPlan plan) {	if (plan == null) return;	LOG.info("========== Start to print the assignment plan ================");	Map<String, List<ServerName>> assignmentMap = new TreeMap<>(plan.getAssignmentMap());	for (Map.Entry<String, List<ServerName>> entry : assignmentMap.entrySet()) {	String serverList = FavoredNodeAssignmentHelper.getFavoredNodesAsString(entry.getValue());	String regionName = entry.getKey();	
region 

public static void printAssignmentPlan(FavoredNodesPlan plan) {	if (plan == null) return;	LOG.info("========== Start to print the assignment plan ================");	Map<String, List<ServerName>> assignmentMap = new TreeMap<>(plan.getAssignmentMap());	for (Map.Entry<String, List<ServerName>> entry : assignmentMap.entrySet()) {	String serverList = FavoredNodeAssignmentHelper.getFavoredNodesAsString(entry.getValue());	String regionName = entry.getKey();	
its favored nodes 

public void updateAssignmentPlanToMeta(FavoredNodesPlan plan) throws IOException {	try {	
start to update the hbase meta with the new assignment plan 

public void updateAssignmentPlanToMeta(FavoredNodesPlan plan) throws IOException {	try {	Map<String, List<ServerName>> assignmentMap = plan.getAssignmentMap();	Map<RegionInfo, List<ServerName>> planToUpdate = new HashMap<>(assignmentMap.size());	Map<String, RegionInfo> regionToRegionInfoMap = getRegionAssignmentSnapshot().getRegionNameToRegionInfoMap();	for (Map.Entry<String, List<ServerName>> entry : assignmentMap.entrySet()) {	planToUpdate.put(regionToRegionInfoMap.get(entry.getKey()), entry.getValue());	}	FavoredNodeAssignmentHelper.updateMetaWithFavoredNodesInfo(planToUpdate, conf);	
updated the hbase meta with the new assignment plan 

public void updateAssignmentPlanToMeta(FavoredNodesPlan plan) throws IOException {	try {	Map<String, List<ServerName>> assignmentMap = plan.getAssignmentMap();	Map<RegionInfo, List<ServerName>> planToUpdate = new HashMap<>(assignmentMap.size());	Map<String, RegionInfo> regionToRegionInfoMap = getRegionAssignmentSnapshot().getRegionNameToRegionInfoMap();	for (Map.Entry<String, List<ServerName>> entry : assignmentMap.entrySet()) {	planToUpdate.put(regionToRegionInfoMap.get(entry.getKey()), entry.getValue());	}	FavoredNodeAssignmentHelper.updateMetaWithFavoredNodesInfo(planToUpdate, conf);	} catch (Exception e) {	
failed to update hbase meta with the new assignment plan because 

private void updateAssignmentPlanToRegionServers(FavoredNodesPlan plan) throws IOException{	
start to update the region servers with the new assignment plan 

singleServerPlan = new FavoredNodesPlan();	}	singleServerPlan.updateFavoredNodesMap(region, favoredServerList);	regionUpdateInfos.add(new Pair<>(region, favoredServerList));	}	}	if (singleServerPlan != null) {	BlockingInterface currentRegionServer = ((ClusterConnection)this.connection).getAdmin(entry.getKey());	UpdateFavoredNodesRequest request = RequestConverter.buildUpdateFavoredNodesRequest(regionUpdateInfos);	UpdateFavoredNodesResponse updateFavoredNodesResponse = currentRegionServer.updateFavoredNodes(null, request);	
region server has updated regions with the assignment plan 

if (singleServerPlan != null) {	BlockingInterface currentRegionServer = ((ClusterConnection)this.connection).getAdmin(entry.getKey());	UpdateFavoredNodesRequest request = RequestConverter.buildUpdateFavoredNodesRequest(regionUpdateInfos);	UpdateFavoredNodesResponse updateFavoredNodesResponse = currentRegionServer.updateFavoredNodes(null, request);	succeededNum ++;	}	} catch (Exception e) {	failedUpdateMap.put(entry.getKey(), e);	}	}	
updated region servers with the new assignment plan 

UpdateFavoredNodesRequest request = RequestConverter.buildUpdateFavoredNodesRequest(regionUpdateInfos);	UpdateFavoredNodesResponse updateFavoredNodesResponse = currentRegionServer.updateFavoredNodes(null, request);	succeededNum ++;	}	} catch (Exception e) {	failedUpdateMap.put(entry.getKey(), e);	}	}	int failedNum = failedUpdateMap.size();	if (failedNum != 0) {	
failed to update the following region servers with its corresponding favored nodes 

UpdateFavoredNodesResponse updateFavoredNodesResponse = currentRegionServer.updateFavoredNodes(null, request);	succeededNum ++;	}	} catch (Exception e) {	failedUpdateMap.put(entry.getKey(), e);	}	}	int failedNum = failedUpdateMap.size();	if (failedNum != 0) {	for (Map.Entry<ServerName, Exception> entry : failedUpdateMap.entrySet() ) {	
failed to update because of 

public void updateAssignmentPlan(FavoredNodesPlan plan) throws IOException {	
start to update the new assignment plan for the hbase meta table and the region servers 

public void updateAssignmentPlan(FavoredNodesPlan plan) throws IOException {	updateAssignmentPlanToMeta(plan);	updateAssignmentPlanToRegionServers(plan);	
finish to update the new assignment plan for the hbase meta table and the region servers 

if (!this.targetTableSet.isEmpty() && !this.targetTableSet.contains(table)) {	return;	}	AssignmentVerificationReport report = new AssignmentVerificationReport();	report.fillUpDispersion(table, snapshot, newPlan);	List<Float> dispersion = report.getDispersionInformation();	if (simplePrint) {	DecimalFormat df = new java.text.DecimalFormat("#.##");	System.out.println("\tAvg dispersion score: " + df.format(dispersion.get(0)) + " hosts;\tMax dispersion score: " + df.format(dispersion.get(1)) + " hosts;\tMin dispersion score: " + df.format(dispersion.get(2)) + " hosts;");	} else {	
for table total regions the average dispersion score is 

for (int i = 0; i < locality.length; i++) {	String copy =  null;	if (i == 0) {	copy = "primary";	} else if (i == 1) {	copy = "secondary";	} else if (i == 2) {	copy = "tertiary" ;	}	float avgLocality = 100 * locality[i] / regions.size();	
for table total regions the average locality for is 

boolean enforceLocality = true;	boolean verificationDetails = false;	if ((cmd.hasOption("l") && cmd.getOptionValue("l").equalsIgnoreCase("false")) || (cmd.hasOption("locality") && cmd.getOptionValue("locality").equalsIgnoreCase("false"))) {	enforceLocality = false;	}	if ((cmd.hasOption("m") && cmd.getOptionValue("m").equalsIgnoreCase("false")) || (cmd.hasOption("min-move") && cmd.getOptionValue("min-move").equalsIgnoreCase("false"))) {	enforceMinAssignmentMove = false;	}	if (cmd.hasOption("zk")) {	conf.set(HConstants.ZOOKEEPER_QUORUM, cmd.getOptionValue("zk"));	
setting the zk quorum 

enforceLocality = false;	}	if ((cmd.hasOption("m") && cmd.getOptionValue("m").equalsIgnoreCase("false")) || (cmd.hasOption("min-move") && cmd.getOptionValue("min-move").equalsIgnoreCase("false"))) {	enforceMinAssignmentMove = false;	}	if (cmd.hasOption("zk")) {	conf.set(HConstants.ZOOKEEPER_QUORUM, cmd.getOptionValue("zk"));	}	if (cmd.hasOption("fs")) {	conf.set(FileSystem.FS_DEFAULT_NAME_KEY, cmd.getOptionValue("fs"));	
setting the hdfs 

enforceMinAssignmentMove = false;	}	if (cmd.hasOption("zk")) {	conf.set(HConstants.ZOOKEEPER_QUORUM, cmd.getOptionValue("zk"));	}	if (cmd.hasOption("fs")) {	conf.set(FileSystem.FS_DEFAULT_NAME_KEY, cmd.getOptionValue("fs"));	}	if (cmd.hasOption("hbase_root")) {	conf.set(HConstants.HBASE_DIR, cmd.getOptionValue("hbase_root"));	
setting the hbase root directory 

rp.printLocalityAndDispersionForCurrentPlan(locality);	} else if (cmd.hasOption("p") || cmd.hasOption("print")) {	FavoredNodesPlan plan = rp.getRegionAssignmentSnapshot().getExistingAssignmentPlan();	printAssignmentPlan(plan);	} else if (cmd.hasOption("overwrite")) {	if (!cmd.hasOption("f") || !cmd.hasOption("r")) {	throw new IllegalArgumentException("Please specify: " + " -update -r regionName -f server1:port,server2:port,server3:port");	}	String regionName = cmd.getOptionValue("r");	String favoredNodesStr = cmd.getOptionValue("f");	
going to update the region with the new favored nodes 

printAssignmentPlan(plan);	} else if (cmd.hasOption("overwrite")) {	if (!cmd.hasOption("f") || !cmd.hasOption("r")) {	throw new IllegalArgumentException("Please specify: " + " -update -r regionName -f server1:port,server2:port,server3:port");	}	String regionName = cmd.getOptionValue("r");	String favoredNodesStr = cmd.getOptionValue("f");	List<ServerName> favoredNodes = null;	RegionInfo regionInfo = rp.getRegionAssignmentSnapshot().getRegionNameToRegionInfoMap().get(regionName);	if (regionInfo == null) {	
cannot find the region from the meta 

}	String regionName = cmd.getOptionValue("r");	String favoredNodesStr = cmd.getOptionValue("f");	List<ServerName> favoredNodes = null;	RegionInfo regionInfo = rp.getRegionAssignmentSnapshot().getRegionNameToRegionInfoMap().get(regionName);	if (regionInfo == null) {	} else {	try {	favoredNodes = getFavoredNodeList(favoredNodesStr);	} catch (IllegalArgumentException e) {	
cannot parse the invalid favored nodes because 

========================= hbase sample_2794 =========================

protected Path setupDataTestDir() {	if (this.dataTestDir != null) {	
data test dir already setup in 

========================= hbase sample_876 =========================

private void validateFalsePosRate(double falsePosRate, int nTrials, double zValueBoundary, CompoundBloomFilter cbf, String additionalMsg) {	double p = BloomFilterFactory.getErrorRate(conf);	double zValue = (falsePosRate - p) / Math.sqrt(p * (1 - p) / nTrials);	String assortedStatsStr = " (targetErrorRate=" + p + ", falsePosRate=" + falsePosRate + ", nTrials=" + nTrials + ")";	
z value is 

int numFalsePos = 0;	Random rand = new Random(EVALUATION_SEED);	int nTrials = NUM_KV[t] * 10;	for (int i = 0; i < nTrials; ++i) {	byte[] query = RandomKeyValueUtil.randomRowOrQualifier(rand);	if (isInBloom(scanner, query, bt, rand)) {	numFalsePos += 1;	}	}	double falsePosRate = numFalsePos * 1.0 / nTrials;	
false positives d out of d f 

}	double falsePosRate = numFalsePos * 1.0 / nTrials;	assertTrue("False positive is too high: " + falsePosRate + " (greater " + "than " + TOO_HIGH_ERROR_RATE + ")" + fakeLookupModeStr, falsePosRate < TOO_HIGH_ERROR_RATE);	double maxZValue = fakeLookupEnabled ? 1.96 : 2.5;	validateFalsePosRate(falsePosRate, nTrials, maxZValue, cbf, fakeLookupModeStr);	int nChunks = cbf.getNumChunks();	if (nChunks > 1) {	numFalsePos -= cbf.getNumPositivesForTesting(nChunks - 1);	nTrials -= cbf.getNumQueriesForTesting(nChunks - 1);	falsePosRate = numFalsePos * 1.0 / nTrials;	
false positive rate without last chunk is 

conf.setInt(BloomFilterFactory.IO_STOREFILE_BLOOM_BLOCK_SIZE, BLOOM_BLOCK_SIZES[t]);	conf.setBoolean(CacheConfig.CACHE_BLOCKS_ON_WRITE_KEY, true);	cacheConf = new CacheConfig(conf);	HFileContext meta = new HFileContextBuilder().withBlockSize(BLOCK_SIZES[t]).build();	StoreFileWriter w = new StoreFileWriter.Builder(conf, cacheConf, fs) .withOutputDir(TEST_UTIL.getDataTestDir()) .withBloomType(bt) .withFileContext(meta) .build();	assertTrue(w.hasGeneralBloom());	assertTrue(w.getGeneralBloomWriter() instanceof CompoundBloomFilterWriter);	CompoundBloomFilterWriter cbbf = (CompoundBloomFilterWriter) w.getGeneralBloomWriter();	int keyCount = 0;	KeyValue prev = null;	
total keys values to insert 

========================= hbase sample_1696 =========================

grantOnTable(TEST_UTIL, USER_RO.getShortName(), TEST_TABLE, TEST_FAMILY, null, Permission.Action.READ);	grantOnTable(TEST_UTIL, USER_ADMIN_CF.getShortName(), TEST_TABLE, TEST_FAMILY, null, Permission.Action.ADMIN, Permission.Action.CREATE);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_ADMIN), Permission.Action.ADMIN);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_CREATE), Permission.Action.CREATE);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_READ), Permission.Action.READ);	grantGlobal(TEST_UTIL, toGroupEntry(GROUP_WRITE), Permission.Action.WRITE);	assertEquals(5, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());	try {	assertEquals(5, AccessControlClient.getUserPermissions(systemUserConnection, TEST_TABLE.toString()).size());	} catch (Throwable e) {	
error during call of accesscontrolclient getuserpermissions 

private static void cleanUp() throws Exception {	try {	deleteTable(TEST_UTIL, TEST_TABLE);	} catch (TableNotFoundException ex) {	
test deleted table 

public void testGlobalAuthorizationForNewRegisteredRS() throws Exception {	
test for global authorization for a new registered regionserver 

AccessTestAction moveAction = new AccessTestAction() {	public Object run() throws Exception {	admin.move(hri.getEncodedNameAsBytes(), Bytes.toBytes(newRs.getServerName().getServerName()));	return null;	}	};	SUPERUSER.runAs(moveAction);	final int RETRIES_LIMIT = 10;	int retries = 0;	while (newRs.getRegions(TEST_TABLE2).size() < 1 && retries < RETRIES_LIMIT) {	
waiting for region to be opened already retried times 

try(Connection conn = ConnectionFactory.createConnection(conf);	Table t = conn.getTable(TEST_TABLE)) {	return t.get(new Get(TEST_ROW));	}	}	};	verifyDenied(getAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, testGrantRevoke.getShortName(), TEST_TABLE, null, null, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

};	verifyDenied(getAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, testGrantRevoke.getShortName(), TEST_TABLE, null, null, Permission.Action.READ);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	try {	revokeFromTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, testGrantRevoke.getShortName(), TEST_TABLE, null, null, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

Table t = conn.getTable(TEST_TABLE)) {	return t.get(new Get(TEST_ROW));	}	}	};	verifyDenied(getAction, testGlobalGrantRevoke);	String userName = testGlobalGrantRevoke.getShortName();	try {	grantGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

}	try {	verifyAllowed(getAction, testGlobalGrantRevoke);	} catch (Exception e) {	revokeGlobal(TEST_UTIL, userName, Permission.Action.READ);	throw e;	}	try {	revokeGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

return null;	}	}	};	verifyDenied(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	String userName = testGrantRevoke.getShortName();	try {	grantGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

String userName = testGrantRevoke.getShortName();	try {	grantGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	try {	grantGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

verifyDenied(putAction, testGrantRevoke);	try {	grantGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.WRITE);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyAllowed(putAction, testGrantRevoke);	try {	revokeGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ, Permission.Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

verifyAllowed(putAction, testGrantRevoke);	try {	revokeGlobalUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, Permission.Action.READ, Permission.Action.WRITE);	} catch (Throwable e) {	}	verifyDenied(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

verifyDenied(putAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Permission.Action.READ);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

verifyDenied(putAction, testGrantRevoke);	try {	grantOnTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Action.WRITE);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyAllowed(putAction, testGrantRevoke);	try {	revokeFromTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Permission.Action.READ, Permission.Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

try {	revokeFromTableUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE, null, null, Permission.Action.READ, Permission.Action.WRITE);	} catch (Throwable e) {	}	verifyDenied(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	String namespace = TEST_TABLE.getNamespaceAsString();	try {	grantOnNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

String namespace = TEST_TABLE.getNamespaceAsString();	try {	grantOnNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.READ);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyDenied(putAction, testGrantRevoke);	try {	grantOnNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

verifyDenied(putAction, testGrantRevoke);	try {	grantOnNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.WRITE);	} catch (Throwable e) {	}	verifyAllowed(getAction, testGrantRevoke);	verifyAllowed(putAction, testGrantRevoke);	try {	revokeFromNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, TEST_TABLE.getNamespaceAsString(), Permission.Action.READ, Permission.Action.WRITE);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

return t.get(new Get(TEST_ROW));	}	}	};	verifyDenied(getAction, testNS);	String userName = testNS.getShortName();	String namespace = TEST_TABLE.getNamespaceAsString();	try {	grantOnNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient grant 

}	try {	verifyAllowed(getAction, testNS);	} catch (Exception e) {	revokeFromNamespace(TEST_UTIL, userName, namespace, Permission.Action.READ);	throw e;	}	try {	revokeFromNamespaceUsingAccessControlClient(TEST_UTIL, systemUserConnection, userName, namespace, Permission.Action.READ);	} catch (Throwable e) {	
error during call of accesscontrolclient revoke 

private PrivilegedAction<List<UserPermission>> getPrivilegedAction(final String regex) {	return new PrivilegedAction<List<UserPermission>>() {	public List<UserPermission> run() {	try(Connection conn = ConnectionFactory.createConnection(conf)) {	return AccessControlClient.getUserPermissions(conn, regex);	} catch (Throwable e) {	
error during call of accesscontrolclient getuserpermissions 

========================= hbase sample_1383 =========================

protected void handleEmptyWALEntryBatch(WALEntryBatch batch, Path currentPath) throws InterruptedException {	
didn t read any new entries from wal 

========================= hbase sample_2956 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1803 =========================

private long getMaxTierAgeCutoff(long now) {	try {	return LongMath.checkedSubtract(now, maxTierAgeMillis);	} catch (ArithmeticException ae) {	
value for will always promote to next tier 

========================= hbase sample_2686 =========================

if (chore == null) {	return false;	}	try {	chore.setChoreServicer(this);	ScheduledFuture<?> future = scheduler.scheduleAtFixedRate(chore, chore.getInitialDelay(), chore.getPeriod(), chore.getTimeUnit());	scheduledChores.put(chore, future);	return true;	} catch (Exception exception) {	if (LOG.isInfoEnabled()) {	
could not successfully schedule chore 

public synchronized void shutdown() {	scheduler.shutdownNow();	if (LOG.isInfoEnabled()) {	
chore service for had on shutdown 

========================= hbase sample_1100 =========================

public Response get(final @Context UriInfo uriInfo, if (LOG.isTraceEnabled()) {	
get 

public Response getBinary(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get as 

public Response getBinary(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	}	servlet.getMetrics().incrementRequests(1);	try {	Cell value = generator.next();	if (value == null) {	if (LOG.isTraceEnabled()) {	
generator exhausted 

public Response delete(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
delete 

========================= hbase sample_3078 =========================

public void testServerSocket() throws IOException {	byte[] addr = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1 };	InetAddress inetAddr = InetAddress.getByAddress(addr);	try {	bindServerSocket(inetAddr);	bindNIOServerSocket(inetAddr);	} catch(java.net.SocketException ex) {	Assert.assertFalse(ex instanceof BindException);	Assert.assertTrue(ex.getMessage().toLowerCase(Locale.ROOT).contains("protocol family"));	
received expected exception 

public void ensurePreferIPv4() throws IOException {	InetAddress[] addrs = InetAddress.getAllByName("localhost");	for (InetAddress addr : addrs) {	
resolved localhost as 

public void testServerSocketFromLocalhostResolution() throws IOException {	InetAddress[] addrs = {InetAddress.getLocalHost()};	for (InetAddress addr : addrs) {	
resolved localhost as 

========================= hbase sample_1415 =========================

public void testThrottling() {	
testThrottling 

========================= hbase sample_1946 =========================

loadOnOpenBlocks.add(b);	}	if (cacheConf.shouldPrefetchOnOpen()) {	PrefetchExecutor.request(path, new Runnable() {	public void run() {	long offset = 0;	long end = 0;	try {	end = getTrailer().getLoadOnOpenDataOffset();	if (LOG.isTraceEnabled()) {	
prefetch start 

break;	}	long onDiskSize = prevBlock != null? prevBlock.getNextBlockOnDiskSize(): -1;	HFileBlock block = readBlock(offset, onDiskSize, true, false, false, false, null, null);	returnBlock(block);	prevBlock = block;	offset += block.getOnDiskSizeWithHeader();	}	} catch (IOException e) {	if (LOG.isTraceEnabled()) {	
prefetch 

long onDiskSize = prevBlock != null? prevBlock.getNextBlockOnDiskSize(): -1;	HFileBlock block = readBlock(offset, onDiskSize, true, false, false, false, null, null);	returnBlock(block);	prevBlock = block;	offset += block.getOnDiskSizeWithHeader();	}	} catch (IOException e) {	if (LOG.isTraceEnabled()) {	}	} catch (NullPointerException e) {	
stream moved closed or prefetch cancelled 

HFileBlock block = readBlock(offset, onDiskSize, true, false, false, false, null, null);	returnBlock(block);	prevBlock = block;	offset += block.getOnDiskSizeWithHeader();	}	} catch (IOException e) {	if (LOG.isTraceEnabled()) {	}	} catch (NullPointerException e) {	} catch (Exception e) {	
prefetch 

private void returnBlockToCache(HFileBlock block) {	if (LOG.isTraceEnabled()) {	
returning the block 

cache.returnBlock(cacheKey, compressedBlock);	}	}	validateBlockType(cachedBlock, expectedBlockType);	if (expectedDataBlockEncoding == null) {	return cachedBlock;	}	DataBlockEncoding actualDataBlockEncoding = cachedBlock.getDataBlockEncoding();	if (cachedBlock.getBlockType().isData() && !actualDataBlockEncoding.equals(expectedDataBlockEncoding)) {	if (!expectedDataBlockEncoding.equals(DataBlockEncoding.NONE) && !actualDataBlockEncoding.equals(DataBlockEncoding.NONE)) {	
evicting cached block with key because of a data block encoding mismatch expected actual 

IdLock.Entry lockEntry = null;	try (TraceScope traceScope = TraceUtil.createTrace("HFileReaderImpl.readBlock")) {	while (true) {	if (cacheConf.shouldReadBlockFromCache(expectedBlockType)) {	if (useLock) {	lockEntry = offsetLock.getLockEntry(dataBlockOffset);	}	HFileBlock cachedBlock = getCachedBlock(cacheKey, cacheBlock, useLock, isCompaction, updateCacheMetrics, expectedBlockType, expectedDataBlockEncoding);	if (cachedBlock != null) {	if (LOG.isTraceEnabled()) {	
from cache 

========================= hbase sample_2393 =========================

} else if (BackupCommand.REPAIR.name().equalsIgnoreCase(cmd)) {	type = BackupCommand.REPAIR;	} else if (BackupCommand.MERGE.name().equalsIgnoreCase(cmd)) {	type = BackupCommand.MERGE;	} else {	System.out.println("Unsupported command for backup: " + cmd);	printToolUsage();	return -1;	}	if (this.cmd.hasOption(OPTION_DEBUG)) {	
org apache hadoop hbase backup 

type = BackupCommand.REPAIR;	} else if (BackupCommand.MERGE.name().equalsIgnoreCase(cmd)) {	type = BackupCommand.MERGE;	} else {	System.out.println("Unsupported command for backup: " + cmd);	printToolUsage();	return -1;	}	if (this.cmd.hasOption(OPTION_DEBUG)) {	} else {	
org apache hadoop hbase backup 

public int run(String[] args) throws IOException {	if (conf == null) {	
tool configuration is not initialized 

} catch (Exception e) {	System.err.println("Error when parsing command-line arguments: " + e.getMessage());	printToolUsage();	return EXIT_FAILURE;	}	processOptions(cmd);	int ret = EXIT_FAILURE;	try {	ret = doWork();	} catch (Exception e) {	
error running command line tool 

========================= hbase sample_572 =========================

try {	if (zigzagLatch != null) {	assert sequence > 0L : "Failed to get sequence from ring buffer";	TraceUtil.addTimelineAnnotation("awaiting safepoint");	syncFuture = zigzagLatch.waitSafePoint(publishSyncOnRingBuffer(sequence));	}	} catch (FailedSyncBeforeLogCloseException e) {	if (isUnflushedEntries()) {	throw e;	}	
failed sync before close but no outstanding appends closing wal 

LOG.error("Failed close of WAL writer " + oldPath + ", unflushedEntries=" + count, e);	throw new FailedLogCloseException(oldPath + ", unflushedEntries=" + count, e);	} finally {	if (zigzagLatch != null) {	zigzagLatch.releaseSafePoint();	if (syncFuture != null) {	try {	blockOnSync(syncFuture);	} catch (IOException ioe) {	if (LOG.isTraceEnabled()) {	
stale sync exception 

protected void doShutdown() throws IOException {	if (this.disruptor != null) {	long timeoutms = conf.getLong("hbase.wal.disruptor.shutdown.timeout.ms", 60000);	try {	this.disruptor.shutdown(timeoutms, TimeUnit.MILLISECONDS);	} catch (TimeoutException e) {	
timed out bringing down disruptor after ms forcing halt it is a problem if this is not an abort dataloss 

if (this.disruptor != null) {	long timeoutms = conf.getLong("hbase.wal.disruptor.shutdown.timeout.ms", 60000);	try {	this.disruptor.shutdown(timeoutms, TimeUnit.MILLISECONDS);	} catch (TimeoutException e) {	this.disruptor.halt();	this.disruptor.shutdown();	}	}	if (LOG.isDebugEnabled()) {	
closing wal writer in 

break;	}	long start = System.nanoTime();	Throwable lastException = null;	try {	TraceUtil.addTimelineAnnotation("syncing writer");	writer.sync();	TraceUtil.addTimelineAnnotation("writer synced");	currentSequence = updateHighestSyncedSequence(currentSequence);	} catch (IOException e) {	
error syncing request close of wal 

long start = System.nanoTime();	Throwable lastException = null;	try {	TraceUtil.addTimelineAnnotation("syncing writer");	writer.sync();	TraceUtil.addTimelineAnnotation("writer synced");	currentSequence = updateHighestSyncedSequence(currentSequence);	} catch (IOException e) {	lastException = e;	} catch (Exception e) {	
UNEXPECTED 

if (lastException != null) {	requestLogRoll();	} else {	checkLogRoll();	}	}	postSync(System.nanoTime() - start, syncCount);	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	} catch (Throwable t) {	
unexpected continuing 

beforeWaitOnSafePoint();	try {	while ((!this.shutdown && this.zigzagLatch.isCocked() && highestSyncedTxid.get() < currentSequence && isOutstandingSyncs()) || isOutstandingSyncsFromRunners()) {	synchronized (this.safePointWaiter) {	this.safePointWaiter.wait(0, 1);	}	}	this.exception = null;	this.zigzagLatch.safePointAttained();	} catch (InterruptedException e) {	
interrupted 

========================= hbase sample_2556 =========================

public void testOnlineConfigChange() throws IOException {	
starting the test 

public void testMasterOnlineConfigChange() throws IOException {	
starting the test 

public void testAllOnlineConfigChange() throws IOException {	
starting the test 

public void testAllCustomOnlineConfigChange() throws IOException {	
starting the test 

========================= hbase sample_2106 =========================

public static void tearDown() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1680 =========================

public synchronized Set<Address> moveServers(Set<Address> servers, String srcGroup, String dstGroup) throws IOException {	RSGroupInfo src = getRSGroupInfo(srcGroup);	RSGroupInfo dst = getRSGroupInfo(dstGroup);	Set<Address> onlineServers = dst.getName().equals(RSGroupInfo.DEFAULT_GROUP)? Utility.getOnlineServers(this.masterServices): null;	for (Address el: servers) {	src.removeServer(el);	if (onlineServers != null) {	if (!onlineServers.contains(el)) {	if (LOG.isDebugEnabled()) {	
dropping during move to default rsgroup because not online 

if (rsGroupInfo != null) {	RSGroupInfo newRsGroupInfo = rsGroupInfos.get(rsGroupInfo.getName());	if (newRsGroupInfo == null) {	rsGroupInfo.removeServer(el);	rsGroupInfos.put(rsGroupInfo.getName(), rsGroupInfo);	} else {	newRsGroupInfo.removeServer(el);	rsGroupInfos.put(newRsGroupInfo.getName(), newRsGroupInfo);	}	}else {	
server does not belong to any rsgroup 

private synchronized void refresh(boolean forceOnline) throws IOException {	List<RSGroupInfo> groupList = new LinkedList<>();	if (forceOnline || isOnline()) {	
refreshing in online mode 

private synchronized void refresh(boolean forceOnline) throws IOException {	List<RSGroupInfo> groupList = new LinkedList<>();	if (forceOnline || isOnline()) {	if (rsGroupTable == null) {	rsGroupTable = conn.getTable(RSGROUP_TABLE_NAME);	}	groupList.addAll(retrieveGroupListFromGroupTable());	} else {	
refreshing in offline mode 

List<ZKUtil.ZKUtilOp> zkOps = new ArrayList<>(newGroupMap.size());	for(String groupName : prevRSGroups) {	if(!newGroupMap.containsKey(groupName)) {	String znode = ZNodePaths.joinZNode(groupBasePath, groupName);	zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));	}	}	for (RSGroupInfo RSGroupInfo : newGroupMap.values()) {	String znode = ZNodePaths.joinZNode(groupBasePath, RSGroupInfo.getName());	RSGroupProtos.RSGroupInfo proto = RSGroupProtobufUtil.toProtoGroupInfo(RSGroupInfo);	
updating znode 

zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));	}	}	for (RSGroupInfo RSGroupInfo : newGroupMap.values()) {	String znode = ZNodePaths.joinZNode(groupBasePath, RSGroupInfo.getName());	RSGroupProtos.RSGroupInfo proto = RSGroupProtobufUtil.toProtoGroupInfo(RSGroupInfo);	ZKUtil.createAndFailSilent(watcher, znode);	zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));	zkOps.add(ZKUtil.ZKUtilOp.createAndFailSilent(znode, ProtobufUtil.prependPBMagic(proto.toByteArray())));	}	
writing zk groupinfo count 

}	for (RSGroupInfo RSGroupInfo : newGroupMap.values()) {	String znode = ZNodePaths.joinZNode(groupBasePath, RSGroupInfo.getName());	RSGroupProtos.RSGroupInfo proto = RSGroupProtobufUtil.toProtoGroupInfo(RSGroupInfo);	ZKUtil.createAndFailSilent(watcher, znode);	zkOps.add(ZKUtil.ZKUtilOp.deleteNodeFailSilent(znode));	zkOps.add(ZKUtil.ZKUtilOp.createAndFailSilent(znode, ProtobufUtil.prependPBMagic(proto.toByteArray())));	}	ZKUtil.multiOrSequential(watcher, zkOps, false);	} catch (KeeperException e) {	
failed to write to rsgroupznode 

private List<ServerName> getOnlineRS() throws IOException {	if (masterServices != null) {	return masterServices.getServerManager().getOnlineServersList();	}	
reading online rs from zookeeper 

private void updateFailedAssignments() {	List<RegionInfo> stuckAssignments = Lists.newArrayList();	for (RegionStateNode state: masterServices.getAssignmentManager().getRegionStates().getRegionsInTransition()) {	if (state.isStuck()) {	stuckAssignments.add(state.getRegionInfo());	}	}	for (RegionInfo region: stuckAssignments) {	
retrying assignment of 

List<RegionInfo> stuckAssignments = Lists.newArrayList();	for (RegionStateNode state: masterServices.getAssignmentManager().getRegionStates().getRegionsInTransition()) {	if (state.isStuck()) {	stuckAssignments.add(state.getRegionInfo());	}	}	for (RegionInfo region: stuckAssignments) {	try {	masterServices.getAssignmentManager().unassign(region);	} catch (IOException e) {	
unable to reassign 

public void run() {	setName(ServerEventsListenerThread.class.getName() + "-" + masterServices.getServerName());	SortedSet<Address> prevDefaultServers = new TreeSet<>();	while(isMasterRunning(masterServices)) {	try {	
updating default servers 

public void run() {	setName(ServerEventsListenerThread.class.getName() + "-" + masterServices.getServerName());	SortedSet<Address> prevDefaultServers = new TreeSet<>();	while(isMasterRunning(masterServices)) {	try {	SortedSet<Address> servers = RSGroupInfoManagerImpl.this.getDefaultServers();	if (!servers.equals(prevDefaultServers)) {	RSGroupInfoManagerImpl.this.updateDefaultServers(servers);	prevDefaultServers = servers;	
updated with servers 

prevDefaultServers = servers;	}	try {	synchronized (this) {	while (!changed) {	wait();	}	changed = false;	}	} catch (InterruptedException e) {	
Interrupted 

try {	synchronized (this) {	while (!changed) {	wait();	}	changed = false;	}	} catch (InterruptedException e) {	}	} catch (IOException e) {	
failed to update default servers 

while (isMasterRunning(masterServices)) {	boolean interrupted = false;	try {	synchronized (this) {	while (!hasChanged) {	wait();	}	hasChanged = false;	}	} catch (InterruptedException e) {	
Interrupted 

}	} catch (InterruptedException e) {	interrupted = true;	}	if (!isMasterRunning(masterServices) || interrupted) {	continue;	}	try {	Thread.sleep(waitInterval);	} catch (InterruptedException e) {	
Interrupted 

public void run() {	setName(RSGroupStartupWorker.class.getName() + "-" + masterServices.getServerName());	if (waitForGroupTableOnline()) {	
groupbasedloadbalancer is now online 

ServerName sn = ServerName.parseVersionedServerName(CellUtil.cloneValue(serverCell));	if (sn == null) {	found.set(false);	} else if (tsm.isTableState(RSGROUP_TABLE_NAME, TableState.State.ENABLED)) {	try {	ClientProtos.ClientService.BlockingInterface rs = conn.getClient(sn);	ClientProtos.GetRequest request = RequestConverter.buildGetRequest(info.getRegionName(), new Get(ROW_KEY));	rs.get(null, request);	assignedRegions.add(info);	} catch(Exception ex) {	
caught exception while verifying group region 

}	if (sn == null) {	nsFound.set(false);	} else if (tsm.isTableState(TableName.NAMESPACE_TABLE_NAME, TableState.State.ENABLED)) {	try {	ClientProtos.ClientService.BlockingInterface rs = conn.getClient(sn);	ClientProtos.GetRequest request = RequestConverter.buildGetRequest(info.getRegionName(), new Get(ROW_KEY));	rs.get(null, request);	nsFound.set(true);	} catch(Exception ex) {	
caught exception while verifying group region 

}	};	MetaTableAccessor.fullScanRegions(conn, visitor);	if (foundRegions.size() < 1 && rootMetaFound && !createSent && nsFound.get()) {	createRSGroupTable();	createSent = true;	}	LOG.info("RSGroup table=" + RSGROUP_TABLE_NAME + " isOnline=" + found.get() + ", regionCount=" + foundRegions.size() + ", assignCount=" + assignedRegions.size() + ", rootMetaFound=" + rootMetaFound);	found.set(found.get() && assignedRegions.size() == foundRegions.size() && foundRegions.size() > 0);	} else {	
waiting for catalog tables to come online 

if (foundRegions.size() < 1 && rootMetaFound && !createSent && nsFound.get()) {	createRSGroupTable();	createSent = true;	}	LOG.info("RSGroup table=" + RSGROUP_TABLE_NAME + " isOnline=" + found.get() + ", regionCount=" + foundRegions.size() + ", assignCount=" + assignedRegions.size() + ", rootMetaFound=" + rootMetaFound);	found.set(found.get() && assignedRegions.size() == foundRegions.size() && foundRegions.size() > 0);	} else {	found.set(false);	}	if (found.get()) {	
with group table online refreshing cached information 

}	if (found.get()) {	RSGroupInfoManagerImpl.this.refresh(true);	online = true;	RSGroupInfoManagerImpl.this.flushConfig();	}	} catch (RuntimeException e) {	throw e;	} catch(Exception e) {	found.set(false);	
failed to perform check 

RSGroupInfoManagerImpl.this.flushConfig();	}	} catch (RuntimeException e) {	throw e;	} catch(Exception e) {	found.set(false);	}	try {	Thread.sleep(100);	} catch (InterruptedException e) {	
sleep interrupted 

========================= hbase sample_3347 =========================

Result result = table2.get(get);	cellScanner = result.cellScanner();	boolean advance = cellScanner.advance();	if (nullExpected) {	assertTrue(!advance);	return null;	}	current = cellScanner.current();	assertArrayEquals(CellUtil.cloneRow(current), row);	for (Tag tag : TestCoprocessorForTagsAtSink.tags) {	
the tag type is 

========================= hbase sample_1395 =========================

for (HStoreFile file : filesToCompact) {	if(allFiles && (file.getModificationTimeStamp() < oldestHFileTimeStampToKeepMVCC)) {	if(fd.minSeqIdToKeep < file.getMaxMemStoreTS()) {	fd.minSeqIdToKeep = file.getMaxMemStoreTS();	}	}	long seqNum = file.getMaxSequenceId();	fd.maxSeqId = Math.max(fd.maxSeqId, seqNum);	StoreFileReader r = file.getReader();	if (r == null) {	
null reader for 

========================= hbase sample_2690 =========================

private void testRetriesExhaustedFailure(final TableName tableName, final MockRSExecutor executor) throws Exception {	final RegionInfo hri = createRegionInfo(tableName, 1);	collectAssignmentManagerMetrics();	rsDispatcher.setMockRsExecutor(executor);	try {	waitOnFuture(submitProcedure(am.createAssignProcedure(hri)));	fail("unexpected assign completion");	} catch (RetriesExhaustedException e) {	
expected exception from assign operation 

private void testFailedOpen(final TableName tableName, final MockRSExecutor executor) throws Exception {	final RegionInfo hri = createRegionInfo(tableName, 1);	rsDispatcher.setMockRsExecutor(executor);	try {	waitOnFuture(submitProcedure(am.createAssignProcedure(hri)));	fail("unexpected assign completion");	} catch (RetriesExhaustedException e) {	
region state 

private void testFailedOpen(final TableName tableName, final MockRSExecutor executor) throws Exception {	final RegionInfo hri = createRegionInfo(tableName, 1);	rsDispatcher.setMockRsExecutor(executor);	try {	waitOnFuture(submitProcedure(am.createAssignProcedure(hri)));	fail("unexpected assign completion");	} catch (RetriesExhaustedException e) {	
expected exception from assign operation 

rsDispatcher.setMockRsExecutor(executor);	AssignProcedure[] assignments = new AssignProcedure[nregions];	long st = System.currentTimeMillis();	bulkSubmit(assignments);	for (int i = 0; i < assignments.length; ++i) {	ProcedureTestingUtility.waitProcedure( master.getMasterProcedureExecutor(), assignments[i]);	assertTrue(assignments[i].toString(), assignments[i].isSuccess());	}	long et = System.currentTimeMillis();	float sec = ((et - st) / 1000.0f);	
t assigning dprocs in s sec 

private byte[] waitOnFuture(final Future<byte[]> future) throws Exception {	try {	return future.get(5, TimeUnit.SECONDS);	} catch (ExecutionException e) {	
ExecutionException 

private void doRestart(final ServerName serverName) {	try {	this.master.restartRegionServer(serverName);	} catch (IOException e) {	
can not restart rs with new startcode 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	if (this.invocations++ > 0) {	return super.execOpenRegion(server, openReq);	}	LOG.info("Return null response from serverName=" + server + "; means STUCK...TODO timeout");	executor.schedule(new Runnable() {	public void run() {	
sending in crash of 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	if (this.invocations++ > 0) {	return super.execOpenRegion(server, openReq);	}	LOG.info("Return null response from serverName=" + server + "; means STUCK...TODO timeout");	executor.schedule(new Runnable() {	public void run() {	
restarting rs of 

protected CloseRegionResponse execCloseRegion(ServerName server, byte[] regionName) throws IOException {	switch (this.invocations++) {	case 0: throw new NotServingRegionException("Fake");	case 1: throw new RegionServerAbortedException("Fake!");	case 2: throw new RegionServerStoppedException("Fake!");	case 3: throw new ServerNotRunningYetException("Fake!");	case 4: LOG.info("Return null response from serverName=" + server + "; means STUCK...TODO timeout");	executor.schedule(new Runnable() {	public void run() {	
sending in crash of 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	switch (rand.nextInt(6)) {	
return opened response 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	switch (rand.nextInt(6)) {	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.OPENED;	
return transition report that opened already opened response 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	switch (rand.nextInt(6)) {	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.OPENED;	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.ALREADY_OPENED;	
return transition report that failed open failed opening response 

protected RegionOpeningState execOpenRegion(final ServerName server, RegionOpenInfo openReq) throws IOException {	switch (rand.nextInt(6)) {	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.OPENED;	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.ALREADY_OPENED;	sendTransitionReport(server, openReq.getRegion(), TransitionCode.FAILED_OPEN);	return OpenRegionResponse.RegionOpeningState.FAILED_OPENING;	}	
return null as response means proc stuck so we send in a crash report after a few seconds 

switch (rand.nextInt(6)) {	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.OPENED;	sendTransitionReport(server, openReq.getRegion(), TransitionCode.OPENED);	return OpenRegionResponse.RegionOpeningState.ALREADY_OPENED;	sendTransitionReport(server, openReq.getRegion(), TransitionCode.FAILED_OPEN);	return OpenRegionResponse.RegionOpeningState.FAILED_OPENING;	}	executor.schedule(new Runnable() {	public void run() {	
delayed crashing of 

========================= hbase sample_1815 =========================

protected List<String> filterMissingFiles(List<String> incrBackupFileList) throws IOException {	List<String> list = new ArrayList<String>();	for (String file : incrBackupFileList) {	Path p = new Path(file);	if (fs.exists(p) || isActiveWalPath(p)) {	list.add(file);	} else {	
can t find file 

tgtFs = FileSystem.get(new URI(backupInfo.getBackupRootDir()), conf);	} catch (URISyntaxException use) {	throw new IOException("Unable to get FileSystem", use);	}	Path rootdir = FSUtils.getRootDir(conf);	Path tgtRoot = new Path(new Path(backupInfo.getBackupRootDir()), backupId);	for (Map.Entry<TableName, Map<String, Map<String, List<Pair<String, Boolean>>>>> tblEntry : map.entrySet()) {	TableName srcTable = tblEntry.getKey();	int srcIdx = getIndex(srcTable, sTableList);	if (srcIdx < 0) {	
couldn t find in source table list 

int idx = file.lastIndexOf("/");	String filename = file;	if (idx > 0) {	filename = file.substring(idx+1);	}	Path p = new Path(famDir, filename);	Path tgt = new Path(tgtFam, filename);	Path archive = new Path(archiveDir, filename);	if (fs.exists(p)) {	if (LOG.isTraceEnabled()) {	
found bulk hfile in for 

if (idx > 0) {	filename = file.substring(idx+1);	}	Path p = new Path(famDir, filename);	Path tgt = new Path(tgtFam, filename);	Path archive = new Path(archiveDir, filename);	if (fs.exists(p)) {	if (LOG.isTraceEnabled()) {	}	if (LOG.isTraceEnabled()) {	
copying to 

Path p = new Path(famDir, filename);	Path tgt = new Path(tgtFam, filename);	Path archive = new Path(archiveDir, filename);	if (fs.exists(p)) {	if (LOG.isTraceEnabled()) {	}	if (LOG.isTraceEnabled()) {	}	activeFiles.add(p.toString());	} else if (fs.exists(archive)){	
copying archive to 

List<String> newlyArchived = new ArrayList<String>();	for (String spath : activeFiles) {	if (!fs.exists(new Path(spath))) {	newlyArchived.add(spath);	}	}	if (newlyArchived.size() > 0) {	activeFiles.removeAll(newlyArchived);	archiveFiles.addAll(newlyArchived);	}	
files have been archived 

public void execute() throws IOException {	try {	beginBackup(backupManager, backupInfo);	backupInfo.setPhase(BackupPhase.PREPARE_INCREMENTAL);	
for incremental backup current table set is 

protected void incrementalCopyHFiles(String[] files, String backupDest) throws IOException {	try {	LOG.debug("Incremental copy HFiles is starting. dest="+backupDest);	backupInfo.setPhase(BackupPhase.INCREMENTAL_COPY);	String[] strArr = new String[files.length + 1];	System.arraycopy(files, 0, strArr, 0, files.length);	strArr[strArr.length - 1] = backupDest;	String jobname = "Incremental_Backup-HFileCopy-" + backupInfo.getBackupId();	if (LOG.isDebugEnabled()) {	
setting incremental copy hfiles job name to 

String[] strArr = new String[files.length + 1];	System.arraycopy(files, 0, strArr, 0, files.length);	strArr[strArr.length - 1] = backupDest;	String jobname = "Incremental_Backup-HFileCopy-" + backupInfo.getBackupId();	if (LOG.isDebugEnabled()) {	}	conf.set(JOB_NAME_CONF_KEY, jobname);	BackupCopyJob copyService = BackupRestoreFactory.getBackupCopyJob(conf);	int res = copyService.copy(backupInfo, backupManager, conf, BackupType.INCREMENTAL, strArr);	if (res != 0) {	
copy incremental hfile files failed with return code 

strArr[strArr.length - 1] = backupDest;	String jobname = "Incremental_Backup-HFileCopy-" + backupInfo.getBackupId();	if (LOG.isDebugEnabled()) {	}	conf.set(JOB_NAME_CONF_KEY, jobname);	BackupCopyJob copyService = BackupRestoreFactory.getBackupCopyJob(conf);	int res = copyService.copy(backupInfo, backupManager, conf, BackupType.INCREMENTAL, strArr);	if (res != 0) {	throw new IOException("Failed copy from " + StringUtils.join(files, ',') + " to " + backupDest);	}	
incremental copy hfiles from to finished 

protected void deleteBulkLoadDirectory() throws IOException {	Path path = getBulkOutputDir();	boolean result = fs.delete(path, true);	if (!result) {	
could not delete 

protected void convertWALsToHFiles() throws IOException {	List<String> incrBackupFileList = backupInfo.getIncrBackupFileList();	Set<TableName> tableSet = backupManager.getIncrementalBackupTableSet();	incrBackupFileList = filterMissingFiles(incrBackupFileList);	for (TableName table : tableSet) {	if (tableExists(table, conn)) {	walToHFiles(incrBackupFileList, table);	} else {	
table does not exists skipping in wal converter 

========================= hbase sample_564 =========================

public boolean saslConnect(InputStream inS, OutputStream outS) throws IOException {	DataInputStream inStream = new DataInputStream(new BufferedInputStream(inS));	DataOutputStream outStream = new DataOutputStream(new BufferedOutputStream(outS));	try {	byte[] saslToken = getInitialResponse();	if (saslToken != null) {	outStream.writeInt(saslToken.length);	outStream.write(saslToken, 0, saslToken.length);	outStream.flush();	if (LOG.isDebugEnabled()) {	
have sent token of size from initsaslcontext 

}	}	if (!isComplete()) {	readStatus(inStream);	int len = inStream.readInt();	if (len == SaslUtil.SWITCH_TO_SIMPLE_AUTH) {	if (!fallbackAllowed) {	throw new IOException("Server asks us to fall back to SIMPLE auth, " + "but this client is configured to only allow secure connections.");	}	if (LOG.isDebugEnabled()) {	
server asks us to fall back to simple auth 

if (!fallbackAllowed) {	throw new IOException("Server asks us to fall back to SIMPLE auth, " + "but this client is configured to only allow secure connections.");	}	if (LOG.isDebugEnabled()) {	}	dispose();	return false;	}	saslToken = new byte[len];	if (LOG.isDebugEnabled()) {	
will read input token of size for processing by initsaslcontext 

}	saslToken = new byte[len];	if (LOG.isDebugEnabled()) {	}	inStream.readFully(saslToken);	}	while (!isComplete()) {	saslToken = evaluateChallenge(saslToken);	if (saslToken != null) {	if (LOG.isDebugEnabled()) {	
will send token of size from initsaslcontext 

if (LOG.isDebugEnabled()) {	}	outStream.writeInt(saslToken.length);	outStream.write(saslToken, 0, saslToken.length);	outStream.flush();	}	if (!isComplete()) {	readStatus(inStream);	saslToken = new byte[inStream.readInt()];	if (LOG.isDebugEnabled()) {	
will read input token of size for processing by initsaslcontext 

}	if (!isComplete()) {	readStatus(inStream);	saslToken = new byte[inStream.readInt()];	if (LOG.isDebugEnabled()) {	}	inStream.readFully(saslToken);	}	}	if (LOG.isDebugEnabled()) {	
sasl client context established negotiated qop 

private void readNextRpcPacket() throws IOException {	
reading next wrapped rpc packet 

private void readNextRpcPacket() throws IOException {	DataInputStream dis = new DataInputStream(in);	int rpcLen = dis.readInt();	byte[] rpcBuf = new byte[rpcLen];	dis.readFully(rpcBuf);	rpcBuf = cryptoAES.unwrap(rpcBuf, 0, rpcBuf.length);	if (LOG.isDebugEnabled()) {	
unwrapping token of length 

public void write(byte[] buf, int off, int len) throws IOException {	if (LOG.isDebugEnabled()) {	
wrapping token of length 

========================= hbase sample_134 =========================

if (midKeyMetadata != null) blockStream.write(midKeyMetadata);	blockWriter.writeHeaderAndData(out);	if (cacheConf != null) {	HFileBlock blockForCaching = blockWriter.getBlockForCaching(cacheConf);	cacheConf.getBlockCache().cacheBlock(new BlockCacheKey(nameForCaching, rootLevelIndexPos, true, blockForCaching.getBlockType()), blockForCaching);	}	}	totalBlockOnDiskSize += blockWriter.getOnDiskSizeWithoutHeader();	totalBlockUncompressedSize += blockWriter.getUncompressedSizeWithoutHeader();	if (LOG.isTraceEnabled()) {	
wrote a level index with root level at pos root level entries total entries on disk size total uncompressed size 

}	return rootLevelIndexPos;	}	public void writeSingleLevelIndex(DataOutput out, String description) throws IOException {	expectNumLevels(1);	if (!singleLevelOnly) throw new IOException("Single-level mode is turned off");	if (rootChunk.getNumEntries() > 0) throw new IOException("Root-level entries already added in " + "single-level mode");	rootChunk = curInlineChunk;	curInlineChunk = new BlockIndexChunk();	if (LOG.isTraceEnabled()) {	
wrote a single level index with entries bytes 

========================= hbase sample_2385 =========================

do {	PrivilegedExceptionAction<VisibilityLabelsResponse> action = new PrivilegedExceptionAction<VisibilityLabelsResponse>() {	public VisibilityLabelsResponse run() throws Exception {	String[] labels = { SECRET, CONFIDENTIAL, PRIVATE, "ABC", "XYZ" };	try (Connection conn = ConnectionFactory.createConnection(conf)) {	VisibilityLabelsResponse resp = VisibilityClient.addLabels(conn, labels);	List<RegionActionResult> results = resp.getResultList();	if (results.get(0).hasException()) {	NameBytesPair pair = results.get(0).getException();	Throwable t = ProtobufUtil.toException(pair);	
got exception writing labels 

public VisibilityLabelsResponse run() throws Exception {	String[] labels = { SECRET, CONFIDENTIAL, PRIVATE, "ABC", "XYZ" };	try (Connection conn = ConnectionFactory.createConnection(conf)) {	VisibilityLabelsResponse resp = VisibilityClient.addLabels(conn, labels);	List<RegionActionResult> results = resp.getResultList();	if (results.get(0).hasException()) {	NameBytesPair pair = results.get(0).getException();	Throwable t = ProtobufUtil.toException(pair);	if (t instanceof VisibilityControllerNotReadyException) {	vcInitialized.set(false);	
visibilitycontroller was not yet initialized 

List<RegionActionResult> results = resp.getResultList();	if (results.get(0).hasException()) {	NameBytesPair pair = results.get(0).getException();	Throwable t = ProtobufUtil.toException(pair);	if (t instanceof VisibilityControllerNotReadyException) {	vcInitialized.set(false);	Threads.sleep(10);	} else {	vcInitialized.set(true);	}	
new labels added 

========================= hbase sample_1403 =========================

cipherProvider = provider.getConf().get(CIPHER_PROVIDER_KEY);	rngAlgorithm = provider.getConf().get(RNG_ALGORITHM_KEY, "SHA1PRNG");	String rngProvider = provider.getConf().get(RNG_PROVIDER_KEY);	try {	if (rngProvider != null) {	rng = SecureRandom.getInstance(rngAlgorithm, rngProvider);	} else {	rng = SecureRandom.getInstance(rngAlgorithm);	}	} catch (GeneralSecurityException e) {	
could not instantiate specified rng falling back to default 

========================= hbase sample_1053 =========================

private void complete(MasterProcedureEnv env, Throwable error) {	if (event == null) {	
procedure event for is null maybe the procedure is created when recovery 

private void complete(MasterProcedureEnv env, Throwable error) {	if (event == null) {	return;	}	if (error != null) {	
refresh peer for on failed 

private void complete(MasterProcedureEnv env, Throwable error) {	if (event == null) {	return;	}	if (error != null) {	this.succ = false;	} else {	
refresh peer for on suceeded 

protected synchronized Procedure<MasterProcedureEnv>[] execute(MasterProcedureEnv env) throws ProcedureYieldException, ProcedureSuspendedException, InterruptedException {	if (dispatched) {	if (succ) {	return null;	}	dispatched = false;	}	if (!env.getRemoteDispatcher().addOperationToNode(targetServer, this)) {	
can not add remote operation for refreshing peer for to this usually because the server is already dead give up and mark the procedure as complete 

========================= hbase sample_2852 =========================

public void testHMConnectorServerWhenStopMaster() throws Exception {	conf.set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, JMXListener.class.getName() + "," + MyAccessController.class.getName());	conf.setInt("master.rmi.registry.port", rmiRegistryPort);	UTIL.startMiniCluster();	admin = UTIL.getConnection().getAdmin();	boolean accessDenied = false;	try {	hasAccess = false;	
stopping hmaster 

public void testHMConnectorServerWhenStopMaster() throws Exception {	conf.set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, JMXListener.class.getName() + "," + MyAccessController.class.getName());	conf.setInt("master.rmi.registry.port", rmiRegistryPort);	UTIL.startMiniCluster();	admin = UTIL.getConnection().getAdmin();	boolean accessDenied = false;	try {	hasAccess = false;	admin.stopMaster();	} catch (AccessDeniedException e) {	
exception occurred while stopping hmaster 

public void testRSConnectorServerWhenStopRegionServer() throws Exception {	conf.set(CoprocessorHost.REGIONSERVER_COPROCESSOR_CONF_KEY, JMXListener.class.getName() + "," + MyAccessController.class.getName());	conf.setInt("regionserver.rmi.registry.port", rmiRegistryPort);	UTIL.startMiniCluster();	admin = UTIL.getConnection().getAdmin();	hasAccess = false;	ServerName serverName = UTIL.getHBaseCluster().getRegionServer(0).getServerName();	
stopping region server 

public void testHMConnectorServerWhenShutdownCluster() throws Exception {	conf.set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, JMXListener.class.getName() + "," + MyAccessController.class.getName());	conf.setInt("master.rmi.registry.port", rmiRegistryPort);	UTIL.startMiniCluster();	admin = UTIL.getConnection().getAdmin();	boolean accessDenied = false;	try {	hasAccess = false;	
stopping hmaster 

public void testHMConnectorServerWhenShutdownCluster() throws Exception {	conf.set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, JMXListener.class.getName() + "," + MyAccessController.class.getName());	conf.setInt("master.rmi.registry.port", rmiRegistryPort);	UTIL.startMiniCluster();	admin = UTIL.getConnection().getAdmin();	boolean accessDenied = false;	try {	hasAccess = false;	admin.shutdown();	} catch (AccessDeniedException e) {	
exception occurred while stopping hmaster 

========================= hbase sample_1287 =========================

Thread.sleep(waitForUnbalanceMilliSec);	ServerName metaServer = cluster.getServerHoldingMeta();	for (ServerName targetServer: targetServers) {	if (context.isStopping()) {	break;	}	if (killedServers.size() >= liveCount) {	break;	}	if (!killMetaRs && targetServer.equals(metaServer)) {	
not killing server because it holds hbase meta 

========================= hbase sample_3310 =========================

public void run() {	try {	while(!this.stop) {	LOG.info("Before " + this.getName()+ ", count=" + this.count);	metaTask();	this.count += 1;	LOG.info("After " + this.getName() + ", count=" + this.count);	Thread.sleep(100);	}	} catch (Throwable t) {	
failed 

public void testMetaScanner() throws Exception {	
starting 

========================= hbase sample_2014 =========================

}	if (!tmp) {	builder.commit();	}	for (Path path: files) {	Iterable<FileStatus> nonSnapshotFiles = getNonSnapshotFiles(cache, path);	assertFalse("Cache didn't find " + path.getName(), Iterables.contains(nonSnapshotFiles, path.getName()));	}	FSUtils.logFileSystemState(fs, rootDir, LOG);	if (removeOnExit) {	
deleting snapshot 

========================= hbase sample_1792 =========================

assertTrue(regions[i] + " region dir does not exist", fs.exists(regionDir));	assertTrue(unwantedRegionDirs.remove(regionDir));	List<Path> allFamilyDirs = FSUtils.getFamilyDirs(fs, regionDir);	for (int j = 0; j < family.length; ++j) {	final Path familyDir = new Path(regionDir, family[j]);	if (hasFamilyDirs) {	assertTrue(family[j] + " family dir does not exist", fs.exists(familyDir));	assertTrue(allFamilyDirs.remove(familyDir));	} else {	if (!fs.exists(familyDir)) {	
family dir does not exist 

assertTrue(allFamilyDirs.remove(familyDir));	} else {	if (!fs.exists(familyDir)) {	}	allFamilyDirs.remove(familyDir);	}	}	assertTrue("found extraneous families: " + allFamilyDirs, allFamilyDirs.isEmpty());	}	assertTrue("found extraneous regions: " + unwantedRegionDirs, unwantedRegionDirs.isEmpty());	
table directory layout is as expected 

private static int countMetaRegions(final HMaster master, final TableName tableName) throws IOException {	final AtomicInteger actualRegCount = new AtomicInteger(0);	final MetaTableAccessor.Visitor visitor = new MetaTableAccessor.Visitor() {	public boolean visit(Result rowResult) throws IOException {	RegionLocations list = MetaTableAccessor.getRegionLocations(rowResult);	if (list == null) {	
no serialized regioninfo in 

public static void testRollbackAndDoubleExecution( final ProcedureExecutor<MasterProcedureEnv> procExec, final long procId, final int lastStep) throws Exception {	testRecoveryAndDoubleExecution(procExec, procId, lastStep, false);	InjectAbortOnLoadListener abortListener = new InjectAbortOnLoadListener(procExec);	abortListener.addProcId(procId);	procExec.registerListener(abortListener);	try {	for (int i = 0; !procExec.isFinished(procId); ++i) {	
restart rollback state 

========================= hbase sample_1842 =========================

FSDataInputStream is = fs.open(path);	HFileContext meta = new HFileContextBuilder() .withHBaseCheckSum(true) .withIncludesMvcc(includesMemstoreTS) .withIncludesTags(includesTag) .withCompression(algo).build();	HFileBlock.FSReader hbr = new HFileBlock.FSReaderImpl(is, totalSize, meta);	long curOffset = 0;	for (int i = 0; i < NUM_TEST_BLOCKS; ++i) {	if (!pread) {	assertEquals(is.getPos(), curOffset + (i == 0 ? 0 : HConstants.HFILEBLOCK_HEADER_SIZE));	}	assertEquals(expectedOffsets.get(i).longValue(), curOffset);	if (detailedLogging) {	
reading block at offset 

long curOffset = 0;	for (int i = 0; i < NUM_TEST_BLOCKS; ++i) {	if (!pread) {	assertEquals(is.getPos(), curOffset + (i == 0 ? 0 : HConstants.HFILEBLOCK_HEADER_SIZE));	}	assertEquals(expectedOffsets.get(i).longValue(), curOffset);	if (detailedLogging) {	}	HFileBlock b = hbr.readBlockData(curOffset, -1, pread, false);	if (detailedLogging) {	
block 

if (cacheOnWrite) {	b = b.unpack(meta, hbr);	ByteBuff bufRead = b.getBufferReadOnly();	ByteBuffer bufExpected = expectedContents.get(i);	boolean bytesAreCorrect = Bytes.compareTo(bufRead.array(), bufRead.arrayOffset(), bufRead.limit() - b.totalChecksumBytes(), bufExpected.array(), bufExpected.arrayOffset(), bufExpected.limit()) == 0;	String wrongBytesMsg = "";	if (!bytesAreCorrect) {	wrongBytesMsg = "Expected bytes in block #" + i + " (algo=" + algo + ", pread=" + pread + ", cacheOnWrite=" + cacheOnWrite + "):\n";	wrongBytesMsg += Bytes.toStringBinary(bufExpected.array(), bufExpected.arrayOffset(), Math.min(32 + 10, bufExpected.limit())) + ", actual:\n" + Bytes.toStringBinary(bufRead.array(), bufRead.arrayOffset(), Math.min(32 + 10, bufRead.limit()));	if (detailedLogging) {	
expected header found header 

if (cacheOnWrite) {	b = b.unpack(meta, hbr);	ByteBuff bufRead = b.getBufferReadOnly();	ByteBuffer bufExpected = expectedContents.get(i);	boolean bytesAreCorrect = Bytes.compareTo(bufRead.array(), bufRead.arrayOffset(), bufRead.limit() - b.totalChecksumBytes(), bufExpected.array(), bufExpected.arrayOffset(), bufExpected.limit()) == 0;	String wrongBytesMsg = "";	if (!bytesAreCorrect) {	wrongBytesMsg = "Expected bytes in block #" + i + " (algo=" + algo + ", pread=" + pread + ", cacheOnWrite=" + cacheOnWrite + "):\n";	wrongBytesMsg += Bytes.toStringBinary(bufExpected.array(), bufExpected.arrayOffset(), Math.min(32 + 10, bufExpected.limit())) + ", actual:\n" + Bytes.toStringBinary(bufRead.array(), bufRead.arrayOffset(), Math.min(32 + 10, bufRead.limit()));	if (detailedLogging) {	
bufread offset limit expected offset limit 

LOG.error("Error in client " + clientId + " trying to read block at " + offset + ", pread=" + pread + ", withOnDiskSize=" + withOnDiskSize, ex);	return false;	}	assertEquals(types.get(blockId), b.getBlockType());	assertEquals(expectedSize, b.getOnDiskSizeWithHeader());	assertEquals(offset, b.getOffset());	++numBlocksRead;	if (pread) ++numPositionalRead;	if (withOnDiskSize) ++numWithOnDiskSize;	}	
client successfully read blocks with pread with ondisksize specified 

if (expectedPrevOffsets != null) {	Long prevOffset = prevOffsetByType.get(bt);	expectedPrevOffsets.add(prevOffset != null ? prevOffset : -1);	prevOffsetByType.put(bt, os.getPos());	}	expectedTypes.add(bt);	hbw.writeHeaderAndData(os);	totalSize += hbw.getOnDiskSizeWithHeader();	if (cacheOnWrite) expectedContents.add(hbw.cloneUncompressedBufferWithHeader());	if (detailedLogging) {	
written block of type uncompressed size packed size at offset 

========================= hbase sample_1511 =========================

public void restart(byte[] firstRow) throws IOException {	currentScan = new Scan(scan);	currentScan.withStartRow(firstRow);	currentScan.setScanMetricsEnabled(true);	if (this.scanner != null) {	if (logScannerActivity) {	
closing the previously opened scanner object 

public void close() {	if (this.scanner != null) {	this.scanner.close();	}	try {	this.htable.close();	} catch (IOException ioe) {	
error closing table 

if (key == null) key = new ImmutableBytesWritable();	if (value == null) value = new Result();	try {	try {	value = this.scanner.next();	if (value != null && value.isStale()) numStale++;	if (logScannerActivity) {	rowcount ++;	if (rowcount >= logPerRowCount) {	long now = System.currentTimeMillis();	
mapper took ms to process rows 

if (rowcount >= logPerRowCount) {	long now = System.currentTimeMillis();	timestamp = now;	rowcount = 0;	}	}	} catch (IOException e) {	if (e instanceof DoNotRetryIOException) {	throw e;	}	
recovered from 

long now = System.currentTimeMillis();	timestamp = now;	rowcount = 0;	}	}	} catch (IOException e) {	if (e instanceof DoNotRetryIOException) {	throw e;	}	if (lastSuccessfulRow == null) {	
we are restarting the first next invocation if your mapper has restarted a few other times like this then you should consider killing this job and investigate why it s taking so long 

if (value != null && value.size() > 0) {	key.set(value.getRow());	lastSuccessfulRow = key.get();	return true;	}	updateCounters();	return false;	} catch (IOException ioe) {	if (logScannerActivity) {	long now = System.currentTimeMillis();	
mapper took ms to process rows 

return;	}	try {	for (Map.Entry<String, Long> entry:scanMetrics.getMetricsMap().entrySet()) {	Counter ct = (Counter)getCounter.invoke(context, HBASE_COUNTER_GROUP_NAME, entry.getKey());	ct.increment(entry.getValue());	}	((Counter) getCounter.invoke(context, HBASE_COUNTER_GROUP_NAME, "NUM_SCANNER_RESTARTS")).increment(numScannerRestarts);	((Counter) getCounter.invoke(context, HBASE_COUNTER_GROUP_NAME, "NUM_SCAN_RESULTS_STALE")).increment(numStale);	} catch (Exception e) {	
can t update counter 

========================= hbase sample_3469 =========================

Field handlerCountField = rpcExecutor.getClass().getSuperclass().getSuperclass().getDeclaredField("handlerCount");	handlerCountField.setAccessible(true);	handlerCountField.set(rpcExecutor, 0);	Field numCallQueuesField = rpcExecutor.getClass().getSuperclass().getSuperclass().getDeclaredField("numCallQueues");	numCallQueuesField.setAccessible(true);	numCallQueuesField.set(rpcExecutor, 1);	Field currentQueueLimitField = rpcExecutor.getClass().getSuperclass().getSuperclass().getDeclaredField("currentQueueLimit");	currentQueueLimitField.setAccessible(true);	currentQueueLimitField.set(rpcExecutor, 100);	} catch (NoSuchFieldException e) {	
no such field exception 

handlerCountField.setAccessible(true);	handlerCountField.set(rpcExecutor, 0);	Field numCallQueuesField = rpcExecutor.getClass().getSuperclass().getSuperclass().getDeclaredField("numCallQueues");	numCallQueuesField.setAccessible(true);	numCallQueuesField.set(rpcExecutor, 1);	Field currentQueueLimitField = rpcExecutor.getClass().getSuperclass().getSuperclass().getDeclaredField("currentQueueLimit");	currentQueueLimitField.setAccessible(true);	currentQueueLimitField.set(rpcExecutor, 100);	} catch (NoSuchFieldException e) {	} catch (IllegalAccessException e) {	
illegal access exception 

while (work.size() < 8) {	Thread.sleep(100);	}	int seqSum = 0;	int totalTime = 0;	for (int i = 0; i < work.size(); ++i) {	LOG.debug("Request i=" + i + " value=" + work.get(i));	seqSum += work.get(i);	totalTime += seqSum;	}	
total time 

private CallRunner getMockedCallRunner(long timestamp, final long sleepTime) throws IOException {	ServerCall putCall = new ServerCall(1, null, null, RPCProtos.RequestHeader.newBuilder().setMethodName("mutate").build(), RequestConverter.buildMutateRequest(Bytes.toBytes("abc"), new Put(Bytes.toBytes("row"))), null, null, 9, null, timestamp, 0, null, null, null) {	public void sendResponseIfReady() throws IOException {	}	};	CallRunner cr = new CallRunner(null, putCall) {	public void run() {	if (sleepTime <= 0) return;	try {	
sleeping for 

private CallRunner getMockedCallRunner(long timestamp, final long sleepTime) throws IOException {	ServerCall putCall = new ServerCall(1, null, null, RPCProtos.RequestHeader.newBuilder().setMethodName("mutate").build(), RequestConverter.buildMutateRequest(Bytes.toBytes("abc"), new Put(Bytes.toBytes("row"))), null, null, 9, null, timestamp, 0, null, null, null) {	public void sendResponseIfReady() throws IOException {	}	};	CallRunner cr = new CallRunner(null, putCall) {	public void run() {	if (sleepTime <= 0) return;	try {	Thread.sleep(sleepTime);	
done sleeping for 

========================= hbase sample_1907 =========================

public void testFullBackupWithFailuresAndRestore() throws Exception {	autoRestoreOnFailure = false;	conf1.set(TableBackupClient.BACKUP_CLIENT_IMPL_CLASS, FullTableBackupClientForTest.class.getName());	int maxStage = Stage.values().length -1;	for (int stage = 0; stage < maxStage; stage++) {	
running stage 

========================= hbase sample_533 =========================

private static long getMergedRegionIdTimestamp(final RegionInfo regionToMergeA, final RegionInfo regionToMergeB) {	long rid = EnvironmentEdgeManager.currentTime();	if (rid < regionToMergeA.getRegionId() || rid < regionToMergeB.getRegionId()) {	
clock skew merging regions id are and but current time here is 

case MERGE_TABLE_REGIONS_CREATE_MERGED_REGION: cleanupMergedRegion(env);	break;	case MERGE_TABLE_REGIONS_CLOSE_REGIONS: rollbackCloseRegionsForMerge(env);	break;	case MERGE_TABLE_REGIONS_PRE_MERGE_OPERATION: postRollBackMergeRegions(env);	break;	case MERGE_TABLE_REGIONS_PREPARE: break;	default: throw new UnsupportedOperationException(this + " unhandled state=" + state);	}	} catch (Exception e) {	
failed rollback attempt step for merging the regions in table 

RegionState regionStateA = regionStates.getRegionState(regionsToMerge[0].getEncodedName());	RegionState regionStateB = regionStates.getRegionState(regionsToMerge[1].getEncodedName());	if (regionStateA == null || regionStateB == null) {	throw new UnknownRegionException( regionStateA == null ? regionsToMerge[0].getEncodedName() : regionsToMerge[1].getEncodedName());	}	if (!regionStateA.isOpened() || !regionStateB.isOpened()) {	throw new MergeRegionException( "Unable to merge regions not online " + regionStateA + ", " + regionStateB);	}	if (!env.getMasterServices().isSplitOrMergeEnabled(MasterSwitchType.MERGE)) {	String regionsStr = Arrays.deepToString(regionsToMerge);	
merge switch is off skip merge of 

private void preMergeRegionsCommit(final MasterProcedureEnv env) throws IOException {	final MasterCoprocessorHost cpHost = env.getMasterCoprocessorHost();	if (cpHost != null) {	final List<Mutation> metaEntries = new ArrayList<Mutation>();	cpHost.preMergeRegionsCommit(regionsToMerge, metaEntries, getUser());	try {	for (Mutation p : metaEntries) {	RegionInfo.parseRegionName(p.getRow());	}	} catch (IOException e) {	
row key of mutation from coprocessor is not parsable as region name mutations from coprocessor should only be for hbase meta table 

========================= hbase sample_2782 =========================

private void verify(final Table table) throws IOException {	Scan scan = new Scan();	scan.addColumn(FAMILY_NAME, COLUMN_NAME);	scan.setMaxVersions(1);	ResultScanner scanner = table.getScanner(scan);	for (Result r: scanner) {	for (Cell kv : r.listCells()) {	
t t t t 

========================= hbase sample_3384 =========================

tablesToIndex = new HashMap<>();	tables = new ArrayList<>();	this.rackManager = rackManager != null ? rackManager : new DefaultRackManager();	numRegions = 0;	List<List<Integer>> serversPerHostList = new ArrayList<>();	List<List<Integer>> serversPerRackList = new ArrayList<>();	this.clusterState = clusterState;	this.regionFinder = regionFinder;	for (ServerName sn : clusterState.keySet()) {	if (sn == null) {	
todo enable trace on baseloadbalancer empty servername skipping unassigned regions 

tables = new ArrayList<>();	this.rackManager = rackManager != null ? rackManager : new DefaultRackManager();	numRegions = 0;	List<List<Integer>> serversPerHostList = new ArrayList<>();	List<List<Integer>> serversPerRackList = new ArrayList<>();	this.clusterState = clusterState;	this.regionFinder = regionFinder;	for (ServerName sn : clusterState.keySet()) {	if (sn == null) {	if (LOG.isTraceEnabled()) {	
empty servername 

serverIndexToRackIndex = new int[numServers];	regionsPerServer = new int[numServers][];	regionsPerHost = new int[numHosts][];	regionsPerRack = new int[numRacks][];	primariesOfRegionsPerServer = new int[numServers][];	primariesOfRegionsPerHost = new int[numHosts][];	primariesOfRegionsPerRack = new int[numRacks][];	int tableIndex = 0, regionIndex = 0, regionPerServerIndex = 0;	for (Entry<ServerName, List<RegionInfo>> entry : clusterState.entrySet()) {	if (entry.getKey() == null) {	
servername is null skipping 

protected boolean needsBalance(Cluster c) {	ClusterLoadState cs = new ClusterLoadState(c.clusterState);	if (cs.getNumServers() < MIN_SERVER_BALANCE) {	if (LOG.isDebugEnabled()) {	
not running balancer because only active regionserver s 

if (!masterRegions.isEmpty()) {	regions = new ArrayList<>(regions);	regions.removeAll(masterRegions);	}	}	if (regions == null || regions.isEmpty()) {	return assignments;	}	int numServers = servers == null ? 0 : servers.size();	if (numServers == 0) {	
wanted to do round robin assignment but no servers to assign to 

if (shouldBeOnMaster(regionInfo)) {	return masterServerName;	}	if (!LoadBalancer.isTablesOnMaster(getConf())) {	servers = new ArrayList<>(servers);	servers.remove(masterServerName);	}	}	int numServers = servers == null ? 0 : servers.size();	if (numServers == 0) {	
wanted to retain assignment but no servers to assign to 

servers = new ArrayList<>(servers);	servers.remove(masterServerName);	List<RegionInfo> masterRegions = assignments.get(masterServerName);	regions = regions.entrySet().stream().filter(e -> !masterRegions.contains(e.getKey())) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));	}	if (regions.isEmpty()) {	return assignments;	}	int numServers = servers == null ? 0 : servers.size();	if (numServers == 0) {	
wanted to do retain assignment but no servers to assign to 

}	assignments.get(target).add(region);	}	numRetainedAssigments++;	}	}	String randomAssignMsg = "";	if (numRandomAssignments > 0) {	randomAssignMsg = numRandomAssignments + " regions were assigned " + "to random hosts, since the old hosts for these regions are no " + "longer present in the cluster. These hosts were:\n  " + Joiner.on("\n  ").join(oldHostsNoLongerPresent);	}	
reassigned regions retained the pre restart assignment 

public void stop(String why) {	
load balancer stop requested 

========================= hbase sample_2829 =========================

private synchronized void warnStuckTasks() {	if (rpcWarnTime > 0) {	final long now = EnvironmentEdgeManager.currentTime();	for (Iterator<TaskAndWeakRefPair> it = rpcTasks.iterator();	it.hasNext();) {	TaskAndWeakRefPair pair = it.next();	MonitoredTask stat = pair.get();	if ((stat.getState() == MonitoredTaskImpl.State.RUNNING) && (now >= stat.getWarnTime() + rpcWarnTime)) {	
task may be stuck 

private synchronized void purgeExpiredTasks() {	for (Iterator<TaskAndWeakRefPair> it = tasks.iterator();	it.hasNext();) {	TaskAndWeakRefPair pair = it.next();	MonitoredTask stat = pair.get();	if (pair.isDead()) {	if (stat.getState() == MonitoredTaskImpl.State.RUNNING) {	
status appears to have been leaked 

========================= hbase sample_2983 =========================

public void tearDown() throws Exception {	admin.listTableNames(Pattern.compile(tableName.getNameAsString() + ".*"), false) .whenCompleteAsync((tables, err) -> {	if (tables != null) {	tables.forEach(table -> {	try {	admin.disableTable(table).join();	} catch (Exception e) {	
table already disabled so just deleting it 

========================= hbase sample_2080 =========================

while (System.currentTimeMillis() < timeout && m.size()!=2){	try {	Thread.sleep(250);	} catch (InterruptedException e) {	LOG.warn(StringUtils.stringifyException(e));	}	m = regionLocator.getAllRegionLocations();	}	assertEquals(m.size(), 2);	regionMap = m;	
regions 

========================= hbase sample_3042 =========================

protected void verify(TableName tableName) throws IOException {	Table table = UTIL.getConnection().getTable(tableName);	boolean verified = false;	long pause = UTIL.getConfiguration().getLong("hbase.client.pause", 5 * 1000);	int numRetries = UTIL.getConfiguration().getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	
verification attempt 

Table table = UTIL.getConnection().getTable(tableName);	boolean verified = false;	long pause = UTIL.getConfiguration().getLong("hbase.client.pause", 5 * 1000);	int numRetries = UTIL.getConfiguration().getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 5);	for (int i = 0; i < numRetries; i++) {	try {	verifyAttempt(table);	verified = true;	break;	} catch (NullPointerException e) {	
verification attempt failed 

========================= hbase sample_3412 =========================

boolean inTransition = false;	for (RegionState rs : admin.getClusterMetrics(EnumSet.of(Option.REGIONS_IN_TRANSITION)) .getRegionStatesInTransition()) {	if (RegionInfo.COMPARATOR.compare(rs.getRegion(), region) == 0) {	inTransition = true;	break;	}	}	if (!inTransition) {	return;	}	
region still in transition waiting for it to become assigned 

for (RegionState rs : admin.getClusterMetrics(EnumSet.of(Option.REGIONS_IN_TRANSITION)) .getRegionStatesInTransition()) {	if (RegionInfo.COMPARATOR.compare(rs.getRegion(), region) == 0) {	inTransition = true;	break;	}	}	if (!inTransition) {	return;	}	} catch (IOException e) {	
exception when waiting for region to become assigned retrying 

========================= hbase sample_2203 =========================

public void testRepairBackupDelete() throws Exception {	
test repair backup delete on a single table with data 

public void testRepairBackupDelete() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	assertTrue(checkSucceeded(backupId));	
backup complete 

========================= hbase sample_548 =========================

performFlush(scanner, mw, smallestReadPoint, throughputController);	result = mw.commitWriters(cacheFlushSeqNum, false);	success = true;	}	} finally {	if (!success && (mw != null)) {	for (Path leftoverFile : mw.abortWriters()) {	try {	store.getFileSystem().delete(leftoverFile, false);	} catch (Exception e) {	
failed to delete a file after failed flush 

for (Path leftoverFile : mw.abortWriters()) {	try {	store.getFileSystem().delete(leftoverFile, false);	} catch (Exception e) {	}	}	}	try {	scanner.close();	} catch (IOException ex) {	
failed to close flush scanner ignoring 

========================= hbase sample_2716 =========================

scan.setMaxVersions();	List<RowRange> ranges = new ArrayList<>();	ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));	ranges.add(new RowRange(Bytes.toBytes(15), true, Bytes.toBytes(40), false));	ranges.add(new RowRange(Bytes.toBytes(65), true, Bytes.toBytes(75), false));	ranges.add(new RowRange(Bytes.toBytes(60), true, null, false));	ranges.add(new RowRange(Bytes.toBytes(60), true, Bytes.toBytes(80), false));	MultiRowRangeFilter filter = new MultiRowRangeFilter(ranges);	scan.setFilter(filter);	int resultsSize = getResultsSize(ht, scan);	
found results 

generateRows(numRows, ht, family, qf, value);	Scan scan = new Scan();	scan.setMaxVersions();	List<RowRange> ranges = new ArrayList<>();	ranges.add(new RowRange(Bytes.toBytes(30), true, Bytes.toBytes(40), false));	ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));	ranges.add(new RowRange(Bytes.toBytes(60), true, Bytes.toBytes(70), false));	MultiRowRangeFilter filter = new MultiRowRangeFilter(ranges);	scan.setFilter(filter);	int resultsSize = getResultsSize(ht, scan);	
found results 

scan.setMaxVersions();	List<RowRange> ranges = new ArrayList<>();	ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));	ranges.add(new RowRange(Bytes.toBytes(20), true, Bytes.toBytes(40), false));	ranges.add(new RowRange(Bytes.toBytes(65), true, Bytes.toBytes(75), false));	ranges.add(new RowRange(Bytes.toBytes(60), true, null, false));	ranges.add(new RowRange(Bytes.toBytes(60), true, Bytes.toBytes(80), false));	MultiRowRangeFilter filter = new MultiRowRangeFilter(ranges);	scan.setFilter(filter);	int resultsSize = getResultsSize(ht, scan);	
found results 

generateRows(numRows, ht, family, qf, value);	Scan scan = new Scan();	scan.setMaxVersions();	List<RowRange> ranges = new ArrayList<>();	ranges.add(new RowRange(Bytes.toBytes(10), true, Bytes.toBytes(20), false));	ranges.add(new RowRange(Bytes.toBytes(20), false, Bytes.toBytes(40), false));	ranges.add(new RowRange(Bytes.toBytes(65), true, Bytes.toBytes(75), false));	MultiRowRangeFilter filter = new MultiRowRangeFilter(ranges);	scan.setFilter(filter);	int resultsSize = getResultsSize(ht, scan);	
found results 

MultiRowRangeFilter filter1 = new MultiRowRangeFilter(ranges1);	List<RowRange> ranges2 = new ArrayList<>();	ranges2.add(new RowRange(Bytes.toBytes(20), true, Bytes.toBytes(40), false));	ranges2.add(new RowRange(Bytes.toBytes(80), true, Bytes.toBytes(90), false));	MultiRowRangeFilter filter2 = new MultiRowRangeFilter(ranges2);	FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ALL);	filterList.addFilter(filter1);	filterList.addFilter(filter2);	scan.setFilter(filterList);	int resultsSize = getResultsSize(ht, scan);	
found results 

MultiRowRangeFilter filter1 = new MultiRowRangeFilter(ranges1);	List<RowRange> ranges2 = new ArrayList<>();	ranges2.add(new RowRange(Bytes.toBytes(20), true, Bytes.toBytes(40), false));	ranges2.add(new RowRange(Bytes.toBytes(80), true, Bytes.toBytes(90), false));	MultiRowRangeFilter filter2 = new MultiRowRangeFilter(ranges2);	FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);	filterList.addFilter(filter1);	filterList.addFilter(filter2);	scan.setFilter(filterList);	int resultsSize = getResultsSize(ht, scan);	
found results 

========================= hbase sample_1993 =========================

public Monkeys(Configuration conf) {	this.conf = Preconditions.checkNotNull(conf, "Should specify a configuration");	this.monkeyRunner = new ChaosMonkeyRunner();	this.runner = () -> {	try {	monkeyRunner.getAndStartMonkey();	} catch (Exception e) {	
exception occured when running chaos monkeys 

public void startChaos() {	executor.execute(runner);	
chaos monkeys are running 

public void stopChaos() {	monkeyRunner.stopRunner();	
chaos monkeys are stopped 

public void close() throws IOException {	executor.shutdown();	try {	executor.awaitTermination(10, TimeUnit.SECONDS);	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	
interruption occured while stopping chaos monkeys 

========================= hbase sample_3279 =========================

public static List<Pair<RegionInfo, ServerName>> getTableRegionsAndLocations( Connection connection, @Nullable final TableName tableName, final boolean excludeOfflinedSplitParents) throws IOException {	if (tableName != null && tableName.equals(TableName.META_TABLE_NAME)) {	throw new IOException("This method can't be used to locate meta regions;" + " use MetaTableLocator instead");	}	CollectingVisitor<Pair<RegionInfo, ServerName>> visitor = new CollectingVisitor<Pair<RegionInfo, ServerName>>() {	private RegionLocations current = null;	public boolean visit(Result r) throws IOException {	current = getRegionLocations(r);	if (current == null || current.getRegionLocation().getRegionInfo() == null) {	
no serialized regioninfo in 

public static void fullScanMetaAndPrint(Connection connection) throws IOException {	Visitor v = new Visitor() {	public boolean visit(Result r) throws IOException {	if (r ==  null || r.isEmpty()) return true;	
fullscanmetaandprint current meta row 

public static void fullScanMetaAndPrint(Connection connection) throws IOException {	Visitor v = new Visitor() {	public boolean visit(Result r) throws IOException {	if (r ==  null || r.isEmpty()) return true;	TableState state = getTableState(r);	if (state != null) {	
table state 

if (!visitor.visit(data)) break;	if (++currentRow >= rowUpperLimit) break;	}	}	}	if (visitor != null && visitor instanceof Closeable) {	try {	((Closeable) visitor).close();	} catch (Throwable t) {	ExceptionUtil.rethrowIfInterrupt(t);	
got exception in closing the meta scanner visitor 

public static void addSpiltsToParent(Connection connection, RegionInfo regionInfo, RegionInfo splitA, RegionInfo splitB) throws IOException {	Table meta = getMetaHTable(connection);	try {	Put put = makePutFromRegionInfo(regionInfo);	addDaughtersToPut(put, splitA, splitB);	meta.put(put);	debugLogMutation(put);	
added region 

if (RegionReplicaUtil.isDefaultReplica(regionInfo)) {	Put put = makePutFromRegionInfo(regionInfo, ts);	addRegionStateToPut(put, RegionState.State.CLOSED);	for (int i = 1; i < regionReplication; i++) {	addEmptyLocation(put, i);	}	puts.add(put);	}	}	putsToMetaTable(connection, puts);	
added regions to meta 

public static void updateTableState(Connection connection, TableState state) throws IOException {	Put put = makePutFromTableState(state);	putToMetaTable(connection, put);	
updated table state to in meta 

public static void deleteTableState(Connection connection, TableName table) throws IOException {	long time = EnvironmentEdgeManager.currentTime();	Delete delete = new Delete(table.getName());	delete.addColumns(getTableFamily(), getTableStateColumn(), time);	deleteFromMetaTable(connection, delete);	
deleted table state from meta 

public static void deleteRegion(Connection connection, RegionInfo regionInfo) throws IOException {	long time = EnvironmentEdgeManager.currentTime();	Delete delete = new Delete(regionInfo.getRegionName());	delete.addFamily(getCatalogFamily(), time);	deleteFromMetaTable(connection, delete);	
deleted 

public static void deleteRegions(Connection connection, List<RegionInfo> regionsInfo, long ts) throws IOException {	List<Delete> deletes = new ArrayList<>(regionsInfo.size());	for (RegionInfo hri: regionsInfo) {	Delete e = new Delete(hri.getRegionName());	e.addFamily(getCatalogFamily(), ts);	deletes.add(e);	}	deleteFromMetaTable(connection, deletes);	
deleted regions from meta 

public static void deleteRegions(Connection connection, List<RegionInfo> regionsInfo, long ts) throws IOException {	List<Delete> deletes = new ArrayList<>(regionsInfo.size());	for (RegionInfo hri: regionsInfo) {	Delete e = new Delete(hri.getRegionName());	e.addFamily(getCatalogFamily(), ts);	deletes.add(e);	}	deleteFromMetaTable(connection, deletes);	
deleted regions 

public static void overwriteRegions(Connection connection, List<RegionInfo> regionInfos, int regionReplication) throws IOException {	long now = EnvironmentEdgeManager.currentTime();	deleteRegions(connection, regionInfos, now);	addRegionsToMeta(connection, regionInfos, regionReplication, now+1);	
overwritten regions to meta 

public static void overwriteRegions(Connection connection, List<RegionInfo> regionInfos, int regionReplication) throws IOException {	long now = EnvironmentEdgeManager.currentTime();	deleteRegions(connection, regionInfos, now);	addRegionsToMeta(connection, regionInfos, regionReplication, now+1);	
overwritten regions 

========================= hbase sample_323 =========================

public void nodeChildrenChanged(String path) {	if (path.equals(watcher.znodePaths.splitLogZNode)) {	if (LOG.isTraceEnabled()) {	
tasks arrived or departed on 

return false;	}	}	try {	try {	if ((data = ZKUtil.getDataNoWatch(watcher, path, stat)) == null) {	SplitLogCounters.tot_wkr_failed_to_grab_task_no_data.increment();	return false;	}	} catch (KeeperException e) {	
failed to get data for znode 

return false;	}	} catch (KeeperException e) {	SplitLogCounters.tot_wkr_failed_to_grab_task_exception.increment();	return false;	}	SplitLogTask slt;	try {	slt = SplitLogTask.parseFrom(data);	} catch (DeserializationException e) {	
failed parse data for znode 

SplitLogCounters.tot_wkr_failed_to_grab_task_lost_race.increment();	return false;	}	if (ZKSplitLog.isRescanNode(watcher, currentTask)) {	ZkSplitLogWorkerCoordination.ZkSplitTaskDetails splitTaskDetails = new ZkSplitLogWorkerCoordination.ZkSplitTaskDetails();	splitTaskDetails.setTaskNode(currentTask);	splitTaskDetails.setCurTaskZKVersion(new MutableInt(currentVersion));	endTask(new SplitLogTask.Done(server.getServerName()), SplitLogCounters.tot_wkr_task_acquired_rescan, splitTaskDetails);	return false;	}	
worker acquired task 

endTask(new SplitLogTask.Done(server.getServerName()), SplitLogCounters.tot_wkr_task_acquired_rescan, splitTaskDetails);	return false;	}	SplitLogCounters.tot_wkr_task_acquired.increment();	getDataSetWatchAsync();	submitTask(path, currentVersion, reportPeriod);	try {	int sleepTime = RandomUtils.nextInt(0, 500) + 500;	Thread.sleep(sleepTime);	} catch (InterruptedException e) {	
interrupted while yielding for other region servers 

public boolean progress() {	long t = EnvironmentEdgeManager.currentTime();	if ((t - last_report_at) > reportPeriod) {	last_report_at = t;	int latestZKVersion = attemptToOwnTask(false, watcher, server.getServerName(), curTask, zkVersion.intValue());	if (latestZKVersion < 0) {	
failed to heartbeat the task 

private int getNumExpectedTasksPerRS(int numTasks) {	int availableRSs = 1;	try {	List<String> regionServers = ZKUtil.listChildrenNoWatch(watcher, watcher.znodePaths.rsZNode);	availableRSs = Math.max(availableRSs, (regionServers == null) ? 0 : regionServers.size());	} catch (KeeperException e) {	
getavailableregionservers got zookeeper exception 

protected static int attemptToOwnTask(boolean isFirstTime, ZKWatcher zkw, ServerName server, String task, int taskZKVersion) {	int latestZKVersion = FAILED_TO_OWN_TASK;	try {	SplitLogTask slt = new SplitLogTask.Owned(server);	Stat stat = zkw.getRecoverableZooKeeper().setData(task, slt.toByteArray(), taskZKVersion);	if (stat == null) {	
zk setdata returned null for path 

if (stat == null) {	SplitLogCounters.tot_wkr_task_heartbeat_failed.increment();	return FAILED_TO_OWN_TASK;	}	latestZKVersion = stat.getVersion();	SplitLogCounters.tot_wkr_task_heartbeat.increment();	return latestZKVersion;	} catch (KeeperException e) {	if (!isFirstTime) {	if (e.code().equals(KeeperException.Code.NONODE)) {	
nonode failed to assert ownership for 

SplitLogCounters.tot_wkr_task_heartbeat_failed.increment();	return FAILED_TO_OWN_TASK;	}	latestZKVersion = stat.getVersion();	SplitLogCounters.tot_wkr_task_heartbeat.increment();	return latestZKVersion;	} catch (KeeperException e) {	if (!isFirstTime) {	if (e.code().equals(KeeperException.Code.NONODE)) {	} else if (e.code().equals(KeeperException.Code.BADVERSION)) {	
badversion failed to assert ownership for 

return FAILED_TO_OWN_TASK;	}	latestZKVersion = stat.getVersion();	SplitLogCounters.tot_wkr_task_heartbeat.increment();	return latestZKVersion;	} catch (KeeperException e) {	if (!isFirstTime) {	if (e.code().equals(KeeperException.Code.NONODE)) {	} else if (e.code().equals(KeeperException.Code.BADVERSION)) {	} else {	
failed to assert ownership for 

SplitLogCounters.tot_wkr_task_heartbeat.increment();	return latestZKVersion;	} catch (KeeperException e) {	if (!isFirstTime) {	if (e.code().equals(KeeperException.Code.NONODE)) {	} else if (e.code().equals(KeeperException.Code.BADVERSION)) {	} else {	}	}	} catch (InterruptedException e1) {	
interrupted while trying to assert ownership of 

public void taskLoop() throws InterruptedException {	while (!shouldStop) {	int seq_start = taskReadySeq.get();	List<String> paths;	paths = getTaskList();	if (paths == null) {	
could not get tasks did someone remove worker thread exiting 

offset = i;	break;	}	}	int numTasks = paths.size();	int expectedTasksPerRS = getNumExpectedTasksPerRS(numTasks);	boolean taskGrabbed = false;	for (int i = 0; i < numTasks; i++) {	while (!shouldStop) {	if (this.areSplittersAvailable(expectedTasksPerRS)) {	
current region server is ready to take more tasks will get task list and try grab tasks again 

int numTasks = paths.size();	int expectedTasksPerRS = getNumExpectedTasksPerRS(numTasks);	boolean taskGrabbed = false;	for (int i = 0; i < numTasks; i++) {	while (!shouldStop) {	if (this.areSplittersAvailable(expectedTasksPerRS)) {	int idx = (i + offset) % paths.size();	taskGrabbed |= grabTask(ZNodePaths.joinZNode( watcher.znodePaths.splitLogZNode, paths.get(idx)));	break;	} else {	
current region server has tasks in progress and can t take more 

private List<String> getTaskList() throws InterruptedException {	List<String> childrenPaths = null;	long sleepTime = 1000;	while (!shouldStop) {	try {	childrenPaths = ZKUtil.listChildrenAndWatchForNewChildren(watcher, watcher.znodePaths.splitLogZNode);	if (childrenPaths != null) {	return childrenPaths;	}	} catch (KeeperException e) {	
could not get children of znode 

List<String> childrenPaths = null;	long sleepTime = 1000;	while (!shouldStop) {	try {	childrenPaths = ZKUtil.listChildrenAndWatchForNewChildren(watcher, watcher.znodePaths.splitLogZNode);	if (childrenPaths != null) {	return childrenPaths;	}	} catch (KeeperException e) {	}	
retry listchildren of znode after sleep for ms 

public boolean isReady() throws InterruptedException {	int result = -1;	try {	result = ZKUtil.checkExists(watcher, watcher.znodePaths.splitLogZNode);	} catch (KeeperException e) {	
exception when checking for retrying 

public boolean isReady() throws InterruptedException {	int result = -1;	try {	result = ZKUtil.checkExists(watcher, watcher.znodePaths.splitLogZNode);	} catch (KeeperException e) {	}	if (result == -1) {	
znode does not exist waiting for master to create 

========================= hbase sample_2192 =========================

hcd.setValue(HColumnDescriptor.DFS_REPLICATION, "-1");	checkTableIsIllegal(htd);	try {	hcd.setDFSReplication((short) -1);	fail("Should throw exception if an illegal value is explicitly being set");	} catch (IllegalArgumentException e) {	}	htd.setMemStoreFlushSize(0);	htd.setConfiguration("hbase.table.sanity.checks", Boolean.FALSE.toString());	checkTableIsLegal(htd);	
memstore flushsize for table descriptor or is too small which might cause very frequent flushing 

========================= hbase sample_2038 =========================

public void testNoExceptionFromDirectoryWithRacyChildren() throws Exception {	Stoppable stop = new StoppableImplementation();	HBaseTestingUtility localUtil = new HBaseTestingUtility();	Configuration conf = localUtil.getConfiguration();	final Path testDir = UTIL.getDataTestDir();	final FileSystem fs = UTIL.getTestFileSystem();	
writing test data to 

========================= hbase sample_1881 =========================

public boolean load() throws ExecutionException, InterruptedException, TimeoutException {	setConf();	ExecutorService loadPool = Executors.newFixedThreadPool(1);	Future<Boolean> loadTask = loadPool.submit(new Load(this));	loadPool.shutdown();	try {	if (!loadPool.awaitTermination((long) this.timeout, TimeUnit.SECONDS)) {	
timed out before finishing the loading operation timeout sec 

if (!loadPool.awaitTermination((long) this.timeout, TimeUnit.SECONDS)) {	loadPool.shutdownNow();	}	} catch (InterruptedException e) {	loadPool.shutdownNow();	Thread.currentThread().interrupt();	}	try {	return loadTask.get(5, TimeUnit.SECONDS);	} catch (InterruptedException e) {	
interrupted while loading regions on 

}	} catch (InterruptedException e) {	loadPool.shutdownNow();	Thread.currentThread().interrupt();	}	try {	return loadTask.get(5, TimeUnit.SECONDS);	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	
error while loading regions on regionserver 

public Boolean call() throws IOException {	Connection conn = ConnectionFactory.createConnection(rm.conf);	try {	List<RegionInfo> regionsToMove = readRegionsFromFile(rm.filename);	if (regionsToMove.isEmpty()) {	
no regions to load exiting 

if (regionsToMove.isEmpty()) {	return true;	}	Admin admin = conn.getAdmin();	try {	loadRegions(admin, rm.hostname, rm.port, regionsToMove, rm.ack);	} finally {	admin.close();	}	} catch (Exception e) {	
error while loading regions to 

public boolean unload() throws InterruptedException, ExecutionException, TimeoutException {	setConf();	deleteFile(this.filename);	ExecutorService unloadPool = Executors.newFixedThreadPool(1);	Future<Boolean> unloadTask = unloadPool.submit(new Unload(this));	unloadPool.shutdown();	try {	if (!unloadPool.awaitTermination((long) this.timeout, TimeUnit.SECONDS)) {	
timed out before finishing the unloading operation timeout sec 

if (!unloadPool.awaitTermination((long) this.timeout, TimeUnit.SECONDS)) {	unloadPool.shutdownNow();	}	} catch (InterruptedException e) {	unloadPool.shutdownNow();	Thread.currentThread().interrupt();	}	try {	return unloadTask.get(5, TimeUnit.SECONDS);	} catch (InterruptedException e) {	
interrupted while unloading regions from 

}	} catch (InterruptedException e) {	unloadPool.shutdownNow();	Thread.currentThread().interrupt();	}	try {	return unloadTask.get(5, TimeUnit.SECONDS);	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	
error while unloading regions from regionserver 

public Boolean call() throws IOException {	Connection conn = ConnectionFactory.createConnection(rm.conf);	try {	Admin admin = conn.getAdmin();	ArrayList<String> regionServers = getServers(admin);	if (LOG.isDebugEnabled()) {	
online region servers 

try {	Admin admin = conn.getAdmin();	ArrayList<String> regionServers = getServers(admin);	if (LOG.isDebugEnabled()) {	}	String server = stripServer(regionServers, hostname, port);	stripExcludes(regionServers, rm.excludeFile);	stripMaster(regionServers, admin);	unloadRegions(admin, server, regionServers, rm.ack, movedRegions);	} catch (Exception e) {	
error while unloading regions 

int maxWaitInSeconds = admin.getConfiguration().getInt(SERVERSTART_WAIT_MAX_KEY, DEFAULT_SERVERSTART_WAIT_MAX);	long maxWait = EnvironmentEdgeManager.currentTime() + maxWaitInSeconds * 1000;	while ((EnvironmentEdgeManager.currentTime() < maxWait) && (server == null)) {	try {	ArrayList<String> regionServers = getServers(admin);	server = stripServer(regionServers, hostname, port);	if (server != null) {	break;	}	} catch (IOException e) {	
could not get list of region servers 

if (server != null) {	break;	}	} catch (IOException e) {	} catch (Exception e) {	LOG.info("hostname=" + hostname + " is not up yet, waiting");	}	try {	Thread.sleep(500);	} catch (InterruptedException e) {	
interrupted while waiting for to be up quitting now 

} catch (Exception e) {	LOG.info("hostname=" + hostname + " is not up yet, waiting");	}	try {	Thread.sleep(500);	} catch (InterruptedException e) {	throw e;	}	}	if (server == null) {	
host is not up giving up 

}	try {	Thread.sleep(500);	} catch (InterruptedException e) {	throw e;	}	}	if (server == null) {	throw new Exception("Host to load regions not online");	}	
moving regions to using threads ack mode 

if (server == null) {	throw new Exception("Host to load regions not online");	}	ExecutorService moveRegionsPool = Executors.newFixedThreadPool(this.maxthreads);	List<Future<Boolean>> taskList = new ArrayList<>();	int counter = 0;	while (counter < regionsToMove.size()) {	RegionInfo region = regionsToMove.get(counter);	String currentServer = getServerNameForRegion(admin, region);	if (currentServer == null) {	
could not get server for region moving on 

if (!moveRegionsPool.awaitTermination(timeoutInSeconds, TimeUnit.SECONDS)) {	moveRegionsPool.shutdownNow();	}	} catch (InterruptedException e) {	moveRegionsPool.shutdownNow();	Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	
was not able to move region exiting now 

} catch (InterruptedException e) {	moveRegionsPool.shutdownNow();	Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	
interrupted while waiting for thread to complete 

Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	
got exception from thread while moving region 

for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	throw e;	} catch (CancellationException e) {	
thread for moving region cancelled timeout for cancellation secs 

private void unloadRegions(Admin admin, String server, ArrayList<String> regionServers, boolean ack, List<RegionInfo> movedRegions) throws Exception {	List<RegionInfo> regionsToMove = new ArrayList<>();	regionsToMove = getRegions(this.conf, server);	if (regionsToMove.isEmpty()) {	
no regions to move quitting now 

private void unloadRegions(Admin admin, String server, ArrayList<String> regionServers, boolean ack, List<RegionInfo> movedRegions) throws Exception {	List<RegionInfo> regionsToMove = new ArrayList<>();	regionsToMove = getRegions(this.conf, server);	if (regionsToMove.isEmpty()) {	return;	} else if (regionServers.isEmpty()) {	
no regions were moved no servers available 

} else if (regionServers.isEmpty()) {	throw new Exception("No online region servers");	}	while (true) {	regionsToMove = getRegions(this.conf, server);	regionsToMove.removeAll(movedRegions);	if (regionsToMove.isEmpty()) {	break;	}	int counter = 0;	
moving regions from to servers using threads ack mode 

if (!moveRegionsPool.awaitTermination(timeoutInSeconds, TimeUnit.SECONDS)) {	moveRegionsPool.shutdownNow();	}	} catch (InterruptedException e) {	moveRegionsPool.shutdownNow();	Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	
was not able to move region exiting now 

} catch (InterruptedException e) {	moveRegionsPool.shutdownNow();	Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	
interrupted while waiting for thread to complete 

Thread.currentThread().interrupt();	}	for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	
got exception from thread while moving region 

for (Future<Boolean> future : taskList) {	try {	if (!future.get(5, TimeUnit.SECONDS)) {	throw new Exception("Could not move region Exception");	}	} catch (InterruptedException e) {	throw e;	} catch (ExecutionException e) {	throw e;	} catch (CancellationException e) {	
thread for moving region cancelled timeout for cancellation secs 

public Boolean call() throws IOException, InterruptedException {	boolean moved = false;	int count = 0;	int retries = admin.getConfiguration().getInt(MOVE_RETRIES_MAX_KEY, DEFAULT_MOVE_RETRIES_MAX);	int maxWaitInSeconds = admin.getConfiguration().getInt(MOVE_WAIT_MAX_KEY, DEFAULT_MOVE_WAIT_MAX);	long startTime = EnvironmentEdgeManager.currentTime();	boolean sameServer = true;	isSuccessfulScan(admin, region);	
moving region from to 

public Boolean call() throws IOException, InterruptedException {	boolean moved = false;	int count = 0;	int retries = admin.getConfiguration().getInt(MOVE_RETRIES_MAX_KEY, DEFAULT_MOVE_RETRIES_MAX);	int maxWaitInSeconds = admin.getConfiguration().getInt(MOVE_WAIT_MAX_KEY, DEFAULT_MOVE_WAIT_MAX);	long startTime = EnvironmentEdgeManager.currentTime();	boolean sameServer = true;	isSuccessfulScan(admin, region);	while (count < retries && sameServer) {	if (count > 0) {	
retry of maximum 

if (!sameServer) {	break;	}	Thread.sleep(100);	}	}	if (sameServer) {	LOG.error("Region: " + region.getRegionNameAsString() + " stuck on " + this.sourceServer + ",newServer=" + this.targetServer);	} else {	isSuccessfulScan(admin, region);	
moved region cost 

public Boolean call() {	try {	
moving region from to 

public Boolean call() {	try {	admin.move(region.getEncodedNameAsBytes(), Bytes.toBytes(targetServer));	
moved from to 

public Boolean call() {	try {	admin.move(region.getEncodedNameAsBytes(), Bytes.toBytes(targetServer));	} catch (Exception e) {	
error moving region 

try {	fis = new FileInputStream(f);	dis = new DataInputStream(fis);	int numRegions = dis.readInt();	int index = 0;	while (index < numRegions) {	regions.add(RegionInfo.parseFromOrNull(Bytes.readByteArray(dis)));	index++;	}	} catch (IOException e) {	
error while reading regions from file 

FileOutputStream fos = null;	DataOutputStream dos = null;	try {	fos = new FileOutputStream(filename);	dos = new DataOutputStream(fos);	dos.writeInt(movedRegions.size());	for (RegionInfo region : movedRegions) {	Bytes.writeByteArray(dos, RegionInfo.toByteArray(region));	}	} catch (IOException e) {	
error was not able to write regions moved to output file but moved regions 

if (excludeFile != null) {	ArrayList<String> excludes = readExcludes(excludeFile);	Iterator<String> i = regionServers.iterator();	while (i.hasNext()) {	String rs = i.next();	String rsPort = rs.split(ServerName.SERVERNAME_SEPARATOR)[0] + ":" + rs.split(ServerName.SERVERNAME_SEPARATOR)[1];	if (excludes.contains(rsPort)) {	i.remove();	}	}	
valid region server targets are 

if (excludeFile != null) {	ArrayList<String> excludes = readExcludes(excludeFile);	Iterator<String> i = regionServers.iterator();	while (i.hasNext()) {	String rs = i.next();	String rsPort = rs.split(ServerName.SERVERNAME_SEPARATOR)[0] + ":" + rs.split(ServerName.SERVERNAME_SEPARATOR)[1];	if (excludes.contains(rsPort)) {	i.remove();	}	}	
excluded servers are 

private void stripMaster(ArrayList<String> regionServers, Admin admin) throws IOException {	ServerName master = admin.getClusterMetrics(EnumSet.of(Option.MASTER)).getMasterName();	String masterHostname = master.getHostname();	int masterPort = master.getPort();	try {	stripServer(regionServers, masterHostname, masterPort);	} catch (Exception e) {	
could not remove master from list of rs 

BufferedReader br = null;	try {	br = new BufferedReader(new FileReader(f));	while ((line = br.readLine()) != null) {	line = line.trim();	if (!line.equals("")) {	excludeServers.add(line);	}	}	} catch (IOException e) {	
exception while reading excludes file continuing anyways 

ResultScanner scanner = table.getScanner(scan);	try {	scanner.next();	} finally {	scanner.close();	}	} finally {	table.close();	}	} catch (IOException e) {	
could not scan region 

if (!admin.isTableEnabled(region.getTable())) {	return null;	}	if (region.isMetaRegion()) {	ZKWatcher zkw = new ZKWatcher(admin.getConfiguration(), "region_mover", null);	MetaTableLocator locator = new MetaTableLocator();	int maxWaitInSeconds = admin.getConfiguration().getInt(MOVE_WAIT_MAX_KEY, DEFAULT_MOVE_WAIT_MAX);	try {	server = locator.waitMetaRegionLocation(zkw, maxWaitInSeconds * 1000).toString();	} catch (InterruptedException e) {	
interrupted while waiting for location of meta 

get.addColumn(HConstants.CATALOG_FAMILY, HConstants.STARTCODE_QUALIFIER);	Result result = table.get(get);	if (result != null) {	byte[] servername = result.getValue(HConstants.CATALOG_FAMILY, HConstants.SERVER_QUALIFIER);	byte[] startcode = result.getValue(HConstants.CATALOG_FAMILY, HConstants.STARTCODE_QUALIFIER);	if (servername != null) {	server = Bytes.toString(servername).replaceFirst(":", ",").toLowerCase() + "," + Bytes.toLong(startcode);	}	}	} catch (IOException e) {	
could not get server name for region 

========================= hbase sample_2254 =========================

private void requestRegionSplit() {	final TableName table = parent.getTable();	final RegionInfo hri_a = RegionInfoBuilder.newBuilder(table) .setStartKey(parent.getStartKey()) .setEndKey(midKey) .build();	final RegionInfo hri_b = RegionInfoBuilder.newBuilder(table) .setStartKey(midKey) .setEndKey(parent.getEndKey()) .build();	if (!server.reportRegionStateTransition(new RegionStateTransitionContext( TransitionCode.READY_TO_SPLIT, HConstants.NO_SEQNUM, -1, parent, hri_a, hri_b))) {	
unable to ask master to split 

========================= hbase sample_2604 =========================

protected StateMachineProcedure.Flow executeFromState(TestProcEnv env, State state) {	switch (state) {	
execute step 

protected StateMachineProcedure.Flow executeFromState(TestProcEnv env, State state) {	switch (state) {	setNextState(State.STATE_2);	iResult += 3;	break;	
execute step 

iResult += 3;	break;	if (submitChildProc) {	addChildProcedure(new TestStateMachineProcedure(), new TestStateMachineProcedure());	setNextState(State.DONE);	} else {	setNextState(State.STATE_3);	}	iResult += 5;	break;	
execute step 

if (submitChildProc) {	addChildProcedure(new TestStateMachineProcedure(), new TestStateMachineProcedure());	setNextState(State.DONE);	} else {	setNextState(State.STATE_3);	}	iResult += 5;	break;	Threads.sleepWithoutInterrupt(procSleepInterval);	if (aborted.get()) {	
aborted step 

protected void rollbackState(TestProcEnv env, final State state) {	switch (state) {	
rollback step 

protected void rollbackState(TestProcEnv env, final State state) {	switch (state) {	break;	
rollback step 

protected void rollbackState(TestProcEnv env, final State state) {	switch (state) {	break;	break;	
rollback step 

========================= hbase sample_1182 =========================

public Job createSubmittableJob(String[] args) throws IOException {	FileSystem fs = sourceHashDir.getFileSystem(getConf());	if (!fs.exists(sourceHashDir)) {	throw new IOException("Source hash dir not found: " + sourceHashDir);	}	HashTable.TableHash tableHash = HashTable.TableHash.read(getConf(), sourceHashDir);	
read source hash manifest 

public Job createSubmittableJob(String[] args) throws IOException {	FileSystem fs = sourceHashDir.getFileSystem(getConf());	if (!fs.exists(sourceHashDir)) {	throw new IOException("Source hash dir not found: " + sourceHashDir);	}	HashTable.TableHash tableHash = HashTable.TableHash.read(getConf(), sourceHashDir);	
read partition keys 

public Job createSubmittableJob(String[] args) throws IOException {	FileSystem fs = sourceHashDir.getFileSystem(getConf());	if (!fs.exists(sourceHashDir)) {	throw new IOException("Source hash dir not found: " + sourceHashDir);	}	HashTable.TableHash tableHash = HashTable.TableHash.read(getConf(), sourceHashDir);	if (!tableHash.tableName.equals(sourceTableName)) {	
table name mismatch manifest indicates hash was taken from but job is reading from 

protected void setup(Context context) throws IOException {	Configuration conf = context.getConfiguration();	sourceHashDir = new Path(conf.get(SOURCE_HASH_DIR_CONF_KEY));	sourceConnection = openConnection(conf, SOURCE_ZK_CLUSTER_CONF_KEY, null);	targetConnection = openConnection(conf, TARGET_ZK_CLUSTER_CONF_KEY, TableOutputFormat.OUTPUT_CONF_PREFIX);	sourceTable = openTable(sourceConnection, conf, SOURCE_TABLE_CONF_KEY);	targetTable = openTable(targetConnection, conf, TARGET_TABLE_CONF_KEY);	dryRun = conf.getBoolean(SOURCE_TABLE_CONF_KEY, false);	sourceTableHash = HashTable.TableHash.read(conf, sourceHashDir);	
read source hash manifest 

protected void setup(Context context) throws IOException {	Configuration conf = context.getConfiguration();	sourceHashDir = new Path(conf.get(SOURCE_HASH_DIR_CONF_KEY));	sourceConnection = openConnection(conf, SOURCE_ZK_CLUSTER_CONF_KEY, null);	targetConnection = openConnection(conf, TARGET_ZK_CLUSTER_CONF_KEY, TableOutputFormat.OUTPUT_CONF_PREFIX);	sourceTable = openTable(sourceConnection, conf, SOURCE_TABLE_CONF_KEY);	targetTable = openTable(targetConnection, conf, TARGET_TABLE_CONF_KEY);	dryRun = conf.getBoolean(SOURCE_TABLE_CONF_KEY, false);	sourceTableHash = HashTable.TableHash.read(conf, sourceHashDir);	
read partition keys 

if (targetHasher.getBatchSize() == 0) {	context.getCounter(Counter.EMPTY_BATCHES).increment(1);	}	ImmutableBytesWritable targetHash = targetHasher.getBatchHash();	if (targetHash.equals(currentSourceHash)) {	context.getCounter(Counter.HASHES_MATCHED).increment(1);	} else {	context.getCounter(Counter.HASHES_NOT_MATCHED).increment(1);	ImmutableBytesWritable stopRow = nextSourceKey == null ? new ImmutableBytesWritable(sourceTableHash.stopRow) : nextSourceKey;	if (LOG.isDebugEnabled()) {	
hash mismatch key range to sourcehash targethash 

ResultScanner targetScanner = targetTable.getScanner(new Scan(scan));	CellScanner targetCells = new CellScanner(targetScanner.iterator());	boolean rangeMatched = true;	byte[] nextSourceRow = sourceCells.nextRow();	byte[] nextTargetRow = targetCells.nextRow();	while(nextSourceRow != null || nextTargetRow != null) {	boolean rowMatched;	int rowComparison = compareRowKeys(nextSourceRow, nextTargetRow);	if (rowComparison < 0) {	if (LOG.isInfoEnabled()) {	
target missing row 

boolean rowMatched;	int rowComparison = compareRowKeys(nextSourceRow, nextTargetRow);	if (rowComparison < 0) {	if (LOG.isInfoEnabled()) {	}	context.getCounter(Counter.TARGETMISSINGROWS).increment(1);	rowMatched = syncRowCells(context, nextSourceRow, sourceCells, EMPTY_CELL_SCANNER);	nextSourceRow = sourceCells.nextRow();	} else if (rowComparison > 0) {	if (LOG.isInfoEnabled()) {	
source missing row 

Put put = null;	Delete delete = null;	long matchingCells = 0;	boolean matchingRow = true;	Cell sourceCell = sourceCells.nextCellInRow();	Cell targetCell = targetCells.nextCellInRow();	while (sourceCell != null || targetCell != null) {	int cellKeyComparison = compareCellKeysWithinRow(sourceCell, targetCell);	if (cellKeyComparison < 0) {	if (LOG.isDebugEnabled()) {	
target missing cell 

matchingRow = false;	if (!dryRun) {	if (put == null) {	put = new Put(rowKey);	}	put.add(sourceCell);	}	sourceCell = sourceCells.nextCellInRow();	} else if (cellKeyComparison > 0) {	if (LOG.isDebugEnabled()) {	
source missing cell 

delete = new Delete(rowKey);	}	delete.addColumn(CellUtil.cloneFamily(targetCell), CellUtil.cloneQualifier(targetCell), targetCell.getTimestamp());	}	targetCell = targetCells.nextCellInRow();	} else {	if (CellUtil.matchingValue(sourceCell, targetCell)) {	matchingCells++;	} else {	if (LOG.isDebugEnabled()) {	
different values 

delete = new Delete(rowKey);	}	delete.addColumn(CellUtil.cloneFamily(targetCell), CellUtil.cloneQualifier(targetCell), targetCell.getTimestamp());	}	targetCell = targetCells.nextCellInRow();	} else {	if (CellUtil.matchingValue(sourceCell, targetCell)) {	matchingCells++;	} else {	if (LOG.isDebugEnabled()) {	
source cell value 

delete = new Delete(rowKey);	}	delete.addColumn(CellUtil.cloneFamily(targetCell), CellUtil.cloneQualifier(targetCell), targetCell.getTimestamp());	}	targetCell = targetCells.nextCellInRow();	} else {	if (CellUtil.matchingValue(sourceCell, targetCell)) {	matchingCells++;	} else {	if (LOG.isDebugEnabled()) {	
target cell value 

}	try {	sourceTable.close();	targetTable.close();	sourceConnection.close();	targetConnection.close();	} catch (Throwable t) {	if (mapperException == null) {	mapperException = t;	} else {	
suppressing exception from closing tables 

public int run(String[] args) throws Exception {	String[] otherArgs = new GenericOptionsParser(getConf(), args).getRemainingArgs();	if (!doCommandLine(otherArgs)) {	return 1;	}	Job job = createSubmittableJob(otherArgs);	if (!job.waitForCompletion(true)) {	
map reduce job failed 

========================= hbase sample_3445 =========================

public MobFileCache(Configuration conf) {	this.conf = conf;	this.mobFileMaxCacheSize = conf.getInt(MobConstants.MOB_FILE_CACHE_SIZE_KEY, MobConstants.DEFAULT_MOB_FILE_CACHE_SIZE);	isCacheEnabled = (mobFileMaxCacheSize > 0);	map = new ConcurrentHashMap<>(mobFileMaxCacheSize);	if (isCacheEnabled) {	long period = conf.getLong(MobConstants.MOB_CACHE_EVICT_PERIOD, MobConstants.DEFAULT_MOB_CACHE_EVICT_PERIOD);	evictRemainRatio = conf.getFloat(MobConstants.MOB_CACHE_EVICT_REMAIN_RATIO, MobConstants.DEFAULT_EVICT_REMAIN_RATIO);	if (evictRemainRatio < 0.0) {	evictRemainRatio = 0.0f;	
is less than is used 

this.mobFileMaxCacheSize = conf.getInt(MobConstants.MOB_FILE_CACHE_SIZE_KEY, MobConstants.DEFAULT_MOB_FILE_CACHE_SIZE);	isCacheEnabled = (mobFileMaxCacheSize > 0);	map = new ConcurrentHashMap<>(mobFileMaxCacheSize);	if (isCacheEnabled) {	long period = conf.getLong(MobConstants.MOB_CACHE_EVICT_PERIOD, MobConstants.DEFAULT_MOB_CACHE_EVICT_PERIOD);	evictRemainRatio = conf.getFloat(MobConstants.MOB_CACHE_EVICT_REMAIN_RATIO, MobConstants.DEFAULT_EVICT_REMAIN_RATIO);	if (evictRemainRatio < 0.0) {	evictRemainRatio = 0.0f;	} else if (evictRemainRatio > 1.0) {	evictRemainRatio = 1.0f;	
is larger than is used 

if (evictRemainRatio < 0.0) {	evictRemainRatio = 0.0f;	} else if (evictRemainRatio > 1.0) {	evictRemainRatio = 1.0f;	}	this.scheduleThreadPool.scheduleAtFixedRate(new EvictionThread(this), period, period, TimeUnit.SECONDS);	if (LOG.isDebugEnabled()) {	LOG.debug("MobFileCache enabled with cacheSize=" + mobFileMaxCacheSize + ", evictPeriods=" +  period + "sec, evictRemainRatio=" + evictRemainRatio);	}	} else {	
mobfilecache disabled 

if (isCacheEnabled) {	IdLock.Entry lockEntry = null;	try {	lockEntry = keyLock.getLockEntry(fileName.hashCode());	CachedMobFile evictedFile = map.remove(fileName);	if (evictedFile != null) {	evictedFile.close();	evictedFileCount.increment();	}	} catch (IOException e) {	
failed to evict the file 

public void closeFile(MobFile file) {	IdLock.Entry lockEntry = null;	try {	if (!isCacheEnabled) {	file.close();	} else {	lockEntry = keyLock.getLockEntry(file.getFileName().hashCode());	file.close();	}	} catch (IOException e) {	
mobfilecache exception happen during close 

public void shutdown() {	this.scheduleThreadPool.shutdown();	for (int i = 0; i < 100; i++) {	if (!this.scheduleThreadPool.isShutdown()) {	try {	Thread.sleep(10);	} catch (InterruptedException e) {	
interrupted while sleeping 

try {	Thread.sleep(10);	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	break;	}	}	}	if (!this.scheduleThreadPool.isShutdown()) {	List<Runnable> runnables = this.scheduleThreadPool.shutdownNow();	
still running 

public void printStatistics() {	long access = count.get() - lastAccess;	long missed = miss.sum() - lastMiss;	long evicted = evictedFileCount.sum() - lastEvictedFileCount;	int hitRatio = access == 0 ? 0 : (int) (((float) (access - missed)) / (float) access * 100);	
mobfilecache statistics access miss hit hit ratio evicted files 

========================= hbase sample_3015 =========================

public static User getActiveUser() throws IOException {	Optional<User> optionalUser = RpcServer.getRequestUser();	User user;	if (optionalUser.isPresent()) {	user = optionalUser.get();	} else {	user = User.getCurrent();	}	if (LOG.isTraceEnabled()) {	
current active user name is 

private static void getLabelOrdinals(ExpressionNode node, List<Integer> labelOrdinals, Set<Integer> auths, boolean checkAuths, VisibilityLabelOrdinalProvider ordinalProvider) throws IOException, InvalidLabelException {	if (node.isSingleNode()) {	String identifier = null;	int labelOrdinal = 0;	if (node instanceof LeafExpressionNode) {	identifier = ((LeafExpressionNode) node).getIdentifier();	if (LOG.isTraceEnabled()) {	
the identifier is 

========================= hbase sample_2311 =========================

protected void runOneIteration() {	Action action = PolicyBasedChaosMonkey.selectWeightedRandomItem(actions);	try {	action.perform();	} catch (Exception ex) {	
exception occurred during performing action 

========================= hbase sample_3280 =========================

public void start(long startKey, long endKey, int numThreads) throws IOException {	super.start(startKey, endKey, numThreads);	if (verbose) {	
reading keys 

protected void closeTable() {	try {	if (table != null) {	table.close();	}	} catch (IOException e) {	
error closing table 

private void runReader() {	if (verbose) {	
started thread for reads 

}	cfsString += "[" + Bytes.toStringBinary(cf) + "]";	}	}	get = dataGenerator.beforeGet(keyToRead, get);	if (regionReplicaId > 0) {	get.setReplicaId(regionReplicaId);	get.setConsistency(Consistency.TIMELINE);	}	if (verbose) {	
querying key cfs 

boolean isOk = verifyResultAgainstDataGenerator(result, verify, false);	long numErrorsAfterThis = 0;	if (isOk) {	long cols = 0;	for (byte[] cf : result.getMap().keySet()) {	cols += result.getFamilyMap(cf).size();	}	numCols.addAndGet(cols);	} else {	if (writer != null) {	
at the time of failure writer wrote keys 

for (byte[] cf : result.getMap().keySet()) {	cols += result.getFamilyMap(cf).size();	}	numCols.addAndGet(cols);	} else {	if (writer != null) {	}	numErrorsAfterThis = numReadErrors.incrementAndGet();	}	if (numErrorsAfterThis > maxErrors) {	
aborting readers found more than errors 

========================= hbase sample_1317 =========================

public ZKProcedureMemberRpcs(final ZKWatcher watcher, final String procType) throws KeeperException {	this.zkController = new ZKProcedureUtil(watcher, procType) {	public void nodeCreated(String path) {	if (!isInProcedurePath(path)) {	return;	}	
received created event 

String parent = ZKUtil.getParent(path);	if (isReachedNode(parent)) {	receivedReachedGlobalBarrier(path);	return;	} else if (isAbortNode(parent)) {	abort(path);	return;	} else if (isAcquiredNode(parent)) {	startNewSubprocedure(path);	} else {	
ignoring created notification for node 

} else if (isAbortNode(parent)) {	abort(path);	return;	} else if (isAcquiredNode(parent)) {	startNewSubprocedure(path);	} else {	}	}	public void nodeChildrenChanged(String path) {	if (path.equals(this.acquiredZnode)) {	
received procedure start children changed event 

return;	} else if (isAcquiredNode(parent)) {	startNewSubprocedure(path);	} else {	}	}	public void nodeChildrenChanged(String path) {	if (path.equals(this.acquiredZnode)) {	waitForNewProcedures();	} else if (path.equals(this.abortZnode)) {	
received procedure abort children changed event 

private void receivedReachedGlobalBarrier(String path) {	
received reached global barrier 

private void watchForAbortedProcedures() {	
checking for aborted procedures on node 

private void waitForNewProcedures() {	
looking for new procedures under znode 

private void waitForNewProcedures() {	List<String> runningProcedures = null;	try {	runningProcedures = ZKUtil.listChildrenAndWatchForNewChildren(zkController.getWatcher(), zkController.getAcquiredBarrier());	if (runningProcedures == null) {	
no running procedures 

List<String> runningProcedures = null;	try {	runningProcedures = ZKUtil.listChildrenAndWatchForNewChildren(zkController.getWatcher(), zkController.getAcquiredBarrier());	if (runningProcedures == null) {	return;	}	} catch (KeeperException e) {	member.controllerConnectionFailure("General failure when watching for new procedures", e, null);	}	if (runningProcedures == null) {	
no running procedures 

private synchronized void startNewSubprocedure(String path) {	
found procedure znode 

private synchronized void startNewSubprocedure(String path) {	String opName = ZKUtil.getNodeName(path);	String abortZNode = zkController.getAbortZNode(opName);	try {	if (ZKUtil.watchAndCheckExists(zkController.getWatcher(), abortZNode)) {	
not starting because we already have an abort notification 

return;	}	Subprocedure subproc = null;	try {	byte[] data = ZKUtil.getData(zkController.getWatcher(), path);	if (!ProtobufUtil.isPBMagicPrefix(data)) {	String msg = "Data in for starting procedure " + opName + " is illegally formatted (no pb magic). " + "Killing the procedure: " + Bytes.toString(data);	LOG.error(msg);	throw new IllegalArgumentException(msg);	}	
start proc data length is 

}	Subprocedure subproc = null;	try {	byte[] data = ZKUtil.getData(zkController.getWatcher(), path);	if (!ProtobufUtil.isPBMagicPrefix(data)) {	String msg = "Data in for starting procedure " + opName + " is illegally formatted (no pb magic). " + "Killing the procedure: " + Bytes.toString(data);	LOG.error(msg);	throw new IllegalArgumentException(msg);	}	data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	
found data for znode 

byte[] data = ZKUtil.getData(zkController.getWatcher(), path);	if (!ProtobufUtil.isPBMagicPrefix(data)) {	String msg = "Data in for starting procedure " + opName + " is illegally formatted (no pb magic). " + "Killing the procedure: " + Bytes.toString(data);	LOG.error(msg);	throw new IllegalArgumentException(msg);	}	data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	subproc = member.createSubprocedure(opName, data);	member.submitSubprocedure(subproc);	} catch (IllegalArgumentException iae ) {	
illegal argument exception 

String msg = "Data in for starting procedure " + opName + " is illegally formatted (no pb magic). " + "Killing the procedure: " + Bytes.toString(data);	LOG.error(msg);	throw new IllegalArgumentException(msg);	}	data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	subproc = member.createSubprocedure(opName, data);	member.submitSubprocedure(subproc);	} catch (IllegalArgumentException iae ) {	sendMemberAborted(subproc, new ForeignException(getMemberName(), iae));	} catch (IllegalStateException ise) {	
illegal state exception 

public void sendMemberAcquired(Subprocedure sub) throws IOException {	String procName = sub.getName();	try {	
member joining acquired barrier for procedure in zk 

public void sendMemberAcquired(Subprocedure sub) throws IOException {	String procName = sub.getName();	try {	String acquiredZNode = ZNodePaths.joinZNode(ZKProcedureUtil.getAcquireBarrierNode( zkController, procName), memberName);	ZKUtil.createAndFailSilent(zkController.getWatcher(), acquiredZNode);	String reachedBarrier = zkController.getReachedBarrierNode(procName);	
watch for global barrier reached 

public void sendMemberCompleted(Subprocedure sub, byte[] data) throws IOException {	String procName = sub.getName();	
marking procedure completed for member in zk 

public void sendMemberAborted(Subprocedure sub, ForeignException ee) {	if (sub == null) {	
failed due to null subprocedure 

public void sendMemberAborted(Subprocedure sub, ForeignException ee) {	if (sub == null) {	return;	}	String procName = sub.getName();	
aborting procedure in zk 

public void sendMemberAborted(Subprocedure sub, ForeignException ee) {	if (sub == null) {	return;	}	String procName = sub.getName();	String procAbortZNode = zkController.getAbortZNode(procName);	try {	String source = (ee.getSource() == null) ? memberName: ee.getSource();	byte[] errorInfo = ProtobufUtil.prependPBMagic(ForeignException.serialize(source, ee));	ZKUtil.createAndFailSilent(zkController.getWatcher(), procAbortZNode, errorInfo);	
finished creating abort znode 

protected void abort(String abortZNode) {	
aborting procedure member for znode 

return;	} else if (!ProtobufUtil.isPBMagicPrefix(data)) {	String msg = "Illegally formatted data in abort node for proc " + opName + ".  Killing the procedure.";	LOG.error(msg);	ee = new ForeignException(getMemberName(), new IllegalArgumentException(msg));	} else {	data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	ee = ForeignException.deserialize(data);	}	} catch (IOException e) {	
got an error notification for op but we can t read the information killing the procedure 

data = Arrays.copyOfRange(data, ProtobufUtil.lengthOfPBMagic(), data.length);	ee = ForeignException.deserialize(data);	}	} catch (IOException e) {	ee = new ForeignException(getMemberName(), e);	}	this.member.receiveAbortProcedure(opName, ee);	} catch (KeeperException e) {	member.controllerConnectionFailure("Failed to get data for abort znode:" + abortZNode + zkController.getAbortZnode(), e, opName);	} catch (InterruptedException e) {	
abort already in progress 

public void start(final String memberName, final ProcedureMember listener) {	
starting procedure member 

========================= hbase sample_2491 =========================

private void submitProcedures(final int nthreads, final int nprocPerThread, final Class<?> procClazz) throws Exception {	Thread[] submitThreads = new Thread[nthreads];	for (int i = 0; i < submitThreads.length; ++i) {	submitThreads[i] = new Thread() {	public void run() {	for (int i = 0; i < nprocPerThread; ++i) {	try {	procExecutor.submitProcedure((Procedure) procClazz.getDeclaredConstructor().newInstance());	} catch (Exception e) {	
unable to instantiate the procedure 

public void assertSortedExecList(int numProcs) {	assertEquals(numProcs, execList.size());	
exec list 

========================= hbase sample_1194 =========================

String host = entry.getKey();	if (host.endsWith(".")) {	host = host.substring(0, host.length() - 1);	}	float locality = ((float)entry.getValue().get()) / totalBlkCount;	hostLocalityMap.put(host, locality);	}	regionDegreeLocalityMapping.put(regionPath.getName(), hostLocalityMap);	}	} catch (IOException e) {	
problem scanning file system 

if (host.endsWith(".")) {	host = host.substring(0, host.length() - 1);	}	float locality = ((float)entry.getValue().get()) / totalBlkCount;	hostLocalityMap.put(host, locality);	}	regionDegreeLocalityMapping.put(regionPath.getName(), hostLocalityMap);	}	} catch (IOException e) {	} catch (RuntimeException e) {	
problem scanning file system 

========================= hbase sample_2242 =========================

protected abstract AbstractRpcClient<?> createRpcClientRTEDuringConnectionSetup( Configuration conf) throws IOException;	public void testRTEDuringConnectionSetup() throws Exception {	Configuration conf = HBaseConfiguration.create();	RpcServer rpcServer = createRpcServer(null, "testRpcServer", Lists.newArrayList(new RpcServer.BlockingServiceAndInterface( SERVICE, null)), new InetSocketAddress("localhost", 0), CONF, new FifoRpcScheduler(CONF, 1));	try (AbstractRpcClient<?> client = createRpcClientRTEDuringConnectionSetup(conf)) {	rpcServer.start();	BlockingInterface stub = newBlockingStub(client, rpcServer.getListenerAddress());	stub.ping(null, EmptyRequestProto.getDefaultInstance());	fail("Expected an exception to have been thrown!");	} catch (Exception e) {	
caught expected exception 

rpcServer.start();	BlockingInterface stub = newBlockingStub(client, rpcServer.getListenerAddress());	StringBuilder message = new StringBuilder(1200);	for (int i = 0; i < 200; i++) {	message.append("hello.");	}	EchoRequestProto param = EchoRequestProto.newBuilder().setMessage(message.toString()).build();	stub.echo( new HBaseRpcControllerImpl(CellUtil.createCellScanner(ImmutableList.<Cell> of(CELL))), param);	fail("RPC should have failed because it exceeds max request size");	} catch (ServiceException e) {	
caught expected exception 

public void testRemoteError() throws IOException, ServiceException {	RpcServer rpcServer = createRpcServer(null, "testRpcServer", Lists.newArrayList(new RpcServer.BlockingServiceAndInterface( SERVICE, null)), new InetSocketAddress("localhost", 0), CONF, new FifoRpcScheduler(CONF, 1));	try (AbstractRpcClient<?> client = createRpcClient(CONF)) {	rpcServer.start();	BlockingInterface stub = newBlockingStub(client, rpcServer.getListenerAddress());	stub.error(null, EmptyRequestProto.getDefaultInstance());	} catch (ServiceException e) {	
caught expected exception 

int ms = 1000;	int timeout = 100;	for (int i = 0; i < 10; i++) {	pcrc.reset();	pcrc.setCallTimeout(timeout);	long startTime = System.nanoTime();	try {	stub.pause(pcrc, PauseRequestProto.newBuilder().setMs(ms).build());	} catch (ServiceException e) {	long waitTime = (System.nanoTime() - startTime) / 1000000;	
caught expected exception 

public void testConnectionCloseWithOutstandingRPCs() throws InterruptedException, IOException {	Configuration conf = new Configuration(CONF);	RpcServer rpcServer = createTestFailingRpcServer(null, "testRpcServer", Lists.newArrayList(new RpcServer.BlockingServiceAndInterface( SERVICE, null)), new InetSocketAddress("localhost", 0), CONF, new FifoRpcScheduler(CONF, 1));	try (AbstractRpcClient<?> client = createRpcClient(conf)) {	rpcServer.start();	BlockingInterface stub = newBlockingStub(client, rpcServer.getListenerAddress());	EchoRequestProto param = EchoRequestProto.newBuilder().setMessage("hello").build();	stub.echo(null, param);	fail("RPC should have failed because connection closed");	} catch (ServiceException e) {	
caught expected exception 

AbstractRpcClient<?> client = createRpcClient(CONF);	RpcServer rpcServer = createRpcServer(null, "testRpcServer", Lists.newArrayList(new RpcServer.BlockingServiceAndInterface( SERVICE, null)), new InetSocketAddress("localhost", 0), CONF, new FifoRpcScheduler(CONF, 1));	try {	rpcServer.start();	Interface stub = newStub(client, rpcServer.getListenerAddress());	BlockingRpcCallback<EmptyResponseProto> callback = new BlockingRpcCallback<>();	HBaseRpcController pcrc = new HBaseRpcControllerImpl();	stub.error(pcrc, EmptyRequestProto.getDefaultInstance(), callback);	assertNull(callback.get());	assertTrue(pcrc.failed());	
caught expected exception 

stub.pause(pcrc, PauseRequestProto.newBuilder().setMs(ms).build(), callback);	pcrcList.add(pcrc);	callbackList.add(callback);	}	for (BlockingRpcCallback<?> callback : callbackList) {	assertNull(callback.get());	}	long waitTime = (System.nanoTime() - startTime) / 1000000;	for (HBaseRpcController pcrc : pcrcList) {	assertTrue(pcrc.failed());	
caught expected exception 

========================= hbase sample_1897 =========================

public void cleanup() throws ReplicationException {	try {	fs.delete(root, true);	} catch (IOException e) {	
failed to delete files recursively from path 

========================= hbase sample_1878 =========================

public void triggerCacheRefreshForTesting() {	try {	SnapshotFileCache.this.refreshCache();	} catch (IOException e) {	
failed to refresh snapshot hfile cache 

public void triggerCacheRefreshForTesting() {	try {	SnapshotFileCache.this.refreshCache();	} catch (IOException e) {	}	
current cache 

private synchronized void refreshCache() throws IOException {	FileStatus dirStatus;	try {	dirStatus = fs.getFileStatus(snapshotDir);	} catch (FileNotFoundException e) {	if (this.cache.size() > 0) {	
snapshot directory doesn t exist 

}	return;	}	if (dirStatus.getModificationTime() <= this.lastModifiedTime) return;	this.lastModifiedTime = dirStatus.getModificationTime();	this.cache.clear();	Map<String, SnapshotDirectoryInfo> known = new HashMap<>();	FileStatus[] snapshots = FSUtils.listStatus(fs, snapshotDir);	if (snapshots == null) {	if (LOG.isDebugEnabled() && this.snapshots.size() > 0) {	
no snapshots on disk cache empty 

public void run() {	try {	SnapshotFileCache.this.refreshCache();	} catch (IOException e) {	
failed to refresh snapshot hfile cache 

========================= hbase sample_2757 =========================

FixedFileTrailer trailer = FixedFileTrailer.readFromStream(fsdis.getStream(false), fileSize);	HFile.Reader reader = new HFileReaderImpl(path, trailer, fsdis, fileSize, cacheConfig, fsdis.getHfs(), conf);	reader.loadFileInfo();	long offset = trailer.getFirstDataBlockOffset(), max = trailer.getLastDataBlockOffset();	List<HFileBlock> blocks = new ArrayList<>(4);	HFileBlock block;	while (offset <= max) {	block = reader.readBlock(offset, -1, /* cacheBlock */ true, /* pread */ false, offset += block.getOnDiskSizeWithHeader();	blocks.add(block);	}	
read 

========================= hbase sample_1481 =========================

conf.setInt(HFile.FORMAT_VERSION_KEY, 3);	conf.set(HConstants.CRYPTO_KEYPROVIDER_CONF_KEY, KeyProviderForTesting.class.getName());	conf.set(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, "hbase");	conf.setClass("hbase.regionserver.hlog.reader.impl", SecureProtobufLogReader.class, Reader.class);	conf.setClass("hbase.regionserver.hlog.writer.impl", SecureProtobufLogWriter.class, Writer.class);	conf.setBoolean(HConstants.ENABLE_WAL_ENCRYPTION, true);	}	try {	EncryptionTest.testEncryption(conf, "AES", null);	} catch (Exception e) {	
encryption configuration test did not pass skipping test 

public void setUp() throws Exception {	super.setUp();	if (!initialized) {	return;	}	final Admin admin = util.getAdmin();	TableDescriptor tableDescriptor = admin.getDescriptor(getTablename());	for (ColumnFamilyDescriptor columnDescriptor : tableDescriptor.getColumnFamilies()) {	ColumnFamilyDescriptor updatedColumn = ColumnFamilyDescriptorBuilder .newBuilder(columnDescriptor).setEncryptionType("AES").build();	
updating cf schema for 

========================= hbase sample_3238 =========================

public void testGet_NullQualifier() throws IOException {	Table table = TEST_UTIL.createTable(TableName.valueOf(name.getMethodName()), FAMILY);	Put put = new Put(ROW);	put.addColumn(FAMILY, QUALIFIER, VALUE);	table.put(put);	put = new Put(ROW);	put.addColumn(FAMILY, null, VALUE);	table.put(put);	
row put 

public void testGet_NonExistentRow() throws IOException {	Table table = TEST_UTIL.createTable(TableName.valueOf(name.getMethodName()), FAMILY);	Put put = new Put(ROW);	put.addColumn(FAMILY, QUALIFIER, VALUE);	table.put(put);	
row put 

Get get = new Get(ROW);	get.addFamily(FAMILY);	Result r = table.get(get);	assertFalse(r.isEmpty());	System.out.println("Row retrieved successfully");	byte [] missingrow = Bytes.toBytes("missingrow");	get = new Get(missingrow);	get.addFamily(FAMILY);	r = table.get(get);	assertTrue(r.isEmpty());	
row missing as it should be 

public void testMultiRowMutation() throws Exception {	
starting testmultirowmutation 

public void testRowMutation() throws Exception {	
starting testrowmutation 

public void testBatchAppendWithReturnResultFalse() throws Exception {	
starting testbatchappendwithreturnresultfalse 

public void testAppend() throws Exception {	
starting testappend 

private List<Result> doAppend(final boolean walUsed) throws IOException {	
starting testappend walused is 

Put put3 = new Put(Bytes.toBytes("zzz3"));	put3.addColumn(FAMILY, QUALIFIER, VALUE);	ht.put(Arrays.asList(put1, put2, put3));	Scan scan1 = new Scan();	int numRecords = 0;	ResultScanner scanner = ht.getScanner(scan1);	for(Result result : scanner) {	numRecords++;	}	scanner.close();	
test data has records 

public void testScan_NullQualifier() throws IOException {	Table table = TEST_UTIL.createTable(TableName.valueOf(name.getMethodName()), FAMILY);	Put put = new Put(ROW);	put.addColumn(FAMILY, QUALIFIER, VALUE);	table.put(put);	put = new Put(ROW);	put.addColumn(FAMILY, null, VALUE);	table.put(put);	
row put 

========================= hbase sample_2096 =========================

if (reader != null) {	reader.close();	}	if (primaryRegion != null) {	HBaseTestingUtility.closeRegionAndWAL(primaryRegion);	}	if (secondaryRegion != null) {	HBaseTestingUtility.closeRegionAndWAL(secondaryRegion);	}	EnvironmentEdgeManagerTestHelper.reset();	
cleaning test directory 

public void testOnlyReplayingFlushStartDoesNotHoldUpRegionClose() throws IOException {	int start = 0;	
writing some data to primary from to 

public void testOnlyReplayingFlushStartDoesNotHoldUpRegionClose() throws IOException {	int start = 0;	putData(primaryRegion, Durability.SYNC_WAL, start, 100, cq, families);	
flushing primary creating files for stores 

public void testOnlyReplayingFlushStartDoesNotHoldUpRegionClose() throws IOException {	int start = 0;	putData(primaryRegion, Durability.SYNC_WAL, start, 100, cq, families);	primaryRegion.flush(true);	reader = createWALReaderForPrimary();	
replaying edits and flush events in secondary 

primaryRegion.flush(true);	reader = createWALReaderForPrimary();	while (true) {	WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	
replaying flush start in secondary 

while (true) {	WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	secondaryRegion.replayWALFlushStartMarker(flushDesc);	} else if (flushDesc.getAction() == FlushAction.COMMIT_FLUSH) {	
not replaying flush commit in secondary 

public void testReplayFlushesAndCompactions() throws IOException {	putDataWithFlushes(primaryRegion, 100, 300, 100);	
compacting primary only store 

public void testReplayFlushesAndCompactions() throws IOException {	putDataWithFlushes(primaryRegion, 100, 300, 100);	primaryRegion.compactStore(Bytes.toBytes("cf1"), NoLimitThroughputController.INSTANCE);	reader = createWALReaderForPrimary();	
replaying edits and flush events in secondary 

CompactionDescriptor compactionDesc = WALEdit.getCompaction(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	verifyData(secondaryRegion, 0, lastReplayed, cq, families);	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long storeMemstoreSize = store.getMemStoreSize().getHeapSize();	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	long storeFlushableSize = store.getFlushableSize().getHeapSize();	long storeSize = store.getSize();	long storeSizeUncompressed = store.getStoreSizeUncompressed();	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	
replaying flush start in secondary 

long storeMemstoreSize = store.getMemStoreSize().getHeapSize();	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	long storeFlushableSize = store.getFlushableSize().getHeapSize();	long storeSize = store.getSize();	long storeSizeUncompressed = store.getStoreSizeUncompressed();	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	PrepareFlushResult result = secondaryRegion.replayWALFlushStartMarker(flushDesc);	assertNull(result.result);	assertEquals(result.flushOpSeqId, flushDesc.getFlushSequenceNumber());	long newStoreMemstoreSize = store.getMemStoreSize().getHeapSize();	
memstore size reduced by 

long storeFlushableSize = store.getFlushableSize().getHeapSize();	long storeSize = store.getSize();	long storeSizeUncompressed = store.getStoreSizeUncompressed();	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	PrepareFlushResult result = secondaryRegion.replayWALFlushStartMarker(flushDesc);	assertNull(result.result);	assertEquals(result.flushOpSeqId, flushDesc.getFlushSequenceNumber());	long newStoreMemstoreSize = store.getMemStoreSize().getHeapSize();	assertTrue(storeMemstoreSize > newStoreMemstoreSize);	} else if (flushDesc.getAction() == FlushAction.COMMIT_FLUSH) {	
replaying flush commit in secondary 

assertEquals(1, store.getStorefilesCount());	} else {	assertEquals(expectedStoreFileCount, store.getStorefilesCount());	}	}	} else {	lastReplayed = replayEdit(secondaryRegion, entry);	}	}	assertEquals(400-1, lastReplayed);	
verifying edits from secondary 

} else {	assertEquals(expectedStoreFileCount, store.getStorefilesCount());	}	}	} else {	lastReplayed = replayEdit(secondaryRegion, entry);	}	}	assertEquals(400-1, lastReplayed);	verifyData(secondaryRegion, 0, 400, cq, families);	
verifying edits from primary ensuring that files are not deleted 

public void testReplayFlushStartMarkers() throws IOException {	putDataWithFlushes(primaryRegion, 100, 100, 100);	int numRows = 200;	reader =  createWALReaderForPrimary();	
replaying edits and flush events in secondary 

break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long storeMemstoreSize = store.getMemStoreSize().getHeapSize();	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	long storeFlushableSize = store.getFlushableSize().getHeapSize();	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	startFlushDesc = flushDesc;	
replaying flush start in secondary 

long regionMemstoreSize = secondaryRegion.getMemStoreSize();	long storeFlushableSize = store.getFlushableSize().getHeapSize();	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	startFlushDesc = flushDesc;	PrepareFlushResult result = secondaryRegion.replayWALFlushStartMarker(startFlushDesc);	assertNull(result.result);	assertEquals(result.flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(regionMemstoreSize > 0);	assertTrue(storeFlushableSize > 0);	long newStoreMemstoreSize = store.getMemStoreSize().getHeapSize();	
memstore size reduced by 

long newStoreMemstoreSize = store.getMemStoreSize().getHeapSize();	assertTrue(storeMemstoreSize > newStoreMemstoreSize);	verifyData(secondaryRegion, 0, lastReplayed+1, cq, families);	}	verifyData(secondaryRegion, 0, lastReplayed+1, cq, families);	} else {	lastReplayed = replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	
replaying same flush start in secondary again 

}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	PrepareFlushResult result = secondaryRegion.replayWALFlushStartMarker(startFlushDesc);	assertNull(result);	assertNotNull(secondaryRegion.getPrepareFlushResult());	assertEquals(secondaryRegion.getPrepareFlushResult().flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	FlushDescriptor startFlushDescSmallerSeqId = clone(startFlushDesc, startFlushDesc.getFlushSequenceNumber() - 50);	
replaying same flush start in secondary again 

assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	FlushDescriptor startFlushDescSmallerSeqId = clone(startFlushDesc, startFlushDesc.getFlushSequenceNumber() - 50);	result = secondaryRegion.replayWALFlushStartMarker(startFlushDescSmallerSeqId);	assertNull(result);	assertNotNull(secondaryRegion.getPrepareFlushResult());	assertEquals(secondaryRegion.getPrepareFlushResult().flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	FlushDescriptor startFlushDescLargerSeqId = clone(startFlushDesc, startFlushDesc.getFlushSequenceNumber() + 50);	
replaying same flush start in secondary again 

assertEquals(secondaryRegion.getPrepareFlushResult().flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	FlushDescriptor startFlushDescLargerSeqId = clone(startFlushDesc, startFlushDesc.getFlushSequenceNumber() + 50);	result = secondaryRegion.replayWALFlushStartMarker(startFlushDescLargerSeqId);	assertNull(result);	assertNotNull(secondaryRegion.getPrepareFlushResult());	assertEquals(secondaryRegion.getPrepareFlushResult().flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from secondary 

assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	FlushDescriptor startFlushDescLargerSeqId = clone(startFlushDesc, startFlushDesc.getFlushSequenceNumber() + 50);	result = secondaryRegion.replayWALFlushStartMarker(startFlushDescLargerSeqId);	assertNull(result);	assertNotNull(secondaryRegion.getPrepareFlushResult());	assertEquals(secondaryRegion.getPrepareFlushResult().flushOpSeqId, startFlushDesc.getFlushSequenceNumber());	assertTrue(secondaryRegion.getMemStoreSize() > 0);	verifyData(secondaryRegion, 0, numRows, cq, families);	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testReplayFlushCommitMarkerSmallerThanFlushStartMarker() throws IOException {	putDataWithFlushes(primaryRegion, 100, 200, 100);	int numRows = 300;	reader =  createWALReaderForPrimary();	
replaying edits and flush events in secondary 

WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	if (startFlushDesc == null) {	startFlushDesc = flushDesc;	} else {	
replaying flush start in secondary 

} else {	lastReplayed = replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	
testing replaying flush commit on top of flush start 

lastReplayed = replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(commitFlushDesc.getFlushSequenceNumber() < startFlushDesc.getFlushSequenceNumber());	
replaying flush commit in secondary 

expectedStoreFileCount++;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize > 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertEquals(regionMemstoreSize, newRegionMemstoreSize);	assertNotNull(secondaryRegion.getPrepareFlushResult());	
verifying edits from secondary 

for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize > 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertEquals(regionMemstoreSize, newRegionMemstoreSize);	assertNotNull(secondaryRegion.getPrepareFlushResult());	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testReplayFlushCommitMarkerLargerThanFlushStartMarker() throws IOException {	putDataWithFlushes(primaryRegion, 100, 100, 100);	int numRows = 200;	reader =  createWALReaderForPrimary();	
replaying edits and flush events in secondary 

int lastReplayed = 0;	while (true) {	WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	if (startFlushDesc == null) {	
replaying flush start in secondary 

} else {	lastReplayed = replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	
testing replaying flush commit on top of flush start 

lastReplayed = replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(commitFlushDesc.getFlushSequenceNumber() > startFlushDesc.getFlushSequenceNumber());	
replaying flush commit in secondary 

for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize > 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize > 0);	assertTrue(regionMemstoreSize > newRegionMemstoreSize);	assertNull(secondaryRegion.getPrepareFlushResult());	
verifying edits from secondary 

assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize > 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize > 0);	assertTrue(regionMemstoreSize > newRegionMemstoreSize);	assertNull(secondaryRegion.getPrepareFlushResult());	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testReplayFlushCommitMarkerWithoutFlushStartMarker(boolean droppableMemstore) throws IOException {	putDataWithFlushes(primaryRegion, 100, 100, droppableMemstore ? 0 : 100);	int numRows = droppableMemstore ? 100 : 200;	reader =  createWALReaderForPrimary();	
replaying edits and flush events in secondary 

int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	assertNull(secondaryRegion.getPrepareFlushResult());	assertTrue(commitFlushDesc.getFlushSequenceNumber() > 0);	for (HStore store : secondaryRegion.getStores()) {	assertTrue(store.getMaxSequenceId().orElse(0L) <= secondaryRegion.getReadPoint(null));	}	
replaying flush commit in secondary 

assertTrue(newFlushableSize == MutableSegment.DEEP_OVERHEAD);	} else {	assertTrue(newFlushableSize > 0);	}	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	if (droppableMemstore) {	assertTrue(0 == newRegionMemstoreSize);	} else {	assertTrue(regionMemstoreSize == newRegionMemstoreSize);	}	
verifying edits from secondary 

} else {	assertTrue(newFlushableSize > 0);	}	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	if (droppableMemstore) {	assertTrue(0 == newRegionMemstoreSize);	} else {	assertTrue(regionMemstoreSize == newRegionMemstoreSize);	}	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testReplayRegionOpenEvent() throws IOException {	putDataWithFlushes(primaryRegion, 100, 0, 100);	int numRows = 100;	primaryRegion.close();	primaryRegion = HRegion.openHRegion(rootDir, primaryHri, htd, walPrimary, CONF, rss, null);	reader =  createWALReaderForPrimary();	List<RegionEventDescriptor> regionEvents = Lists.newArrayList();	
replaying edits and region events in secondary 

}	assertEquals(3, regionEvents.size());	secondaryRegion.replayWALRegionEventMarker(regionEvents.get(0));	secondaryRegion.replayWALRegionEventMarker(regionEvents.get(1));	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	long regionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(regionMemstoreSize == 0);	
testing replaying region open event 

expectedStoreFileCount++;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize == MutableSegment.DEEP_OVERHEAD);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize == 0);	assertNull(secondaryRegion.getPrepareFlushResult());	
verifying edits from secondary 

for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	long newFlushableSize = store.getFlushableSize().getHeapSize();	assertTrue(newFlushableSize == MutableSegment.DEEP_OVERHEAD);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize == 0);	assertNull(secondaryRegion.getPrepareFlushResult());	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testReplayRegionOpenEventAfterFlushStart() throws IOException {	putDataWithFlushes(primaryRegion, 100, 100, 100);	int numRows = 200;	primaryRegion.close();	primaryRegion = HRegion.openHRegion(rootDir, primaryHri, htd, walPrimary, CONF, rss, null);	reader =  createWALReaderForPrimary();	List<RegionEventDescriptor> regionEvents = Lists.newArrayList();	
replaying edits and region events in secondary 

} else {	replayEdit(secondaryRegion, entry);	}	}	verifyData(secondaryRegion, 0, numRows, cq, families);	assertEquals(3, regionEvents.size());	int expectedStoreFileCount = 0;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	
testing replaying region open event 

expectedStoreFileCount = 2;	for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	MemStoreSize newSnapshotSize = store.getSnapshotSize();	assertTrue(newSnapshotSize.getDataSize() == 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize == 0);	assertNull(secondaryRegion.getPrepareFlushResult());	
verifying edits from secondary 

for (HStore s : secondaryRegion.getStores()) {	assertEquals(expectedStoreFileCount, s.getStorefilesCount());	}	HStore store = secondaryRegion.getStore(Bytes.toBytes("cf1"));	MemStoreSize newSnapshotSize = store.getSnapshotSize();	assertTrue(newSnapshotSize.getDataSize() == 0);	long newRegionMemstoreSize = secondaryRegion.getMemStoreSize();	assertTrue(newRegionMemstoreSize == 0);	assertNull(secondaryRegion.getPrepareFlushResult());	verifyData(secondaryRegion, 0, numRows, cq, families);	
verifying edits from primary 

public void testSkippingEditsWithSmallerSeqIdAfterRegionOpenEvent() throws IOException {	putDataWithFlushes(primaryRegion, 100, 100, 0);	int numRows = 100;	primaryRegion.close();	primaryRegion = HRegion.openHRegion(rootDir, primaryHri, htd, walPrimary, CONF, rss, null);	reader =  createWALReaderForPrimary();	List<RegionEventDescriptor> regionEvents = Lists.newArrayList();	List<WAL.Entry> edits = Lists.newArrayList();	
replaying edits and region events in secondary 

public void testReplayFlushSeqIds() throws IOException {	int start = 0;	
writing some data to primary from to 

public void testReplayFlushSeqIds() throws IOException {	int start = 0;	putData(primaryRegion, Durability.SYNC_WAL, start, 100, cq, families);	
flushing primary creating files for stores 

public void testReplayFlushSeqIds() throws IOException {	int start = 0;	putData(primaryRegion, Durability.SYNC_WAL, start, 100, cq, families);	primaryRegion.flush(true);	reader =  createWALReaderForPrimary();	long flushSeqId = -1;	
replaying flush events in secondary 

reader =  createWALReaderForPrimary();	long flushSeqId = -1;	while (true) {	WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	
replaying flush start in secondary 

WAL.Entry entry = reader.next();	if (entry == null) {	break;	}	FlushDescriptor flushDesc = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flushDesc != null) {	if (flushDesc.getAction() == FlushAction.START_FLUSH) {	secondaryRegion.replayWALFlushStartMarker(flushDesc);	flushSeqId = flushDesc.getFlushSequenceNumber();	} else if (flushDesc.getAction() == FlushAction.COMMIT_FLUSH) {	
replaying flush commit in secondary 

public void testRefresStoreFiles() throws IOException {	assertEquals(0, primaryRegion.getStoreFileList(families).size());	assertEquals(0, secondaryRegion.getStoreFileList(families).size());	secondaryRegion.refreshStoreFiles();	assertEquals(0, secondaryRegion.getStoreFileList(families).size());	putDataWithFlushes(primaryRegion, 100, 100, 0);	int numRows = 100;	secondaryRegion.refreshStoreFiles();	assertPathListsEqual(primaryRegion.getStoreFileList(families), secondaryRegion.getStoreFileList(families));	assertEquals(families.length, secondaryRegion.getStoreFileList(families).size());	
verifying edits from secondary 

int numRows = 100;	secondaryRegion.refreshStoreFiles();	assertPathListsEqual(primaryRegion.getStoreFileList(families), secondaryRegion.getStoreFileList(families));	assertEquals(families.length, secondaryRegion.getStoreFileList(families).size());	verifyData(secondaryRegion, 0, numRows, cq, families);	putDataWithFlushes(primaryRegion, 100, 300, 0);	numRows = 300;	secondaryRegion.refreshStoreFiles();	assertPathListsEqual(primaryRegion.getStoreFileList(families), secondaryRegion.getStoreFileList(families));	assertEquals(families.length * 4, secondaryRegion.getStoreFileList(families).size());	
verifying edits from secondary 

}	primaryRegion.compactStores();	List<HRegion> regions = new ArrayList<>();	regions.add(primaryRegion);	Mockito.doReturn(regions).when(rss).getRegions();	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, rss, false);	cleaner.chore();	secondaryRegion.refreshStoreFiles();	assertPathListsEqual(primaryRegion.getStoreFileList(families), secondaryRegion.getStoreFileList(families));	assertEquals(families.length, secondaryRegion.getStoreFileList(families).size());	
verifying edits from secondary 

primaryRegion.compactStores();	List<HRegion> regions = new ArrayList<>();	regions.add(primaryRegion);	Mockito.doReturn(regions).when(rss).getRegions();	CompactedHFilesDischarger cleaner = new CompactedHFilesDischarger(100, null, rss, false);	cleaner.chore();	secondaryRegion.refreshStoreFiles();	assertPathListsEqual(primaryRegion.getStoreFileList(families), secondaryRegion.getStoreFileList(families));	assertEquals(families.length, secondaryRegion.getStoreFileList(families).size());	verifyData(secondaryRegion, 0, numRows, cq, families);	
replaying edits in secondary 

}	FlushDescriptor flush = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flush != null) {	} else {	replayEdit(secondaryRegion, entry);	}	}	assertTrue(secondaryRegion.getMemStoreSize() > 0);	secondaryRegion.refreshStoreFiles();	assertTrue(secondaryRegion.getMemStoreSize() == 0);	
verifying edits from primary 

FlushDescriptor flush = WALEdit.getFlushDescriptor(entry.getEdit().getCells().get(0));	if (flush != null) {	} else {	replayEdit(secondaryRegion, entry);	}	}	assertTrue(secondaryRegion.getMemStoreSize() > 0);	secondaryRegion.refreshStoreFiles();	assertTrue(secondaryRegion.getMemStoreSize() == 0);	verifyData(primaryRegion, 0, numRows, cq, families);	
verifying edits from secondary 

public void testReplayBulkLoadEvent() throws IOException {	
testreplaybulkloadevent starts 

random.nextBytes(randomValues);	Path testPath = TEST_UTIL.getDataTestDirOnTestFS();	List<Pair<byte[], String>> familyPaths = new ArrayList<>();	int expectedLoadFileCount = 0;	for (byte[] family : families) {	familyPaths.add(new Pair<>(family, createHFileForFamilies(testPath, family, randomValues)));	expectedLoadFileCount++;	}	primaryRegion.bulkLoadHFiles(familyPaths, false, null);	reader = createWALReaderForPrimary();	
replaying edits and region events in secondary 

List<String> storeFileName = new ArrayList<>();	for (StoreDescriptor storeDesc : bulkloadEvent.getStoresList()) {	storeFileName.addAll(storeDesc.getStoreFileList());	}	for (HStore s : secondaryRegion.getStores()) {	for (HStoreFile sf : s.getStorefiles()) {	storeFileName.remove(sf.getPath().getName());	}	}	assertTrue("Found some store file isn't loaded:" + storeFileName, storeFileName.isEmpty());	
verifying edits from secondary 

private void putDataWithFlushes(HRegion region, int flushInterval, int numRows, int numRowsAfterFlush) throws IOException {	int start = 0;	for (; start < numRows; start += flushInterval) {	
writing some data to primary from to 

private void putDataWithFlushes(HRegion region, int flushInterval, int numRows, int numRowsAfterFlush) throws IOException {	int start = 0;	for (; start < numRows; start += flushInterval) {	putData(region, Durability.SYNC_WAL, start, flushInterval, cq, families);	
flushing primary creating files for stores 

private void putDataWithFlushes(HRegion region, int flushInterval, int numRows, int numRowsAfterFlush) throws IOException {	int start = 0;	for (; start < numRows; start += flushInterval) {	putData(region, Durability.SYNC_WAL, start, flushInterval, cq, families);	region.flush(true);	}	
writing some more data to primary not flushing 

========================= hbase sample_1593 =========================

public Response put(final ScannerModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
put 

public Response post(final ScannerModel model, final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
post 

========================= hbase sample_3111 =========================

buf.putShort((short) 2);	buf.putInt(i1);	buf.putInt(i2);	for (int c = 0; c < 5; c++) {	byte[] cq = new byte[4];	Bytes.putBytes(cq, 0, Bytes.toBytes(c), 0, 4);	Put p = new Put(rk);	p.setDurability(Durability.SKIP_WAL);	p.addColumn(cf.getBytes(), cq, Bytes.toBytes(c));	ht.put(p);	
inserting rk cq 

Scan scan = new Scan();	scan.addFamily(cf.getBytes());	FilterList filterList = new FilterList(filters);	scan.setFilter(filterList);	ResultScanner scanner = hTable.getScanner(scan);	List<Cell> results = new ArrayList<>();	Result result;	long timeBeforeScan = System.currentTimeMillis();	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	
got rk cq 

Result result;	long timeBeforeScan = System.currentTimeMillis();	while ((result = scanner.next()) != null) {	for (Cell kv : result.listCells()) {	results.add(kv);	}	}	long scanTime = System.currentTimeMillis() - timeBeforeScan;	scanner.close();	LOG.info("scan time = " + scanTime + "ms");	
found results 

========================= hbase sample_1985 =========================

}	conf.setStrings(TABLES_KEY, tables);	conf.setStrings(TABLE_MAP_KEY, tableMap);	conf.set(FileInputFormat.INPUT_DIR, inputDirs);	Job job = Job.getInstance(conf, conf.get(JOB_NAME_CONF_KEY, NAME + "_" + System.currentTimeMillis()));	job.setJarByClass(WALPlayer.class);	job.setInputFormatClass(WALInputFormat.class);	job.setMapOutputKeyClass(ImmutableBytesWritable.class);	String hfileOutPath = conf.get(BULK_OUTPUT_CONF_KEY);	if (hfileOutPath != null) {	
add incremental job from 

========================= hbase sample_3473 =========================

protected void postPeerModification(MasterProcedureEnv env) throws IOException {	
successfully enabled peer 

========================= hbase sample_2848 =========================

Thread.currentThread().setName(clientId);	Random rand = new Random();	long endTime = System.currentTimeMillis() + NUM_SECONDS * 1000;	while (System.currentTimeMillis() < endTime) {	long id = rand.nextInt(NUM_IDS);	IdLock.Entry lockEntry = idLock.getLockEntry(id);	try {	int sleepMs = 1 + rand.nextInt(4);	String owner = idOwner.get(id);	if (owner != null) {	
id already taken by failed 

========================= hbase sample_1337 =========================

public void testTimeoutAndRetries() throws IOException {	Configuration localConfig = HBaseConfiguration.create(this.conf);	localConfig.set("hbase.client.connection.impl", RpcTimeoutConnection.class.getName());	Connection connection = ConnectionFactory.createConnection(localConfig);	Table table = connection.getTable(TableName.META_TABLE_NAME);	Throwable t = null;	
Start 

public void testTimeoutAndRetries() throws IOException {	Configuration localConfig = HBaseConfiguration.create(this.conf);	localConfig.set("hbase.client.connection.impl", RpcTimeoutConnection.class.getName());	Connection connection = ConnectionFactory.createConnection(localConfig);	Table table = connection.getTable(TableName.META_TABLE_NAME);	Throwable t = null;	try {	table.exists(new Get(Bytes.toBytes("abc")));	} catch (SocketTimeoutException e) {	
got expected exception 

try {	table.exists(new Get(Bytes.toBytes("abc")));	} catch (SocketTimeoutException e) {	t = e;	} catch (RetriesExhaustedException e) {	fail();	} finally {	table.close();	}	connection.close();	
Stop 

int pause = 10;	localConfig.setInt("hbase.client.pause", pause);	localConfig.setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 10);	localConfig.setInt(HConstants.HBASE_CLIENT_META_OPERATION_TIMEOUT, pause - 1);	Connection connection = ConnectionFactory.createConnection(localConfig);	Table table = connection.getTable(TableName.META_TABLE_NAME);	Throwable t = null;	try {	table.exists(new Get(Bytes.toBytes("abc")));	} catch (SocketTimeoutException e) {	
got expected exception 

boolean get = c.getBoolean("hbase.test.do.gets", false);	TableName tableName = TableName.valueOf(BIG_USER_TABLE);	if (get) {	try (Table table = sharedConnection.getTable(tableName)){	Stopwatch stopWatch = Stopwatch.createStarted();	for (int i = 0; i < namespaceSpan; i++) {	byte [] b = format(rd.nextLong());	Get g = new Get(b);	table.get(g);	if (i % printInterval == 0) {	
get 

Stopwatch stopWatch = Stopwatch.createStarted();	for (int i = 0; i < namespaceSpan; i++) {	byte [] b = format(rd.nextLong());	Get g = new Get(b);	table.get(g);	if (i % printInterval == 0) {	stopWatch.reset();	stopWatch.start();	}	}	
finished a cycle putting in ms 

}	} else {	try (BufferedMutator mutator = sharedConnection.getBufferedMutator(tableName)) {	Stopwatch stopWatch = Stopwatch.createStarted();	for (int i = 0; i < namespaceSpan; i++) {	byte [] b = format(rd.nextLong());	Put p = new Put(b);	p.addColumn(HConstants.CATALOG_FAMILY, b, b);	mutator.mutate(p);	if (i % printInterval == 0) {	
put 

for (int i = 0; i < namespaceSpan; i++) {	byte [] b = format(rd.nextLong());	Put p = new Put(b);	p.addColumn(HConstants.CATALOG_FAMILY, b, b);	mutator.mutate(p);	if (i % printInterval == 0) {	stopWatch.reset();	stopWatch.start();	}	}	
finished a cycle putting in ms 

int errCode = 0;	final int servers = 1;	final int regions = 100000;	final long namespaceSpan = 50000000;	final long multiPause = 0;	if ((namespaceSpan < regions) || (regions < servers)) {	throw new IllegalArgumentException("namespaceSpan=" + namespaceSpan + " must be > regions=" + regions + " which must be > servers=" + servers);	}	getConf().set("hbase.client.connection.impl", ManyServersManyRegionsConnection.class.getName());	getConf().set("hbase.client.registry.impl", SimpleRegistry.class.getName());	
hbase client start log errors counter 

========================= hbase sample_70 =========================

public void runLoad() throws Exception {	setupTable();	int numImportRounds = getConf().getInt(BULKLOAD_IMPORT_ROUNDS, DEFAULT_BULKLOAD_IMPORT_ROUNDS);	
running load with numiterations 

public void runLinkedListSparkJob(int iteration) throws Exception {	String jobName =  IntegrationTestSparkBulkLoad.class.getSimpleName() + " _load " + EnvironmentEdgeManager.currentTime();	
running iteration in spark job 

output = util.getDataTestDirOnTestFS(getTablename() + "-" + iteration);	} else {	output = new Path(conf.get(BULKLOAD_OUTPUT_PATH));	}	SparkConf sparkConf = new SparkConf().setAppName(jobName).setMaster("local");	Configuration hbaseConf = new Configuration(getConf());	hbaseConf.setInt(CURRENT_ROUND_NUM, iteration);	int partitionNum = hbaseConf.getInt(BULKLOAD_PARTITIONS_NUM, DEFAULT_BULKLOAD_PARTITIONS_NUM);	JavaSparkContext jsc = new JavaSparkContext(sparkConf);	JavaHBaseContext hbaseContext = new JavaHBaseContext(jsc, hbaseConf);	
partition rdd into parts 

public Iterator<List<byte[]>> call(Integer v1, Iterator v2) throws Exception {	Configuration config = (Configuration) swConfig.value();	int partitionId = v1.intValue();	
starting create list in partition 

public void runCheck() throws Exception {	
running check 

private void runCheckWithRetry() throws Exception {	try {	runCheck();	} catch (Throwable t) {	
received 

private void runCheckWithRetry() throws Exception {	try {	runCheck();	} catch (Throwable t) {	
running the check mr job again to see whether an ephemeral problem or not 

public void setUpCluster() throws Exception {	util = getTestingUtil(getConf());	util.initializeCluster(1);	int replicaCount = getConf().getInt(NUM_REPLICA_COUNT_KEY, DEFAULT_NUM_REPLICA_COUNT);	if (LOG.isDebugEnabled() && replicaCount != DEFAULT_NUM_REPLICA_COUNT) {	
region replicas enabled 

========================= hbase sample_3131 =========================

final Class<? extends InputStream> streamClass = wrappedStream.getClass();	if (this.instanceOfCanUnbuffer == null) {	this.instanceOfCanUnbuffer = false;	Class<?>[] streamInterfaces = streamClass.getInterfaces();	for (Class c : streamInterfaces) {	if (c.getCanonicalName().toString().equals("org.apache.hadoop.fs.CanUnbuffer")) {	try {	this.unbuffer = streamClass.getDeclaredMethod("unbuffer");	} catch (NoSuchMethodException | SecurityException e) {	if (isLogTraceEnabled) {	
failed to find unbuffer method in class so there may be a tcp socket connection left open in close wait state 

this.instanceOfCanUnbuffer = true;	break;	}	}	}	if (this.instanceOfCanUnbuffer) {	try {	this.unbuffer.invoke(wrappedStream);	} catch (IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {	if (isLogTraceEnabled) {	
failed to invoke unbuffer method in class so there may be a tcp socket connection left open in close wait state 

}	if (this.instanceOfCanUnbuffer) {	try {	this.unbuffer.invoke(wrappedStream);	} catch (IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {	if (isLogTraceEnabled) {	}	}	} else {	if (isLogTraceEnabled) {	
failed to find unbuffer method in class so there may be a tcp socket connection left open in close wait state for more details check https 

========================= hbase sample_2370 =========================

public void testStartAfterComplete() throws InterruptedException {	final long time = 10;	ForeignExceptionListener listener = Mockito.mock(ForeignExceptionListener.class);	TimeoutExceptionInjector timer = new TimeoutExceptionInjector(listener, time);	timer.complete();	try {	timer.start();	fail("Timer should fail to start after complete.");	} catch (IllegalStateException e) {	
correctly failed timer 

public void testStartAfterTrigger() throws InterruptedException {	final long time = 10;	ForeignExceptionListener listener = Mockito.mock(ForeignExceptionListener.class);	TimeoutExceptionInjector timer = new TimeoutExceptionInjector(listener, time);	timer.trigger();	try {	timer.start();	fail("Timer should fail to start after complete.");	} catch (IllegalStateException e) {	
correctly failed timer 

========================= hbase sample_1419 =========================

props = readCryptoProps(provider.getConf());	rngAlgorithm = provider.getConf().get(RNG_ALGORITHM_KEY, "SHA1PRNG");	String rngProvider = provider.getConf().get(RNG_PROVIDER_KEY);	try {	if (rngProvider != null) {	rng = SecureRandom.getInstance(rngAlgorithm, rngProvider);	} else {	rng = SecureRandom.getInstance(rngAlgorithm);	}	} catch (GeneralSecurityException e) {	
could not instantiate specified rng falling back to default 

========================= hbase sample_1049 =========================

public CellSetModelStream get(final @Context UriInfo uriInfo) {	if (LOG.isTraceEnabled()) {	
get 

public Response getProtobuf( final @Context UriInfo uriInfo, final @HeaderParam("Accept") String contentType) {	if (LOG.isTraceEnabled()) {	
get as 

========================= hbase sample_3074 =========================

public void tearDown() throws Exception {	EnvironmentEdgeManagerTestHelper.reset();	
cleaning test directory 

Threads.sleep(1);	}	}	} finally {	Mockito.when(server.isStopped()).thenReturn(true);	if (logRoller != null) logRoller.close();	if (region != null) {	try {	region.close(true);	} catch (DroppedSnapshotException e) {	
on way out expected 

========================= hbase sample_1730 =========================

public void receive(ClusterMetrics ncs) {	if (ncs.getDeadServerNames() != null) {	for (ServerName sn : ncs.getDeadServerNames()) {	if (!isDeadServer(sn)) {	
there is a new dead server 

public void exceptionCaught( ChannelHandlerContext ctx, Throwable cause) throws Exception {	
unexpected exception continuing 

========================= hbase sample_342 =========================

public void testWALRollWriting() throws Exception {	setUpforLogRolling();	String className = this.getClass().getName();	StringBuilder v = new StringBuilder(className);	while (v.length() < 1000) {	v.append(className);	}	byte[] value = Bytes.toBytes(v.toString());	HRegionServer regionServer = startAndWriteData(TableName.valueOf(name.getMethodName()), value);	
after writing there are log files 

while (v.length() < 1000) {	v.append(className);	}	byte[] value = Bytes.toBytes(v.toString());	HRegionServer regionServer = startAndWriteData(TableName.valueOf(name.getMethodName()), value);	for (HRegion r : regionServer.getOnlineRegionsLocalContext()) {	r.flush(true);	}	admin.rollWALWriter(regionServer.getServerName());	int count = AbstractFSWALProvider.getNumRolledLogFiles(regionServer.getWAL(null));	
after flushing all regions and rolling logs there are log files 

Configuration conf = new Configuration(TEST_UTIL.getConfiguration());	conf.setInt(HConstants.ZOOKEEPER_CLIENT_PORT, conf.getInt(HConstants.ZOOKEEPER_CLIENT_PORT, 9999)+10);	long start = System.currentTimeMillis();	try {	HBaseAdmin.available(conf);	assertTrue(false);	} catch (ZooKeeperConnectionException ignored) {	} catch (IOException ignored) {	}	long end = System.currentTimeMillis();	
it took ms to find out that hbase was not available 

public void testGetRegion() throws Exception {	HBaseAdmin rawAdmin = TEST_UTIL.getHBaseAdmin();	final TableName tableName = TableName.valueOf(name.getMethodName());	
started 

========================= hbase sample_2059 =========================

public void stop(String why) {	
stop 

public void execProcedure(ProcedureDescription desc) throws IOException {	if (!isBackupEnabled()) {	
backup is not enabled check your setting 

data = conf.get(0).getValue().getBytes();	}	Procedure proc = coordinator.startProcedure(monitor, desc.getInstance(), data, servers);	if (proc == null) {	String msg = "Failed to submit distributed procedure for '" + desc.getInstance() + "'";	LOG.error(msg);	throw new IOException(msg);	}	try {	proc.waitForCompleted();	
done waiting exec procedure for 

data = conf.get(0).getValue().getBytes();	}	Procedure proc = coordinator.startProcedure(monitor, desc.getInstance(), data, servers);	if (proc == null) {	String msg = "Failed to submit distributed procedure for '" + desc.getInstance() + "'";	LOG.error(msg);	throw new IOException(msg);	}	try {	proc.waitForCompleted();	
distributed roll log procedure is successful 

========================= hbase sample_587 =========================

conf.setInt("hbase.ipc.client.failed.servers.expiry", 200);	conf.setInt(ServerManager.WAIT_ON_REGIONSERVERS_MINTOSTART, 1);	final HBaseTestingUtility util = new HBaseTestingUtility(conf);	util.startMiniDFSCluster(3);	util.startMiniZKCluster();	util.createRootDir();	final LocalHBaseCluster cluster = new LocalHBaseCluster(conf, NUM_MASTERS, NUM_RS, HMaster.class, MiniHBaseCluster.MiniHBaseClusterRegionServer.class);	final int MASTER_INDEX = 0;	final MasterThread master = cluster.getMasters().get(MASTER_INDEX);	master.start();	
called master start on 

final HBaseTestingUtility util = new HBaseTestingUtility(conf);	util.startMiniDFSCluster(3);	util.startMiniZKCluster();	util.createRootDir();	final LocalHBaseCluster cluster = new LocalHBaseCluster(conf, NUM_MASTERS, NUM_RS, HMaster.class, MiniHBaseCluster.MiniHBaseClusterRegionServer.class);	final int MASTER_INDEX = 0;	final MasterThread master = cluster.getMasters().get(MASTER_INDEX);	master.start();	Thread shutdownThread = new Thread("Shutdown-Thread") {	public void run() {	
before call to shutdown master 

final MasterThread master = cluster.getMasters().get(MASTER_INDEX);	master.start();	Thread shutdownThread = new Thread("Shutdown-Thread") {	public void run() {	try {	try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {	try (Admin admin = connection.getAdmin()) {	admin.shutdown();	}	}	
after call to shutdown master 

try (Admin admin = connection.getAdmin()) {	admin.shutdown();	}	}	cluster.waitOnMaster(MASTER_INDEX);	} catch (Exception e) {	}	}	};	shutdownThread.start();	
called master join on 

========================= hbase sample_1819 =========================

Class<?> classRef;	Method mBeanMethod;	try {	classRef = Class.forName("com.sun.management.UnixOperatingSystemMXBean");	if (classRef.isInstance(osMbean)) {	mBeanMethod = classRef.getMethod(mBeanMethodName);	unixos = classRef.cast(osMbean);	return (Long) mBeanMethod.invoke(unixos);	}	} catch (Exception e) {	
not able to load class or method for com sun management unixoperatingsystemmxbean 

String[] pidhost = rtname.split("@");	Process p = Runtime.getRuntime().exec( new String[]{"bash", "-c", "ls /proc/" + pidhost[0] + "/fdinfo | wc -l"});	inputStream = p.getInputStream();	inputStreamReader = new InputStreamReader(inputStream, StandardCharsets.UTF_8);	bufferedReader = new BufferedReader(inputStreamReader);	String openFileDesCount;	if ((openFileDesCount = bufferedReader.readLine()) != null) {	return Long.parseLong(openFileDesCount);	}	} catch (IOException ie) {	
not able to get the number of open file descriptors 

String openFileDesCount;	if ((openFileDesCount = bufferedReader.readLine()) != null) {	return Long.parseLong(openFileDesCount);	}	} catch (IOException ie) {	} finally {	if (bufferedReader != null) {	try {	bufferedReader.close();	} catch (IOException e) {	
not able to close the bufferedreader 

if (bufferedReader != null) {	try {	bufferedReader.close();	} catch (IOException e) {	}	}	if (inputStreamReader != null) {	try {	inputStreamReader.close();	} catch (IOException e) {	
not able to close the inputstreamreader 

if (inputStreamReader != null) {	try {	inputStreamReader.close();	} catch (IOException e) {	}	}	if (inputStream != null) {	try {	inputStream.close();	} catch (IOException e) {	
not able to close the inputstream 

count++;	}	return count - 1;	} catch (IOException e) {	return -1;	} finally {	if (bufferedReader != null) {	try {	bufferedReader.close();	} catch (IOException e) {	
not able to close the bufferedreader 

if (bufferedReader != null) {	try {	bufferedReader.close();	} catch (IOException e) {	}	}	if (inputStreamReader != null) {	try {	inputStreamReader.close();	} catch (IOException e) {	
not able to close the inputstreamreader 

if (inputStreamReader != null) {	try {	inputStreamReader.close();	} catch (IOException e) {	}	}	if (inputStream != null) {	try {	inputStream.close();	} catch (IOException e) {	
not able to close the inputstream 

BufferedReader output = null;	try {	Process p = Runtime.getRuntime().exec(new String[]{"bash", "-c", "ulimit -n"});	in = p.getInputStream();	output = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));	String maxFileDesCount;	if ((maxFileDesCount = output.readLine()) != null) {	return Long.parseLong(maxFileDesCount);	}	} catch (IOException ie) {	
not able to get the max number of file descriptors 

String maxFileDesCount;	if ((maxFileDesCount = output.readLine()) != null) {	return Long.parseLong(maxFileDesCount);	}	} catch (IOException ie) {	} finally {	if (output != null) {	try {	output.close();	} catch (IOException e) {	
not able to close the reader 

if (output != null) {	try {	output.close();	} catch (IOException e) {	}	}	if (in != null) {	try {	in.close();	} catch (IOException e) {	
not able to close the inputstream 

========================= hbase sample_991 =========================

protected void preCloseWriter(StoreFileWriter writer) throws IOException {	if (doWriteStripeMetadata) {	if (LOG.isDebugEnabled()) {	
write stripe metadata for 

protected void preCloseWriter(StoreFileWriter writer) throws IOException {	if (doWriteStripeMetadata) {	if (LOG.isDebugEnabled()) {	}	int index = existingWriters.indexOf(writer);	writer.appendFileInfo(StripeStoreFileManager.STRIPE_START_KEY, boundaries.get(index));	writer.appendFileInfo(StripeStoreFileManager.STRIPE_END_KEY, boundaries.get(index + 1));	} else {	if (LOG.isDebugEnabled()) {	
skip writing stripe metadata for 

private void stopUsingCurrentWriter() {	if (currentWriter != null) {	if (LOG.isDebugEnabled()) {	
stopping to use a writer after row wrote out kvs 

public void append(Cell cell) throws IOException {	boolean doCreateWriter = false;	if (currentWriter == null) {	sanityCheckLeft(left, cell);	doCreateWriter = true;	} else if (lastRowInCurrentWriter != null && !PrivateCellUtil.matchingRows(cell, lastRowInCurrentWriter, 0, lastRowInCurrentWriter.length)) {	if (LOG.isDebugEnabled()) {	
stopping to use a writer after row wrote out kvs 

if (LOG.isDebugEnabled()) {	}	lastRowInCurrentWriter = null;	cellsInCurrentWriter = 0;	cellsSeenInPrevious += cellsSeen;	doCreateWriter = true;	}	if (doCreateWriter) {	byte[] boundary = existingWriters.isEmpty() ? left : CellUtil.cloneRow(cell);	if (LOG.isDebugEnabled()) {	
creating new writer starting at 

currentWriter.append(cell);	lastCell = cell;	++cellsInCurrentWriter;	cellsSeen = cellsInCurrentWriter;	if (this.sourceScanner != null) {	cellsSeen = Math.max(cellsSeen, this.sourceScanner.getEstimatedNumberOfKvsScanned() - cellsSeenInPrevious);	}	if (lastRowInCurrentWriter == null && existingWriters.size() < targetCount && cellsSeen >= targetCells) {	lastRowInCurrentWriter = CellUtil.cloneRow(cell);	if (LOG.isDebugEnabled()) {	
preparing to start a new writer after row observed kvs and wrote out kvs 

protected void preCommitWritersInternal() throws IOException {	if (LOG.isDebugEnabled()) {	LOG.debug("Stopping with " + cellsInCurrentWriter + " kvs in last writer" + ((this.sourceScanner == null) ? "" : ("; observed estimated " + this.sourceScanner.getEstimatedNumberOfKvsScanned() + " KVs total")));	}	if (lastCell != null) {	sanityCheckRight(right, lastCell);	}	if (existingWriters.isEmpty() && 1 == targetCount) {	if (LOG.isDebugEnabled()) {	
merge expired stripes into one create an empty file to preserve metadata 

========================= hbase sample_2673 =========================

public static void visitTableStoreFiles(final FileSystem fs, final Path tableDir, final StoreFileVisitor visitor) throws IOException {	List<FileStatus> regions = FSUtils.listStatusWithStatusFilter(fs, tableDir, new FSUtils.RegionDirFilter(fs));	if (regions == null) {	if (LOG.isTraceEnabled()) {	
no regions under directory 

public static void visitRegionStoreFiles(final FileSystem fs, final Path regionDir, final StoreFileVisitor visitor) throws IOException {	List<FileStatus> families = FSUtils.listStatusWithStatusFilter(fs, regionDir, new FSUtils.FamilyDirFilter(fs));	if (families == null) {	if (LOG.isTraceEnabled()) {	
no families under region directory 

}	return;	}	PathFilter fileFilter = new FSUtils.FileFilter(fs);	for (FileStatus family: families) {	Path familyDir = family.getPath();	String familyName = familyDir.getName();	FileStatus[] storeFiles = FSUtils.listStatus(fs, familyDir, fileFilter);	if (storeFiles == null) {	if (LOG.isTraceEnabled()) {	
no hfiles found for family skipping 

========================= hbase sample_2223 =========================

Enumeration<NetworkInterface> netInterfaceList = NetworkInterface.getNetworkInterfaces();	while (netInterfaceList.hasMoreElements()) {	NetworkInterface ni = netInterfaceList.nextElement();	Enumeration<InetAddress> addrList = ni.getInetAddresses();	while (addrList.hasMoreElements()) {	InetAddress addr = addrList.nextElement();	if (addr.isLoopbackAddress() || addr.isLinkLocalAddress() || addr.isMulticastAddress()) {	continue;	}	String hostName = addr.getHostName();	
found on 

Enumeration<NetworkInterface> netInterfaceList = NetworkInterface.getNetworkInterfaces();	while (netInterfaceList.hasMoreElements()) {	NetworkInterface ni = netInterfaceList.nextElement();	Enumeration<InetAddress> addrList = ni.getInetAddresses();	while (addrList.hasMoreElements()) {	InetAddress addr = addrList.nextElement();	if (addr.isLoopbackAddress() || addr.isLinkLocalAddress() || addr.isMulticastAddress()) {	continue;	}	String hostName = addr.getHostName();	
found on 

========================= hbase sample_1726 =========================

public void setUp() throws Exception {	Admin admin = TEST_UTIL.getAdmin();	HTableDescriptor htd = new HTableDescriptor(TEST_TABLE.getTableName());	HColumnDescriptor hcd = new HColumnDescriptor(TEST_FAMILY);	hcd.setMaxVersions(4);	htd.setOwner(USER_OWNER);	htd.addFamily(hcd);	admin.createTable(htd, new byte[][] { Bytes.toBytes("s") });	TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());	
sleeping a second because of hbase 

public void tearDown() throws Exception {	try {	TEST_UTIL.deleteTable(TEST_TABLE.getTableName());	} catch (TableNotFoundException ex) {	
test deleted table 

========================= hbase sample_1376 =========================

protected FlushRegionResponse call(HBaseRpcController controller) throws Exception {	if (!Bytes.equals(location.getRegionInfo().getRegionName(), regionName)) {	if (!reload) {	throw new IOException("Cached location seems to be different than requested region.");	}	
skipping flush region because the located region is different than requested region 

========================= hbase sample_354 =========================

quotaInfo.setQuotas(namespace, quotas);	}	public void visitUserQuotas(String userName, TableName table, Quotas quotas) {	quotaInfo.setQuotas(table, quotas);	}	public void visitUserQuotas(String userName, Quotas quotas) {	quotaInfo.setQuotas(quotas);	}	});	} catch (IOException e) {	
unable to parse user quotas 

QuotaState quotaInfo = new QuotaState(nowTs);	globalQuotas.put(key, quotaInfo);	if (results[i].isEmpty()) continue;	assert Bytes.equals(row, results[i].getRow());	byte[] data = results[i].getValue(QUOTA_FAMILY_INFO, QUOTA_QUALIFIER_SETTINGS);	if (data == null) continue;	try {	Quotas quotas = quotasFromData(data);	quotaInfo.setQuotas(quotas);	} catch (IOException e) {	
unable to parse quotas 

========================= hbase sample_2331 =========================

public void nodeCreated(String path) {	if (path.equals(keysParentZNode)) {	try {	List<ZKUtil.NodeAndData> nodes = ZKUtil.getChildDataAndWatchForNewChildren(watcher, keysParentZNode);	refreshNodes(nodes);	} catch (KeeperException ke) {	
error reading data from zookeeper 

public void nodeDeleted(String path) {	if (keysParentZNode.equals(ZKUtil.getParent(path))) {	String keyId = ZKUtil.getNodeName(path);	try {	Integer id = Integer.valueOf(keyId);	secretManager.removeKey(id);	} catch (NumberFormatException nfe) {	
invalid znode name for key id 

public void nodeDataChanged(String path) {	if (keysParentZNode.equals(ZKUtil.getParent(path))) {	try {	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	if (data == null || data.length == 0) {	
ignoring empty node 

public void nodeDataChanged(String path) {	if (keysParentZNode.equals(ZKUtil.getParent(path))) {	try {	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	if (data == null || data.length == 0) {	return;	}	AuthenticationKey key = (AuthenticationKey)Writables.getWritable(data, new AuthenticationKey());	secretManager.addKey(key);	} catch (KeeperException ke) {	
error reading data from zookeeper 

try {	byte[] data = ZKUtil.getDataAndWatch(watcher, path);	if (data == null || data.length == 0) {	return;	}	AuthenticationKey key = (AuthenticationKey)Writables.getWritable(data, new AuthenticationKey());	secretManager.addKey(key);	} catch (KeeperException ke) {	watcher.abort("Error reading updated key znode "+path, ke);	} catch (IOException ioe) {	
error reading key writables 

public void nodeChildrenChanged(String path) {	if (path.equals(keysParentZNode)) {	try {	List<ZKUtil.NodeAndData> nodes = ZKUtil.getChildDataAndWatchForNewChildren(watcher, keysParentZNode);	refreshNodes(nodes);	} catch (KeeperException ke) {	
error reading data from zookeeper 

private void refreshNodes(List<ZKUtil.NodeAndData> nodes) {	for (ZKUtil.NodeAndData n : nodes) {	String path = n.getNode();	String keyId = ZKUtil.getNodeName(path);	try {	byte[] data = n.getData();	if (data == null || data.length == 0) {	
ignoring empty node 

String path = n.getNode();	String keyId = ZKUtil.getNodeName(path);	try {	byte[] data = n.getData();	if (data == null || data.length == 0) {	continue;	}	AuthenticationKey key = (AuthenticationKey)Writables.getWritable( data, new AuthenticationKey());	secretManager.addKey(key);	} catch (IOException ioe) {	
failed reading new secret key for id from zk 

public void removeKeyFromZK(AuthenticationKey key) {	String keyZNode = getKeyNode(key.getKeyId());	try {	ZKUtil.deleteNode(watcher, keyZNode);	} catch (KeeperException.NoNodeException nne) {	
non existent znode for key 

public void removeKeyFromZK(AuthenticationKey key) {	String keyZNode = getKeyNode(key.getKeyId());	try {	ZKUtil.deleteNode(watcher, keyZNode);	} catch (KeeperException.NoNodeException nne) {	} catch (KeeperException ke) {	
failed removing znode for key 

public void addKeyToZK(AuthenticationKey key) {	String keyZNode = getKeyNode(key.getKeyId());	try {	byte[] keyData = Writables.getBytes(key);	ZKUtil.createSetData(watcher, keyZNode, keyData);	} catch (KeeperException ke) {	
unable to synchronize master key to znode 

public void updateKeyInZK(AuthenticationKey key) {	String keyZNode = getKeyNode(key.getKeyId());	try {	byte[] keyData = Writables.getBytes(key);	try {	ZKUtil.updateExistingNodeData(watcher, keyZNode, keyData, -1);	} catch (KeeperException.NoNodeException ne) {	ZKUtil.createSetData(watcher, keyZNode, keyData);	}	} catch (KeeperException ke) {	
unable to update master key in znode 

========================= hbase sample_2274 =========================

public RegionCoprocessor checkAndGetInstance(Class<?> implClass) throws InstantiationException, IllegalAccessException {	if (RegionCoprocessor.class.isAssignableFrom(implClass)) {	return (RegionCoprocessor)implClass.newInstance();	} else if (CoprocessorService.class.isAssignableFrom(implClass)) {	return new CoprocessorServiceBackwardCompatiblity.RegionCoprocessorService( (CoprocessorService)implClass.newInstance());	} else {	
is not of type regioncoprocessor check the configuration 

========================= hbase sample_2624 =========================

public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException {	try {	if (LOG.isTraceEnabled()) {	
considering the row 

public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException {	try {	if (LOG.isTraceEnabled()) {	
considering the row 

private void writeResult(ImmutableBytesWritable key, Result result, Context context) throws IOException, InterruptedException {	Put put = null;	Delete delete = null;	if (LOG.isTraceEnabled()) {	
considering the row 

public void setup(Context context) {	
setting up mapper 

public void setup(Context context) {	Configuration conf = context.getConfiguration();	cfRenameMap = createCfRenameMap(conf);	filter = instantiateFilter(conf);	String durabilityStr = conf.get(WAL_DURABILITY);	if(durabilityStr != null){	durability = Durability.valueOf(durabilityStr.toUpperCase(Locale.ROOT));	
setting wal durability to 

public void setup(Context context) {	Configuration conf = context.getConfiguration();	cfRenameMap = createCfRenameMap(conf);	filter = instantiateFilter(conf);	String durabilityStr = conf.get(WAL_DURABILITY);	if(durabilityStr != null){	durability = Durability.valueOf(durabilityStr.toUpperCase(Locale.ROOT));	} else {	
setting wal durability to default 

durability = Durability.valueOf(durabilityStr.toUpperCase(Locale.ROOT));	} else {	}	ZKWatcher zkw = null;	Exception ex = null;	try {	zkw = new ZKWatcher(conf, context.getTaskAttemptID().toString(), null);	clusterIds = Collections.singletonList(ZKClusterId.getUUIDForCluster(zkw));	} catch (ZooKeeperConnectionException e) {	ex = e;	
problem connecting to zookeper during task setup 

}	ZKWatcher zkw = null;	Exception ex = null;	try {	zkw = new ZKWatcher(conf, context.getTaskAttemptID().toString(), null);	clusterIds = Collections.singletonList(ZKClusterId.getUUIDForCluster(zkw));	} catch (ZooKeeperConnectionException e) {	ex = e;	} catch (KeeperException e) {	ex = e;	
problem reading zookeeper data during task setup 

Exception ex = null;	try {	zkw = new ZKWatcher(conf, context.getTaskAttemptID().toString(), null);	clusterIds = Collections.singletonList(ZKClusterId.getUUIDForCluster(zkw));	} catch (ZooKeeperConnectionException e) {	ex = e;	} catch (KeeperException e) {	ex = e;	} catch (IOException e) {	ex = e;	
problem setting up task 

public static Filter instantiateFilter(Configuration conf) {	Class<? extends Filter> filterClass = conf.getClass(FILTER_CLASS_CONF_KEY, null, Filter.class);	if (filterClass == null) {	
no configured filter class accepting all keyvalues 

public static Filter instantiateFilter(Configuration conf) {	Class<? extends Filter> filterClass = conf.getClass(FILTER_CLASS_CONF_KEY, null, Filter.class);	if (filterClass == null) {	return null;	}	
attempting to create filter 

Class<? extends Filter> filterClass = conf.getClass(FILTER_CLASS_CONF_KEY, null, Filter.class);	if (filterClass == null) {	return null;	}	String[] filterArgs = conf.getStrings(FILTER_ARGS_CONF_KEY);	ArrayList<byte[]> quotedArgs = toQuotedByteArrays(filterArgs);	try {	Method m = filterClass.getMethod("createFilterFromArguments", ArrayList.class);	return (Filter) m.invoke(null, quotedArgs);	} catch (IllegalAccessException e) {	
couldn t instantiate filter 

return null;	}	String[] filterArgs = conf.getStrings(FILTER_ARGS_CONF_KEY);	ArrayList<byte[]> quotedArgs = toQuotedByteArrays(filterArgs);	try {	Method m = filterClass.getMethod("createFilterFromArguments", ArrayList.class);	return (Filter) m.invoke(null, quotedArgs);	} catch (IllegalAccessException e) {	throw new RuntimeException(e);	} catch (SecurityException e) {	
couldn t instantiate filter 

String[] filterArgs = conf.getStrings(FILTER_ARGS_CONF_KEY);	ArrayList<byte[]> quotedArgs = toQuotedByteArrays(filterArgs);	try {	Method m = filterClass.getMethod("createFilterFromArguments", ArrayList.class);	return (Filter) m.invoke(null, quotedArgs);	} catch (IllegalAccessException e) {	throw new RuntimeException(e);	} catch (SecurityException e) {	throw new RuntimeException(e);	} catch (NoSuchMethodException e) {	
couldn t instantiate filter 

try {	Method m = filterClass.getMethod("createFilterFromArguments", ArrayList.class);	return (Filter) m.invoke(null, quotedArgs);	} catch (IllegalAccessException e) {	throw new RuntimeException(e);	} catch (SecurityException e) {	throw new RuntimeException(e);	} catch (NoSuchMethodException e) {	throw new RuntimeException(e);	} catch (IllegalArgumentException e) {	
couldn t instantiate filter 

return (Filter) m.invoke(null, quotedArgs);	} catch (IllegalAccessException e) {	throw new RuntimeException(e);	} catch (SecurityException e) {	throw new RuntimeException(e);	} catch (NoSuchMethodException e) {	throw new RuntimeException(e);	} catch (IllegalArgumentException e) {	throw new RuntimeException(e);	} catch (InvocationTargetException e) {	
couldn t instantiate filter 

public static Cell filterKv(Filter filter, Cell c) throws IOException {	if (filter != null) {	Filter.ReturnCode code = filter.filterCell(c);	if (LOG.isTraceEnabled()) {	
filter returned for the cell 

String hfileOutPath = conf.get(BULK_OUTPUT_CONF_KEY);	try {	Class<? extends Filter> filter = conf.getClass(FILTER_CLASS_CONF_KEY, null, Filter.class);	if (filter != null) {	TableMapReduceUtil.addDependencyJarsForClasses(conf, filter);	}	} catch (Exception e) {	throw new IOException(e);	}	if (hfileOutPath != null && conf.getBoolean(HAS_LARGE_RESULT, false)) {	
use large result 

job.setMapOutputValueClass(MapReduceExtendedCell.class);	job.getConfiguration().setClass("mapreduce.job.output.key.comparator.class", CellWritableComparable.CellWritableComparator.class, RawComparator.class);	Path partitionsPath = new Path(TotalOrderPartitioner.getPartitionFile(job.getConfiguration()));	FileSystem fs = FileSystem.get(job.getConfiguration());	fs.deleteOnExit(partitionsPath);	job.setPartitionerClass(CellWritableComparablePartitioner.class);	job.setNumReduceTasks(regionLocator.getStartKeys().length);	TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(), org.apache.hbase.thirdparty.com.google.common.base.Preconditions.class);	}	} else if (hfileOutPath != null) {	
writing to hfiles for bulk load 

RegionLocator regionLocator = conn.getRegionLocator(tableName)){	job.setReducerClass(CellSortReducer.class);	Path outputDir = new Path(hfileOutPath);	FileOutputFormat.setOutputPath(job, outputDir);	job.setMapOutputKeyClass(ImmutableBytesWritable.class);	job.setMapOutputValueClass(MapReduceExtendedCell.class);	HFileOutputFormat2.configureIncrementalLoad(job, table.getDescriptor(), regionLocator);	TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(), org.apache.hbase.thirdparty.com.google.common.base.Preconditions.class);	}	} else {	
writing directly to table from mapper 

public static void flushRegionsIfNecessary(Configuration conf) throws IOException, InterruptedException {	String tableName = conf.get(TABLE_NAME);	Admin hAdmin = null;	Connection connection = null;	String durability = conf.get(WAL_DURABILITY);	if (conf.get(BULK_OUTPUT_CONF_KEY) == null && durability != null && Durability.SKIP_WAL.name().equalsIgnoreCase(durability)) {	
flushing all data that skipped the wal 

========================= hbase sample_3465 =========================

protected void closeHTable() {	try {	if (table != null) {	table.close();	}	for (Table table : userVsTable.values()) {	try {	table.close();	} catch (Exception e) {	
error while closing the table 

if (table != null) {	table.close();	}	for (Table table : userVsTable.values()) {	try {	table.close();	} catch (Exception e) {	}	}	} catch (Exception e) {	
error while closing the htable 

if (e instanceof RetriesExhaustedWithDetailsException) {	RetriesExhaustedWithDetailsException aggEx = (RetriesExhaustedWithDetailsException) e;	exceptionInfo = aggEx.getExhaustiveDescription();	} else {	StringWriter stackWriter = new StringWriter();	PrintWriter pw = new PrintWriter(stackWriter);	e.printStackTrace(pw);	pw.flush();	exceptionInfo = StringUtils.stringifyException(e);	}	
failed to mutate after ms region information errors 

========================= hbase sample_1321 =========================

}	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException ignored) {}	}	}	
maximum from this region is 

}	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException ignored) {}	}	}	
minimum from this region is 

}	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException ignored) {}	}	}	
sum from this region is 

response = AggregateResponse.newBuilder().addFirstPart( ByteString.copyFrom(bb)).build();	} catch (IOException e) {	CoprocessorRpcUtils.setControllerException(controller, e);	} finally {	if (scanner != null) {	try {	scanner.close();	} catch (IOException ignored) {}	}	}	
row counter from this region is 

========================= hbase sample_1264 =========================

private void performClusterManagerCommand(ServiceType role, String hostname, RoleCommand command) throws IOException {	
performing command against on 

private void doRoleCommand(String serviceName, String roleName, RoleCommand roleCommand) {	URI uri = UriBuilder.fromUri(serverHostname) .path("api") .path(API_VERSION) .path("clusters") .path(clusterName) .path("services") .path(serviceName) .path("roleCommands") .path(roleCommand.toString()) .build();	String body = "{ \"items\": [ \"" + roleName + "\" ] }";	
executing post against with body 

private JsonNode getJsonNodeFromURIGet(URI uri) throws IOException {	
executing get against 

========================= hbase sample_3259 =========================

private void startHttpServerThread(final String[] args) {	
starting hbase thrift server with http server 

Thread.sleep(100);	}	try {	talkToThriftServer(customHeaderSize);	} catch (Exception ex) {	clientSideException = ex;	} finally {	stopHttpServerThread();	}	if (clientSideException != null) {	
thrift client threw an exception 

private void stopHttpServerThread() throws Exception {	
stopping thrift http server 

private void stopHttpServerThread() throws Exception {	thriftServer.stop();	httpServerThread.join();	if (httpServerException != null) {	
command line invocation of hbase thrift server threw an exception 

========================= hbase sample_753 =========================

public void testFullBackupWithFailures() throws Exception {	conf1.set(TableBackupClient.BACKUP_CLIENT_IMPL_CLASS, FullTableBackupClientForTest.class.getName());	int maxStage = Stage.values().length -1;	for (int stage = 0; stage <= maxStage; stage++) {	
running stage 

========================= hbase sample_544 =========================

try {	TEST_UTIL.waitTableAvailable(tableName);	List<RegionInfo> regionInfos = admin.getRegions(tableName);	assertEquals("Table " + TABLE_NAME + " should have 1 region", 1, regionInfos.size());	boolean success = true;	int i = 0;	for (; i < MAX_TRY; i++) {	try {	testReadRequests(regionInfos.get(0).getRegionName(), 3);	} catch (Throwable t) {	
got exception when try times 

private void testReadRequests(byte[] regionName, int expectedReadRequests) throws Exception {	for (ServerName serverName : serverNames) {	ServerLoad serverLoad = new ServerLoad(admin.getClusterMetrics( EnumSet.of(Option.LIVE_SERVERS)).getLiveServerMetrics().get(serverName));	Map<byte[], RegionLoad> regionsLoad = serverLoad.getRegionsLoad();	RegionLoad regionLoad = regionsLoad.get(regionName);	if (regionLoad != null) {	
server read request is region read request is 

RegionCoprocessorEnvironment env = c.getEnvironment();	Region region = env.getRegion();	try {	putData(region);	RegionScanner scanner = region.getScanner(new Scan());	List<Cell> result = new LinkedList<>();	while (scanner.next(result)) {	result.clear();	}	} catch (Exception e) {	
got exception in coprocessor 

========================= hbase sample_1589 =========================

if (failFast) {	try {	Class<?> c = conf.getClass( HConstants.HBASE_CLIENT_FAST_FAIL_INTERCEPTOR_IMPL, PreemptiveFastFailInterceptor.class);	Constructor<?> constructor = c .getDeclaredConstructor(Configuration.class);	constructor.setAccessible(true);	ret = (RetryingCallerInterceptor) constructor.newInstance(conf);	} catch (Exception e) {	ret = new PreemptiveFastFailInterceptor(conf);	}	}	
using for intercepting the rpcretryingcaller 

========================= hbase sample_401 =========================

protected boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	
sleeping times 

protected boolean sleepForRetries(String msg, int sleepMultiplier) {	try {	if (LOG.isTraceEnabled()) {	}	Thread.sleep(this.sleepForRetries * sleepMultiplier);	} catch (InterruptedException e) {	
interrupted while sleeping between retries 

private void reconnectToPeerCluster() {	ClusterConnection connection = null;	try {	connection = (ClusterConnection) ConnectionFactory.createConnection(this.conf);	} catch (IOException ioe) {	
failed to create connection for peer cluster 

CompletionService<Integer> pool = new ExecutorCompletionService<>(this.exec);	List<List<Entry>> batches;	String walGroupId = replicateContext.getWalGroupId();	int sleepMultiplier = 1;	if (!peersSelected && this.isRunning()) {	connectToPeers();	peersSelected = true;	}	int numSinks = replicationSinkMgr.getNumSinks();	if (numSinks == 0) {	
no replication sinks found returning without replicating the source should retry with the same set of edits 

}	if (this.conn == null || this.conn.isClosed()) {	reconnectToPeerCluster();	}	try {	int futures = 0;	for (int i=0; i<batches.size(); i++) {	List<Entry> entries = batches.get(i);	if (!entries.isEmpty()) {	if (LOG.isTraceEnabled()) {	
submitting entries of total size 

throw iox;	}	if (lastWriteTime > 0) {	this.metrics.setAgeOfLastShippedOp(lastWriteTime, walGroupId);	}	return true;	} catch (IOException ioe) {	this.metrics.refreshAgeOfLastShippedOp(walGroupId);	if (ioe instanceof RemoteException) {	ioe = ((RemoteException) ioe).unwrapRemoteException();	
can t replicate because of an error on the remote cluster 

} catch (IOException ioe) {	this.metrics.refreshAgeOfLastShippedOp(walGroupId);	if (ioe instanceof RemoteException) {	ioe = ((RemoteException) ioe).unwrapRemoteException();	if (ioe instanceof TableNotFoundException) {	if (dropOnDeletedTables) {	TableName table = parseTable(ioe.getMessage());	if (table != null) {	try (Connection localConn = ConnectionFactory.createConnection(ctx.getLocalConfiguration())) {	if (!localConn.getAdmin().tableExists(table)) {	
missing table detected at sink local table also does not exist filtering edits for 

if (ioe instanceof TableNotFoundException) {	if (dropOnDeletedTables) {	TableName table = parseTable(ioe.getMessage());	if (table != null) {	try (Connection localConn = ConnectionFactory.createConnection(ctx.getLocalConfiguration())) {	if (!localConn.getAdmin().tableExists(table)) {	batches = filterBatches(batches, table);	continue;	}	} catch (IOException iox) {	
exception checking for local table 

try (Connection localConn = ConnectionFactory.createConnection(ctx.getLocalConfiguration())) {	if (!localConn.getAdmin().tableExists(table)) {	batches = filterBatches(batches, table);	continue;	}	} catch (IOException iox) {	}	}	}	} else {	
peer encountered remoteexception rechecking all sinks 

}	}	}	} else {	replicationSinkMgr.chooseSinks();	}	} else {	if (ioe instanceof SocketTimeoutException) {	sleepForRetries("Encountered a SocketTimeoutException. Since the " + "call to the remote cluster timed out, which is usually " + "caused by a machine failure or a massive slowdown", this.socketTimeoutMultiplier);	} else if (ioe instanceof ConnectException || ioe instanceof UnknownHostException) {	
peer is unavailable rechecking all sinks 

}	} else {	replicationSinkMgr.chooseSinks();	}	} else {	if (ioe instanceof SocketTimeoutException) {	sleepForRetries("Encountered a SocketTimeoutException. Since the " + "call to the remote cluster timed out, which is usually " + "caused by a machine failure or a massive slowdown", this.socketTimeoutMultiplier);	} else if (ioe instanceof ConnectException || ioe instanceof UnknownHostException) {	replicationSinkMgr.chooseSinks();	} else {	
can t replicate because of a local or network error 

protected void doStop() {	disconnect();	if (this.conn != null) {	try {	this.conn.close();	this.conn = null;	} catch (IOException e) {	
failed to close the connection 

protected void replicateEntries(BlockingInterface rrs, final List<Entry> batch, String replicationClusterId, Path baseNamespaceDir, Path hfileArchiveDir) throws IOException {	if (LOG.isTraceEnabled()) {	long size = 0;	for (Entry e: entries) {	size += e.getKey().estimatedSerializedSizeOf();	size += e.getEdit().estimatedSerializedSizeOf();	}	
replicating batch of entries with total size bytes to 

if (LOG.isTraceEnabled()) {	long size = 0;	for (Entry e: entries) {	size += e.getKey().estimatedSerializedSizeOf();	size += e.getEdit().estimatedSerializedSizeOf();	}	}	try {	ReplicationProtbufUtil.replicateWALEntry(rrs, batch.toArray(new Entry[batch.size()]), replicationClusterId, baseNamespaceDir, hfileArchiveDir);	if (LOG.isTraceEnabled()) {	
completed replicating batch 

size += e.getKey().estimatedSerializedSizeOf();	size += e.getEdit().estimatedSerializedSizeOf();	}	}	try {	ReplicationProtbufUtil.replicateWALEntry(rrs, batch.toArray(new Entry[batch.size()]), replicationClusterId, baseNamespaceDir, hfileArchiveDir);	if (LOG.isTraceEnabled()) {	}	} catch (IOException e) {	if (LOG.isTraceEnabled()) {	
failed replicating batch 

========================= hbase sample_2960 =========================

public void testIncrementWithDeletes() throws Exception {	
starting 

public void testIncrementingInvalidValue() throws Exception {	
starting 

public void testBatchIncrementsWithReturnResultFalse() throws Exception {	
starting testbatchincrementswithreturnresultfalse 

public void testIncrementInvalidArguments() throws Exception {	
starting 

public void testIncrementOutOfOrder() throws Exception {	
starting 

public void testIncrementOnSameColumn() throws Exception {	
starting 

public void testIncrementIncrZeroAtFirst() throws Exception {	
starting 

public void testIncrement() throws Exception {	
starting 

========================= hbase sample_2063 =========================

private static void resetAcls(final ZKWatcher zkw, final String znode, final boolean eraseAcls) throws Exception {	List<String> children = ZKUtil.listChildrenNoWatch(zkw, znode);	if (children != null) {	for (String child: children) {	resetAcls(zkw, ZNodePaths.joinZNode(znode, child), eraseAcls);	}	}	ZooKeeper zk = zkw.getRecoverableZooKeeper().getZooKeeper();	if (eraseAcls) {	
erase acls for 

List<String> children = ZKUtil.listChildrenNoWatch(zkw, znode);	if (children != null) {	for (String child: children) {	resetAcls(zkw, ZNodePaths.joinZNode(znode, child), eraseAcls);	}	}	ZooKeeper zk = zkw.getRecoverableZooKeeper().getZooKeeper();	if (eraseAcls) {	zk.setACL(znode, ZooDefs.Ids.OPEN_ACL_UNSAFE, -1);	} else {	
set acls for 

private static void resetAcls(final Configuration conf, boolean eraseAcls) throws Exception {	ZKWatcher zkw = new ZKWatcher(conf, "ZKAclReset", null);	try {	
Erase Set hbase acls for 

========================= hbase sample_728 =========================

table.put(put);	region.flush(true);	byte[] QUALIFIER2 = Bytes.add(QUALIFIER, QUALIFIER);	put = new Put(ROW2);	put.addColumn(FAMILY, QUALIFIER2, data2);	table.put(put);	put = new Put(ROW3);	put.addColumn(FAMILY, QUALIFIER2, data2);	table.put(put);	region.flush(true);	
about to split on 

region.flush(true);	TEST_UTIL.getAdmin().split(tableName, ROW1);	Collection<ServerName> regionServers = TEST_UTIL.getAdmin().getRegionServers();	Iterator<ServerName> serverItr = regionServers.iterator();	serverItr.hasNext();	ServerName rs = serverItr.next();	List<RegionInfo> onlineRegions = TEST_UTIL.getAdmin().getRegions(rs);	while (onlineRegions.size() != 2) {	onlineRegions = TEST_UTIL.getAdmin().getRegions(rs);	Thread.sleep(100);	
waiting on split to complete 

private void slowdownCode(final ObserverContext<RegionCoprocessorEnvironment> e, boolean isGet) {	CountDownLatch latch = getCdl().get();	try {	System.out.println(latch.getCount() + " is the count " + isGet);	if (latch.getCount() > 0) {	if (isGet) {	countOfGets.incrementAndGet();	} else {	countOfNext.incrementAndGet();	}	
waiting for the countercountdownlatch 

========================= hbase sample_2126 =========================

protected void runTestOnTable(Table table) throws IOException {	JobConf jobConf = null;	try {	
before map reduce startup 

protected void runTestOnTable(Table table) throws IOException {	JobConf jobConf = null;	try {	jobConf = new JobConf(UTIL.getConfiguration(), TestTableMapReduce.class);	jobConf.setJobName("process column contents");	jobConf.setNumReduceTasks(1);	TableMapReduceUtil.initTableMapJob(table.getName().getNameAsString(), Bytes.toString(INPUT_FAMILY), ProcessContentsMapper.class, ImmutableBytesWritable.class, Put.class, jobConf);	TableMapReduceUtil.initTableReduceJob(table.getName().getNameAsString(), IdentityTableReduce.class, jobConf);	
started 

protected void runTestOnTable(Table table) throws IOException {	JobConf jobConf = null;	try {	jobConf = new JobConf(UTIL.getConfiguration(), TestTableMapReduce.class);	jobConf.setJobName("process column contents");	jobConf.setNumReduceTasks(1);	TableMapReduceUtil.initTableMapJob(table.getName().getNameAsString(), Bytes.toString(INPUT_FAMILY), ProcessContentsMapper.class, ImmutableBytesWritable.class, Put.class, jobConf);	TableMapReduceUtil.initTableReduceJob(table.getName().getNameAsString(), IdentityTableReduce.class, jobConf);	RunningJob job = JobClient.runJob(jobConf);	assertTrue(job.isSuccessful());	
after map reduce completion 

========================= hbase sample_3367 =========================

private void unassignExcessMetaReplica(int numMetaReplicasConfigured) {	final ZKWatcher zooKeeper = master.getZooKeeper();	try {	List<String> metaReplicaZnodes = zooKeeper.getMetaReplicaNodes();	for (String metaReplicaZnode : metaReplicaZnodes) {	int replicaId = zooKeeper.znodePaths.getMetaReplicaIdFromZnode(metaReplicaZnode);	if (replicaId >= numMetaReplicasConfigured) {	RegionState r = MetaTableLocator.getMetaRegionState(zooKeeper, replicaId);	
closing excess replica of meta region 

List<String> metaReplicaZnodes = zooKeeper.getMetaReplicaNodes();	for (String metaReplicaZnode : metaReplicaZnodes) {	int replicaId = zooKeeper.znodePaths.getMetaReplicaIdFromZnode(metaReplicaZnode);	if (replicaId >= numMetaReplicasConfigured) {	RegionState r = MetaTableLocator.getMetaRegionState(zooKeeper, replicaId);	ServerManager.closeRegionSilentlyAndWait(master.getClusterConnection(), r.getServerName(), r.getRegion(), 30000);	ZKUtil.deleteNode(zooKeeper, zooKeeper.znodePaths.getZNodeForReplica(replicaId));	}	}	} catch (Exception ex) {	
ignoring exception 

protected void assignMeta(int replicaId) throws InterruptedException, IOException, KeeperException {	final AssignmentManager assignmentManager = master.getAssignmentManager();	if (replicaId == RegionInfo.DEFAULT_REPLICA_ID) {	status.setStatus("Assigning hbase:meta region");	} else {	status.setStatus("Assigning hbase:meta region, replicaId " + replicaId);	}	RegionState metaState = MetaTableLocator.getMetaRegionState(master.getZooKeeper(), replicaId);	
meta state from zookeeper 

========================= hbase sample_2825 =========================

public void requestLock() throws IOException {	if (procId == null) {	try {	procId = stub.requestLock(null, lockRequest).getProcId();	} catch (Exception e) {	throw ProtobufUtil.handleRemoteException(e);	}	worker.start();	} else {	
lock already queued 

public boolean await(long timeout, TimeUnit timeUnit) throws InterruptedException {	final boolean result = latch.await(timeout, timeUnit);	String lockRequestStr = lockRequest.toString().replace("\n", ", ");	if (result) {	
acquired 

public boolean await(long timeout, TimeUnit timeUnit) throws InterruptedException {	final boolean result = latch.await(timeout, timeUnit);	String lockRequestStr = lockRequest.toString().replace("\n", ", ");	if (result) {	} else {	
failed acquire in s s of s 

public void run() {	final LockHeartbeatRequest lockHeartbeatRequest = LockHeartbeatRequest.newBuilder().setProcId(procId).build();	LockHeartbeatResponse response;	while (true) {	try {	response = stub.lockHeartbeat(null, lockHeartbeatRequest);	} catch (Exception e) {	e = ProtobufUtil.handleRemoteException(e);	locked.set(false);	
heartbeat failed releasing 

if (isLocked()) {	sleepTime = Math.max(response.getTimeoutMs() - heartbeatTimeBuffer, 1);	}	if (testingSleepTime != 0) {	sleepTime = testingSleepTime;	}	Thread.sleep(sleepTime);	} catch (InterruptedException e) {	locked.set(false);	if (!this.shutdown) {	
interrupted releasing 

========================= hbase sample_3019 =========================

private Superusers(){}	public static void initialize(Configuration conf) throws IOException {	superUsers = new HashSet<>();	superGroups = new HashSet<>();	systemUser = User.getCurrent();	if (systemUser == null) {	throw new IllegalStateException("Unable to obtain the current user, " + "authorization checks for internal operations will not work correctly!");	}	String currentUser = systemUser.getShortName();	
current user name is 

========================= hbase sample_1024 =========================

public static boolean verify(byte[] value, byte[]... seedStrings) {	byte[] expectedData = getValueForRowColumn(value.length, seedStrings);	boolean equals = Bytes.equals(expectedData, value);	if (!equals && LOG.isDebugEnabled() && logLimit > 0) {	
verify failed expected value actual value 

========================= hbase sample_840 =========================

public int run(String[] args) throws Exception {	Job job = createSubmittableJob(args);	if (job == null) return 1;	if (!job.waitForCompletion(true)) {	
map reduce job failed 

public int run(String[] args) throws Exception {	Job job = createSubmittableJob(args);	if (job == null) return 1;	if (!job.waitForCompletion(true)) {	if (bulkload) {	
files are not bulkloaded 

if (bulkload) {	}	return 1;	}	int code = 0;	if (bulkload) {	code = new LoadIncrementalHFiles(this.getConf()).run(new String[]{this.bulkloadDir.toString(), this.dstTableName});	if (code == 0) {	FileSystem fs = FileSystem.get(this.getConf());	if (!fs.delete(this.bulkloadDir, true)) {	
deleting folder failed 

========================= hbase sample_3449 =========================

RegionServerServices rss = region.getRegionServerServices();	if (rss == null) {	return 0;	}	TableName tablename = region.getTableDescriptor().getTableName();	int tableRegionsCount = 0;	try {	List<? extends Region> hri = rss.getRegions(tablename);	tableRegionsCount = hri == null || hri.isEmpty() ? 0 : hri.size();	} catch (IOException e) {	
failed getonlineregions 

========================= hbase sample_2608 =========================

try {	currentReplicators = queueStorage.getListOfReplicators();	} catch (ReplicationException e) {	server.abort("Failed to get all replicators", e);	return;	}	if (currentReplicators == null || currentReplicators.isEmpty()) {	return;	}	List<ServerName> otherRegionServers = replicationTracker.getListOfRegionServers().stream() .map(ServerName::valueOf).collect(Collectors.toList());	
current list of replicators other rss 

for (ReplicationSourceInterface src : oldsources) {	if (peerId.equals(src.getPeerId())) {	oldSourcesToDelete.add(src);	}	}	for (ReplicationSourceInterface src : oldSourcesToDelete) {	src.terminate(terminateMessage);	removeRecoveredSource(src);	}	}	
number of deleted recovered sources for 

public void refreshSources(String peerId) throws IOException {	String terminateMessage = "Peer " + peerId + " state or config changed. Will close the previous replication source and open a new one";	ReplicationPeer peer = replicationPeers.getPeer(peerId);	ReplicationSourceInterface src = createSource(peerId, peer);	synchronized (this.latestPaths) {	ReplicationSourceInterface toRemove = this.sources.put(peerId, src);	if (toRemove != null) {	
terminate replication source for 

ReplicationSourceInterface src = createSource(peerId, peer);	synchronized (this.latestPaths) {	ReplicationSourceInterface toRemove = this.sources.put(peerId, src);	if (toRemove != null) {	toRemove.terminate(terminateMessage);	}	for (SortedSet<String> walsByGroup : walsById.get(peerId).values()) {	walsByGroup.forEach(wal -> src.enqueueLog(new Path(this.logDir, wal)));	}	}	
startup replication source for 

private void transferQueues(ServerName deadRS) {	if (server.getServerName().equals(deadRS)) {	return;	}	NodeFailoverWorker transfer = new NodeFailoverWorker(deadRS);	try {	this.executor.execute(transfer);	} catch (RejectedExecutionException ex) {	
cancelling the transfer of because of 

public void run() {	try {	Thread.sleep(sleepBeforeFailover + (long) (ThreadLocalRandom.current().nextFloat() * sleepBeforeFailover));	} catch (InterruptedException e) {	
interrupted while waiting before transferring a queue 

public void run() {	try {	Thread.sleep(sleepBeforeFailover + (long) (ThreadLocalRandom.current().nextFloat() * sleepBeforeFailover));	} catch (InterruptedException e) {	Thread.currentThread().interrupt();	}	if (server.isStopped()) {	
not transferring queue since we are shutting down 

while (!queues.isEmpty()) {	Pair<String, SortedSet<String>> peer = queueStorage.claimQueue(deadRS, queues.get(ThreadLocalRandom.current().nextInt(queues.size())), server.getServerName());	long sleep = sleepBeforeFailover / 2;	if (!peer.getSecond().isEmpty()) {	newQueues.put(peer.getFirst(), peer.getSecond());	sleep = sleepBeforeFailover;	}	try {	Thread.sleep(sleep);	} catch (InterruptedException e) {	
interrupted while waiting before transferring a queue 

return;	}	for (Map.Entry<String, Set<String>> entry : newQueues.entrySet()) {	String queueId = entry.getKey();	Set<String> walsSet = entry.getValue();	try {	ReplicationQueueInfo replicationQueueInfo = new ReplicationQueueInfo(queueId);	String actualPeerId = replicationQueueInfo.getPeerId();	ReplicationPeer peer = replicationPeers.getPeer(actualPeerId);	if (peer == null) {	
skipping failover for peer of node peer is null 

removeRecoveredSource(src);	continue;	}	oldsources.add(src);	for (String wal : walsSet) {	src.enqueueLog(new Path(oldLogDir, wal));	}	src.startup();	}	} catch (IOException e) {	
failed creating a source 

========================= hbase sample_2937 =========================

Table table = util.getConnection().getTable(TEST_TABLE);	ColumnAggregationNullResponseSumRequest.Builder builder = ColumnAggregationNullResponseSumRequest .newBuilder();	builder.setFamily(ByteString.copyFrom(TEST_FAMILY));	if (TEST_QUALIFIER != null && TEST_QUALIFIER.length > 0) {	builder.setQualifier(ByteString.copyFrom(TEST_QUALIFIER));	}	Map<byte[], ColumnAggregationNullResponseSumResponse> results = table.batchCoprocessorService( ColumnAggregationServiceNullResponse.getDescriptor().findMethodByName("sum"), builder.build(), ROWS[0], ROWS[ROWS.length - 1], ColumnAggregationNullResponseSumResponse.getDefaultInstance());	int sumResult = 0;	int expectedResult = 0;	for (Map.Entry<byte[], ColumnAggregationNullResponseSumResponse> e : results.entrySet()) {	
got value for region 

public void testAggregationWithReturnValue() throws Throwable {	Table table = util.getConnection().getTable(TEST_TABLE);	Map<byte[], SumResponse> results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[0], ROWS[ROWS.length - 1]);	int sumResult = 0;	int expectedResult = 0;	for (Map.Entry<byte[], SumResponse> e : results.entrySet()) {	
got value for region 

}	for (int i = 0; i < ROWSIZE; i++) {	expectedResult += i;	}	assertEquals("Invalid result", expectedResult, sumResult);	results.clear();	results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[rowSeperator1], ROWS[ROWS.length - 1]);	sumResult = 0;	expectedResult = 0;	for (Map.Entry<byte[], SumResponse> e : results.entrySet()) {	
got value for region 

public void testAggregation() throws Throwable {	Table table = util.getConnection().getTable(TEST_TABLE);	Map<byte[], SumResponse> results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[0], ROWS[ROWS.length - 1]);	int sumResult = 0;	int expectedResult = 0;	for (Map.Entry<byte[], SumResponse> e : results.entrySet()) {	
got value for region 

sumResult += e.getValue().getSum();	}	for (int i = 0; i < ROWSIZE; i++) {	expectedResult += i;	}	assertEquals("Invalid result", expectedResult, sumResult);	results = sum(table, TEST_FAMILY, TEST_QUALIFIER, ROWS[rowSeperator1], ROWS[ROWS.length - 1]);	sumResult = 0;	expectedResult = 0;	for (Map.Entry<byte[], SumResponse> e : results.entrySet()) {	
got value for region 

builder.setQualifier(ByteString.copyFrom(TEST_QUALIFIER));	}	boolean hasError = false;	try {	table.batchCoprocessorService( ColumnAggregationWithErrorsProtos.ColumnAggregationServiceWithErrors.getDescriptor() .findMethodByName("sum"), builder.build(), ROWS[0], ROWS[ROWS.length - 1], ColumnAggregationWithErrorsSumResponse.getDefaultInstance(), new Batch.Callback<ColumnAggregationWithErrorsSumResponse>() {	public void update(byte[] region, byte[] row, ColumnAggregationWithErrorsSumResponse result) {	results.put(region, result);	}	});	} catch (Throwable t) {	
exceptions in coprocessor service 

public void update(byte[] region, byte[] row, ColumnAggregationWithErrorsSumResponse result) {	results.put(region, result);	}	});	} catch (Throwable t) {	hasError = true;	}	int sumResult = 0;	int expectedResult = 0;	for (Map.Entry<byte[], ColumnAggregationWithErrorsSumResponse> e : results.entrySet()) {	
got value for region 

========================= hbase sample_1248 =========================

public void onConfigurationChange(Configuration conf) {	super.onConfigurationChange(conf);	int newSize = conf.getInt(OLD_WALS_CLEANER_SIZE, OLD_WALS_CLEANER_DEFAULT_SIZE);	if (newSize == oldWALsCleaner.size()) {	if (LOG.isDebugEnabled()) {	
size from configuration is the same as previous which is no need to update 

private List<Thread> createOldWalsCleaner(int size) {	
creating oldwals cleaners with size 

boolean succeed = false;	boolean interrupted = false;	try {	context = pendingDelete.take();	if (context != null) {	FileStatus toClean = context.getTargetToClean();	succeed = this.fs.delete(toClean.getPath(), false);	}	} catch (InterruptedException ite) {	if (context != null) {	
interrupted while cleaning oldwals try to clean it next round 

context = pendingDelete.take();	if (context != null) {	FileStatus toClean = context.getTargetToClean();	succeed = this.fs.delete(toClean.getPath(), false);	}	} catch (InterruptedException ite) {	if (context != null) {	}	interrupted = true;	} catch (IOException e) {	
failed to clean oldwals with exception 

if (context != null) {	context.setResult(succeed);	}	if (interrupted) {	Thread.currentThread().interrupt();	break;	}	}	}	if (LOG.isDebugEnabled()) {	
exiting cleaner 

========================= hbase sample_2872 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	boolean major = RandomUtils.nextInt(0, 100) < majorRatio;	LOG.info("Performing action: Compact random region of table " + tableName + ", major=" + major);	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	
table doesn t have regions to compact 

Admin admin = util.getAdmin();	boolean major = RandomUtils.nextInt(0, 100) < majorRatio;	LOG.info("Performing action: Compact random region of table " + tableName + ", major=" + major);	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	try {	if (major) {	
major compacting region 

LOG.info("Performing action: Compact random region of table " + tableName + ", major=" + major);	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	try {	if (major) {	admin.majorCompactRegion(region.getRegionName());	} else {	
compacting region 

return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	try {	if (major) {	admin.majorCompactRegion(region.getRegionName());	} else {	admin.compactRegion(region.getRegionName());	}	} catch (Exception ex) {	
compaction failed might be caused by other chaos 

========================= hbase sample_3330 =========================

private void setupTable(final Connection connection, TableName table, int cfs) throws IOException {	try {	
creating table 

private void setupTable(final Connection connection, TableName table, int cfs) throws IOException {	try {	try (Admin admin = connection.getAdmin()) {	admin.createTable(createTableDesc(table, cfs));	}	} catch (TableExistsException tee) {	
table already exists 

private void setupTableWithSplitkeys(TableName table, int cfs, byte[][] SPLIT_KEYS) throws IOException {	try {	
creating table 

private void setupTableWithSplitkeys(TableName table, int cfs, byte[][] SPLIT_KEYS) throws IOException {	try {	util.createTable(createTableDesc(table, cfs), SPLIT_KEYS);	} catch (TableExistsException tee) {	
table already exists 

}	int regions;	do {	regions = 0;	for (RegionInfo hri : ProtobufUtil.getOnlineRegions(hrs.getRSRpcServices())) {	if (hri.getTable().equals(table)) {	regions++;	}	}	if (regions != 2) {	
taking some time to complete split 

setupTable(connection, table, 10);	LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration()) {	protected List<LoadQueueItem> tryAtomicRegionLoad( ClientServiceCallable<byte[]> serviceCallable, TableName tableName, final byte[] first, Collection<LoadQueueItem> lqis) throws IOException {	int i = attmptedCalls.incrementAndGet();	if (i == 1) {	Connection errConn;	try {	errConn = getMockedConnection(util.getConfiguration());	serviceCallable = this.buildClientServiceCallable(errConn, table, first, lqis, true);	} catch (Exception e) {	
mocking cruft should never happen 

========================= hbase sample_2171 =========================

public RegionServerSnapshotManager() {}	public void start() {	
start snapshot manager 

public void stop(boolean force) throws IOException {	String mode = force ? "abruptly" : "gracefully";	
stopping regionserversnapshotmanager 

public Subprocedure buildSubprocedure(SnapshotDescription snapshot) {	if (rss.isStopping() || rss.isStopped()) {	throw new IllegalStateException("Can't start snapshot on RS: " + rss.getServerName() + ", because stopping/stopped!");	}	List<HRegion> involvedRegions;	try {	involvedRegions = getRegionsToSnapshot(snapshot);	} catch (IOException e1) {	throw new IllegalStateException("Failed to figure out if we should handle a snapshot - " + "something has gone awry with the online regions.", e1);	}	
launching subprocedure for snapshot from table type 

========================= hbase sample_2521 =========================

public void testEntrySizeLimit() throws Exception {	final int NITEMS = 20;	for (int i = 1; i <= NITEMS; ++i) {	final byte[] data = new byte[256 << i];	
writing s 

========================= hbase sample_1198 =========================

public void run() {	boolean done = false;	if (asyncProcess.primaryCallTimeoutMicroseconds > 0) {	try {	done = waitUntilDone(startTime * 1000L + asyncProcess.primaryCallTimeoutMicroseconds);	} catch (InterruptedException ex) {	
replica thread was interrupted no replica calls 

private void addReplicaActions(int index, Map<ServerName, MultiAction> actionsByServer, List<Action> unknownReplicaActions) {	if (results[index] != null) return;	Action action = initialActions.get(index);	RegionLocations loc = findAllLocationsOrFail(action, true);	if (loc == null) return;	HRegionLocation[] locs = loc.getRegionLocations();	if (locs.length == 1) {	
no replicas found for 

if (res.type() == AbstractResponse.ResponseType.MULTI) {	receiveMultiAction(multiAction, server, (MultiResponse) res, numAttempt);	} else {	if (results != null) {	SingleResponse singleResponse = (SingleResponse) res;	results[0] = singleResponse.getEntry();	}	decActionCounter(1);	}	} catch (Throwable t) {	
internal asyncprocess error for processing for 

private void startWaitingForReplicaCalls(List<Action> actionsForReplicaThread) {	long startTime = EnvironmentEdgeManager.currentTime();	ReplicaCallIssuingRunnable replicaRunnable = new ReplicaCallIssuingRunnable( actionsForReplicaThread, startTime);	if (asyncProcess.primaryCallTimeoutMicroseconds == 0) {	replicaRunnable.run();	} else {	try {	pool.submit(replicaRunnable);	} catch (RejectedExecutionException ree) {	
replica task was rejected by the pool no replica calls 

int failed = 0, stopped = 0;	List<Action> toReplay = new ArrayList<>();	for (Map.Entry<byte[], List<Action>> e : rsActions.actions.entrySet()) {	byte[] regionName = e.getKey();	byte[] row = e.getValue().iterator().next().getAction().getRow();	try {	if (tableName != null) {	asyncProcess.connection.updateCachedLocations(tableName, regionName, row, ClientExceptionsUtil.isMetaClearingException(t) ? null : t, server);	}	} catch (Throwable ex) {	
couldn t update cached region locations 

backOffTime = errorsByServer.calculateBackoffTime(oldServer, asyncProcess.pause);	}	if (numAttempt > asyncProcess.startLogErrorsCnt) {	LOG.info(createLog(numAttempt, failureCount, toReplay.size(), oldServer, throwable, backOffTime, true, null, -1, -1));	}	try {	if (backOffTime > 0) {	Thread.sleep(backOffTime);	}	} catch (InterruptedException e) {	
not sent operations 

int failureCount = 0;	boolean canRetry = true;	Map<byte[], MultiResponse.RegionResult> results = responses.getResults();	updateStats(server, results);	int failed = 0, stopped = 0;	for (Map.Entry<byte[], List<Action>> regionEntry : multiAction.actions.entrySet()) {	byte[] regionName = regionEntry.getKey();	Map<Integer, Object> regionResults = results.get(regionName) == null ?  null : results.get(regionName).result;	if (regionResults == null) {	if (!responses.getExceptions().containsKey(regionName)) {	
server sent us neither results nor exceptions for 

for (Action sentAction : regionEntry.getValue()) {	Object result = regionResults.get(sentAction.getOriginalIndex());	if (result == null || result instanceof Throwable) {	Row row = sentAction.getAction();	throwable = ClientExceptionsUtil.findException(result);	if (!regionFailureRegistered) {	regionFailureRegistered = true;	try {	asyncProcess.connection.updateCachedLocations( tableName, regionName, row.getRow(), result, server);	} catch (Throwable ex) {	
couldn t update cached region locations 

} else if (retry == Retry.NO_OTHER_SUCCEEDED) {	++stopped;	} else {	++failed;	}	} else {	if (callback != null) {	try {	this.callback.update(regionName, sentAction.getAction().getRow(), (CResult) result);	} catch (Throwable t) {	
user callback threw an exception for ignoring 

if (failureCount == 0) {	errorsByServer.reportServerError(server);	canRetry = errorsByServer.canTryMore(numAttempt);	}	if (null == tableName && ClientExceptionsUtil.isMetaClearingException(throwable)) {	asyncProcess.connection.clearCaches(server);	} else {	try {	asyncProcess.connection.updateCachedLocations( tableName, region, actions.get(0).getAction().getRow(), throwable, server);	} catch (Throwable ex) {	
couldn t update cached region locations 

long lastLog = EnvironmentEdgeManager.currentTime();	long currentInProgress;	while (0 != (currentInProgress = actionsInProgress.get())) {	long now = EnvironmentEdgeManager.currentTime();	if (hasWait && (now * 1000L) > cutoff) {	return false;	}	if (!hasWait) {	if (now > lastLog + 10000) {	lastLog = now;	
waiting for actions to finish on table 

========================= hbase sample_440 =========================

when(masterServices.getAssignmentManager().getRegionStates(). getRegionServerOfRegion(any())).thenReturn(sn);	for (Map.Entry<byte[], Integer> region : regionSizes.entrySet()) {	RegionLoad regionLoad = Mockito.mock(RegionLoad.class);	when(regionLoad.getName()).thenReturn(region.getKey());	when(regionLoad.getStorefileSizeMB()).thenReturn(region.getValue());	when((Object) masterServices.getServerManager().getLoad(sn). getRegionsLoad().get(region.getKey())).thenReturn(regionLoad);	}	try {	when(masterRpcServices.isSplitOrMergeEnabled(any(), any())).thenReturn( IsSplitOrMergeEnabledResponse.newBuilder().setEnabled(true).build());	} catch (ServiceException se) {	
error setting issplitormergeenabled switch 

========================= hbase sample_1874 =========================

public void beforeMethod() throws Exception {	if(!initialized) {	
setting up integrationtestrsgroup 

public void beforeMethod() throws Exception {	if(!initialized) {	
initializing cluster with servers 

public void beforeMethod() throws Exception {	if(!initialized) {	TEST_UTIL = new IntegrationTestingUtility();	TEST_UTIL.getConfiguration().set(HConstants.HBASE_MASTER_LOADBALANCER_CLASS, RSGroupBasedLoadBalancer.class.getName());	TEST_UTIL.getConfiguration().set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY, RSGroupAdminEndpoint.class.getName());	((IntegrationTestingUtility)TEST_UTIL).initializeCluster(NUM_SLAVES_BASE);	admin = TEST_UTIL.getAdmin();	cluster = TEST_UTIL.getHBaseClusterInterface();	rsGroupAdmin = new VerifyingRSGroupAdminClient(new RSGroupAdminClient(TEST_UTIL.getConnection()), TEST_UTIL.getConfiguration());	
done initializing cluster 

public void afterMethod() throws Exception {	
cleaning up previous test run 

public void afterMethod() throws Exception {	deleteTableIfNecessary();	deleteNamespaceIfNecessary();	deleteGroups();	admin.setBalancerRunning(true, true);	
restoring the cluster 

public void afterMethod() throws Exception {	deleteTableIfNecessary();	deleteNamespaceIfNecessary();	deleteGroups();	admin.setBalancerRunning(true, true);	((IntegrationTestingUtility)TEST_UTIL).restoreCluster();	
done restoring the cluster 

public void afterMethod() throws Exception {	deleteTableIfNecessary();	deleteNamespaceIfNecessary();	deleteGroups();	admin.setBalancerRunning(true, true);	((IntegrationTestingUtility)TEST_UTIL).restoreCluster();	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	
waiting for cleanup to finish 

deleteGroups();	admin.setBalancerRunning(true, true);	((IntegrationTestingUtility)TEST_UTIL).restoreCluster();	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return rsGroupAdmin.getRSGroupInfo(RSGroupInfo.DEFAULT_GROUP).getServers().size() >= NUM_SLAVES_BASE;	}	});	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	
waiting for regionservers to be registered 

TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return rsGroupAdmin.getRSGroupInfo(RSGroupInfo.DEFAULT_GROUP).getServers().size() >= NUM_SLAVES_BASE;	}	});	TEST_UTIL.waitFor(WAIT_TIMEOUT, new Waiter.Predicate<Exception>() {	public boolean evaluate() throws Exception {	return rsGroupAdmin.getRSGroupInfo(RSGroupInfo.DEFAULT_GROUP).getServers().size() == getNumServers();	}	});	
done cleaning up previous test run 

========================= hbase sample_3263 =========================

public void start() throws IOException {	stateManager.start();	
namespaceauditor started 

private void checkTableTypeAndThrowException(TableName name) throws IOException {	if (name.isSystemTable()) {	
namespace auditor checks not performed for table 

========================= hbase sample_2472 =========================

List<String> tasks = ZKUtil.listChildrenNoWatch(watcher, watcher.znodePaths.splitLogZNode);	if (tasks != null) {	int listSize = tasks.size();	for (int i = 0; i < listSize; i++) {	if (!ZKSplitLog.isRescanNode(tasks.get(i))) {	count++;	}	}	}	} catch (KeeperException ke) {	
failed to check remaining tasks 

private void handleUnassignedTask(String path) {	if (ZKSplitLog.isRescanNode(watcher, path)) {	return;	}	Task task = findOrCreateOrphanTask(path);	if (task.isOrphan() && (task.incarnation.get() == 0)) {	
resubmitting unassigned orphan task 

public boolean resubmitTask(String path, Task task, ResubmitDirective directive) {	if (task.status != IN_PROGRESS) {	return false;	}	int version;	if (directive != FORCE) {	final long time = EnvironmentEdgeManager.currentTime() - task.last_update;	final boolean alive = details.getMaster().getServerManager() != null ? details.getMaster().getServerManager() .isServerOnline(task.cur_worker_name) : true;	if (alive && time < timeout) {	
skipping the resubmit of because the server is not marked as dead we waited for while the timeout is 

if (directive != FORCE) {	final long time = EnvironmentEdgeManager.currentTime() - task.last_update;	final boolean alive = details.getMaster().getServerManager() != null ? details.getMaster().getServerManager() .isServerOnline(task.cur_worker_name) : true;	if (alive && time < timeout) {	return false;	}	if (task.unforcedResubmits.get() >= resubmitThreshold) {	if (!task.resubmitThresholdReached) {	task.resubmitThresholdReached = true;	SplitLogCounters.tot_mgr_resubmit_threshold_reached.increment();	
skipping resubmissions of task because threshold reached 

task.resubmitThresholdReached = true;	SplitLogCounters.tot_mgr_resubmit_threshold_reached.increment();	}	return false;	}	version = task.last_version;	} else {	SplitLogCounters.tot_mgr_resubmit_force.increment();	version = -1;	}	
resubmitting task 

if (ignoreZKDeleteForTesting) {	return;	}	Task task;	task = details.getTasks().remove(path);	if (task == null) {	if (ZKSplitLog.isRescanNode(watcher, path)) {	SplitLogCounters.tot_mgr_rescan_deleted.increment();	}	SplitLogCounters.tot_mgr_missing_state_in_delete.increment();	
deleted task without in memory state 

private void deleteNodeFailure(String path) {	
failed to delete node and will retry soon 

private void createRescanFailure() {	
logic failure rescan failure must not happen 

private void createNodeSuccess(String path) {	
put up splitlog task at znode 

private void createNodeFailure(String path) {	
failed to create task node 

private void getDataSetWatchSuccess(String path, byte[] data, int version) throws DeserializationException {	if (data == null) {	if (version == Integer.MIN_VALUE) {	setDone(path, SUCCESS);	return;	}	SplitLogCounters.tot_mgr_null_data.increment();	
logic error got null data 

return;	}	data = ZKMetadata.removeMetaData(data);	SplitLogTask slt = SplitLogTask.parseFrom(data);	if (slt.isUnassigned()) {	LOG.debug("task not yet acquired " + path + " ver = " + version);	handleUnassignedTask(path);	} else if (slt.isOwned()) {	heartbeat(path, version, slt.getServerName());	} else if (slt.isResigned()) {	
task entered state 

data = ZKMetadata.removeMetaData(data);	SplitLogTask slt = SplitLogTask.parseFrom(data);	if (slt.isUnassigned()) {	LOG.debug("task not yet acquired " + path + " ver = " + version);	handleUnassignedTask(path);	} else if (slt.isOwned()) {	heartbeat(path, version, slt.getServerName());	} else if (slt.isResigned()) {	resubmitOrFail(path, FORCE);	} else if (slt.isDone()) {	
task entered state 

if (taskFinisher != null && !ZKSplitLog.isRescanNode(watcher, path)) {	if (taskFinisher.finish(slt.getServerName(), ZKSplitLog.getFileName(path)) == Status.DONE) {	setDone(path, SUCCESS);	} else {	resubmitOrFail(path, CHECK);	}	} else {	setDone(path, SUCCESS);	}	} else if (slt.isErr()) {	
task entered state 

private void getDataSetWatchFailure(String path) {	
failed to set data watch 

private void setDone(String path, TerminationStatus status) {	Task task = details.getTasks().get(path);	if (task == null) {	if (!ZKSplitLog.isRescanNode(watcher, path)) {	SplitLogCounters.tot_mgr_unacquired_orphan_done.increment();	
unacquired orphan task is done 

Task task = details.getTasks().get(path);	if (task == null) {	if (!ZKSplitLog.isRescanNode(watcher, path)) {	SplitLogCounters.tot_mgr_unacquired_orphan_done.increment();	}	} else {	synchronized (task) {	if (task.status == IN_PROGRESS) {	if (status == SUCCESS) {	SplitLogCounters.tot_mgr_log_split_success.increment();	
done splitting 

if (!ZKSplitLog.isRescanNode(watcher, path)) {	SplitLogCounters.tot_mgr_unacquired_orphan_done.increment();	}	} else {	synchronized (task) {	if (task.status == IN_PROGRESS) {	if (status == SUCCESS) {	SplitLogCounters.tot_mgr_log_split_success.increment();	} else {	SplitLogCounters.tot_mgr_log_split_err.increment();	
error splitting 

private Task findOrCreateOrphanTask(String path) {	return computeIfAbsent(details.getTasks(), path, Task::new, () -> {	
creating orphan task 

private void heartbeat(String path, int new_version, ServerName workerName) {	Task task = findOrCreateOrphanTask(path);	if (new_version != task.last_version) {	if (task.isUnassigned()) {	
task acquired by 

private void lookForOrphans() {	List<String> orphans;	try {	orphans = ZKUtil.listChildrenNoWatch(this.watcher, this.watcher.znodePaths.splitLogZNode);	if (orphans == null) {	
could not get children of 

private void lookForOrphans() {	List<String> orphans;	try {	orphans = ZKUtil.listChildrenNoWatch(this.watcher, this.watcher.znodePaths.splitLogZNode);	if (orphans == null) {	return;	}	} catch (KeeperException e) {	
could not get children of 

} catch (KeeperException e) {	return;	}	int rescan_nodes = 0;	int listSize = orphans.size();	for (int i = 0; i < listSize; i++) {	String path = orphans.get(i);	String nodepath = ZNodePaths.joinZNode(watcher.znodePaths.splitLogZNode, path);	if (ZKSplitLog.isRescanNode(watcher, nodepath)) {	rescan_nodes++;	
found orphan rescan node 

return;	}	int rescan_nodes = 0;	int listSize = orphans.size();	for (int i = 0; i < listSize; i++) {	String path = orphans.get(i);	String nodepath = ZNodePaths.joinZNode(watcher.znodePaths.splitLogZNode, path);	if (ZKSplitLog.isRescanNode(watcher, nodepath)) {	rescan_nodes++;	} else {	
found orphan task 

int listSize = orphans.size();	for (int i = 0; i < listSize; i++) {	String path = orphans.get(i);	String nodepath = ZNodePaths.joinZNode(watcher.znodePaths.splitLogZNode, path);	if (ZKSplitLog.isRescanNode(watcher, nodepath)) {	rescan_nodes++;	} else {	}	getDataSetWatch(nodepath, zkretries);	}	
found orphan tasks and rescan nodes 

private boolean resubmit(String path, int version) {	try {	SplitLogTask slt = new SplitLogTask.Unassigned(this.details.getServerName());	if (ZKUtil.setData(this.watcher, path, slt.toByteArray(), version) == false) {	
failed to resubmit task version changed 

private boolean resubmit(String path, int version) {	try {	SplitLogTask slt = new SplitLogTask.Unassigned(this.details.getServerName());	if (ZKUtil.setData(this.watcher, path, slt.toByteArray(), version) == false) {	return false;	}	} catch (NoNodeException e) {	
failed to resubmit because znode doesn t exist task done or forced done by removing the znode 

private boolean resubmit(String path, int version) {	try {	SplitLogTask slt = new SplitLogTask.Unassigned(this.details.getServerName());	if (ZKUtil.setData(this.watcher, path, slt.toByteArray(), version) == false) {	return false;	}	} catch (NoNodeException e) {	try {	getDataSetWatchSuccess(path, null, Integer.MIN_VALUE);	} catch (DeserializationException e1) {	
failed to re resubmit task because of deserialization issue 

return false;	}	} catch (NoNodeException e) {	try {	getDataSetWatchSuccess(path, null, Integer.MIN_VALUE);	} catch (DeserializationException e1) {	return false;	}	return false;	} catch (KeeperException.BadVersionException e) {	
failed to resubmit task version changed 

try {	getDataSetWatchSuccess(path, null, Integer.MIN_VALUE);	} catch (DeserializationException e1) {	return false;	}	return false;	} catch (KeeperException.BadVersionException e) {	return false;	} catch (KeeperException e) {	SplitLogCounters.tot_mgr_resubmit_failed.increment();	
failed to resubmit 

public void processResult(int rc, String path, Object ctx, String name) {	SplitLogCounters.tot_mgr_node_create_result.increment();	if (rc != 0) {	if (needAbandonRetries(rc, "Create znode " + path)) {	createNodeFailure(path);	return;	}	if (rc == KeeperException.Code.NODEEXISTS.intValue()) {	
found pre existing znode 

public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {	SplitLogCounters.tot_mgr_get_data_result.increment();	if (rc != 0) {	if (needAbandonRetries(rc, "GetData from znode " + path)) {	return;	}	if (rc == KeeperException.Code.NONODE.intValue()) {	SplitLogCounters.tot_mgr_get_data_nonode.increment();	
task znode vanished or not created yet 

getDataSetWatchFailure(path);	} else {	SplitLogCounters.tot_mgr_get_data_retry.increment();	getDataSetWatch(path, retry_count - 1);	}	return;	}	try {	getDataSetWatchSuccess(path, data, stat.getVersion());	} catch (DeserializationException e) {	
deserialization problem 

if (rc != 0) {	if (needAbandonRetries(rc, "Delete znode " + path)) {	details.getFailedDeletions().add(path);	return;	}	if (rc != KeeperException.Code.NONODE.intValue()) {	SplitLogCounters.tot_mgr_node_delete_err.increment();	Long retry_count = (Long) ctx;	LOG.warn("delete rc=" + KeeperException.Code.get(rc) + " for " + path + " remaining retries=" + retry_count);	if (retry_count == 0) {	
delete failed 

details.getFailedDeletions().add(path);	deleteNodeFailure(path);	} else {	deleteNode(path, retry_count - 1);	}	return;	} else {	LOG.info(path + " does not exist. Either was created but deleted behind our" + " back by another pending delete OR was deleted" + " in earlier retry rounds. zkretries = " + ctx);	}	} else {	
deleted 

========================= hbase sample_2188 =========================

EngineType engine = EngineType.valueOf(proto.getEngine());	comparator = new RegexStringComparator(proto.getPattern(), proto.getPatternFlags(), engine);	} else {	comparator = new RegexStringComparator(proto.getPattern(), proto.getPatternFlags());	}	String charset = proto.getCharset();	if (charset.length() > 0) {	try {	comparator.getEngine().setCharset(charset);	} catch (IllegalCharsetNameException e) {	
invalid charset 

========================= hbase sample_293 =========================

public StripeStoreConfig(Configuration config, StoreConfigInformation sci) {	this.level0CompactMinFiles = config.getInt(MIN_FILES_L0_KEY, 4);	this.flushIntoL0 = config.getBoolean(FLUSH_TO_L0_KEY, false);	int minMinFiles = flushIntoL0 ? 3 : 4;	int minFiles = config.getInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MIN_KEY, -1);	this.stripeCompactMinFiles = config.getInt(MIN_FILES_KEY, Math.max(minMinFiles, minFiles));	this.stripeCompactMaxFiles = config.getInt(MAX_FILES_KEY, config.getInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MAX_KEY, 10));	this.maxRegionSplitImbalance = getFloat(config, MAX_REGION_SPLIT_IMBALANCE_KEY, 1.5f, true);	float splitPartCount = getFloat(config, SPLIT_PARTS_KEY, 2f, true);	if (Math.abs(splitPartCount - 1.0) < EPSILON) {	
split part count cannot be using the default 

}	this.splitPartCount = splitPartCount;	double flushSize = sci.getMemStoreFlushSize();	if (flushSize == 0) {	flushSize = 128 * 1024 * 1024;	}	long defaultSplitSize = (long)(flushSize * getLevel0MinFiles() * 4 * splitPartCount);	this.sizeToSplitAt = config.getLong(SIZE_TO_SPLIT_KEY, defaultSplitSize);	int initialCount = config.getInt(INITIAL_STRIPE_COUNT_KEY, 1);	if (initialCount == 0) {	
initial stripe count is using the default 

private static float getFloat( Configuration config, String key, float defaultValue, boolean moreThanOne) {	float value = config.getFloat(key, defaultValue);	if (value < EPSILON) {	
s is set to or negative using default value of f 

========================= hbase sample_2537 =========================

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	enableTable_result result = new enableTable_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	disableTable_result result = new disableTable_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	isTableEnabled_result result = new isTableEnabled_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	compact_result result = new compact_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	majorCompact_result result = new majorCompact_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<ByteBuffer>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<ByteBuffer>>() {	public void onComplete(List<ByteBuffer> o) {	getTableNames_result result = new getTableNames_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Map<ByteBuffer,ColumnDescriptor>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Map<ByteBuffer,ColumnDescriptor>>() {	public void onComplete(Map<ByteBuffer,ColumnDescriptor> o) {	getColumnDescriptors_result result = new getColumnDescriptors_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRegionInfo>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRegionInfo>>() {	public void onComplete(List<TRegionInfo> o) {	getTableRegions_result result = new getTableRegions_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	createTable_result result = new createTable_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteTable_result result = new deleteTable_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TCell>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TCell>>() {	public void onComplete(List<TCell> o) {	get_result result = new get_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TCell>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TCell>>() {	public void onComplete(List<TCell> o) {	getVer_result result = new getVer_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TCell>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TCell>>() {	public void onComplete(List<TCell> o) {	getVerTs_result result = new getVerTs_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRow_result result = new getRow_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowWithColumns_result result = new getRowWithColumns_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowTs_result result = new getRowTs_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowWithColumnsTs_result result = new getRowWithColumnsTs_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRows_result result = new getRows_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowsWithColumns_result result = new getRowsWithColumns_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowsTs_result result = new getRowsTs_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	getRowsWithColumnsTs_result result = new getRowsWithColumnsTs_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	mutateRow_result result = new mutateRow_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	mutateRowTs_result result = new mutateRowTs_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	mutateRows_result result = new mutateRows_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	mutateRowsTs_result result = new mutateRowsTs_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Long>() {	public void onComplete(Long o) {	atomicIncrement_result result = new atomicIncrement_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteAll_result result = new deleteAll_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteAllTs_result result = new deleteAllTs_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteAllRow_result result = new deleteAllRow_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	increment_result result = new increment_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	incrementRows_result result = new incrementRows_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	deleteAllRowTs_result result = new deleteAllRowTs_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpenWithScan_result result = new scannerOpenWithScan_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpen_result result = new scannerOpen_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpenWithStop_result result = new scannerOpenWithStop_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpenWithPrefix_result result = new scannerOpenWithPrefix_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpenTs_result result = new scannerOpenTs_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Integer>() {	public void onComplete(Integer o) {	scannerOpenWithStopTs_result result = new scannerOpenWithStopTs_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	scannerGet_result result = new scannerGet_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TRowResult>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TRowResult>>() {	public void onComplete(List<TRowResult> o) {	scannerGetList_result result = new scannerGetList_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<Void> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Void>() {	public void onComplete(Void o) {	scannerClose_result result = new scannerClose_result();	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<TRegionInfo> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<TRegionInfo>() {	public void onComplete(TRegionInfo o) {	getRegionInfo_result result = new getRegionInfo_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

public AsyncMethodCallback<List<TCell>> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {	final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<List<TCell>>() {	public void onComplete(List<TCell> o) {	append_result result = new append_result();	result.success = o;	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

final org.apache.thrift.AsyncProcessFunction fcall = this;	return new AsyncMethodCallback<Boolean>() {	public void onComplete(Boolean o) {	checkAndPut_result result = new checkAndPut_result();	result.success = o;	result.setSuccessIsSet(true);	try {	fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);	return;	} catch (Exception e) {	
exception writing to internal frame buffer 

msg = result;	}	else {	msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;	msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());	}	try {	fcall.sendResponse(fb,msg,msgType,seqid);	return;	} catch (Exception ex) {	
exception writing to internal frame buffer 

========================= hbase sample_786 =========================

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	
performing action flush random region of table 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	
table doesn t have regions to flush 

public void perform() throws Exception {	HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	
flushing region 

HBaseTestingUtility util = context.getHBaseIntegrationTestingUtility();	Admin admin = util.getAdmin();	List<HRegionInfo> regions = admin.getTableRegions(tableName);	if (regions == null || regions.isEmpty()) {	return;	}	HRegionInfo region = PolicyBasedChaosMonkey.selectRandomItem( regions.toArray(new HRegionInfo[regions.size()]));	try {	admin.flushRegion(region.getRegionName());	} catch (Exception ex) {	
flush failed might be caused by other chaos 

========================= hbase sample_3326 =========================

public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {	if (table == null || table.isSystemTable()) {	
normalization of system table isn t allowed 

public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {	if (table == null || table.isSystemTable()) {	return null;	}	List<NormalizationPlan> plans = new ArrayList<>();	List<RegionInfo> tableRegions = masterServices.getAssignmentManager().getRegionStates(). getRegionsOfTable(table);	if (tableRegions == null || tableRegions.size() < MIN_REGION_COUNT) {	int nrRegions = tableRegions == null ? 0 : tableRegions.size();	
table has regions required min number of regions for normalizer to run is not running normalizer 

public List<NormalizationPlan> computePlanForTable(TableName table) throws HBaseIOException {	if (table == null || table.isSystemTable()) {	return null;	}	List<NormalizationPlan> plans = new ArrayList<>();	List<RegionInfo> tableRegions = masterServices.getAssignmentManager().getRegionStates(). getRegionsOfTable(table);	if (tableRegions == null || tableRegions.size() < MIN_REGION_COUNT) {	int nrRegions = tableRegions == null ? 0 : tableRegions.size();	return null;	}	
computing normalization plan for table number of regions 

int acutalRegionCnt = 0;	for (int i = 0; i < tableRegions.size(); i++) {	RegionInfo hri = tableRegions.get(i);	long regionSize = getRegionSize(hri);	if (regionSize > 0) {	acutalRegionCnt++;	totalSizeMb += regionSize;	}	}	double avgRegionSize = acutalRegionCnt == 0 ? 0 : totalSizeMb / (double) acutalRegionCnt;	
table total aggregated regions size 

int acutalRegionCnt = 0;	for (int i = 0; i < tableRegions.size(); i++) {	RegionInfo hri = tableRegions.get(i);	long regionSize = getRegionSize(hri);	if (regionSize > 0) {	acutalRegionCnt++;	totalSizeMb += regionSize;	}	}	double avgRegionSize = acutalRegionCnt == 0 ? 0 : totalSizeMb / (double) acutalRegionCnt;	
table average region size 

acutalRegionCnt++;	totalSizeMb += regionSize;	}	}	double avgRegionSize = acutalRegionCnt == 0 ? 0 : totalSizeMb / (double) acutalRegionCnt;	int candidateIdx = 0;	boolean splitEnabled = true, mergeEnabled = true;	try {	splitEnabled = masterRpcServices.isSplitOrMergeEnabled(null, RequestConverter.buildIsSplitOrMergeEnabledRequest(MasterSwitchType.SPLIT)).getEnabled();	} catch (org.apache.hbase.thirdparty.com.google.protobuf.ServiceException e) {	
unable to determine whether split is enabled 

double avgRegionSize = acutalRegionCnt == 0 ? 0 : totalSizeMb / (double) acutalRegionCnt;	int candidateIdx = 0;	boolean splitEnabled = true, mergeEnabled = true;	try {	splitEnabled = masterRpcServices.isSplitOrMergeEnabled(null, RequestConverter.buildIsSplitOrMergeEnabledRequest(MasterSwitchType.SPLIT)).getEnabled();	} catch (org.apache.hbase.thirdparty.com.google.protobuf.ServiceException e) {	}	try {	mergeEnabled = masterRpcServices.isSplitOrMergeEnabled(null, RequestConverter.buildIsSplitOrMergeEnabledRequest(MasterSwitchType.MERGE)).getEnabled();	} catch (org.apache.hbase.thirdparty.com.google.protobuf.ServiceException e) {	
unable to determine whether split is enabled 

}	try {	mergeEnabled = masterRpcServices.isSplitOrMergeEnabled(null, RequestConverter.buildIsSplitOrMergeEnabledRequest(MasterSwitchType.MERGE)).getEnabled();	} catch (org.apache.hbase.thirdparty.com.google.protobuf.ServiceException e) {	}	while (candidateIdx < tableRegions.size()) {	RegionInfo hri = tableRegions.get(candidateIdx);	long regionSize = getRegionSize(hri);	if (regionSize > 2 * avgRegionSize) {	if (splitEnabled) {	
table large region has size more than twice avg size splitting 

plans.add(new SplitNormalizationPlan(hri, null));	}	} else {	if (candidateIdx == tableRegions.size()-1) {	break;	}	if (mergeEnabled) {	RegionInfo hri2 = tableRegions.get(candidateIdx+1);	long regionSize2 = getRegionSize(hri2);	if (regionSize >= 0 && regionSize2 >= 0 && regionSize + regionSize2 < avgRegionSize) {	
table small region size plus its neighbor size less than the avg size merging them 

long regionSize2 = getRegionSize(hri2);	if (regionSize >= 0 && regionSize2 >= 0 && regionSize + regionSize2 < avgRegionSize) {	plans.add(new MergeNormalizationPlan(hri, hri2));	candidateIdx++;	}	}	}	candidateIdx++;	}	if (plans.isEmpty()) {	
no normalization needed regions look good for table 

private long getRegionSize(RegionInfo hri) {	ServerName sn = masterServices.getAssignmentManager().getRegionStates(). getRegionServerOfRegion(hri);	RegionLoad regionLoad = masterServices.getServerManager().getLoad(sn). getRegionsLoad().get(hri.getRegionName());	if (regionLoad == null) {	
was not found in regionsload 

========================= hbase sample_2864 =========================

public ByteBufferPool(int bufferSize, int maxPoolSize, boolean directByteBuffer) {	this.bufferSize = bufferSize;	this.maxPoolSize = maxPoolSize;	this.directByteBuffer = directByteBuffer;	
created bytebufferpool with buffersize and maxpoolsize 

ByteBuffer bb = buffers.poll();	if (bb != null) {	bb.clear();	return bb;	}	while (true) {	int c = this.count.intValue();	if (c >= this.maxPoolSize) {	if (maxPoolSizeInfoLevelLogged) {	if (LOG.isDebugEnabled()) {	
pool already reached its max capacity and no free buffers now consider increasing the value for 

bb.clear();	return bb;	}	while (true) {	int c = this.count.intValue();	if (c >= this.maxPoolSize) {	if (maxPoolSizeInfoLevelLogged) {	if (LOG.isDebugEnabled()) {	}	} else {	
pool already reached its max capacity and no free buffers now consider increasing the value for 

}	} else {	maxPoolSizeInfoLevelLogged = true;	}	return null;	}	if (!this.count.compareAndSet(c, c + 1)) {	continue;	}	if (LOG.isTraceEnabled()) {	
creating a new offheap bytebuffer of size 

public void putbackBuffer(ByteBuffer buf) {	if (buf.capacity() != this.bufferSize || (this.directByteBuffer ^ buf.isDirect())) {	
trying to put a buffer not created by this pool will be just ignored 

========================= hbase sample_1065 =========================

public static void doTestWithMapReduce(HBaseTestingUtility util, TableName tableName, String snapshotName, byte[] startRow, byte[] endRow, Path tableDir, int numRegions, int numSplitsPerRegion, int expectedNumSplits, boolean shutdownCluster) throws Exception {	
testing with mapreduce 

public static void doTestWithMapReduce(HBaseTestingUtility util, TableName tableName, String snapshotName, byte[] startRow, byte[] endRow, Path tableDir, int numRegions, int numSplitsPerRegion, int expectedNumSplits, boolean shutdownCluster) throws Exception {	
create the table and snapshot 

public static void doTestWithMapReduce(HBaseTestingUtility util, TableName tableName, String snapshotName, byte[] startRow, byte[] endRow, Path tableDir, int numRegions, int numSplitsPerRegion, int expectedNumSplits, boolean shutdownCluster) throws Exception {	createTableAndSnapshot(util, tableName, snapshotName, startRow, endRow, numRegions);	if (shutdownCluster) {	
shutting down hbase cluster 

========================= hbase sample_3408 =========================

try {	Scan scan = new Scan();	scan.setBatch(2);	SingleColumnValueFilter filter = new SingleColumnValueFilter( Bytes.toBytes(columnFamily), Bytes.toBytes("c5"), CompareOperator .EQUAL, new SubstringComparator("2_c5"));	scan.setFilter(filter);	Table table = openTable(tableName);	ResultScanner scanner = table.getScanner(scan);	for (Result result : scanner) {	for (Cell kv : result.listCells()) {	kv_number++;	
kv 

for (Result result : scanner) {	for (Cell kv : result.listCells()) {	kv_number++;	}	}	scanner.close();	table.close();	} catch (Exception e) {	assertNotNull("No IncompatibleFilterException catched", e);	}	
check the fetched kv number 

========================= hbase sample_1966 =========================

private StoreFileWriter(FileSystem fs, Path path, final Configuration conf, CacheConfig cacheConf, final CellComparator comparator, BloomType bloomType, long maxKeys, InetSocketAddress[] favoredNodes, HFileContext fileContext, boolean shouldDropCacheBehind) throws IOException {	this.timeRangeTracker = TimeRangeTracker.create(TimeRangeTracker.Type.NON_SYNC);	writer = HFile.getWriterFactory(conf, cacheConf) .withPath(fs, path) .withComparator(comparator) .withFavoredNodes(favoredNodes) .withFileContext(fileContext) .withShouldDropCacheBehind(shouldDropCacheBehind) .create();	generalBloomFilterWriter = BloomFilterFactory.createGeneralBloomAtWrite( conf, cacheConf, bloomType, (int) Math.min(maxKeys, Integer.MAX_VALUE), writer);	if (generalBloomFilterWriter != null) {	this.bloomType = bloomType;	if (LOG.isTraceEnabled()) {	
bloom filter type for 

} else {	this.bloomType = BloomType.NONE;	}	if (this.bloomType != BloomType.ROWCOL) {	this.deleteFamilyBloomFilterWriter = BloomFilterFactory .createDeleteBloomAtWrite(conf, cacheConf, (int) Math.min(maxKeys, Integer.MAX_VALUE), writer);	deleteFamilyBloomContext = new RowBloomContext(deleteFamilyBloomFilterWriter, comparator);	} else {	deleteFamilyBloomFilterWriter = null;	}	if (deleteFamilyBloomFilterWriter != null && LOG.isTraceEnabled()) {	
delete family bloom filter type for 

public void close() throws IOException {	boolean hasGeneralBloom = this.closeGeneralBloomFilter();	boolean hasDeleteFamilyBloom = this.closeDeleteFamilyBloomFilter();	writer.close();	if (LOG.isTraceEnabled()) {	
no general bloom and no DeleteFamily was added to hfile 

========================= hbase sample_2649 =========================

public void testBackupStatusProgress() throws Exception {	
test backup status progress on a single table with data 

public void testBackupStatusProgress() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	
backup complete 

public void testBackupStatusProgressCommand() throws Exception {	
test backup status progress on a single table with data command line 

public void testBackupStatusProgressCommand() throws Exception {	List<TableName> tableList = Lists.newArrayList(table1);	String backupId = fullTableBackup(tableList);	
backup complete 

========================= hbase sample_552 =========================

public static void cleanupTest() throws Exception {	try {	UTIL.shutdownMiniCluster();	} catch (Exception e) {	
failure shutting down cluster 

========================= hbase sample_1823 =========================

final List<Subprocedure> subprocs = new ArrayList<>();	for (int i = 0; i < procMembers.size(); i++) {	ForeignExceptionDispatcher cohortMonitor = new ForeignExceptionDispatcher();	Subprocedure commit = Mockito .spy(new SubprocedureImpl(procMembers.get(i).getFirst(), opName, cohortMonitor, WAKE_FREQUENCY, TIMEOUT));	subprocs.add(commit);	}	final AtomicInteger i = new AtomicInteger(0);	Mockito.when(subprocFactory.buildSubprocedure(Mockito.eq(opName), (byte[]) Mockito.argThat(new ArrayEquals(data)))).thenAnswer( new Answer<Subprocedure>() {	public Subprocedure answer(InvocationOnMock invocation) throws Throwable {	int index = i.getAndIncrement();	
task size getting 

final List<Subprocedure> cohortTasks = new ArrayList<>();	final int[] elem = new int[1];	for (int i = 0; i < members.size(); i++) {	ForeignExceptionDispatcher cohortMonitor = new ForeignExceptionDispatcher();	final ProcedureMember comms = members.get(i).getFirst();	Subprocedure commit = Mockito .spy(new SubprocedureImpl(comms, opName, cohortMonitor, WAKE_FREQUENCY, TIMEOUT));	Mockito.doAnswer(new Answer<Void>() {	public Void answer(InvocationOnMock invocation) throws Throwable {	int index = elem[0];	if (index == memberErrorIndex) {	
sending error to coordinator 

for (int i = 0; i < members.size(); i++) {	ForeignExceptionDispatcher cohortMonitor = new ForeignExceptionDispatcher();	final ProcedureMember comms = members.get(i).getFirst();	Subprocedure commit = Mockito .spy(new SubprocedureImpl(comms, opName, cohortMonitor, WAKE_FREQUENCY, TIMEOUT));	Mockito.doAnswer(new Answer<Void>() {	public Void answer(InvocationOnMock invocation) throws Throwable {	int index = elem[0];	if (index == memberErrorIndex) {	ForeignException remoteCause = new ForeignException("TIMER", new TimeoutException("subprocTimeout" , 1, 2, 0));	Subprocedure r = ((Subprocedure) invocation.getMock());	
remote commit failure not propagating error 

private void verifyCohortSuccessful(List<String> cohortNames, SubprocedureFactory subprocFactory, Iterable<Subprocedure> cohortTasks, VerificationMode prepare, VerificationMode commit, VerificationMode cleanup, VerificationMode finish, boolean opHasError) throws Exception {	Mockito.verify(subprocFactory, Mockito.times(cohortNames.size())).buildSubprocedure( Mockito.eq(opName), (byte[]) Mockito.argThat(new ArrayEquals(data)));	int j = 0;	for (Subprocedure op : cohortTasks) {	
checking mock 

========================= hbase sample_1570 =========================

public void testAbortFromRPC() throws Exception {	TableName tableName = TableName.valueOf("testAbortFromRPC");	Table table = testUtil.createTable(tableName, FAMILY_BYTES);	testUtil.loadTable(table, FAMILY_BYTES);	
wrote data 

public void testAbortFromRPC() throws Exception {	TableName tableName = TableName.valueOf("testAbortFromRPC");	Table table = testUtil.createTable(tableName, FAMILY_BYTES);	testUtil.loadTable(table, FAMILY_BYTES);	cluster.flushcache(tableName);	
flushed table 

========================= hbase sample_1659 =========================

public void init(Context context) throws IOException {	this.ctx = context;	if (this.ctx != null){	ReplicationPeer peer = this.ctx.getReplicationPeer();	if (peer != null){	peer.registerPeerConfigListener(this);	} else {	
not tracking replication peer config changes for peer id because there s no such peer 

}	if (ctx != null && ctx.getPeerConfig() != null) {	String filterNameCSV = ctx.getPeerConfig().getConfiguration().get(REPLICATION_WALENTRYFILTER_CONFIG_KEY);	if (filterNameCSV != null && !filterNameCSV.isEmpty()) {	String[] filterNames = filterNameCSV.split(",");	for (String filterName : filterNames) {	try {	Class<?> clazz = Class.forName(filterName);	filters.add((WALEntryFilter) clazz.newInstance());	} catch (Exception e) {	
unable to create walentryfilter 

========================= hbase sample_2976 =========================

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	CountDownLatch latch = cdl.get();	try {	if (sleepTime.get() > 0) {	
sleeping for ms 

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() == 0) {	CountDownLatch latch = cdl.get();	try {	if (sleepTime.get() > 0) {	Thread.sleep(sleepTime.get());	} else if (latch.getCount() > 0) {	
waiting for the countercountdownlatch 

} else if (latch.getCount() > 0) {	latch.await(2, TimeUnit.MINUTES);	if (latch.getCount() > 0) {	throw new RuntimeException("Can't wait more");	}	}	} catch (InterruptedException e1) {	LOG.error(e1.toString(), e1);	}	} else {	
we re not the primary replicas 

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() <= 1) {	
throw region server stopped exceptoin for replica id 

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() <= 1) {	throw new RegionServerStoppedException("Server " + e.getEnvironment().getServerName() + " not running");	} else {	
we re replica region 

public void preScannerOpen(final ObserverContext<RegionCoprocessorEnvironment> e, final Scan scan) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() <= 1) {	
throw region server stopped exceptoin for replica id 

public void preScannerOpen(final ObserverContext<RegionCoprocessorEnvironment> e, final Scan scan) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().getReplicaId() <= 1) {	throw new RegionServerStoppedException("Server " + e.getEnvironment().getServerName() + " not running");	} else {	
we re replica region 

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (throwException) {	if (!e.getEnvironment().getRegion().getRegionInfo().isMetaRegion() && (replicaId == 0)) {	
get throw region server stopped exceptoin for region 

public void preGetOp(final ObserverContext<RegionCoprocessorEnvironment> e, final Get get, final List<Cell> results) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (throwException) {	if (!e.getEnvironment().getRegion().getRegionInfo().isMetaRegion() && (replicaId == 0)) {	throw new RegionServerStoppedException("Server " + e.getEnvironment().getServerName() + " not running");	}	} else {	
get we re replica region 

public void preScannerOpen(final ObserverContext<RegionCoprocessorEnvironment> e, final Scan scan) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().isMetaRegion() && (replicaId == 0)) {	if (slowDownPrimaryMetaScan) {	
scan with primary meta region slow down a bit 

public void preScannerOpen(final ObserverContext<RegionCoprocessorEnvironment> e, final Scan scan) throws IOException {	int replicaId = e.getEnvironment().getRegion().getRegionInfo().getReplicaId();	if (e.getEnvironment().getRegion().getRegionInfo().isMetaRegion() && (replicaId == 0)) {	if (slowDownPrimaryMetaScan) {	try {	Thread.sleep(META_SCAN_TIMEOUT_IN_MILLISEC - 50);	} catch (InterruptedException ie) {	}	}	if (throwException) {	
scan throw region server stopped exceptoin for replica 

if (e.getEnvironment().getRegion().getRegionInfo().isMetaRegion() && (replicaId == 0)) {	if (slowDownPrimaryMetaScan) {	try {	Thread.sleep(META_SCAN_TIMEOUT_IN_MILLISEC - 50);	} catch (InterruptedException ie) {	}	}	if (throwException) {	throw new RegionServerStoppedException("Server " + e.getEnvironment().getServerName() + " not running");	} else {	
scan we re replica region 

try {	Thread.sleep(META_SCAN_TIMEOUT_IN_MILLISEC - 50);	} catch (InterruptedException ie) {	}	}	if (throwException) {	throw new RegionServerStoppedException("Server " + e.getEnvironment().getServerName() + " not running");	} else {	}	} else {	
scan we re replica region 

hdt.addFamily(fam);	hdt.addCoprocessor(SlowMeCopro.class.getName());	HTU.getAdmin().createTable(hdt, HBaseTestingUtility.KEYS_FOR_HBA_CREATE_TABLE);	Configuration conf2 = HBaseConfiguration.create(HTU.getConfiguration());	conf2.set(HConstants.HBASE_CLIENT_INSTANCE_ID, String.valueOf(-1));	conf2.set(HConstants.ZOOKEEPER_ZNODE_PARENT, "/2");	MiniZooKeeperCluster miniZK = HTU.getZkCluster();	HTU2 = new HBaseTestingUtility(conf2);	HTU2.setZkCluster(miniZK);	HTU2.startMiniCluster(NB_SERVERS);	
setup second zk 

ReplicationAdmin admin = new ReplicationAdmin(HTU.getConfiguration());	ReplicationPeerConfig rpc = new ReplicationPeerConfig();	rpc.setClusterKey(HTU2.getClusterKey());	admin.addPeer("2", rpc, null);	admin.close();	Put p = new Put(row);	p.addColumn(row, row, row);	final Table table = HTU.getConnection().getTable(hdt.getTableName());	table.put(p);	HTU.getAdmin().flush(table.getName());	
put flush done on the first cluster now doing a get on the same cluster 

public void testBulkLoad() throws IOException {	
creating test table 

public void testBulkLoad() throws IOException {	HTableDescriptor hdt = HTU.createTableDescriptor("testBulkLoad");	hdt.setRegionReplication(NB_SERVERS);	hdt.addCoprocessor(SlowMeCopro.class.getName());	Table table = HTU.createTable(hdt, new byte[][]{f}, null);	
creating test data 

Path dir = HTU.getDataTestDirOnTestFS("testBulkLoad");	final int numRows = 10;	final byte[] qual = Bytes.toBytes("qual");	final byte[] val  = Bytes.toBytes("val");	final List<Pair<byte[], String>> famPaths = new ArrayList<>();	for (HColumnDescriptor col : hdt.getColumnFamilies()) {	Path hfile = new Path(dir, col.getNameAsString());	TestHRegionServerBulkLoad.createHFile(HTU.getTestFileSystem(), hfile, col.getName(), qual, val, numRows);	famPaths.add(new Pair<>(col.getName(), hfile.toString()));	}	
loading test data 

for (HColumnDescriptor col : hdt.getColumnFamilies()) {	Path hfile = new Path(dir, col.getNameAsString());	TestHRegionServerBulkLoad.createHFile(HTU.getTestFileSystem(), hfile, col.getName(), qual, val, numRows);	famPaths.add(new Pair<>(col.getName(), hfile.toString()));	}	final ClusterConnection conn = (ClusterConnection) HTU.getAdmin().getConnection();	table = conn.getTable(hdt.getTableName());	final String bulkToken = new SecureBulkLoadClient(HTU.getConfiguration(), table).prepareBulkLoad(conn);	ClientServiceCallable<Void> callable = new ClientServiceCallable<Void>(conn, hdt.getTableName(), TestHRegionServerBulkLoad.rowkey(0), new RpcControllerFactory(HTU.getConfiguration()).newController(), HConstants.PRIORITY_UNSET) {	protected Void rpcCall() throws Exception {	
going to connect to server for row 

try (Table table = conn.getTable(getTableName())) {	secureClient = new SecureBulkLoadClient(HTU.getConfiguration(), table);	secureClient.secureBulkLoadHFiles(getStub(), famPaths, regionName, true, null, bulkToken);	}	return null;	}	};	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(HTU.getConfiguration());	RpcRetryingCaller<Void> caller = factory.newCaller();	caller.callWithRetries(callable, 10000);	
verifying data load 

};	RpcRetryingCallerFactory factory = new RpcRetryingCallerFactory(HTU.getConfiguration());	RpcRetryingCaller<Void> caller = factory.newCaller();	caller.callWithRetries(callable, 10000);	for (int i = 0; i < numRows; i++) {	byte[] row = TestHRegionServerBulkLoad.rowkey(i);	Get g = new Get(row);	Result r = table.get(g);	Assert.assertFalse(r.isStale());	}	
verifying replica queries 

RegionLocations url = ((ClusterConnection) HTU.getConnection()) .locateRegion(hdt.getTableName(), row, false, false);	if (!url.getDefaultRegionLocation().getServerName().equals( mrl.getDefaultRegionLocation().getServerName())) {	HTU.moveRegionAndWait(url.getDefaultRegionLocation().getRegionInfo(), mrl.getDefaultRegionLocation().getServerName());	}	if (url.getRegionLocation(1).getServerName().equals(mrl.getDefaultRegionLocation() .getServerName())) {	HTU.moveRegionAndWait(url.getRegionLocation(1).getRegionInfo(), url.getDefaultRegionLocation().getServerName());	}	while (true) {	mrl = ((ClusterConnection) HTU.getConnection()) .locateRegion(TableName.META_TABLE_NAME, HConstants.EMPTY_START_ROW, false, false);	url = ((ClusterConnection) HTU.getConnection()) .locateRegion(hdt.getTableName(), row, false, true);	
meta locations 

RegionLocations url = ((ClusterConnection) HTU.getConnection()) .locateRegion(hdt.getTableName(), row, false, false);	if (!url.getDefaultRegionLocation().getServerName().equals( mrl.getDefaultRegionLocation().getServerName())) {	HTU.moveRegionAndWait(url.getDefaultRegionLocation().getRegionInfo(), mrl.getDefaultRegionLocation().getServerName());	}	if (url.getRegionLocation(1).getServerName().equals(mrl.getDefaultRegionLocation() .getServerName())) {	HTU.moveRegionAndWait(url.getRegionLocation(1).getRegionInfo(), url.getDefaultRegionLocation().getServerName());	}	while (true) {	mrl = ((ClusterConnection) HTU.getConnection()) .locateRegion(TableName.META_TABLE_NAME, HConstants.EMPTY_START_ROW, false, false);	url = ((ClusterConnection) HTU.getConnection()) .locateRegion(hdt.getTableName(), row, false, true);	
table locations 

HTU.moveRegionAndWait(url.getRegionLocation(1).getRegionInfo(), url.getDefaultRegionLocation().getServerName());	}	while (true) {	mrl = ((ClusterConnection) HTU.getConnection()) .locateRegion(TableName.META_TABLE_NAME, HConstants.EMPTY_START_ROW, false, false);	url = ((ClusterConnection) HTU.getConnection()) .locateRegion(hdt.getTableName(), row, false, true);	ServerName a = url.getDefaultRegionLocation().getServerName();	ServerName b = mrl.getDefaultRegionLocation().getServerName();	if(a.equals(b)) {	break;	} else {	
waiting for new region info to be updated in meta table 

========================= hbase sample_2130 =========================

